{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory containing your CSV files\n",
    "csv_directory = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and append its data to the combined DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(csv_directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = combined_df.append(df, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the moves with the labels \"STOP\", so we don´t have the duplicates of the moves\n",
    "values_to_exclude = ['STOP']\n",
    "df = combined_df[~combined_df['Behavior type'].isin(values_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# exclude the music_start and music_stop tokens\n",
    "values_to_exclude = ['music_start', 'music_stop' ]\n",
    "df = df[~combined_df['Behavior'].isin(values_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation id</th>\n",
       "      <th>Observation date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Observation duration</th>\n",
       "      <th>Observation type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Media duration (s)</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Behavioral category</th>\n",
       "      <th>Behavior type</th>\n",
       "      <th>Time</th>\n",
       "      <th>Media file name</th>\n",
       "      <th>Image index</th>\n",
       "      <th>Image file path</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>2023-12-21 23:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.781</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>208.708</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L2F2</td>\n",
       "      <td>groove_walk</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>11.311</td>\n",
       "      <td>ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>2023-12-21 23:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.781</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>208.708</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L2F2</td>\n",
       "      <td>lindy_circle</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>17.117</td>\n",
       "      <td>ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>2023-12-21 23:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.781</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>208.708</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L2F2</td>\n",
       "      <td>swingout</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>20.888</td>\n",
       "      <td>ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>2023-12-21 23:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.781</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>208.708</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L2F2</td>\n",
       "      <td>swingout</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>24.191</td>\n",
       "      <td>ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>2023-12-21 23:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.781</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>208.708</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L2F2</td>\n",
       "      <td>break</td>\n",
       "      <td>improvisational_break</td>\n",
       "      <td>START</td>\n",
       "      <td>27.628</td>\n",
       "      <td>ratingcont_L2F2_free_video.MOV</td>\n",
       "      <td>828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>2023-12-23 17:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.581</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>203.703</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L3F3</td>\n",
       "      <td>break</td>\n",
       "      <td>improvisational_break</td>\n",
       "      <td>START</td>\n",
       "      <td>175.008</td>\n",
       "      <td>ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>5245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>2023-12-23 17:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.581</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>203.703</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L3F3</td>\n",
       "      <td>send_out</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>179.179</td>\n",
       "      <td>ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>5370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>2023-12-23 17:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.581</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>203.703</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L3F3</td>\n",
       "      <td>come_back</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>181.882</td>\n",
       "      <td>ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>5451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>2023-12-23 17:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.581</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>203.703</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L3F3</td>\n",
       "      <td>basic_closed</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>184.584</td>\n",
       "      <td>ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>5532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>2023-12-23 17:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.581</td>\n",
       "      <td>Media file(s)</td>\n",
       "      <td>player #1:ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>203.703</td>\n",
       "      <td>29.97</td>\n",
       "      <td>L3F3</td>\n",
       "      <td>promenade</td>\n",
       "      <td>move</td>\n",
       "      <td>START</td>\n",
       "      <td>187.254</td>\n",
       "      <td>ratingcont_L3F3_free_video.MOV</td>\n",
       "      <td>5612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Observation id     Observation date  Description  \\\n",
       "1     ratingcont_L2F2_free_video  2023-12-21 23:21:26          NaN   \n",
       "3     ratingcont_L2F2_free_video  2023-12-21 23:21:26          NaN   \n",
       "5     ratingcont_L2F2_free_video  2023-12-21 23:21:26          NaN   \n",
       "7     ratingcont_L2F2_free_video  2023-12-21 23:21:26          NaN   \n",
       "9     ratingcont_L2F2_free_video  2023-12-21 23:21:26          NaN   \n",
       "...                          ...                  ...          ...   \n",
       "4505  ratingcont_L3F3_free_video  2023-12-23 17:36:39          NaN   \n",
       "4507  ratingcont_L3F3_free_video  2023-12-23 17:36:39          NaN   \n",
       "4509  ratingcont_L3F3_free_video  2023-12-23 17:36:39          NaN   \n",
       "4511  ratingcont_L3F3_free_video  2023-12-23 17:36:39          NaN   \n",
       "4513  ratingcont_L3F3_free_video  2023-12-23 17:36:39          NaN   \n",
       "\n",
       "      Observation duration Observation type  \\\n",
       "1                  180.781    Media file(s)   \n",
       "3                  180.781    Media file(s)   \n",
       "5                  180.781    Media file(s)   \n",
       "7                  180.781    Media file(s)   \n",
       "9                  180.781    Media file(s)   \n",
       "...                    ...              ...   \n",
       "4505               180.581    Media file(s)   \n",
       "4507               180.581    Media file(s)   \n",
       "4509               180.581    Media file(s)   \n",
       "4511               180.581    Media file(s)   \n",
       "4513               180.581    Media file(s)   \n",
       "\n",
       "                                        Source  Media duration (s)    FPS  \\\n",
       "1     player #1:ratingcont_L2F2_free_video.MOV             208.708  29.97   \n",
       "3     player #1:ratingcont_L2F2_free_video.MOV             208.708  29.97   \n",
       "5     player #1:ratingcont_L2F2_free_video.MOV             208.708  29.97   \n",
       "7     player #1:ratingcont_L2F2_free_video.MOV             208.708  29.97   \n",
       "9     player #1:ratingcont_L2F2_free_video.MOV             208.708  29.97   \n",
       "...                                        ...                 ...    ...   \n",
       "4505  player #1:ratingcont_L3F3_free_video.MOV             203.703  29.97   \n",
       "4507  player #1:ratingcont_L3F3_free_video.MOV             203.703  29.97   \n",
       "4509  player #1:ratingcont_L3F3_free_video.MOV             203.703  29.97   \n",
       "4511  player #1:ratingcont_L3F3_free_video.MOV             203.703  29.97   \n",
       "4513  player #1:ratingcont_L3F3_free_video.MOV             203.703  29.97   \n",
       "\n",
       "     Subject      Behavior    Behavioral category Behavior type     Time  \\\n",
       "1       L2F2   groove_walk                   move         START   11.311   \n",
       "3       L2F2  lindy_circle                   move         START   17.117   \n",
       "5       L2F2      swingout                   move         START   20.888   \n",
       "7       L2F2      swingout                   move         START   24.191   \n",
       "9       L2F2         break  improvisational_break         START   27.628   \n",
       "...      ...           ...                    ...           ...      ...   \n",
       "4505    L3F3         break  improvisational_break         START  175.008   \n",
       "4507    L3F3      send_out                   move         START  179.179   \n",
       "4509    L3F3     come_back                   move         START  181.882   \n",
       "4511    L3F3  basic_closed                   move         START  184.584   \n",
       "4513    L3F3     promenade                   move         START  187.254   \n",
       "\n",
       "                     Media file name  Image index  Image file path Comment  \n",
       "1     ratingcont_L2F2_free_video.MOV          339              NaN     NaN  \n",
       "3     ratingcont_L2F2_free_video.MOV          513              NaN     NaN  \n",
       "5     ratingcont_L2F2_free_video.MOV          626              NaN     NaN  \n",
       "7     ratingcont_L2F2_free_video.MOV          725              NaN     NaN  \n",
       "9     ratingcont_L2F2_free_video.MOV          828              NaN     NaN  \n",
       "...                              ...          ...              ...     ...  \n",
       "4505  ratingcont_L3F3_free_video.MOV         5245              NaN     NaN  \n",
       "4507  ratingcont_L3F3_free_video.MOV         5370              NaN     NaN  \n",
       "4509  ratingcont_L3F3_free_video.MOV         5451              NaN     NaN  \n",
       "4511  ratingcont_L3F3_free_video.MOV         5532              NaN     NaN  \n",
       "4513  ratingcont_L3F3_free_video.MOV         5612              NaN     NaN  \n",
       "\n",
       "[2219 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_sequences_df = df.groupby('Observation id')['Behavior'].agg(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation id</th>\n",
       "      <th>Behavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratingcont_L10F10_closed_video</td>\n",
       "      <td>[groove_walk, swingout, swingout, swingout, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ratingcont_L10F10_free_video</td>\n",
       "      <td>[groove_walk, swingout, swingout, swingout, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratingcont_L10F10_open_video</td>\n",
       "      <td>[groove_walk, swingout, pass_by, pass_by, come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratingcont_L10F9_closed_video</td>\n",
       "      <td>[swingout, swingout, swingout, swingout, lindy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratingcont_L10F9_free_video</td>\n",
       "      <td>[swingout, swingout, swingout, lindy_circle, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ratingcont_L10F9_open_video</td>\n",
       "      <td>[swingout, swingout, swingout, pass_by, pass_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ratingcont_L11F11_closed_video</td>\n",
       "      <td>[come_back, basic_closed, send_out, pass_by, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ratingcont_L11F11_free_video</td>\n",
       "      <td>[groove_walk, basic_closed, basic_closed, send...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratingcont_L11F11_open_video</td>\n",
       "      <td>[come_back, basic_closed, send_out, pass_by, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ratingcont_L11F12_closed_video</td>\n",
       "      <td>[groove_walk, come_back, basic_closed, basic_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ratingcont_L11F12_free_video</td>\n",
       "      <td>[groove_walk, come_back, basic_closed, basic_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ratingcont_L12F12_closed_video</td>\n",
       "      <td>[groove_walk, basic_closed, tuck_turn, come_ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ratingcont_L12F12_free_video</td>\n",
       "      <td>[groove_walk, break, lindy_circle, swingout, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratingcont_L12F12_open_video</td>\n",
       "      <td>[groove_walk, swingout, lindy_circle, tuck_tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ratingcont_L1F1_closed_video</td>\n",
       "      <td>[come_back, basic_closed, tuck_turn, pass_by, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ratingcont_L1F1_free_video</td>\n",
       "      <td>[come_back, tuck_turn, pass_by, pass_by, come_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ratingcont_L1F1_open_video</td>\n",
       "      <td>[pass_by, pass_by, come_back, tuck_turn, pass_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ratingcont_L2F2_closed_video</td>\n",
       "      <td>[groove_walk, swingout, swingout, lindy_circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ratingcont_L2F2_free_video</td>\n",
       "      <td>[groove_walk, lindy_circle, swingout, swingout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ratingcont_L2F2_open_video</td>\n",
       "      <td>[groove_walk, break, lindy_circle, tuck_turn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ratingcont_L3F3_closed_video</td>\n",
       "      <td>[groove_walk, tuck_turn, pass_by, sweetheart, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ratingcont_L3F3_free_video</td>\n",
       "      <td>[groove_walk, send_out, pass_by, sugar_push, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ratingcont_L3F3_open_video</td>\n",
       "      <td>[groove_walk, come_back, basic_closed, tuck_tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ratingcont_L4F4_closed_video</td>\n",
       "      <td>[swingout, pass_by, pass_by, come_back, send_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ratingcont_L4F4_free_video</td>\n",
       "      <td>[groove_walk, swingout, swingout, corridor, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ratingcont_L4F4_open_video</td>\n",
       "      <td>[swingout, pass_by, come_back, tuck_turn, outs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ratingcont_L5F5_closed_video</td>\n",
       "      <td>[basic_closed, tuck_turn, pass_by, pass_by, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ratingcont_L5F5_free_video</td>\n",
       "      <td>[basic_closed, tuck_turn, pass_by, pass_by, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ratingcont_L5F5_open_video</td>\n",
       "      <td>[basic_closed, tuck_turn, pass_by, sweetheart,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ratingcont_L6F6_closed_video</td>\n",
       "      <td>[groove_walk, basic_closed, basic_closed, basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ratingcont_L6F6_free_video</td>\n",
       "      <td>[groove_walk, pass_by, lindy_circle, swingout,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ratingcont_L6F6_open_video</td>\n",
       "      <td>[groove_walk, pass_by, pass_by, pass_by, lindy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ratingcont_L7F7_closed_video</td>\n",
       "      <td>[groove_walk, basic_closed, tuck_turn, pass_by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ratingcont_L7F7_free_video</td>\n",
       "      <td>[groove_walk, basic_closed, tuck_turn, pass_by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ratingcont_L7F7_open_video</td>\n",
       "      <td>[groove_walk, tuck_turn, pass_by, pass_by, bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ratingcont_L8F8_closed_video</td>\n",
       "      <td>[groove_walk, basic_closed, basic_closed, basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ratingcont_L8F8_free_video</td>\n",
       "      <td>[groove_walk, pass_by, swingout, pass_by, swin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ratingcont_L8F8_open_video</td>\n",
       "      <td>[groove_walk, basic_closed, tuck_turn, pass_by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ratingcont_L9F9_closed_video</td>\n",
       "      <td>[groove_walk, pass_by, sweetheart, pass_by, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ratingcont_L9F9_free_video</td>\n",
       "      <td>[groove_walk, pass_by, pass_by, swingout, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ratingcont_L9F9_open_video</td>\n",
       "      <td>[groove_walk, sugar_push, pass_by, pass_by, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Observation id  \\\n",
       "0   ratingcont_L10F10_closed_video   \n",
       "1     ratingcont_L10F10_free_video   \n",
       "2     ratingcont_L10F10_open_video   \n",
       "3    ratingcont_L10F9_closed_video   \n",
       "4      ratingcont_L10F9_free_video   \n",
       "5      ratingcont_L10F9_open_video   \n",
       "6   ratingcont_L11F11_closed_video   \n",
       "7     ratingcont_L11F11_free_video   \n",
       "8     ratingcont_L11F11_open_video   \n",
       "9   ratingcont_L11F12_closed_video   \n",
       "10    ratingcont_L11F12_free_video   \n",
       "11  ratingcont_L12F12_closed_video   \n",
       "12    ratingcont_L12F12_free_video   \n",
       "13    ratingcont_L12F12_open_video   \n",
       "14    ratingcont_L1F1_closed_video   \n",
       "15      ratingcont_L1F1_free_video   \n",
       "16      ratingcont_L1F1_open_video   \n",
       "17    ratingcont_L2F2_closed_video   \n",
       "18      ratingcont_L2F2_free_video   \n",
       "19      ratingcont_L2F2_open_video   \n",
       "20    ratingcont_L3F3_closed_video   \n",
       "21      ratingcont_L3F3_free_video   \n",
       "22      ratingcont_L3F3_open_video   \n",
       "23    ratingcont_L4F4_closed_video   \n",
       "24      ratingcont_L4F4_free_video   \n",
       "25      ratingcont_L4F4_open_video   \n",
       "26    ratingcont_L5F5_closed_video   \n",
       "27      ratingcont_L5F5_free_video   \n",
       "28      ratingcont_L5F5_open_video   \n",
       "29    ratingcont_L6F6_closed_video   \n",
       "30      ratingcont_L6F6_free_video   \n",
       "31      ratingcont_L6F6_open_video   \n",
       "32    ratingcont_L7F7_closed_video   \n",
       "33      ratingcont_L7F7_free_video   \n",
       "34      ratingcont_L7F7_open_video   \n",
       "35    ratingcont_L8F8_closed_video   \n",
       "36      ratingcont_L8F8_free_video   \n",
       "37      ratingcont_L8F8_open_video   \n",
       "38    ratingcont_L9F9_closed_video   \n",
       "39      ratingcont_L9F9_free_video   \n",
       "40      ratingcont_L9F9_open_video   \n",
       "\n",
       "                                             Behavior  \n",
       "0   [groove_walk, swingout, swingout, swingout, li...  \n",
       "1   [groove_walk, swingout, swingout, swingout, li...  \n",
       "2   [groove_walk, swingout, pass_by, pass_by, come...  \n",
       "3   [swingout, swingout, swingout, swingout, lindy...  \n",
       "4   [swingout, swingout, swingout, lindy_circle, t...  \n",
       "5   [swingout, swingout, swingout, pass_by, pass_b...  \n",
       "6   [come_back, basic_closed, send_out, pass_by, o...  \n",
       "7   [groove_walk, basic_closed, basic_closed, send...  \n",
       "8   [come_back, basic_closed, send_out, pass_by, p...  \n",
       "9   [groove_walk, come_back, basic_closed, basic_c...  \n",
       "10  [groove_walk, come_back, basic_closed, basic_c...  \n",
       "11  [groove_walk, basic_closed, tuck_turn, come_ba...  \n",
       "12  [groove_walk, break, lindy_circle, swingout, p...  \n",
       "13  [groove_walk, swingout, lindy_circle, tuck_tur...  \n",
       "14  [come_back, basic_closed, tuck_turn, pass_by, ...  \n",
       "15  [come_back, tuck_turn, pass_by, pass_by, come_...  \n",
       "16  [pass_by, pass_by, come_back, tuck_turn, pass_...  \n",
       "17  [groove_walk, swingout, swingout, lindy_circle...  \n",
       "18  [groove_walk, lindy_circle, swingout, swingout...  \n",
       "19  [groove_walk, break, lindy_circle, tuck_turn, ...  \n",
       "20  [groove_walk, tuck_turn, pass_by, sweetheart, ...  \n",
       "21  [groove_walk, send_out, pass_by, sugar_push, s...  \n",
       "22  [groove_walk, come_back, basic_closed, tuck_tu...  \n",
       "23  [swingout, pass_by, pass_by, come_back, send_o...  \n",
       "24  [groove_walk, swingout, swingout, corridor, pa...  \n",
       "25  [swingout, pass_by, come_back, tuck_turn, outs...  \n",
       "26  [basic_closed, tuck_turn, pass_by, pass_by, sw...  \n",
       "27  [basic_closed, tuck_turn, pass_by, pass_by, sw...  \n",
       "28  [basic_closed, tuck_turn, pass_by, sweetheart,...  \n",
       "29  [groove_walk, basic_closed, basic_closed, basi...  \n",
       "30  [groove_walk, pass_by, lindy_circle, swingout,...  \n",
       "31  [groove_walk, pass_by, pass_by, pass_by, lindy...  \n",
       "32  [groove_walk, basic_closed, tuck_turn, pass_by...  \n",
       "33  [groove_walk, basic_closed, tuck_turn, pass_by...  \n",
       "34  [groove_walk, tuck_turn, pass_by, pass_by, bar...  \n",
       "35  [groove_walk, basic_closed, basic_closed, basi...  \n",
       "36  [groove_walk, pass_by, swingout, pass_by, swin...  \n",
       "37  [groove_walk, basic_closed, tuck_turn, pass_by...  \n",
       "38  [groove_walk, pass_by, sweetheart, pass_by, su...  \n",
       "39  [groove_walk, pass_by, pass_by, swingout, pass...  \n",
       "40  [groove_walk, sugar_push, pass_by, pass_by, pa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_sequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "moves_sequences_df.to_csv('LindyHop_moves_sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to strings\n",
    "##moves_sequences_df['Behavior'] = data['Behavior'].apply(lambda x: str(x))\n",
    "# Save to CSV\n",
    "##moves_sequences_df.to_csv('LindyHop_moves_sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to strings\n",
    "##moves_sequences_df['Behavior'] = data['Behavior'].apply(lambda x: str(x))\n",
    "\n",
    "# Save to CSV\n",
    "##moves_sequences_df.to_csv('filename.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['groove_walk', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'come_back', 'basic_closed', 'swingout', 'swingout', 'swingout', 'swingout', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'swingout', 'swingout', 'swingout', 'swingout', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'outside_spin', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'outside_spin', 'come_back', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'sugar_push', 'come_back', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'outside_spin', 'come_back', 'basic_closed', 'swingout', 'swingout', 'swingout'], ['groove_walk', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'pass_by', 'outside_spin', 'come_back', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'basic_open', 'swingout', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'outside_spin', 'corridor', 'swingout', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'come_back', 'basic_closed', 'send_out', 'swingout', 'swingout', 'swingout'], ['groove_walk', 'swingout', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'basic_closed', 'tuck_turn', 'pass_by', 'swingout', 'swingout', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'outside_spin', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'outside_spin', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by'], ['swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'come_back', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'outside_spin', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'pass_by', 'sugar_push', 'basic_open', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'outside_spin', 'sugar_push', 'sweetheart', 'pass_by', 'sugar_push', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'swingout', 'swingout', 'lindy_circle'], ['swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'inside_spin', 'lindy_circle', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'inside_spin', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'swingout', 'swingout', 'swingout', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'sweetheart', 'pass_by', 'outside_spin', 'lindy_circle', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'outside_spin', 'come_back', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'swingout', 'swingout'], ['swingout', 'swingout', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'swingout', 'pass_by', 'come_back'], ['come_back', 'basic_closed', 'send_out', 'pass_by', 'outside_spin', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'promenade', 'tuck_turn', 'pass_by', 'sweetheart', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'tuck_turn', 'sugar_push', 'sugar_push', 'sugar_push', 'tuck_turn', 'come_back', 'basic_closed', 'groove_walk', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'send_out', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'frankie´s_sixes', 'come_back', 'basic_closed', 'promenade', 'tuck_turn', 'pass_by', 'sweetheart', 'pass_by', 'come_back', 'basic_closed', 'tuck_turn', 'sweetheart', 'pass_by', 'sugar_push', 'sweetheart', 'come_back', 'basic_closed', 'basic_closed', 'basic_closed'], ['groove_walk', 'basic_closed', 'basic_closed', 'send_out', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'groove_walk', 'basic_closed', 'tuck_turn', 'pass_by', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'sugar_push', 'sugar_push', 'tuck_turn', 'pass_by', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'sweetheart', 'sweetheart', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'pass_by', 'swingout', 'come_back', 'send_out', 'sugar_push', 'sweetheart', 'come_back', 'basic_closed', 'promenade'], ['come_back', 'basic_closed', 'send_out', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'swingout', 'swingout', 'switches', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'pass_by', 'hand_to_hand', 'pass_by', 'come_back', 'send_out', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'basic_closed', 'swingout', 'come_back', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'tuck_turn', 'pass_by', 'break', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'break', 'pass_by', 'come_back', 'swingout', 'swingout', 'frankie´s_points', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'inside_spin', 'come_back', 'basic_closed', 'send_out', 'break', 'come_back', 'basic_closed', 'basic_closed', 'promenade', 'tuck_turn', 'pass_by'], ['groove_walk', 'come_back', 'basic_closed', 'basic_closed', 'send_out', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'frankie´s_sixes', 'pass_by', 'sweetheart', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'send_out', 'break', 'come_back', 'basic_closed', 'swingout', 'swingout', 'swingout', 'swingout', 'come_back', 'basic_closed', 'basic_closed', 'promenade', 'tuck_turn', 'pass_by', 'sugar_push', 'sugar_push', 'pass_by', 'come_back', 'break', 'basic_closed', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'sweetheart', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'send_out', 'swingout', 'swingout', 'come_back'], ['groove_walk', 'come_back', 'basic_closed', 'basic_closed', 'send_out', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'break', 'basic_closed', 'tuck_turn', 'pass_by', 'break', 'come_back', 'basic_closed', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'promenade', 'tuck_turn', 'pass_by', 'outside_spin', 'come_back', 'basic_closed', 'basic_closed', 'send_out', 'outside_spin', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'swingout', 'sugar_push', 'sugar_push', 'come_back', 'basic_closed', 'outside_spin', 'break', 'basic_closed', 'promenade', 'tuck_turn', 'outside_spin', 'pass_by', 'sweetheart', 'pass_by', 'break', 'pass_by', 'sugar_push', 'sugar_push', 'inside_turn', 'pass_by'], ['groove_walk', 'basic_closed', 'tuck_turn', 'come_back', 'swingout', 'lindy_circle', 'inside_turn', 'sugar_push', 'pass_by', 'lindy_circle', 'swingout', 'tuck_turn', 'sugar_push', 'pass_by', 'lindy_circle', 'pass_by', 'sugar_push', 'pass_by', 'outside_spin', 'sugar_push', 'pass_by', 'sweetheart', 'outside_turn', 'lindy_circle', 'groove_walk', 'lindy_circle', 'tuck_turn', 'sugar_push', 'pass_by', 'lindy_circle', 'tuck_turn', 'break', 'outside_turn', 'lindy_circle', 'tuck_turn', 'frankie´s_sixes', 'come_back', 'groove_walk', 'swingout', 'swingout', 'outside_turn', 'pass_by', 'sugar_push', 'tuck_turn', 'pass_by', 'come_back', 'basic_closed', 'break', 'sweetheart', 'pass_by', 'sugar_push', 'pass_by', 'sling_shot', 'lindy_circle', 'inside_turn', 'pass_by', 'come_back', 'basic_closed', 'break', 'sweetheart', 'inside_spin'], ['groove_walk', 'break', 'lindy_circle', 'swingout', 'pass_by', 'pass_by', 'lindy_circle', 'send_out', 'sugar_push', 'pass_by', 'barrel_turn', 'lindy_circle', 'tuck_turn', 'sugar_push', 'pass_by', 'basic_closed', 'basic_closed', 'basic_closed', 'swingout', 'lindy_circle', 'inside_turn', 'hand_to_hand', 'inside_turn', 'lindy_circle', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'lindy_circle', 'inside_spin', 'outside_turn', 'sweetheart', 'barrel_turn', 'lindy_circle', 'tuck_turn', 'outside_spin', 'break', 'pass_by', 'sugar_push', 'swingout', 'lindy_circle', 'inside_turn', 'frankie´s_sixes', 'sugar_push', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'sugar_push', 'come_back', 'basic_closed', 'break', 'barrel_turn', 'outside_turn', 'basic_closed', 'lindy_circle', 'inside_turn', 'sugar_push', 'swingout', 'lindy_circle', 'tuck_turn', 'basic_closed', 'swingout', 'hand_to_hand', 'inside_turn', 'come_back'], ['groove_walk', 'swingout', 'lindy_circle', 'tuck_turn', 'sugar_push', 'pass_by', 'swingout', 'outside_spin', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'swingout', 'switches', 'pass_by', 'pass_by', 'sugar_push', 'swingout', 'swingout', 'pass_by', 'come_back', 'basic_closed', 'tuck_turn', 'basic_closed', 'groove_walk', 'tuck_turn', 'lindy_circle', 'tuck_turn', 'frankie´s_sixes', 'basic_closed', 'tuck_turn', 'sugar_push', 'pass_by', 'break', 'swingout', 'outside_turn', 'sugar_push', 'pass_by', 'come_back', 'groove_walk', 'pass_by', 'lindy_circle', 'tuck_turn', 'switches', 'swingout', 'pass_by', 'frankie´s_sixes', 'basic_open', 'basic_open', 'lindy_circle', 'tuck_turn', 'sugar_push', 'pass_by', 'break', 'come_back'], ['come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'sugar_push', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'break', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'come_back', 'promenade', 'tuck_turn', 'pass_by', 'sweetheart', 'come_back', 'break', 'tuck_turn', 'pass_by', 'sweetheart', 'pass_by', 'outside_spin', 'come_back', 'groove_walk', 'inside_spin', 'come_back', 'send_out', 'pass_by', 'pass_by', 'come_back', 'swingout', 'swingout', 'swingout', 'come_back', 'groove_walk', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'frankie´s_sixes', 'come_back'], ['come_back', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'swingout', 'pass_by', 'outside_spin', 'come_back', 'groove_walk', 'corridor', 'inside_spin', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'promenade', 'tuck_turn', 'inside_turn', 'pass_by', 'come_back', 'swingout', 'swingout', 'lindy_circle', 'promenade', 'groove_walk', 'tuck_turn', 'pass_by', 'frankie´s_sixes', 'come_back', 'promenade', 'groove_walk', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'come_back', 'swingout', 'swingout', 'come_back', 'outside_turn', 'pass_by', 'come_back', 'groove_walk', 'break', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'break', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'come_back'], ['pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'swingout', 'swingout', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'groove_walk', 'sweetheart', 'pass_by', 'outside_spin', 'pass_by', 'come_back', 'swingout', 'pass_by', 'pass_by', 'break', 'pass_by', 'come_back', 'promenade', 'groove_walk', 'tuck_turn', 'pass_by', 'come_back', 'outside_turn', 'pass_by', 'come_back', 'basic_charleston', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'sugar_push', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes'], ['groove_walk', 'swingout', 'swingout', 'lindy_circle', 'break', 'swingout', 'break', 'lindy_circle', 'swingout', 'swingout', 'lindy_circle', 'break', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'come_back', 'tuck_turn', 'outside_spin', 'come_back', 'swingout', 'swingout', 'swingout', 'break', 'lindy_circle', 'break', 'send_out', 'break', 'swingout', 'swingout', 'lindy_circle', 'pop_turn', 'frankie´s_sixes', 'pass_by', 'break', 'lindy_circle', 'swingout', 'lindy_circle', 'tuck_turn', 'break', 'come_back', 'swingout', 'swingout', 'swingout', 'swingout'], ['groove_walk', 'lindy_circle', 'swingout', 'swingout', 'break', 'lindy_circle', 'tuck_turn', 'outside_spin', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'mini_dip', 'pass_by', 'outside_spin', 'pass_by', 'barrel_turn', 'break', 'lindy_circle', 'groove_walk', 'tuck_turn', 'frankie´s_sixes', 'lindy_circle', 'swingout', 'swingout', 'swingout', 'switches', 'lindy_circle', 'promenade', 'promenade', 'tuck_turn', 'outside_spin', 'break', 'pass_by', 'pass_by', 'break', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'break', 'come_back', 'send_out', 'pass_by', 'come_back', 'send_out', 'break', 'lindy_circle', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'break', 'lindy_circle', 'tuck_turn', 'break'], ['groove_walk', 'break', 'lindy_circle', 'tuck_turn', 'outside_spin', 'break', 'pass_by', 'pass_by', 'pass_by', 'hand_to_hand', 'pass_by', 'pass_by', 'lindy_circle', 'break', 'tuck_turn', 'swingout', 'switches', 'lindy_circle', 'swingout', 'send_out', 'break', 'pass_by', 'pass_by', 'break', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'break', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'barrel_turn', 'swingout', 'swingout', 'lindy_circle', 'break', 'send_out', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'hand_to_hand', 'pass_by', 'pass_by', 'swingout', 'switches', 'lindy_circle', 'swingout', 'swingout', 'lindy_circle'], ['groove_walk', 'tuck_turn', 'pass_by', 'sweetheart', 'pass_by', 'outside_spin', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'outside_spin', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'groove_walk', 'basic_closed', 'promenade', 'promenade', 'send_out', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'swingout', 'break', 'pass_by', 'sweetheart', 'pass_by', 'break', 'pass_by', 'sweetheart', 'pass_by', 'break', 'outside_turn', 'pass_by', 'swingout', 'lindy_circle', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'break', 'send_out', 'pass_by', 'pass_by', 'outside_turn', 'outside_spin', 'outside_spin', 'barrel_turn', 'break', 'pass_by', 'groove_walk', 'come_back', 'send_out', 'break', 'pass_by', 'tuck_turn', 'pass_by', 'outside_spin'], ['groove_walk', 'send_out', 'pass_by', 'sugar_push', 'sugar_push', 'sugar_push', 'pass_by', 'pass_by', 'break', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'outside_spin', 'frankie´s_sixes', 'pass_by', 'break', 'pass_by', 'pass_by', 'inside_turn', 'pass_by', 'pass_by', 'pass_by', 'sling_shot', 'pass_by', 'lindy_circle', 'groove_walk', 'swingout', 'swingout', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'barrel_turn', 'break', 'pass_by', 'pass_by', 'pass_by', 'barrel_turn', 'break', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'break', 'send_out', 'come_back', 'basic_closed', 'promenade'], ['groove_walk', 'come_back', 'basic_closed', 'tuck_turn', 'come_back', 'basic_closed', 'send_out', 'pass_by', 'break', 'pass_by', 'come_back', 'tuck_turn', 'break', 'pass_by', 'break', 'pass_by', 'swingout', 'swingout', 'break', 'come_back', 'swingout', 'come_back', 'tuck_turn', 'sweetheart', 'pass_by', 'come_back', 'break', 'pass_by', 'break', 'pass_by', 'swingout'], ['swingout', 'pass_by', 'pass_by', 'come_back', 'send_out', 'break', 'pass_by', 'sweetheart', 'frankie´s_sixes', 'swingout', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'lindy_circle', 'basic_closed', 'corridor', 'basic_closed', 'send_out', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'come_back', 'swingout', 'break', 'come_back', 'swingout', 'pass_by', 'pass_by', 'sweetheart', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'come_back', 'send_out', 'pass_by', 'come_back', 'break', 'basic_closed', 'corridor', 'swingout'], ['groove_walk', 'swingout', 'swingout', 'corridor', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'break', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'come_back', 'swingout', 'swingout', 'pass_by', 'pass_by', 'basic_open', 'pass_by', 'break', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'lindy_circle', 'swingout', 'pass_by', 'break', 'pass_by', 'pass_by', 'come_back', 'send_out', 'break', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'swingout', 'send_out', 'pass_by', 'pass_by', 'outside_spin', 'pass_by', 'pass_by', 'come_back', 'swingout', 'pass_by', 'come_back', 'swingout', 'break', 'pass_by', 'come_back', 'send_out', 'pass_by', 'pass_by'], ['swingout', 'pass_by', 'come_back', 'tuck_turn', 'outside_spin', 'pass_by', 'basic_open', 'pass_by', 'break', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'come_back', 'send_out', 'break', 'pass_by', 'outside_spin', 'pass_by', 'come_back', 'swingout', 'pass_by', 'sugar_push', 'sugar_push', 'pass_by', 'come_back', 'break', 'send_out', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'send_out', 'pass_by', 'lindy_circle', 'tuck_turn', 'break', 'pass_by', 'sweetheart', 'pass_by', 'come_back', 'swingout', 'pass_by', 'break', 'pass_by', 'break', 'pass_by', 'come_back', 'corridor', 'swingout', 'break', 'pass_by', 'pass_by', 'break', 'switches', 'pass_by', 'come_back', 'corridor'], ['basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'outside_spin', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'sailor_kicks', 'pass_by', 'frankie´s_sixes', 'pass_by', 'pass_by', 'frankie´s_sixes', 'break', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'swingout'], ['basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'break', 'outside_spin', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'outside_spin', 'pass_by', 'swingout', 'pass_by', 'lindy_circle', 'tuck_turn', 'break', 'inside_turn', 'come_back', 'tuck_turn', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'outside_spin', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'sailor_kicks', 'pass_by', 'sweetheart'], ['basic_closed', 'tuck_turn', 'pass_by', 'sweetheart', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'sailor_kicks', 'pass_by', 'frankie´s_sixes', 'barrel_turn', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'lindy_circle', 'tuck_turn', 'outside_spin', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'break', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'sweetheart', 'pass_by'], ['groove_walk', 'basic_closed', 'basic_closed', 'basic_closed', 'send_out', 'break', 'pass_by', 'sugar_push', 'pass_by', 'lindy_circle', 'send_out', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'break', 'barrel_turn', 'sweetheart', 'outside_spin', 'pass_by', 'break', 'swingout', 'break', 'pass_by', 'lindy_circle', 'send_out', 'pass_by', 'outside_spin', 'pass_by', 'sugar_push', 'pass_by', 'lindy_circle', 'tuck_turn', 'outside_spin', 'pass_by', 'break', 'pass_by', 'barrel_turn', 'break', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'switches', 'pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'swingout', 'pass_by', 'break', 'pass_by', 'outside_spin', 'pass_by', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'lindy_circle', 'tuck_turn'], ['groove_walk', 'pass_by', 'lindy_circle', 'swingout', 'sugar_push', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'barrel_turn', 'pass_by', 'break', 'lindy_circle', 'basic_closed', 'tuck_turn', 'pass_by', 'break', 'lindy_circle', 'promenade', 'swingout', 'swingout', 'swingout', 'break', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'barrel_turn', 'break', 'pass_by', 'sugar_push', 'pass_by', 'lindy_circle', 'basic_closed', 'lindy_circle', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'sugar_push', 'sailor_kicks', 'pass_by', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'pass_by', 'outside_spin', 'pass_by', 'lindy_circle', 'tuck_turn', 'break', 'lindy_circle', 'swingout', 'swingout', 'break', 'lindy_circle'], ['groove_walk', 'pass_by', 'pass_by', 'pass_by', 'lindy_circle', 'swingout', 'lindy_circle', 'send_out', 'sugar_push', 'pass_by', 'swingout', 'come_back', 'tuck_turn', 'pass_by'], ['groove_walk', 'basic_closed', 'tuck_turn', 'pass_by', 'mini_dip', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'swingout', 'lindy_circle', 'break', 'tuck_turn', 'pass_by', 'pass_by', 'outside_turn', 'pass_by', 'swingout', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'barrel_turn', 'outside_turn', 'sugar_push', 'sugar_push', 'sweetheart', 'pass_by', 'swingout', 'inside_turn', 'swingout', 'outside_spin', 'outside_turn', 'pass_by', 'pass_by', 'break', 'come_back', 'groove_walk', 'basic_closed', 'pass_by', 'sweetheart', 'break', 'barrel_turn', 'sweetheart', 'barrel_turn', 'sweetheart', 'inside_turn', 'basic_closed', 'swingout', 'swingout', 'basic_closed', 'pop_turn'], ['groove_walk', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'sweetheart', 'break', 'pass_by', 'pass_by', 'come_back', 'groove_walk', 'tuck_turn', 'pass_by', 'come_back', 'break', 'basic_closed', 'send_out', 'outside_spin', 'pass_by', 'break', 'pass_by', 'swingout', 'swingout', 'outside_turn', 'pass_by', 'barrel_turn', 'break', 'pass_by', 'sweetheart', 'barrel_turn', 'come_back', 'basic_closed', 'break', 'tuck_turn', 'pass_by', 'break', 'pass_by', 'break', 'promenade', 'tuck_turn', 'pass_by', 'barrel_turn', 'pass_by', 'sweetheart', 'pass_by', 'pass_by', 'barrel_turn', 'break', 'tuck_turn', 'pass_by', 'sugar_push', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break'], ['groove_walk', 'tuck_turn', 'pass_by', 'pass_by', 'barrel_turn', 'pass_by', 'pass_by', 'tuck_turn', 'pass_by', 'pass_by', 'sweetheart', 'lindy_circle', 'break', 'send_out', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'sweetheart', 'groove_walk', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'break', 'pass_by', 'swingout', 'break', 'pass_by', 'pass_by', 'break', 'inside_turn', 'swingout', 'pass_by', 'break', 'inside_turn', 'tuck_turn', 'outside_turn', 'pass_by', 'break', 'outside_spin', 'pass_by', 'hallelujah_rocks', 'break', 'outside_turn', 'pass_by', 'pass_by', 'pass_by', 'sweetheart', 'pass_by', 'pass_by', 'outside_turn', 'pass_by', 'break', 'swingout', 'swingout', 'pass_by', 'pass_by', 'pass_by'], ['groove_walk', 'basic_closed', 'basic_closed', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'inside_turn', 'inside_turn', 'inside_turn', 'barrel_turn', 'outside_spin', 'sweetheart', 'pass_by', 'pass_by', 'swingout', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'sailor_kicks', 'barrel_turn', 'sweetheart', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'swingout', 'swingout', 'inside_turn', 'inside_turn', 'pass_by', 'pass_by'], ['groove_walk', 'pass_by', 'swingout', 'pass_by', 'swingout', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'basic_closed', 'corridor', 'tuck_turn', 'outside_spin', 'pass_by', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'basic_open', 'pass_by', 'pass_by', 'swingout', 'swingout', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'come_back', 'basic_closed', 'promenade', 'send_out', 'swingout', 'pass_by', 'come_back', 'promenade', 'basic_closed', 'basic_closed', 'tuck_turn', 'outside_spin', 'pass_by', 'pass_by', 'pass_by', 'basic_open', 'pass_by'], ['groove_walk', 'basic_closed', 'tuck_turn', 'pass_by', 'break', 'pass_by', 'pass_by', 'break', 'pass_by', 'pass_by', 'pass_by', 'break', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'basic_open', 'break', 'pass_by', 'pass_by', 'pass_by', 'switches', 'pass_by', 'pass_by', 'pass_by', 'basic_open', 'break', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'break', 'basic_closed', 'tuck_turn', 'pass_by', 'break', 'pass_by', 'come_back', 'basic_closed', 'tuck_turn', 'break', 'pass_by', 'pass_by', 'basic_open', 'swingout', 'come_back', 'tuck_turn', 'pass_by', 'break', 'pass_by', 'pass_by', 'break'], ['groove_walk', 'pass_by', 'sweetheart', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'frankie´s_sixes', 'pass_by', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'frankie´s_sixes', 'pass_by', 'pass_by', 'hand_to_hand', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'swingout', 'swingout', 'pass_by', 'swingout', 'outside_turn', 'pass_by', 'swingout', 'inside_turn', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'sugar_push', 'pass_by', 'pass_by', 'sugar_push', 'outside_spin', 'pass_by', 'sugar_push', 'swingout', 'swingout', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'sugar_push', 'swingout', 'corridor', 'pass_by', 'frankie´s_sixes'], ['groove_walk', 'pass_by', 'pass_by', 'swingout', 'pass_by', 'swingout', 'pass_by', 'hand_to_hand', 'pass_by', 'sugar_push', 'pass_by', 'outside_spin', 'pass_by', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'inside_spin', 'pass_by', 'pass_by', 'swingout', 'swingout', 'outside_turn', 'pass_by', 'sugar_push', 'sling_shot', 'sling_shot', 'pass_by', 'sugar_push', 'pass_by', 'sugar_push', 'swingout', 'pass_by', 'frankie´s_sixes', 'corridor', 'pass_by', 'frankie´s_sixes', 'pass_by', 'pass_by', 'pass_by', 'frankie´s_sixes', 'come_back', 'basic_closed', 'tuck_turn', 'basic_closed', 'swingout', 'basic_closed', 'tuck_turn'], ['groove_walk', 'sugar_push', 'pass_by', 'pass_by', 'pass_by', 'sugar_push', 'frankie´s_sixes', 'pass_by', 'pass_by', 'outside_spin', 'pass_by', 'frankie´s_sixes', 'pass_by', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'swingout', 'pass_by', 'pass_by', 'outside_spin', 'pass_by', 'outside_spin', 'frankie´s_sixes', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'pass_by', 'sugar_push', 'pass_by', 'pass_by', 'swingout', 'swingout', 'pass_by', 'sugar_push', 'pass_by', 'pass_by']]\n"
     ]
    }
   ],
   "source": [
    "# Extract the lists from the specified column\n",
    "lists_extracted = moves_sequences_df['Behavior'].tolist()\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(lists_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lists_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length: 14\n",
      "Maximum length: 66\n",
      "Total: 2219\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each sequence and get min and max and total of items\n",
    "lengths = [len(sublist) for sublist in lists_extracted]\n",
    "# Find the minimum and maximum lengths\n",
    "min_length = min(lengths) if lengths else None\n",
    "max_length = max(lengths) if lengths else None\n",
    "total = sum(lengths)\n",
    "\n",
    "print(\"Minimum length:\", min_length)\n",
    "print(\"Maximum length:\", max_length)\n",
    "print(\"Total:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to create a list of strings\n",
    "## list_of_strings = [', '.join(sublist) for sublist in lists_extracted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sequences' is a list containing the dance move sequences\n",
    "# Flatten the list of sequences\n",
    "## flat_sequences = [move for sequence in lists_extracted for move in sequence]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-One LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input-output pairs \n",
    "\n",
    "The function to split the sequence data into input and target arrays is created. It maintains the sequence structure in the following way:\n",
    "-  it loops through each sequence (equivalent to one dance) and creates input-output pairs only from the current sequence or dance (\"for sequence in encoded_sequences\")\n",
    "\n",
    "The resulting function makes sure that *music_stop* token is never taken as an input to predict the next move, while it is still used as a target to be predicted based on the move just before it. The *music_start* token is never used as a target to be predicted base on the previous move, while it is still used as an input to predict the next move. This way, each dance sequence is treated separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input-ouput sequences for many-to-many (mtm) modeling\n",
    "def create_input_output_pairs_mtm(data, time_steps):\n",
    "    x, y = [], []\n",
    "\n",
    "    for sequence in data:\n",
    "        for i in range(len(sequence) - time_steps):\n",
    "            x.append(sequence[i:(i + time_steps)])  # Input sequence of 4 moves\n",
    "            y.append(sequence[(i + 1):(i + 1 + time_steps)])  # Output sequence of 4 moves\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(H, epochs):\n",
    "    \"\"\"\n",
    "    Utility function for plotting model history using matplotlib\n",
    "    \n",
    "    H: model history \n",
    "    epochs: number of epochs for which the model was trained\n",
    "    \"\"\"\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many LSTM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the moves to integers\n",
    "\n",
    "The sequences of dance moves are encoded while maintaining the sequence structure so each dance is encoded separately and outputed as separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'frankie´s_sixes',\n",
       "  'hallelujah_rocks',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'frankie´s_points',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'inside_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sling_shot',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'inside_spin'],\n",
       " ['groove_walk',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'come_back'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'switches',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'corridor',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back'],\n",
       " ['pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_charleston',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'corridor',\n",
       "  'hand_to_hand_charleston',\n",
       "  'frankie´s_sixes'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'pop_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'mini_dip',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle'],\n",
       " ['groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'outside_spin',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'groove_walk',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin'],\n",
       " ['groove_walk',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sling_shot',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout'],\n",
       " ['swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'corridor'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'sweetheart'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'barrel_turn',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'mini_dip',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'outside_spin',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'inside_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'pop_turn'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'tuck_turn',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'hallelujah_rocks',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'barrel_turn',\n",
       "  'outside_spin',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sling_shot',\n",
       "  'sling_shot',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'tuck_turn'],\n",
       " ['groove_walk',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 9, 28, 28, 28, 15,  2, 31, 19,  5,  2, 28, 28, 28, 28, 19, 19, 26,\n",
       "        19,  5, 28, 28, 28, 28,  5, 31, 19, 19, 17, 19,  5, 31, 19, 19, 26,\n",
       "        19, 17,  5, 28, 15, 31, 19, 28, 28, 28, 28, 15,  2, 31, 19, 19, 26,\n",
       "         5, 31, 19, 26, 19, 17,  5,  2, 28, 28, 28]),\n",
       " array([ 9, 28, 28, 28, 15,  2, 31, 19, 15, 24, 19, 17,  5, 28, 28, 28, 28,\n",
       "        15,  2, 31, 19, 19, 19, 19, 19,  3, 28, 28, 28, 28, 28, 15,  2, 31,\n",
       "        19, 19, 19, 17,  6, 28, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 19,\n",
       "        28, 28, 28,  5,  2, 24, 28, 28, 28]),\n",
       " array([ 9, 28, 19, 19,  5, 31,  2, 31, 19, 28, 28,  5, 31, 19, 19, 28, 28,\n",
       "        28, 15, 31, 19, 17, 19, 19, 19, 27, 19, 26, 19,  5, 31, 19, 19, 28,\n",
       "        28, 28, 15,  2, 31, 19, 17,  5,  2,  2, 31, 19, 26, 19]),\n",
       " array([28, 28, 28, 28, 15, 31, 19,  5, 28, 28, 28, 15, 31, 19, 17,  5,  2,\n",
       "        31, 19, 26, 27, 19, 19, 26,  3, 28, 28, 28, 28, 15, 31, 19, 17, 26,\n",
       "        27, 19, 26, 19, 19,  5, 31, 19, 28, 28, 15, 31, 19, 19, 26, 27, 19,\n",
       "        28, 28, 15]),\n",
       " array([28, 28, 28, 15, 31, 19, 19, 13, 15, 28, 28, 28, 15, 31, 19, 13, 15,\n",
       "        31, 19, 19, 19, 15, 28, 28, 28,  5,  2, 31, 19, 26, 19, 27, 19, 17,\n",
       "        15, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 26, 19, 17,  5, 28, 28,\n",
       "        15,  2, 28, 28]),\n",
       " array([28, 28, 28, 19, 19, 19,  5, 31, 19, 19, 26, 27, 19, 19, 19, 15,  2,\n",
       "        31, 19, 28, 19,  5]),\n",
       " array([ 5,  2, 24, 19, 17,  5,  2, 31, 17, 19,  5,  2, 21, 31, 19, 27, 19,\n",
       "        28, 28, 15, 31, 31, 26, 26, 26, 31,  5,  2,  9,  2, 31, 19, 19,  5,\n",
       "        24, 19, 19, 19, 27,  8,  5,  2, 21, 31, 19, 27, 19,  5,  2, 31, 27,\n",
       "        19, 26, 27,  5,  2,  2,  2]),\n",
       " array([ 9,  2,  2, 24, 19, 19,  5,  2,  9,  2, 31, 19, 17, 19,  5,  2, 28,\n",
       "        28, 15, 31, 19, 19, 19,  8, 19, 26, 26, 31, 19,  5,  2, 31, 17, 19,\n",
       "         5,  2,  2, 31, 27, 27, 19, 19,  5,  2,  2, 31, 19, 19, 19,  5,  2,\n",
       "        24, 19, 28,  5, 24, 26, 27,  5,  2, 21]),\n",
       " array([ 5,  2, 24, 19, 19,  5,  2, 28, 28, 29,  5,  2, 31, 19,  5,  2, 24,\n",
       "        19, 11, 19,  5, 24,  8, 10,  5,  2, 28,  5,  2, 24, 26, 26, 31, 19,\n",
       "         4,  5,  2, 31, 19, 19, 19,  4, 19,  5, 28, 28,  7,  5,  2, 31, 17,\n",
       "        19, 13,  5,  2, 24,  4,  5,  2,  2, 21, 31, 19]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19, 19,  5,  2,  2, 31, 17, 19, 17, 19,  5,\n",
       "         2,  2, 31, 19,  8, 19, 27, 19,  5,  2,  2, 24,  4,  5,  2, 28, 28,\n",
       "        28, 28,  5,  2,  2, 21, 31, 19, 26, 26, 19,  5,  4,  2,  2, 24, 26,\n",
       "        26, 27, 19,  5,  2,  2, 24, 28, 28,  5]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19,  5,  2,  4,  2, 31, 19,  4,  5,  2, 28,\n",
       "        28, 28, 15,  2,  2, 31, 17, 19,  5,  2,  2, 21, 31, 19, 17,  5,  2,\n",
       "         2, 24, 17, 19, 19,  5,  2, 24, 28, 26, 26,  5,  2, 17,  4,  2, 21,\n",
       "        31, 17, 19, 27, 19,  4, 19, 26, 26, 14, 19]),\n",
       " array([ 9,  2, 31,  5, 28, 15, 14, 26, 19, 15, 28, 31, 26, 19, 15, 19, 26,\n",
       "        19, 17, 26, 19, 27, 18, 15,  9, 15, 31, 26, 19, 15, 31,  4, 18, 15,\n",
       "        31,  8,  5,  9, 28, 28, 18, 19, 26, 31, 19,  5,  2,  4, 27, 19, 26,\n",
       "        19, 25, 15, 14, 19,  5,  2,  4, 27, 13]),\n",
       " array([ 9,  4, 15, 28, 19, 19, 15, 24, 26, 19,  0, 15, 31, 26, 19,  2,  2,\n",
       "         2, 28, 15, 14, 11, 14, 15, 31, 19, 26, 19, 15, 13, 18, 27,  0, 15,\n",
       "        31, 17,  4, 19, 26, 28, 15, 14,  8, 26, 19, 15, 31, 19, 26,  5,  2,\n",
       "         4,  0, 18,  2, 15, 14, 26, 28, 15, 31,  2, 28, 11, 14,  5]),\n",
       " array([ 9, 28, 15, 31, 26, 19, 28, 17, 19, 26, 19,  5, 28, 29, 19, 19, 26,\n",
       "        28, 28, 19,  5,  2, 31,  2,  9, 31, 15, 31,  8,  2, 31, 26, 19,  4,\n",
       "        28, 18, 26, 19,  5,  9, 19, 15, 31, 29, 28, 19,  8,  3,  3, 15, 31,\n",
       "        26, 19,  4,  5]),\n",
       " array([ 5,  2, 31, 19, 19,  5, 31, 19, 26,  5,  2, 31, 19, 19,  5,  4, 31,\n",
       "        19, 26, 19,  5, 31, 19,  5, 21, 31, 19, 27,  5,  4, 31, 19, 27, 19,\n",
       "        17,  5,  9, 13,  5, 24, 19, 19,  5, 28, 28, 28,  5,  9, 31, 19, 26,\n",
       "        19,  5, 31, 19,  8,  5]),\n",
       " array([ 5, 31, 19, 19,  5, 28, 19, 17,  5,  9,  6, 13,  5, 31, 19, 19,  5,\n",
       "        21, 31, 14, 19,  5, 28, 28, 15, 21,  9, 31, 19,  8,  5, 21,  9, 31,\n",
       "        19, 26, 19,  5, 28, 28,  5, 18, 19,  5,  9,  4, 31, 19, 26, 19,  4,\n",
       "         5, 31, 19, 19,  5]),\n",
       " array([19, 19,  5, 31, 19, 19,  5, 31, 19, 19, 19,  5, 28, 28,  5, 31, 19,\n",
       "        19,  9, 27, 19, 17, 19,  5, 28, 19, 19,  4, 19,  5, 21,  9, 31, 19,\n",
       "         5, 18, 19,  5,  1, 31, 19, 26, 19, 19,  5, 31, 19, 26, 19, 28, 28,\n",
       "        15,  6, 12,  8]),\n",
       " array([ 9, 28, 28, 15,  4, 28,  4, 15, 28, 28, 15,  4, 31, 19, 19, 19, 15,\n",
       "        31, 19, 19, 19,  5, 31,  5, 31, 17,  5, 28, 28, 28,  4, 15,  4, 24,\n",
       "         4, 28, 28, 15, 20,  8, 19,  4, 15, 28, 15, 31,  4,  5, 28, 28, 28,\n",
       "        28]),\n",
       " array([ 9, 15, 28, 28,  4, 15, 31, 17, 19, 19, 28, 19, 16, 19, 17, 19,  0,\n",
       "         4, 15,  9, 31,  8, 15, 28, 28, 28, 29, 15, 21, 21, 31, 17,  4, 19,\n",
       "        19,  4, 19, 19, 15, 31,  4,  5, 24, 19,  5, 24,  4, 15, 31, 19, 15,\n",
       "        24,  4, 15, 31,  4]),\n",
       " array([ 9,  4, 15, 31, 17,  4, 19, 19, 19, 11, 19, 19, 15,  4, 31, 28, 29,\n",
       "        15, 28, 24,  4, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19,  4, 19, 19,\n",
       "        15, 31, 19,  0, 28, 28, 15,  4, 24, 19, 19, 15, 31, 19, 11, 19, 19,\n",
       "        28, 29, 15, 28, 28, 15]),\n",
       " array([ 9, 31, 19, 27, 19, 17, 19, 19, 19, 19, 17, 19, 19, 19,  5,  9,  2,\n",
       "        21, 21, 24, 19, 19, 19, 28, 28,  4, 19, 27, 19,  4, 19, 27, 19,  4,\n",
       "        18, 19, 28, 15, 28, 19, 19, 19,  5,  4, 24, 19, 19, 18, 17, 17,  0,\n",
       "         4, 19,  9,  5, 24,  4, 19, 31, 19, 17]),\n",
       " array([ 9, 24, 19, 26, 26, 26, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        27, 17,  8, 19,  4, 19, 19, 14, 19, 19, 19, 25, 19, 15,  9, 28, 28,\n",
       "        28, 28, 15, 31,  0,  4, 19, 19, 19,  0,  4, 19, 19, 19,  5,  4, 24,\n",
       "         5,  2, 21]),\n",
       " array([ 9,  5,  2, 31,  5,  2, 24, 19,  4, 19,  5, 31,  4, 19,  4, 19, 28,\n",
       "        28,  4,  5, 28,  5, 31, 27, 19,  5,  4, 19,  4, 19, 28]),\n",
       " array([28, 19, 19,  5, 24,  4, 19, 27,  8, 28,  2, 31, 17, 19, 15,  2,  6,\n",
       "         2, 24, 19, 19, 27, 19, 28, 19, 19,  5, 28,  4,  5, 28, 19, 19, 27,\n",
       "         5, 31, 19, 19, 19, 19, 15,  2, 31, 19,  5, 24, 19,  5,  4,  2,  6,\n",
       "        28]),\n",
       " array([ 9, 28, 28,  6, 19, 19, 19, 19,  5,  4, 19, 19, 19, 27,  5, 28, 28,\n",
       "        19, 19,  3, 19,  4, 19, 19,  5,  2, 15, 28, 19,  4, 19, 19,  5, 24,\n",
       "         4, 19, 19, 27, 19,  5,  2,  2, 28, 24, 19, 19, 17, 19, 19,  5, 28,\n",
       "        19,  5, 28,  4, 19,  5, 24, 19, 19]),\n",
       " array([28, 19,  5, 31, 17, 19,  3, 19,  4, 19, 19, 19, 15, 31, 19,  5, 24,\n",
       "         4, 19, 17, 19,  5, 28, 19, 26, 26, 19,  5,  4, 24, 19, 19, 19,  5,\n",
       "        24, 19, 15, 31,  4, 19, 27, 19,  5, 28, 19,  4, 19,  4, 19,  5,  6,\n",
       "        28,  4, 19, 19,  4, 29, 19,  5,  6]),\n",
       " array([ 2, 31, 19, 19, 27, 19, 17, 19, 28, 19, 19, 19, 26, 19, 19, 28, 19,\n",
       "        19,  8, 19, 28, 19, 19, 27, 19, 19, 19, 19, 15, 31, 19, 19, 23, 19,\n",
       "         8, 19, 19,  8,  4, 19, 28, 19, 19,  8, 19, 28, 19, 19, 19, 19, 28]),\n",
       " array([ 2, 31, 19, 19, 28, 19,  4, 17, 19,  5,  2,  2,  2, 31, 19, 19,  8,\n",
       "        19, 28, 19, 15, 31, 19,  5, 31, 19, 19, 19, 19,  8, 19, 17, 19, 28,\n",
       "        19, 15, 31,  4, 14,  5, 31, 19,  8, 19, 28, 19, 17, 19, 28, 19, 19,\n",
       "        28, 19, 19, 19, 23, 19, 27]),\n",
       " array([ 2, 31, 19, 27, 19, 19, 19, 28, 19, 23, 19,  8,  0, 28, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19,  8, 19, 28, 19, 15, 31, 17, 19, 19, 28, 19,\n",
       "        19, 19, 19, 28, 19, 19,  4, 19, 28, 19, 19, 19, 27, 19, 28, 19, 19,\n",
       "        27, 19]),\n",
       " array([ 9,  2,  2,  2, 24,  4, 19, 26, 19, 15, 24, 19, 19, 28, 28, 28,  4,\n",
       "         0, 27, 17, 19,  4, 28,  4, 19, 15, 24, 19, 17, 19, 26, 19, 15, 31,\n",
       "        17, 19,  4, 19,  0,  4, 19, 15, 31, 19, 29, 19, 15, 31, 19, 28, 19,\n",
       "         4, 19, 17, 19, 15,  2, 31, 19, 19, 15, 31]),\n",
       " array([ 9, 19, 15, 28, 26, 19, 28, 19, 19,  0, 19,  4, 15,  2, 31, 19,  4,\n",
       "        15, 21, 28, 28, 28,  4,  5,  2, 31, 17,  0,  4, 19, 26, 19, 15,  2,\n",
       "        15, 31, 19, 15, 24, 26, 23, 19, 28, 15, 31, 19, 15, 24, 19, 17, 19,\n",
       "        15, 31,  4, 15, 28, 28,  4, 15]),\n",
       " array([ 9, 19, 19, 19, 15, 28, 15, 24, 26, 19, 28,  5, 31, 19]),\n",
       " array([ 9,  2, 31, 19, 16,  5,  2, 31, 17, 19, 28, 15,  4, 31, 19, 19, 18,\n",
       "        19, 28, 19, 28, 19, 19,  0, 18, 26, 26, 27, 19, 28, 14, 28, 17, 18,\n",
       "        19, 19,  4,  5,  9,  2, 19, 27,  4,  0, 27,  0, 27, 14,  2, 28, 28,\n",
       "         2, 20]),\n",
       " array([ 9,  2, 31, 19, 19, 27,  4, 19, 19,  5,  9, 31, 19,  5,  4,  2, 24,\n",
       "        17, 19,  4, 19, 28, 28, 18, 19,  0,  4, 19, 27,  0,  5,  2,  4, 31,\n",
       "        19,  4, 19,  4, 21, 31, 19,  0, 19, 27, 19, 19,  0,  4, 31, 19, 26,\n",
       "        26, 22, 30, 30,  4]),\n",
       " array([ 9, 31, 19, 19,  0, 19, 19, 31, 19, 19, 27, 15,  4, 24, 19, 19, 28,\n",
       "        19, 27,  9, 19, 19, 19, 28,  4, 19, 28,  4, 19, 19,  4, 14, 28, 19,\n",
       "         4, 14, 31, 18, 19,  4, 17, 19, 10,  4, 18, 19, 19, 19, 27, 19, 19,\n",
       "        18, 19,  4, 28, 28, 19, 19, 19]),\n",
       " array([ 9,  2,  2,  2,  2, 31, 19, 19, 14, 14, 14,  0, 17, 27, 19, 19, 28,\n",
       "         5,  2,  2, 31, 19, 19, 19, 28, 28, 28, 19, 19, 19, 19,  5,  2, 24,\n",
       "        23,  0, 27, 19, 19,  5,  2,  2,  2, 31, 19, 19,  5,  2,  2, 31, 28,\n",
       "        28, 14, 14, 19, 19]),\n",
       " array([ 9, 19, 28, 19, 28,  5,  2,  2, 31, 19, 19,  5,  2,  2, 31, 19,  5,\n",
       "         2,  2,  2,  6, 31, 17, 19, 19,  5, 31, 19, 19,  5,  2,  2, 31, 19,\n",
       "        19,  3, 19, 19, 28, 28, 28, 19, 19, 19, 28,  5,  2, 21, 24, 28, 19,\n",
       "         5, 21,  2,  2, 31, 17, 19, 19, 19,  3, 19]),\n",
       " array([ 9,  2, 31, 19,  4, 19, 19,  4, 19, 19, 19,  4, 19,  5,  2,  2, 31,\n",
       "        19, 19,  3,  4, 19, 19, 19, 29, 19, 19, 19,  3,  4, 19,  5,  2,  2,\n",
       "         4,  2, 31, 19,  4, 19,  5,  2, 31,  4, 19, 19,  3, 28,  5, 31, 19,\n",
       "         4, 19, 19,  4]),\n",
       " array([ 9, 19, 27, 19, 26, 27, 19,  8, 19, 19, 19, 28, 19,  8, 19, 19, 11,\n",
       "        19,  5, 31, 19, 28, 28, 19, 28, 18, 19, 28, 14, 19, 19,  8, 19, 26,\n",
       "        19, 19, 26, 17, 19, 26, 28, 28, 19, 19, 19, 19, 19, 26, 28,  6, 19,\n",
       "         8]),\n",
       " array([ 9, 19, 19, 28, 19, 28, 19, 11, 19, 26, 19, 17, 19, 19, 26, 27, 19,\n",
       "        13, 19, 19, 28, 28, 18, 19, 26, 25, 25, 19, 26, 19, 26, 28, 19,  8,\n",
       "         6, 19,  8, 19, 19, 19,  8,  5,  2, 31,  2, 28,  2, 31]),\n",
       " array([ 9, 26, 19, 19, 19, 26,  8, 19, 19, 17, 19,  8, 19, 19,  8, 19, 28,\n",
       "        19, 19, 26, 19, 28, 19, 19, 17, 19, 17,  8, 19, 19, 19, 19, 19, 26,\n",
       "        19, 19, 28, 28, 19, 26, 19, 19])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten all sequences into a single list to find unique moves\n",
    "all_moves = [move for sequence in lists_extracted for move in sequence]\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_moves)\n",
    "\n",
    "# Number of unique classes (moves)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Function to convert moves to integers\n",
    "def encode_sequence(sequence):\n",
    "    # Encode the sequence\n",
    "    return label_encoder.transform(sequence)\n",
    "\n",
    "# Apply encoding to each sequence\n",
    "encoded_sequences = [encode_sequence(sequence) for sequence in lists_extracted]\n",
    "encoded_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded number 0 corresponds to class label 'barrel_turn'\n",
      "Encoded number 1 corresponds to class label 'basic_charleston'\n",
      "Encoded number 2 corresponds to class label 'basic_closed'\n",
      "Encoded number 3 corresponds to class label 'basic_open'\n",
      "Encoded number 4 corresponds to class label 'break'\n",
      "Encoded number 5 corresponds to class label 'come_back'\n",
      "Encoded number 6 corresponds to class label 'corridor'\n",
      "Encoded number 7 corresponds to class label 'frankie´s_points'\n",
      "Encoded number 8 corresponds to class label 'frankie´s_sixes'\n",
      "Encoded number 9 corresponds to class label 'groove_walk'\n",
      "Encoded number 10 corresponds to class label 'hallelujah_rocks'\n",
      "Encoded number 11 corresponds to class label 'hand_to_hand'\n",
      "Encoded number 12 corresponds to class label 'hand_to_hand_charleston'\n",
      "Encoded number 13 corresponds to class label 'inside_spin'\n",
      "Encoded number 14 corresponds to class label 'inside_turn'\n",
      "Encoded number 15 corresponds to class label 'lindy_circle'\n",
      "Encoded number 16 corresponds to class label 'mini_dip'\n",
      "Encoded number 17 corresponds to class label 'outside_spin'\n",
      "Encoded number 18 corresponds to class label 'outside_turn'\n",
      "Encoded number 19 corresponds to class label 'pass_by'\n",
      "Encoded number 20 corresponds to class label 'pop_turn'\n",
      "Encoded number 21 corresponds to class label 'promenade'\n",
      "Encoded number 22 corresponds to class label 's_turn'\n",
      "Encoded number 23 corresponds to class label 'sailor_kicks'\n",
      "Encoded number 24 corresponds to class label 'send_out'\n",
      "Encoded number 25 corresponds to class label 'sling_shot'\n",
      "Encoded number 26 corresponds to class label 'sugar_push'\n",
      "Encoded number 27 corresponds to class label 'sweetheart'\n",
      "Encoded number 28 corresponds to class label 'swingout'\n",
      "Encoded number 29 corresponds to class label 'switches'\n",
      "Encoded number 30 corresponds to class label 'tandem'\n",
      "Encoded number 31 corresponds to class label 'tuck_turn'\n"
     ]
    }
   ],
   "source": [
    "# Extract class labels\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# Display the mapping between encoded numbers and original class labels\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Encoded number {i} corresponds to class label '{label}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the iput-output data \n",
    "\n",
    "\n",
    "The function below splits the sequence data into input and target arrays of 4 moves. It maintains the sequence structure in the following way:\n",
    "-  it loops through each sequence (equivalent to one dance) and creates input-output combinations of 4 moves only from the current sequence or dance (\"for sequence in data\")\n",
    "\n",
    "The resulting function makes sure that the last move of each sequence is never taken as an input to predict the next move, while it is still used as a target to be predicted based on the move just before it. The first move is never used as a target to be predicted base on the previous move, while it is still used as an input to predict the next move. This way, each dance sequence is treated separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 9, 28, 28, 28, 15,  2, 31, 19,  5,  2, 28, 28, 28, 28, 19, 19, 26,\n",
       "        19,  5, 28, 28, 28, 28,  5, 31, 19, 19, 17, 19,  5, 31, 19, 19, 26,\n",
       "        19, 17,  5, 28, 15, 31, 19, 28, 28, 28, 28, 15,  2, 31, 19, 19, 26,\n",
       "         5, 31, 19, 26, 19, 17,  5,  2, 28, 28, 28]),\n",
       " array([ 9, 28, 28, 28, 15,  2, 31, 19, 15, 24, 19, 17,  5, 28, 28, 28, 28,\n",
       "        15,  2, 31, 19, 19, 19, 19, 19,  3, 28, 28, 28, 28, 28, 15,  2, 31,\n",
       "        19, 19, 19, 17,  6, 28, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 19,\n",
       "        28, 28, 28,  5,  2, 24, 28, 28, 28]),\n",
       " array([ 9, 28, 19, 19,  5, 31,  2, 31, 19, 28, 28,  5, 31, 19, 19, 28, 28,\n",
       "        28, 15, 31, 19, 17, 19, 19, 19, 27, 19, 26, 19,  5, 31, 19, 19, 28,\n",
       "        28, 28, 15,  2, 31, 19, 17,  5,  2,  2, 31, 19, 26, 19]),\n",
       " array([28, 28, 28, 28, 15, 31, 19,  5, 28, 28, 28, 15, 31, 19, 17,  5,  2,\n",
       "        31, 19, 26, 27, 19, 19, 26,  3, 28, 28, 28, 28, 15, 31, 19, 17, 26,\n",
       "        27, 19, 26, 19, 19,  5, 31, 19, 28, 28, 15, 31, 19, 19, 26, 27, 19,\n",
       "        28, 28, 15]),\n",
       " array([28, 28, 28, 15, 31, 19, 19, 13, 15, 28, 28, 28, 15, 31, 19, 13, 15,\n",
       "        31, 19, 19, 19, 15, 28, 28, 28,  5,  2, 31, 19, 26, 19, 27, 19, 17,\n",
       "        15, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 26, 19, 17,  5, 28, 28,\n",
       "        15,  2, 28, 28]),\n",
       " array([28, 28, 28, 19, 19, 19,  5, 31, 19, 19, 26, 27, 19, 19, 19, 15,  2,\n",
       "        31, 19, 28, 19,  5]),\n",
       " array([ 5,  2, 24, 19, 17,  5,  2, 31, 17, 19,  5,  2, 21, 31, 19, 27, 19,\n",
       "        28, 28, 15, 31, 31, 26, 26, 26, 31,  5,  2,  9,  2, 31, 19, 19,  5,\n",
       "        24, 19, 19, 19, 27,  8,  5,  2, 21, 31, 19, 27, 19,  5,  2, 31, 27,\n",
       "        19, 26, 27,  5,  2,  2,  2]),\n",
       " array([ 9,  2,  2, 24, 19, 19,  5,  2,  9,  2, 31, 19, 17, 19,  5,  2, 28,\n",
       "        28, 15, 31, 19, 19, 19,  8, 19, 26, 26, 31, 19,  5,  2, 31, 17, 19,\n",
       "         5,  2,  2, 31, 27, 27, 19, 19,  5,  2,  2, 31, 19, 19, 19,  5,  2,\n",
       "        24, 19, 28,  5, 24, 26, 27,  5,  2, 21]),\n",
       " array([ 5,  2, 24, 19, 19,  5,  2, 28, 28, 29,  5,  2, 31, 19,  5,  2, 24,\n",
       "        19, 11, 19,  5, 24,  8, 10,  5,  2, 28,  5,  2, 24, 26, 26, 31, 19,\n",
       "         4,  5,  2, 31, 19, 19, 19,  4, 19,  5, 28, 28,  7,  5,  2, 31, 17,\n",
       "        19, 13,  5,  2, 24,  4,  5,  2,  2, 21, 31, 19]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19, 19,  5,  2,  2, 31, 17, 19, 17, 19,  5,\n",
       "         2,  2, 31, 19,  8, 19, 27, 19,  5,  2,  2, 24,  4,  5,  2, 28, 28,\n",
       "        28, 28,  5,  2,  2, 21, 31, 19, 26, 26, 19,  5,  4,  2,  2, 24, 26,\n",
       "        26, 27, 19,  5,  2,  2, 24, 28, 28,  5]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19,  5,  2,  4,  2, 31, 19,  4,  5,  2, 28,\n",
       "        28, 28, 15,  2,  2, 31, 17, 19,  5,  2,  2, 21, 31, 19, 17,  5,  2,\n",
       "         2, 24, 17, 19, 19,  5,  2, 24, 28, 26, 26,  5,  2, 17,  4,  2, 21,\n",
       "        31, 17, 19, 27, 19,  4, 19, 26, 26, 14, 19]),\n",
       " array([ 9,  2, 31,  5, 28, 15, 14, 26, 19, 15, 28, 31, 26, 19, 15, 19, 26,\n",
       "        19, 17, 26, 19, 27, 18, 15,  9, 15, 31, 26, 19, 15, 31,  4, 18, 15,\n",
       "        31,  8,  5,  9, 28, 28, 18, 19, 26, 31, 19,  5,  2,  4, 27, 19, 26,\n",
       "        19, 25, 15, 14, 19,  5,  2,  4, 27, 13]),\n",
       " array([ 9,  4, 15, 28, 19, 19, 15, 24, 26, 19,  0, 15, 31, 26, 19,  2,  2,\n",
       "         2, 28, 15, 14, 11, 14, 15, 31, 19, 26, 19, 15, 13, 18, 27,  0, 15,\n",
       "        31, 17,  4, 19, 26, 28, 15, 14,  8, 26, 19, 15, 31, 19, 26,  5,  2,\n",
       "         4,  0, 18,  2, 15, 14, 26, 28, 15, 31,  2, 28, 11, 14,  5]),\n",
       " array([ 9, 28, 15, 31, 26, 19, 28, 17, 19, 26, 19,  5, 28, 29, 19, 19, 26,\n",
       "        28, 28, 19,  5,  2, 31,  2,  9, 31, 15, 31,  8,  2, 31, 26, 19,  4,\n",
       "        28, 18, 26, 19,  5,  9, 19, 15, 31, 29, 28, 19,  8,  3,  3, 15, 31,\n",
       "        26, 19,  4,  5]),\n",
       " array([ 5,  2, 31, 19, 19,  5, 31, 19, 26,  5,  2, 31, 19, 19,  5,  4, 31,\n",
       "        19, 26, 19,  5, 31, 19,  5, 21, 31, 19, 27,  5,  4, 31, 19, 27, 19,\n",
       "        17,  5,  9, 13,  5, 24, 19, 19,  5, 28, 28, 28,  5,  9, 31, 19, 26,\n",
       "        19,  5, 31, 19,  8,  5]),\n",
       " array([ 5, 31, 19, 19,  5, 28, 19, 17,  5,  9,  6, 13,  5, 31, 19, 19,  5,\n",
       "        21, 31, 14, 19,  5, 28, 28, 15, 21,  9, 31, 19,  8,  5, 21,  9, 31,\n",
       "        19, 26, 19,  5, 28, 28,  5, 18, 19,  5,  9,  4, 31, 19, 26, 19,  4,\n",
       "         5, 31, 19, 19,  5]),\n",
       " array([19, 19,  5, 31, 19, 19,  5, 31, 19, 19, 19,  5, 28, 28,  5, 31, 19,\n",
       "        19,  9, 27, 19, 17, 19,  5, 28, 19, 19,  4, 19,  5, 21,  9, 31, 19,\n",
       "         5, 18, 19,  5,  1, 31, 19, 26, 19, 19,  5, 31, 19, 26, 19, 28, 28,\n",
       "        15,  6, 12,  8]),\n",
       " array([ 9, 28, 28, 15,  4, 28,  4, 15, 28, 28, 15,  4, 31, 19, 19, 19, 15,\n",
       "        31, 19, 19, 19,  5, 31,  5, 31, 17,  5, 28, 28, 28,  4, 15,  4, 24,\n",
       "         4, 28, 28, 15, 20,  8, 19,  4, 15, 28, 15, 31,  4,  5, 28, 28, 28,\n",
       "        28]),\n",
       " array([ 9, 15, 28, 28,  4, 15, 31, 17, 19, 19, 28, 19, 16, 19, 17, 19,  0,\n",
       "         4, 15,  9, 31,  8, 15, 28, 28, 28, 29, 15, 21, 21, 31, 17,  4, 19,\n",
       "        19,  4, 19, 19, 15, 31,  4,  5, 24, 19,  5, 24,  4, 15, 31, 19, 15,\n",
       "        24,  4, 15, 31,  4]),\n",
       " array([ 9,  4, 15, 31, 17,  4, 19, 19, 19, 11, 19, 19, 15,  4, 31, 28, 29,\n",
       "        15, 28, 24,  4, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19,  4, 19, 19,\n",
       "        15, 31, 19,  0, 28, 28, 15,  4, 24, 19, 19, 15, 31, 19, 11, 19, 19,\n",
       "        28, 29, 15, 28, 28, 15]),\n",
       " array([ 9, 31, 19, 27, 19, 17, 19, 19, 19, 19, 17, 19, 19, 19,  5,  9,  2,\n",
       "        21, 21, 24, 19, 19, 19, 28, 28,  4, 19, 27, 19,  4, 19, 27, 19,  4,\n",
       "        18, 19, 28, 15, 28, 19, 19, 19,  5,  4, 24, 19, 19, 18, 17, 17,  0,\n",
       "         4, 19,  9,  5, 24,  4, 19, 31, 19, 17]),\n",
       " array([ 9, 24, 19, 26, 26, 26, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        27, 17,  8, 19,  4, 19, 19, 14, 19, 19, 19, 25, 19, 15,  9, 28, 28,\n",
       "        28, 28, 15, 31,  0,  4, 19, 19, 19,  0,  4, 19, 19, 19,  5,  4, 24,\n",
       "         5,  2, 21]),\n",
       " array([ 9,  5,  2, 31,  5,  2, 24, 19,  4, 19,  5, 31,  4, 19,  4, 19, 28,\n",
       "        28,  4,  5, 28,  5, 31, 27, 19,  5,  4, 19,  4, 19, 28]),\n",
       " array([28, 19, 19,  5, 24,  4, 19, 27,  8, 28,  2, 31, 17, 19, 15,  2,  6,\n",
       "         2, 24, 19, 19, 27, 19, 28, 19, 19,  5, 28,  4,  5, 28, 19, 19, 27,\n",
       "         5, 31, 19, 19, 19, 19, 15,  2, 31, 19,  5, 24, 19,  5,  4,  2,  6,\n",
       "        28]),\n",
       " array([ 9, 28, 28,  6, 19, 19, 19, 19,  5,  4, 19, 19, 19, 27,  5, 28, 28,\n",
       "        19, 19,  3, 19,  4, 19, 19,  5,  2, 15, 28, 19,  4, 19, 19,  5, 24,\n",
       "         4, 19, 19, 27, 19,  5,  2,  2, 28, 24, 19, 19, 17, 19, 19,  5, 28,\n",
       "        19,  5, 28,  4, 19,  5, 24, 19, 19]),\n",
       " array([28, 19,  5, 31, 17, 19,  3, 19,  4, 19, 19, 19, 15, 31, 19,  5, 24,\n",
       "         4, 19, 17, 19,  5, 28, 19, 26, 26, 19,  5,  4, 24, 19, 19, 19,  5,\n",
       "        24, 19, 15, 31,  4, 19, 27, 19,  5, 28, 19,  4, 19,  4, 19,  5,  6,\n",
       "        28,  4, 19, 19,  4, 29, 19,  5,  6]),\n",
       " array([ 2, 31, 19, 19, 27, 19, 17, 19, 28, 19, 19, 19, 26, 19, 19, 28, 19,\n",
       "        19,  8, 19, 28, 19, 19, 27, 19, 19, 19, 19, 15, 31, 19, 19, 23, 19,\n",
       "         8, 19, 19,  8,  4, 19, 28, 19, 19,  8, 19, 28, 19, 19, 19, 19, 28]),\n",
       " array([ 2, 31, 19, 19, 28, 19,  4, 17, 19,  5,  2,  2,  2, 31, 19, 19,  8,\n",
       "        19, 28, 19, 15, 31, 19,  5, 31, 19, 19, 19, 19,  8, 19, 17, 19, 28,\n",
       "        19, 15, 31,  4, 14,  5, 31, 19,  8, 19, 28, 19, 17, 19, 28, 19, 19,\n",
       "        28, 19, 19, 19, 23, 19, 27]),\n",
       " array([ 2, 31, 19, 27, 19, 19, 19, 28, 19, 23, 19,  8,  0, 28, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19,  8, 19, 28, 19, 15, 31, 17, 19, 19, 28, 19,\n",
       "        19, 19, 19, 28, 19, 19,  4, 19, 28, 19, 19, 19, 27, 19, 28, 19, 19,\n",
       "        27, 19]),\n",
       " array([ 9,  2,  2,  2, 24,  4, 19, 26, 19, 15, 24, 19, 19, 28, 28, 28,  4,\n",
       "         0, 27, 17, 19,  4, 28,  4, 19, 15, 24, 19, 17, 19, 26, 19, 15, 31,\n",
       "        17, 19,  4, 19,  0,  4, 19, 15, 31, 19, 29, 19, 15, 31, 19, 28, 19,\n",
       "         4, 19, 17, 19, 15,  2, 31, 19, 19, 15, 31]),\n",
       " array([ 9, 19, 15, 28, 26, 19, 28, 19, 19,  0, 19,  4, 15,  2, 31, 19,  4,\n",
       "        15, 21, 28, 28, 28,  4,  5,  2, 31, 17,  0,  4, 19, 26, 19, 15,  2,\n",
       "        15, 31, 19, 15, 24, 26, 23, 19, 28, 15, 31, 19, 15, 24, 19, 17, 19,\n",
       "        15, 31,  4, 15, 28, 28,  4, 15]),\n",
       " array([ 9, 19, 19, 19, 15, 28, 15, 24, 26, 19, 28,  5, 31, 19]),\n",
       " array([ 9,  2, 31, 19, 16,  5,  2, 31, 17, 19, 28, 15,  4, 31, 19, 19, 18,\n",
       "        19, 28, 19, 28, 19, 19,  0, 18, 26, 26, 27, 19, 28, 14, 28, 17, 18,\n",
       "        19, 19,  4,  5,  9,  2, 19, 27,  4,  0, 27,  0, 27, 14,  2, 28, 28,\n",
       "         2, 20]),\n",
       " array([ 9,  2, 31, 19, 19, 27,  4, 19, 19,  5,  9, 31, 19,  5,  4,  2, 24,\n",
       "        17, 19,  4, 19, 28, 28, 18, 19,  0,  4, 19, 27,  0,  5,  2,  4, 31,\n",
       "        19,  4, 19,  4, 21, 31, 19,  0, 19, 27, 19, 19,  0,  4, 31, 19, 26,\n",
       "        26, 22, 30, 30,  4]),\n",
       " array([ 9, 31, 19, 19,  0, 19, 19, 31, 19, 19, 27, 15,  4, 24, 19, 19, 28,\n",
       "        19, 27,  9, 19, 19, 19, 28,  4, 19, 28,  4, 19, 19,  4, 14, 28, 19,\n",
       "         4, 14, 31, 18, 19,  4, 17, 19, 10,  4, 18, 19, 19, 19, 27, 19, 19,\n",
       "        18, 19,  4, 28, 28, 19, 19, 19]),\n",
       " array([ 9,  2,  2,  2,  2, 31, 19, 19, 14, 14, 14,  0, 17, 27, 19, 19, 28,\n",
       "         5,  2,  2, 31, 19, 19, 19, 28, 28, 28, 19, 19, 19, 19,  5,  2, 24,\n",
       "        23,  0, 27, 19, 19,  5,  2,  2,  2, 31, 19, 19,  5,  2,  2, 31, 28,\n",
       "        28, 14, 14, 19, 19]),\n",
       " array([ 9, 19, 28, 19, 28,  5,  2,  2, 31, 19, 19,  5,  2,  2, 31, 19,  5,\n",
       "         2,  2,  2,  6, 31, 17, 19, 19,  5, 31, 19, 19,  5,  2,  2, 31, 19,\n",
       "        19,  3, 19, 19, 28, 28, 28, 19, 19, 19, 28,  5,  2, 21, 24, 28, 19,\n",
       "         5, 21,  2,  2, 31, 17, 19, 19, 19,  3, 19]),\n",
       " array([ 9,  2, 31, 19,  4, 19, 19,  4, 19, 19, 19,  4, 19,  5,  2,  2, 31,\n",
       "        19, 19,  3,  4, 19, 19, 19, 29, 19, 19, 19,  3,  4, 19,  5,  2,  2,\n",
       "         4,  2, 31, 19,  4, 19,  5,  2, 31,  4, 19, 19,  3, 28,  5, 31, 19,\n",
       "         4, 19, 19,  4]),\n",
       " array([ 9, 19, 27, 19, 26, 27, 19,  8, 19, 19, 19, 28, 19,  8, 19, 19, 11,\n",
       "        19,  5, 31, 19, 28, 28, 19, 28, 18, 19, 28, 14, 19, 19,  8, 19, 26,\n",
       "        19, 19, 26, 17, 19, 26, 28, 28, 19, 19, 19, 19, 19, 26, 28,  6, 19,\n",
       "         8]),\n",
       " array([ 9, 19, 19, 28, 19, 28, 19, 11, 19, 26, 19, 17, 19, 19, 26, 27, 19,\n",
       "        13, 19, 19, 28, 28, 18, 19, 26, 25, 25, 19, 26, 19, 26, 28, 19,  8,\n",
       "         6, 19,  8, 19, 19, 19,  8,  5,  2, 31,  2, 28,  2, 31]),\n",
       " array([ 9, 26, 19, 19, 19, 26,  8, 19, 19, 17, 19,  8, 19, 19,  8, 19, 28,\n",
       "        19, 19, 26, 19, 28, 19, 19, 17, 19, 17,  8, 19, 19, 19, 19, 19, 26,\n",
       "        19, 19, 28, 28, 19, 26, 19, 19])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will be using encoded sequences from before\n",
    "encoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = create_input_output_pairs_mtm(encoded_sequences, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xx, yy = create_input_output_pairs_mtm(encoded_sequences, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19,  5]),\n",
       " array([31, 19,  5,  2]),\n",
       " array([19,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 19]),\n",
       " array([28, 28, 19, 19]),\n",
       " array([28, 19, 19, 26]),\n",
       " array([19, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28,  5]),\n",
       " array([28, 28,  5, 31]),\n",
       " array([28,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 17]),\n",
       " array([19, 19, 17, 19]),\n",
       " array([19, 17, 19,  5]),\n",
       " array([17, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 26]),\n",
       " array([19, 19, 26, 19]),\n",
       " array([19, 26, 19, 17]),\n",
       " array([26, 19, 17,  5]),\n",
       " array([19, 17,  5, 28]),\n",
       " array([17,  5, 28, 15]),\n",
       " array([ 5, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 28]),\n",
       " array([31, 19, 28, 28]),\n",
       " array([19, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19, 26]),\n",
       " array([19, 19, 26,  5]),\n",
       " array([19, 26,  5, 31]),\n",
       " array([26,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19, 17]),\n",
       " array([26, 19, 17,  5]),\n",
       " array([19, 17,  5,  2]),\n",
       " array([17,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 15]),\n",
       " array([31, 19, 15, 24]),\n",
       " array([19, 15, 24, 19]),\n",
       " array([15, 24, 19, 17]),\n",
       " array([24, 19, 17,  5]),\n",
       " array([19, 17,  5, 28]),\n",
       " array([17,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 19]),\n",
       " array([19, 19, 19, 19]),\n",
       " array([19, 19, 19,  3]),\n",
       " array([19, 19,  3, 28]),\n",
       " array([19,  3, 28, 28]),\n",
       " array([ 3, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 17]),\n",
       " array([19, 19, 17,  6]),\n",
       " array([19, 17,  6, 28]),\n",
       " array([17,  6, 28, 28]),\n",
       " array([ 6, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 19]),\n",
       " array([19, 19, 19, 19]),\n",
       " array([19, 19, 19, 28]),\n",
       " array([19, 19, 28, 28]),\n",
       " array([19, 28, 28, 28]),\n",
       " array([28, 28, 28,  5]),\n",
       " array([28, 28,  5,  2]),\n",
       " array([28,  5,  2, 24]),\n",
       " array([ 5,  2, 24, 28]),\n",
       " array([ 2, 24, 28, 28]),\n",
       " array([24, 28, 28, 28]),\n",
       " array([28, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31,  2]),\n",
       " array([ 5, 31,  2, 31]),\n",
       " array([31,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 28]),\n",
       " array([31, 19, 28, 28]),\n",
       " array([19, 28, 28,  5]),\n",
       " array([28, 28,  5, 31]),\n",
       " array([28,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 28]),\n",
       " array([19, 19, 28, 28]),\n",
       " array([19, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 17]),\n",
       " array([31, 19, 17, 19]),\n",
       " array([19, 17, 19, 19]),\n",
       " array([17, 19, 19, 19]),\n",
       " array([19, 19, 19, 27]),\n",
       " array([19, 19, 27, 19]),\n",
       " array([19, 27, 19, 26]),\n",
       " array([27, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 28]),\n",
       " array([19, 19, 28, 28]),\n",
       " array([19, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 17]),\n",
       " array([31, 19, 17,  5]),\n",
       " array([19, 17,  5,  2]),\n",
       " array([17,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19,  5]),\n",
       " array([31, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 17]),\n",
       " array([31, 19, 17,  5]),\n",
       " array([19, 17,  5,  2]),\n",
       " array([17,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 26]),\n",
       " array([31, 19, 26, 27]),\n",
       " array([19, 26, 27, 19]),\n",
       " array([26, 27, 19, 19]),\n",
       " array([27, 19, 19, 26]),\n",
       " array([19, 19, 26,  3]),\n",
       " array([19, 26,  3, 28]),\n",
       " array([26,  3, 28, 28]),\n",
       " array([ 3, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 17]),\n",
       " array([31, 19, 17, 26]),\n",
       " array([19, 17, 26, 27]),\n",
       " array([17, 26, 27, 19]),\n",
       " array([26, 27, 19, 26]),\n",
       " array([27, 19, 26, 19]),\n",
       " array([19, 26, 19, 19]),\n",
       " array([26, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 28]),\n",
       " array([31, 19, 28, 28]),\n",
       " array([19, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 26]),\n",
       " array([19, 19, 26, 27]),\n",
       " array([19, 26, 27, 19]),\n",
       " array([26, 27, 19, 28]),\n",
       " array([27, 19, 28, 28]),\n",
       " array([19, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 13]),\n",
       " array([19, 19, 13, 15]),\n",
       " array([19, 13, 15, 28]),\n",
       " array([13, 15, 28, 28]),\n",
       " array([15, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 13]),\n",
       " array([31, 19, 13, 15]),\n",
       " array([19, 13, 15, 31]),\n",
       " array([13, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 15]),\n",
       " array([19, 19, 15, 28]),\n",
       " array([19, 15, 28, 28]),\n",
       " array([15, 28, 28, 28]),\n",
       " array([28, 28, 28,  5]),\n",
       " array([28, 28,  5,  2]),\n",
       " array([28,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19, 27]),\n",
       " array([26, 19, 27, 19]),\n",
       " array([19, 27, 19, 17]),\n",
       " array([27, 19, 17, 15]),\n",
       " array([19, 17, 15, 28]),\n",
       " array([17, 15, 28, 28]),\n",
       " array([15, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 19]),\n",
       " array([19, 19, 19, 26]),\n",
       " array([19, 19, 26, 19]),\n",
       " array([19, 26, 19, 17]),\n",
       " array([26, 19, 17,  5]),\n",
       " array([19, 17,  5, 28]),\n",
       " array([17,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2, 28]),\n",
       " array([15,  2, 28, 28]),\n",
       " array([28, 28, 19, 19]),\n",
       " array([28, 19, 19, 19]),\n",
       " array([19, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 26]),\n",
       " array([19, 19, 26, 27]),\n",
       " array([19, 26, 27, 19]),\n",
       " array([26, 27, 19, 19]),\n",
       " array([27, 19, 19, 19]),\n",
       " array([19, 19, 19, 15]),\n",
       " array([19, 19, 15,  2]),\n",
       " array([19, 15,  2, 31]),\n",
       " array([15,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 28]),\n",
       " array([31, 19, 28, 19]),\n",
       " array([19, 28, 19,  5]),\n",
       " array([ 2, 24, 19, 17]),\n",
       " array([24, 19, 17,  5]),\n",
       " array([19, 17,  5,  2]),\n",
       " array([17,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 17]),\n",
       " array([ 2, 31, 17, 19]),\n",
       " array([31, 17, 19,  5]),\n",
       " array([17, 19,  5,  2]),\n",
       " array([19,  5,  2, 21]),\n",
       " array([ 5,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 19]),\n",
       " array([21, 31, 19, 27]),\n",
       " array([31, 19, 27, 19]),\n",
       " array([19, 27, 19, 28]),\n",
       " array([27, 19, 28, 28]),\n",
       " array([19, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 31]),\n",
       " array([15, 31, 31, 26]),\n",
       " array([31, 31, 26, 26]),\n",
       " array([31, 26, 26, 26]),\n",
       " array([26, 26, 26, 31]),\n",
       " array([26, 26, 31,  5]),\n",
       " array([26, 31,  5,  2]),\n",
       " array([31,  5,  2,  9]),\n",
       " array([5, 2, 9, 2]),\n",
       " array([ 2,  9,  2, 31]),\n",
       " array([ 9,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5, 24]),\n",
       " array([19,  5, 24, 19]),\n",
       " array([ 5, 24, 19, 19]),\n",
       " array([24, 19, 19, 19]),\n",
       " array([19, 19, 19, 27]),\n",
       " array([19, 19, 27,  8]),\n",
       " array([19, 27,  8,  5]),\n",
       " array([27,  8,  5,  2]),\n",
       " array([ 8,  5,  2, 21]),\n",
       " array([ 5,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 19]),\n",
       " array([21, 31, 19, 27]),\n",
       " array([31, 19, 27, 19]),\n",
       " array([19, 27, 19,  5]),\n",
       " array([27, 19,  5,  2]),\n",
       " array([19,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 27]),\n",
       " array([ 2, 31, 27, 19]),\n",
       " array([31, 27, 19, 26]),\n",
       " array([27, 19, 26, 27]),\n",
       " array([19, 26, 27,  5]),\n",
       " array([26, 27,  5,  2]),\n",
       " array([27,  5,  2,  2]),\n",
       " array([5, 2, 2, 2]),\n",
       " array([ 2,  2, 24, 19]),\n",
       " array([ 2, 24, 19, 19]),\n",
       " array([24, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2,  9]),\n",
       " array([5, 2, 9, 2]),\n",
       " array([ 2,  9,  2, 31]),\n",
       " array([ 9,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 17]),\n",
       " array([31, 19, 17, 19]),\n",
       " array([19, 17, 19,  5]),\n",
       " array([17, 19,  5,  2]),\n",
       " array([19,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 15]),\n",
       " array([28, 28, 15, 31]),\n",
       " array([28, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19,  8]),\n",
       " array([19, 19,  8, 19]),\n",
       " array([19,  8, 19, 26]),\n",
       " array([ 8, 19, 26, 26]),\n",
       " array([19, 26, 26, 31]),\n",
       " array([26, 26, 31, 19]),\n",
       " array([26, 31, 19,  5]),\n",
       " array([31, 19,  5,  2]),\n",
       " array([19,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 17]),\n",
       " array([ 2, 31, 17, 19]),\n",
       " array([31, 17, 19,  5]),\n",
       " array([17, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 27]),\n",
       " array([ 2, 31, 27, 27]),\n",
       " array([31, 27, 27, 19]),\n",
       " array([27, 27, 19, 19]),\n",
       " array([27, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2, 24]),\n",
       " array([ 5,  2, 24, 19]),\n",
       " array([ 2, 24, 19, 28]),\n",
       " array([24, 19, 28,  5]),\n",
       " array([19, 28,  5, 24]),\n",
       " array([28,  5, 24, 26]),\n",
       " array([ 5, 24, 26, 27]),\n",
       " array([24, 26, 27,  5]),\n",
       " array([26, 27,  5,  2]),\n",
       " array([27,  5,  2, 21]),\n",
       " array([ 2, 24, 19, 19]),\n",
       " array([24, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 29]),\n",
       " array([28, 28, 29,  5]),\n",
       " array([28, 29,  5,  2]),\n",
       " array([29,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 19]),\n",
       " array([ 2, 31, 19,  5]),\n",
       " array([31, 19,  5,  2]),\n",
       " array([19,  5,  2, 24]),\n",
       " array([ 5,  2, 24, 19]),\n",
       " array([ 2, 24, 19, 11]),\n",
       " array([24, 19, 11, 19]),\n",
       " array([19, 11, 19,  5]),\n",
       " array([11, 19,  5, 24]),\n",
       " array([19,  5, 24,  8]),\n",
       " array([ 5, 24,  8, 10]),\n",
       " array([24,  8, 10,  5]),\n",
       " array([ 8, 10,  5,  2]),\n",
       " array([10,  5,  2, 28]),\n",
       " array([ 5,  2, 28,  5]),\n",
       " array([ 2, 28,  5,  2]),\n",
       " array([28,  5,  2, 24]),\n",
       " array([ 5,  2, 24, 26]),\n",
       " array([ 2, 24, 26, 26]),\n",
       " array([24, 26, 26, 31]),\n",
       " array([26, 26, 31, 19]),\n",
       " array([26, 31, 19,  4]),\n",
       " array([31, 19,  4,  5]),\n",
       " array([19,  4,  5,  2]),\n",
       " array([ 4,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19,  4]),\n",
       " array([19, 19,  4, 19]),\n",
       " array([19,  4, 19,  5]),\n",
       " array([ 4, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28,  7]),\n",
       " array([28, 28,  7,  5]),\n",
       " array([28,  7,  5,  2]),\n",
       " array([ 7,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 17]),\n",
       " array([ 2, 31, 17, 19]),\n",
       " array([31, 17, 19, 13]),\n",
       " array([17, 19, 13,  5]),\n",
       " array([19, 13,  5,  2]),\n",
       " array([13,  5,  2, 24]),\n",
       " array([ 5,  2, 24,  4]),\n",
       " array([ 2, 24,  4,  5]),\n",
       " array([24,  4,  5,  2]),\n",
       " array([4, 5, 2, 2]),\n",
       " array([ 5,  2,  2, 21]),\n",
       " array([ 2,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 19]),\n",
       " array([ 5,  2,  2, 24]),\n",
       " array([ 2,  2, 24, 19]),\n",
       " array([ 2, 24, 19, 19]),\n",
       " array([24, 19, 19, 19]),\n",
       " array([19, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 17]),\n",
       " array([ 2, 31, 17, 19]),\n",
       " array([31, 17, 19, 17]),\n",
       " array([17, 19, 17, 19]),\n",
       " array([19, 17, 19,  5]),\n",
       " array([17, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 19]),\n",
       " array([ 2, 31, 19,  8]),\n",
       " array([31, 19,  8, 19]),\n",
       " array([19,  8, 19, 27]),\n",
       " array([ 8, 19, 27, 19]),\n",
       " array([19, 27, 19,  5]),\n",
       " array([27, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 24]),\n",
       " array([ 2,  2, 24,  4]),\n",
       " array([ 2, 24,  4,  5]),\n",
       " array([24,  4,  5,  2]),\n",
       " array([ 4,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([28, 28, 28,  5]),\n",
       " array([28, 28,  5,  2]),\n",
       " array([28,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 21]),\n",
       " array([ 2,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 19]),\n",
       " array([21, 31, 19, 26]),\n",
       " array([31, 19, 26, 26]),\n",
       " array([19, 26, 26, 19]),\n",
       " array([26, 26, 19,  5]),\n",
       " array([26, 19,  5,  4]),\n",
       " array([19,  5,  4,  2]),\n",
       " array([5, 4, 2, 2]),\n",
       " array([ 4,  2,  2, 24]),\n",
       " array([ 2,  2, 24, 26]),\n",
       " array([ 2, 24, 26, 26]),\n",
       " array([24, 26, 26, 27]),\n",
       " array([26, 26, 27, 19]),\n",
       " array([26, 27, 19,  5]),\n",
       " array([27, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 24]),\n",
       " array([ 2,  2, 24, 28]),\n",
       " array([ 2, 24, 28, 28]),\n",
       " array([24, 28, 28,  5]),\n",
       " array([ 5,  2,  2, 24]),\n",
       " array([ 2,  2, 24, 19]),\n",
       " array([ 2, 24, 19, 19]),\n",
       " array([24, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2,  4]),\n",
       " array([5, 2, 4, 2]),\n",
       " array([ 2,  4,  2, 31]),\n",
       " array([ 4,  2, 31, 19]),\n",
       " array([ 2, 31, 19,  4]),\n",
       " array([31, 19,  4,  5]),\n",
       " array([19,  4,  5,  2]),\n",
       " array([ 4,  5,  2, 28]),\n",
       " array([ 5,  2, 28, 28]),\n",
       " array([ 2, 28, 28, 28]),\n",
       " array([28, 28, 28, 15]),\n",
       " array([28, 28, 15,  2]),\n",
       " array([28, 15,  2,  2]),\n",
       " array([15,  2,  2, 31]),\n",
       " array([ 2,  2, 31, 17]),\n",
       " array([ 2, 31, 17, 19]),\n",
       " array([31, 17, 19,  5]),\n",
       " array([17, 19,  5,  2]),\n",
       " array([19,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 21]),\n",
       " array([ 2,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 19]),\n",
       " array([21, 31, 19, 17]),\n",
       " array([31, 19, 17,  5]),\n",
       " array([19, 17,  5,  2]),\n",
       " array([17,  5,  2,  2]),\n",
       " array([ 5,  2,  2, 24]),\n",
       " array([ 2,  2, 24, 17]),\n",
       " array([ 2, 24, 17, 19]),\n",
       " array([24, 17, 19, 19]),\n",
       " array([17, 19, 19,  5]),\n",
       " array([19, 19,  5,  2]),\n",
       " array([19,  5,  2, 24]),\n",
       " array([ 5,  2, 24, 28]),\n",
       " array([ 2, 24, 28, 26]),\n",
       " array([24, 28, 26, 26]),\n",
       " array([28, 26, 26,  5]),\n",
       " array([26, 26,  5,  2]),\n",
       " array([26,  5,  2, 17]),\n",
       " array([ 5,  2, 17,  4]),\n",
       " array([ 2, 17,  4,  2]),\n",
       " array([17,  4,  2, 21]),\n",
       " array([ 4,  2, 21, 31]),\n",
       " array([ 2, 21, 31, 17]),\n",
       " array([21, 31, 17, 19]),\n",
       " array([31, 17, 19, 27]),\n",
       " array([17, 19, 27, 19]),\n",
       " array([19, 27, 19,  4]),\n",
       " array([27, 19,  4, 19]),\n",
       " array([19,  4, 19, 26]),\n",
       " array([ 4, 19, 26, 26]),\n",
       " array([19, 26, 26, 14]),\n",
       " array([26, 26, 14, 19]),\n",
       " array([ 2, 31,  5, 28]),\n",
       " array([31,  5, 28, 15]),\n",
       " array([ 5, 28, 15, 14]),\n",
       " array([28, 15, 14, 26]),\n",
       " array([15, 14, 26, 19]),\n",
       " array([14, 26, 19, 15]),\n",
       " array([26, 19, 15, 28]),\n",
       " array([19, 15, 28, 31]),\n",
       " array([15, 28, 31, 26]),\n",
       " array([28, 31, 26, 19]),\n",
       " array([31, 26, 19, 15]),\n",
       " array([26, 19, 15, 19]),\n",
       " array([19, 15, 19, 26]),\n",
       " array([15, 19, 26, 19]),\n",
       " array([19, 26, 19, 17]),\n",
       " array([26, 19, 17, 26]),\n",
       " array([19, 17, 26, 19]),\n",
       " array([17, 26, 19, 27]),\n",
       " array([26, 19, 27, 18]),\n",
       " array([19, 27, 18, 15]),\n",
       " array([27, 18, 15,  9]),\n",
       " array([18, 15,  9, 15]),\n",
       " array([15,  9, 15, 31]),\n",
       " array([ 9, 15, 31, 26]),\n",
       " array([15, 31, 26, 19]),\n",
       " array([31, 26, 19, 15]),\n",
       " array([26, 19, 15, 31]),\n",
       " array([19, 15, 31,  4]),\n",
       " array([15, 31,  4, 18]),\n",
       " array([31,  4, 18, 15]),\n",
       " array([ 4, 18, 15, 31]),\n",
       " array([18, 15, 31,  8]),\n",
       " array([15, 31,  8,  5]),\n",
       " array([31,  8,  5,  9]),\n",
       " array([ 8,  5,  9, 28]),\n",
       " array([ 5,  9, 28, 28]),\n",
       " array([ 9, 28, 28, 18]),\n",
       " array([28, 28, 18, 19]),\n",
       " array([28, 18, 19, 26]),\n",
       " array([18, 19, 26, 31]),\n",
       " array([19, 26, 31, 19]),\n",
       " array([26, 31, 19,  5]),\n",
       " array([31, 19,  5,  2]),\n",
       " array([19,  5,  2,  4]),\n",
       " array([ 5,  2,  4, 27]),\n",
       " array([ 2,  4, 27, 19]),\n",
       " array([ 4, 27, 19, 26]),\n",
       " array([27, 19, 26, 19]),\n",
       " array([19, 26, 19, 25]),\n",
       " array([26, 19, 25, 15]),\n",
       " array([19, 25, 15, 14]),\n",
       " array([25, 15, 14, 19]),\n",
       " array([15, 14, 19,  5]),\n",
       " array([14, 19,  5,  2]),\n",
       " array([19,  5,  2,  4]),\n",
       " array([ 5,  2,  4, 27]),\n",
       " array([ 2,  4, 27, 13]),\n",
       " array([ 4, 15, 28, 19]),\n",
       " array([15, 28, 19, 19]),\n",
       " array([28, 19, 19, 15]),\n",
       " array([19, 19, 15, 24]),\n",
       " array([19, 15, 24, 26]),\n",
       " array([15, 24, 26, 19]),\n",
       " array([24, 26, 19,  0]),\n",
       " array([26, 19,  0, 15]),\n",
       " array([19,  0, 15, 31]),\n",
       " array([ 0, 15, 31, 26]),\n",
       " array([15, 31, 26, 19]),\n",
       " array([31, 26, 19,  2]),\n",
       " array([26, 19,  2,  2]),\n",
       " array([19,  2,  2,  2]),\n",
       " array([ 2,  2,  2, 28]),\n",
       " array([ 2,  2, 28, 15]),\n",
       " array([ 2, 28, 15, 14]),\n",
       " array([28, 15, 14, 11]),\n",
       " array([15, 14, 11, 14]),\n",
       " array([14, 11, 14, 15]),\n",
       " array([11, 14, 15, 31]),\n",
       " array([14, 15, 31, 19]),\n",
       " array([15, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19, 15]),\n",
       " array([26, 19, 15, 13]),\n",
       " array([19, 15, 13, 18]),\n",
       " array([15, 13, 18, 27]),\n",
       " array([13, 18, 27,  0]),\n",
       " array([18, 27,  0, 15]),\n",
       " array([27,  0, 15, 31]),\n",
       " array([ 0, 15, 31, 17]),\n",
       " array([15, 31, 17,  4]),\n",
       " array([31, 17,  4, 19]),\n",
       " array([17,  4, 19, 26]),\n",
       " array([ 4, 19, 26, 28]),\n",
       " array([19, 26, 28, 15]),\n",
       " array([26, 28, 15, 14]),\n",
       " array([28, 15, 14,  8]),\n",
       " array([15, 14,  8, 26]),\n",
       " array([14,  8, 26, 19]),\n",
       " array([ 8, 26, 19, 15]),\n",
       " array([26, 19, 15, 31]),\n",
       " array([19, 15, 31, 19]),\n",
       " array([15, 31, 19, 26]),\n",
       " array([31, 19, 26,  5]),\n",
       " array([19, 26,  5,  2]),\n",
       " array([26,  5,  2,  4]),\n",
       " array([5, 2, 4, 0]),\n",
       " array([ 2,  4,  0, 18]),\n",
       " array([ 4,  0, 18,  2]),\n",
       " array([ 0, 18,  2, 15]),\n",
       " array([18,  2, 15, 14]),\n",
       " array([ 2, 15, 14, 26]),\n",
       " array([15, 14, 26, 28]),\n",
       " array([14, 26, 28, 15]),\n",
       " array([26, 28, 15, 31]),\n",
       " array([28, 15, 31,  2]),\n",
       " array([15, 31,  2, 28]),\n",
       " array([31,  2, 28, 11]),\n",
       " array([ 2, 28, 11, 14]),\n",
       " array([28, 11, 14,  5]),\n",
       " array([28, 15, 31, 26]),\n",
       " array([15, 31, 26, 19]),\n",
       " array([31, 26, 19, 28]),\n",
       " array([26, 19, 28, 17]),\n",
       " array([19, 28, 17, 19]),\n",
       " array([28, 17, 19, 26]),\n",
       " array([17, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 28]),\n",
       " array([19,  5, 28, 29]),\n",
       " array([ 5, 28, 29, 19]),\n",
       " array([28, 29, 19, 19]),\n",
       " array([29, 19, 19, 26]),\n",
       " array([19, 19, 26, 28]),\n",
       " array([19, 26, 28, 28]),\n",
       " array([26, 28, 28, 19]),\n",
       " array([28, 28, 19,  5]),\n",
       " array([28, 19,  5,  2]),\n",
       " array([19,  5,  2, 31]),\n",
       " array([ 5,  2, 31,  2]),\n",
       " array([ 2, 31,  2,  9]),\n",
       " array([31,  2,  9, 31]),\n",
       " array([ 2,  9, 31, 15]),\n",
       " array([ 9, 31, 15, 31]),\n",
       " array([31, 15, 31,  8]),\n",
       " array([15, 31,  8,  2]),\n",
       " array([31,  8,  2, 31]),\n",
       " array([ 8,  2, 31, 26]),\n",
       " array([ 2, 31, 26, 19]),\n",
       " array([31, 26, 19,  4]),\n",
       " array([26, 19,  4, 28]),\n",
       " array([19,  4, 28, 18]),\n",
       " array([ 4, 28, 18, 26]),\n",
       " array([28, 18, 26, 19]),\n",
       " array([18, 26, 19,  5]),\n",
       " array([26, 19,  5,  9]),\n",
       " array([19,  5,  9, 19]),\n",
       " array([ 5,  9, 19, 15]),\n",
       " array([ 9, 19, 15, 31]),\n",
       " array([19, 15, 31, 29]),\n",
       " array([15, 31, 29, 28]),\n",
       " array([31, 29, 28, 19]),\n",
       " array([29, 28, 19,  8]),\n",
       " array([28, 19,  8,  3]),\n",
       " array([19,  8,  3,  3]),\n",
       " array([ 8,  3,  3, 15]),\n",
       " array([ 3,  3, 15, 31]),\n",
       " array([ 3, 15, 31, 26]),\n",
       " array([15, 31, 26, 19]),\n",
       " array([31, 26, 19,  4]),\n",
       " array([26, 19,  4,  5]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 26]),\n",
       " array([31, 19, 26,  5]),\n",
       " array([19, 26,  5,  2]),\n",
       " array([26,  5,  2, 31]),\n",
       " array([ 5,  2, 31, 19]),\n",
       " array([ 2, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5,  4]),\n",
       " array([19,  5,  4, 31]),\n",
       " array([ 5,  4, 31, 19]),\n",
       " array([ 4, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19,  5]),\n",
       " array([31, 19,  5, 21]),\n",
       " array([19,  5, 21, 31]),\n",
       " array([ 5, 21, 31, 19]),\n",
       " array([21, 31, 19, 27]),\n",
       " array([31, 19, 27,  5]),\n",
       " array([19, 27,  5,  4]),\n",
       " array([27,  5,  4, 31]),\n",
       " array([ 5,  4, 31, 19]),\n",
       " array([ 4, 31, 19, 27]),\n",
       " array([31, 19, 27, 19]),\n",
       " array([19, 27, 19, 17]),\n",
       " array([27, 19, 17,  5]),\n",
       " array([19, 17,  5,  9]),\n",
       " array([17,  5,  9, 13]),\n",
       " array([ 5,  9, 13,  5]),\n",
       " array([ 9, 13,  5, 24]),\n",
       " array([13,  5, 24, 19]),\n",
       " array([ 5, 24, 19, 19]),\n",
       " array([24, 19, 19,  5]),\n",
       " array([19, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28,  5]),\n",
       " array([28, 28,  5,  9]),\n",
       " array([28,  5,  9, 31]),\n",
       " array([ 5,  9, 31, 19]),\n",
       " array([ 9, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19,  8]),\n",
       " array([31, 19,  8,  5]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5, 28]),\n",
       " array([19,  5, 28, 19]),\n",
       " array([ 5, 28, 19, 17]),\n",
       " array([28, 19, 17,  5]),\n",
       " array([19, 17,  5,  9]),\n",
       " array([17,  5,  9,  6]),\n",
       " array([ 5,  9,  6, 13]),\n",
       " array([ 9,  6, 13,  5]),\n",
       " array([ 6, 13,  5, 31]),\n",
       " array([13,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5, 21]),\n",
       " array([19,  5, 21, 31]),\n",
       " array([ 5, 21, 31, 14]),\n",
       " array([21, 31, 14, 19]),\n",
       " array([31, 14, 19,  5]),\n",
       " array([14, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 15]),\n",
       " array([28, 28, 15, 21]),\n",
       " array([28, 15, 21,  9]),\n",
       " array([15, 21,  9, 31]),\n",
       " array([21,  9, 31, 19]),\n",
       " array([ 9, 31, 19,  8]),\n",
       " array([31, 19,  8,  5]),\n",
       " array([19,  8,  5, 21]),\n",
       " array([ 8,  5, 21,  9]),\n",
       " array([ 5, 21,  9, 31]),\n",
       " array([21,  9, 31, 19]),\n",
       " array([ 9, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19,  5]),\n",
       " array([26, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28,  5]),\n",
       " array([28, 28,  5, 18]),\n",
       " array([28,  5, 18, 19]),\n",
       " array([ 5, 18, 19,  5]),\n",
       " array([18, 19,  5,  9]),\n",
       " array([19,  5,  9,  4]),\n",
       " array([ 5,  9,  4, 31]),\n",
       " array([ 9,  4, 31, 19]),\n",
       " array([ 4, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19,  4]),\n",
       " array([26, 19,  4,  5]),\n",
       " array([19,  4,  5, 31]),\n",
       " array([ 4,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19,  5]),\n",
       " array([19, 19,  5, 28]),\n",
       " array([19,  5, 28, 28]),\n",
       " array([ 5, 28, 28,  5]),\n",
       " array([28, 28,  5, 31]),\n",
       " array([28,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 19]),\n",
       " array([31, 19, 19,  9]),\n",
       " array([19, 19,  9, 27]),\n",
       " array([19,  9, 27, 19]),\n",
       " array([ 9, 27, 19, 17]),\n",
       " array([27, 19, 17, 19]),\n",
       " array([19, 17, 19,  5]),\n",
       " array([17, 19,  5, 28]),\n",
       " array([19,  5, 28, 19]),\n",
       " array([ 5, 28, 19, 19]),\n",
       " array([28, 19, 19,  4]),\n",
       " array([19, 19,  4, 19]),\n",
       " array([19,  4, 19,  5]),\n",
       " array([ 4, 19,  5, 21]),\n",
       " array([19,  5, 21,  9]),\n",
       " array([ 5, 21,  9, 31]),\n",
       " array([21,  9, 31, 19]),\n",
       " array([ 9, 31, 19,  5]),\n",
       " array([31, 19,  5, 18]),\n",
       " array([19,  5, 18, 19]),\n",
       " array([ 5, 18, 19,  5]),\n",
       " array([18, 19,  5,  1]),\n",
       " array([19,  5,  1, 31]),\n",
       " array([ 5,  1, 31, 19]),\n",
       " array([ 1, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19, 19]),\n",
       " array([26, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31, 19]),\n",
       " array([ 5, 31, 19, 26]),\n",
       " array([31, 19, 26, 19]),\n",
       " array([19, 26, 19, 28]),\n",
       " array([26, 19, 28, 28]),\n",
       " array([19, 28, 28, 15]),\n",
       " array([28, 28, 15,  6]),\n",
       " array([28, 15,  6, 12]),\n",
       " array([15,  6, 12,  8]),\n",
       " array([28, 28, 15,  4]),\n",
       " array([28, 15,  4, 28]),\n",
       " array([15,  4, 28,  4]),\n",
       " array([ 4, 28,  4, 15]),\n",
       " array([28,  4, 15, 28]),\n",
       " array([ 4, 15, 28, 28]),\n",
       " array([15, 28, 28, 15]),\n",
       " array([28, 28, 15,  4]),\n",
       " array([28, 15,  4, 31]),\n",
       " array([15,  4, 31, 19]),\n",
       " array([ 4, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19, 15]),\n",
       " array([19, 19, 15, 31]),\n",
       " array([19, 15, 31, 19]),\n",
       " array([15, 31, 19, 19]),\n",
       " array([31, 19, 19, 19]),\n",
       " array([19, 19, 19,  5]),\n",
       " array([19, 19,  5, 31]),\n",
       " array([19,  5, 31,  5]),\n",
       " array([ 5, 31,  5, 31]),\n",
       " array([31,  5, 31, 17]),\n",
       " array([ 5, 31, 17,  5]),\n",
       " array([31, 17,  5, 28]),\n",
       " array([17,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28,  4]),\n",
       " array([28, 28,  4, 15]),\n",
       " array([28,  4, 15,  4]),\n",
       " array([ 4, 15,  4, 24]),\n",
       " array([15,  4, 24,  4]),\n",
       " array([ 4, 24,  4, 28]),\n",
       " array([24,  4, 28, 28]),\n",
       " array([ 4, 28, 28, 15]),\n",
       " array([28, 28, 15, 20]),\n",
       " array([28, 15, 20,  8]),\n",
       " array([15, 20,  8, 19]),\n",
       " array([20,  8, 19,  4]),\n",
       " array([ 8, 19,  4, 15]),\n",
       " array([19,  4, 15, 28]),\n",
       " array([ 4, 15, 28, 15]),\n",
       " array([15, 28, 15, 31]),\n",
       " array([28, 15, 31,  4]),\n",
       " array([15, 31,  4,  5]),\n",
       " array([31,  4,  5, 28]),\n",
       " array([ 4,  5, 28, 28]),\n",
       " array([ 5, 28, 28, 28]),\n",
       " array([28, 28, 28, 28]),\n",
       " array([15, 28, 28,  4]),\n",
       " array([28, 28,  4, 15]),\n",
       " array([28,  4, 15, 31]),\n",
       " array([ 4, 15, 31, 17]),\n",
       " array([15, 31, 17, 19]),\n",
       " array([31, 17, 19, 19]),\n",
       " array([17, 19, 19, 28]),\n",
       " array([19, 19, 28, 19]),\n",
       " array([19, 28, 19, 16]),\n",
       " array([28, 19, 16, 19]),\n",
       " array([19, 16, 19, 17]),\n",
       " array([16, 19, 17, 19]),\n",
       " array([19, 17, 19,  0]),\n",
       " array([17, 19,  0,  4]),\n",
       " array([19,  0,  4, 15]),\n",
       " array([ 0,  4, 15,  9]),\n",
       " array([ 4, 15,  9, 31]),\n",
       " array([15,  9, 31,  8]),\n",
       " array([ 9, 31,  8, 15]),\n",
       " array([31,  8, 15, 28]),\n",
       " array([ 8, 15, 28, 28]),\n",
       " array([15, 28, 28, 28]),\n",
       " array([28, 28, 28, 29]),\n",
       " array([28, 28, 29, 15]),\n",
       " array([28, 29, 15, 21]),\n",
       " array([29, 15, 21, 21]),\n",
       " array([15, 21, 21, 31]),\n",
       " array([21, 21, 31, 17]),\n",
       " array([21, 31, 17,  4]),\n",
       " array([31, 17,  4, 19]),\n",
       " array([17,  4, 19, 19]),\n",
       " array([ 4, 19, 19,  4]),\n",
       " array([19, 19,  4, 19]),\n",
       " array([19,  4, 19, 19]),\n",
       " array([ 4, 19, 19, 15]),\n",
       " array([19, 19, 15, 31]),\n",
       " array([19, 15, 31,  4]),\n",
       " array([15, 31,  4,  5]),\n",
       " array([31,  4,  5, 24]),\n",
       " array([ 4,  5, 24, 19]),\n",
       " array([ 5, 24, 19,  5]),\n",
       " array([24, 19,  5, 24]),\n",
       " array([19,  5, 24,  4]),\n",
       " array([ 5, 24,  4, 15]),\n",
       " array([24,  4, 15, 31]),\n",
       " array([ 4, 15, 31, 19]),\n",
       " array([15, 31, 19, 15]),\n",
       " array([31, 19, 15, 24]),\n",
       " array([19, 15, 24,  4]),\n",
       " array([15, 24,  4, 15]),\n",
       " array([24,  4, 15, 31]),\n",
       " array([ 4, 15, 31,  4]),\n",
       " array([ 4, 15, 31, 17]),\n",
       " array([15, 31, 17,  4]),\n",
       " array([31, 17,  4, 19]),\n",
       " array([17,  4, 19, 19]),\n",
       " array([ 4, 19, 19, 19]),\n",
       " array([19, 19, 19, 11]),\n",
       " array([19, 19, 11, 19]),\n",
       " array([19, 11, 19, 19]),\n",
       " array([11, 19, 19, 15]),\n",
       " array([19, 19, 15,  4]),\n",
       " array([19, 15,  4, 31]),\n",
       " array([15,  4, 31, 28]),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xx: (2055, 4, 32)\n",
      "Shape of yy: (2055, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convert x and y to one-hot encoding\n",
    "xx_one_hot = to_categorical(xx, num_classes=num_classes)\n",
    "yy_one_hot = to_categorical(yy, num_classes=num_classes)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of xx:\", xx_one_hot.shape)\n",
    "print(\"Shape of yy:\", yy_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xx: (2055, 4, 32)\n",
      "Shape of yy: (2055, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convert to TensorFlow tensors\n",
    "xx_tensor = tf.convert_to_tensor(xx_one_hot)\n",
    "yy_tensor = tf.convert_to_tensor(yy_one_hot)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of xx:\", xx_tensor.shape)\n",
    "print(\"Shape of yy:\", yy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xx_train: (1644, 4, 32)\n",
      "Shape of yy_train: (1644, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets (80-20 split)\n",
    "split_index_2 = int(0.8 * len(xx_tensor))\n",
    "xx_train, xx_val = xx_tensor[:split_index_2], xx_tensor[split_index_2:]\n",
    "yy_train, yy_val = yy_tensor[:split_index_2], yy_tensor[split_index_2:]\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of xx_train:\", xx_train.shape)\n",
    "print(\"Shape of yy_train:\", yy_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Baseline Many-to-Many LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 4, 64)             24832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 26,912\n",
      "Trainable params: 26,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, TimeDistributed\n",
    "import random\n",
    "\n",
    "\n",
    "# Set a new random seed\n",
    "new_seed = 42\n",
    "tf.random.set_seed(new_seed)\n",
    "np.random.seed(new_seed)\n",
    "random.seed(new_seed)\n",
    "\n",
    "# Define the LSTM model for many-to-many\n",
    "many_to_many_baseline_model = Sequential([\n",
    "    LSTM(64, input_shape=(4, 32), return_sequences=True), # 64 units, return full sequence\n",
    "    Dropout(0.2),                                         # Dropout for regularization\n",
    "    TimeDistributed(Dense(32, activation='softmax'))      # Apply Dense layer to each timestep\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "many_to_many_baseline_model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "many_to_many_baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "103/103 [==============================] - 3s 8ms/step - loss: 3.2774 - accuracy: 0.2151 - val_loss: 2.6921 - val_accuracy: 0.3954\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.6079 - accuracy: 0.3142 - val_loss: 2.4834 - val_accuracy: 0.4027\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.3838 - accuracy: 0.3373 - val_loss: 2.3034 - val_accuracy: 0.4483\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1787 - accuracy: 0.4011 - val_loss: 2.2299 - val_accuracy: 0.4538\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0721 - accuracy: 0.4258 - val_loss: 2.2049 - val_accuracy: 0.4519\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0184 - accuracy: 0.4290 - val_loss: 2.1867 - val_accuracy: 0.4501\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9631 - accuracy: 0.4351 - val_loss: 2.1726 - val_accuracy: 0.4422\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9501 - accuracy: 0.4173 - val_loss: 2.1655 - val_accuracy: 0.4446\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9265 - accuracy: 0.4310 - val_loss: 2.1767 - val_accuracy: 0.4538\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9152 - accuracy: 0.4263 - val_loss: 2.1741 - val_accuracy: 0.4416\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8841 - accuracy: 0.4385 - val_loss: 2.1625 - val_accuracy: 0.4507\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8877 - accuracy: 0.4364 - val_loss: 2.1875 - val_accuracy: 0.4325\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8646 - accuracy: 0.4400 - val_loss: 2.1926 - val_accuracy: 0.4361\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.8452 - accuracy: 0.4449 - val_loss: 2.1903 - val_accuracy: 0.4313\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8545 - accuracy: 0.4422 - val_loss: 2.1882 - val_accuracy: 0.4416\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8124 - accuracy: 0.4403 - val_loss: 2.1845 - val_accuracy: 0.4373\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8210 - accuracy: 0.4443 - val_loss: 2.2047 - val_accuracy: 0.4313\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8010 - accuracy: 0.4477 - val_loss: 2.1926 - val_accuracy: 0.4355\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7886 - accuracy: 0.4487 - val_loss: 2.2174 - val_accuracy: 0.4227\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.8267 - accuracy: 0.4315 - val_loss: 2.2118 - val_accuracy: 0.4203\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7940 - accuracy: 0.4444 - val_loss: 2.2361 - val_accuracy: 0.4039\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7746 - accuracy: 0.4534 - val_loss: 2.2166 - val_accuracy: 0.4264\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7485 - accuracy: 0.4595 - val_loss: 2.2261 - val_accuracy: 0.4167\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7396 - accuracy: 0.4583 - val_loss: 2.2503 - val_accuracy: 0.3984\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.7441 - accuracy: 0.4470 - val_loss: 2.2480 - val_accuracy: 0.4075\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.7423 - accuracy: 0.4570 - val_loss: 2.2493 - val_accuracy: 0.4118\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.7384 - accuracy: 0.4514 - val_loss: 2.2733 - val_accuracy: 0.4027\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7238 - accuracy: 0.4526 - val_loss: 2.2783 - val_accuracy: 0.3978\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7086 - accuracy: 0.4524 - val_loss: 2.2801 - val_accuracy: 0.4039\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7147 - accuracy: 0.4580 - val_loss: 2.2747 - val_accuracy: 0.4106\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7076 - accuracy: 0.4586 - val_loss: 2.3021 - val_accuracy: 0.3984\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6907 - accuracy: 0.4647 - val_loss: 2.3024 - val_accuracy: 0.4094\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7176 - accuracy: 0.4588 - val_loss: 2.3016 - val_accuracy: 0.4009\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6876 - accuracy: 0.4510 - val_loss: 2.3057 - val_accuracy: 0.4100\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6686 - accuracy: 0.4721 - val_loss: 2.3225 - val_accuracy: 0.3948\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.6715 - accuracy: 0.4693 - val_loss: 2.3238 - val_accuracy: 0.4039\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6487 - accuracy: 0.4744 - val_loss: 2.3337 - val_accuracy: 0.3990\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6536 - accuracy: 0.4684 - val_loss: 2.3525 - val_accuracy: 0.3869\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6560 - accuracy: 0.4766 - val_loss: 2.3493 - val_accuracy: 0.3796\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6515 - accuracy: 0.4756 - val_loss: 2.3623 - val_accuracy: 0.3978\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6480 - accuracy: 0.4776 - val_loss: 2.3508 - val_accuracy: 0.4051\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6144 - accuracy: 0.4859 - val_loss: 2.3738 - val_accuracy: 0.3790\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6235 - accuracy: 0.4777 - val_loss: 2.3801 - val_accuracy: 0.3978\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6224 - accuracy: 0.4801 - val_loss: 2.3682 - val_accuracy: 0.4045\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6062 - accuracy: 0.4927 - val_loss: 2.3867 - val_accuracy: 0.3856\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.6141 - accuracy: 0.4808 - val_loss: 2.3809 - val_accuracy: 0.3838\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5948 - accuracy: 0.4907 - val_loss: 2.4037 - val_accuracy: 0.3729\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5983 - accuracy: 0.4837 - val_loss: 2.4012 - val_accuracy: 0.3832\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6099 - accuracy: 0.4796 - val_loss: 2.4132 - val_accuracy: 0.3850\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5880 - accuracy: 0.4849 - val_loss: 2.4112 - val_accuracy: 0.3783\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5751 - accuracy: 0.4918 - val_loss: 2.4359 - val_accuracy: 0.3735\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5862 - accuracy: 0.4888 - val_loss: 2.4221 - val_accuracy: 0.3850\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5749 - accuracy: 0.4899 - val_loss: 2.4367 - val_accuracy: 0.3698\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.5851 - accuracy: 0.4819 - val_loss: 2.4295 - val_accuracy: 0.3741\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5438 - accuracy: 0.5002 - val_loss: 2.4394 - val_accuracy: 0.3747\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5871 - accuracy: 0.5005 - val_loss: 2.4590 - val_accuracy: 0.3692\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5552 - accuracy: 0.4941 - val_loss: 2.4512 - val_accuracy: 0.3735\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5766 - accuracy: 0.4933 - val_loss: 2.4805 - val_accuracy: 0.3704\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5428 - accuracy: 0.4993 - val_loss: 2.4729 - val_accuracy: 0.3747\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5519 - accuracy: 0.5030 - val_loss: 2.4664 - val_accuracy: 0.3826\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5557 - accuracy: 0.4984 - val_loss: 2.4835 - val_accuracy: 0.3759\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5424 - accuracy: 0.4990 - val_loss: 2.4896 - val_accuracy: 0.3686\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5221 - accuracy: 0.5136 - val_loss: 2.4836 - val_accuracy: 0.3686\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5474 - accuracy: 0.5002 - val_loss: 2.4877 - val_accuracy: 0.3838\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5424 - accuracy: 0.5030 - val_loss: 2.5050 - val_accuracy: 0.3723\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5228 - accuracy: 0.5095 - val_loss: 2.5055 - val_accuracy: 0.3777\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5242 - accuracy: 0.5052 - val_loss: 2.5004 - val_accuracy: 0.3814\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5008 - accuracy: 0.5134 - val_loss: 2.5063 - val_accuracy: 0.3704\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5038 - accuracy: 0.5044 - val_loss: 2.5193 - val_accuracy: 0.3723\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5063 - accuracy: 0.5114 - val_loss: 2.5144 - val_accuracy: 0.3832\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5207 - accuracy: 0.5082 - val_loss: 2.5196 - val_accuracy: 0.3717\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5211 - accuracy: 0.5101 - val_loss: 2.5334 - val_accuracy: 0.3686\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4939 - accuracy: 0.5095 - val_loss: 2.5320 - val_accuracy: 0.3735\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4831 - accuracy: 0.5170 - val_loss: 2.5519 - val_accuracy: 0.3613\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4899 - accuracy: 0.5108 - val_loss: 2.5394 - val_accuracy: 0.3644\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4664 - accuracy: 0.5234 - val_loss: 2.5487 - val_accuracy: 0.3710\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4997 - accuracy: 0.5154 - val_loss: 2.5491 - val_accuracy: 0.3637\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4958 - accuracy: 0.5214 - val_loss: 2.5645 - val_accuracy: 0.3631\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4853 - accuracy: 0.5120 - val_loss: 2.5503 - val_accuracy: 0.3723\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4801 - accuracy: 0.5216 - val_loss: 2.5476 - val_accuracy: 0.3765\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4830 - accuracy: 0.5185 - val_loss: 2.5646 - val_accuracy: 0.3686\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4909 - accuracy: 0.5194 - val_loss: 2.5757 - val_accuracy: 0.3698\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4512 - accuracy: 0.5189 - val_loss: 2.5703 - val_accuracy: 0.3753\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4714 - accuracy: 0.5217 - val_loss: 2.5812 - val_accuracy: 0.3729\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4874 - accuracy: 0.5095 - val_loss: 2.5873 - val_accuracy: 0.3680\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4515 - accuracy: 0.5207 - val_loss: 2.5961 - val_accuracy: 0.3656\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4661 - accuracy: 0.5279 - val_loss: 2.5976 - val_accuracy: 0.3723\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4751 - accuracy: 0.5176 - val_loss: 2.6044 - val_accuracy: 0.3589\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4661 - accuracy: 0.5205 - val_loss: 2.6093 - val_accuracy: 0.3686\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4603 - accuracy: 0.5182 - val_loss: 2.6165 - val_accuracy: 0.3619\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4553 - accuracy: 0.5138 - val_loss: 2.6124 - val_accuracy: 0.3613\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4476 - accuracy: 0.5281 - val_loss: 2.6198 - val_accuracy: 0.3613\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4421 - accuracy: 0.5224 - val_loss: 2.6332 - val_accuracy: 0.3717\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4629 - accuracy: 0.5220 - val_loss: 2.6199 - val_accuracy: 0.3613\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4593 - accuracy: 0.5165 - val_loss: 2.6261 - val_accuracy: 0.3686\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4495 - accuracy: 0.5254 - val_loss: 2.6503 - val_accuracy: 0.3650\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4553 - accuracy: 0.5289 - val_loss: 2.6395 - val_accuracy: 0.3662\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4318 - accuracy: 0.5270 - val_loss: 2.6397 - val_accuracy: 0.3765\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4132 - accuracy: 0.5420 - val_loss: 2.6530 - val_accuracy: 0.3668\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4188 - accuracy: 0.5346 - val_loss: 2.6346 - val_accuracy: 0.3704\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4512 - accuracy: 0.5241 - val_loss: 2.6592 - val_accuracy: 0.3607\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4506 - accuracy: 0.5234 - val_loss: 2.6667 - val_accuracy: 0.3613\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4358 - accuracy: 0.5271 - val_loss: 2.6573 - val_accuracy: 0.3698\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4228 - accuracy: 0.5283 - val_loss: 2.6624 - val_accuracy: 0.3698\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4188 - accuracy: 0.5334 - val_loss: 2.6647 - val_accuracy: 0.3668\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4229 - accuracy: 0.5315 - val_loss: 2.6660 - val_accuracy: 0.3777\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4295 - accuracy: 0.5294 - val_loss: 2.6715 - val_accuracy: 0.3753\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4189 - accuracy: 0.5446 - val_loss: 2.6896 - val_accuracy: 0.3607\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4105 - accuracy: 0.5379 - val_loss: 2.6903 - val_accuracy: 0.3558\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.5272 - val_loss: 2.6889 - val_accuracy: 0.3668\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4206 - accuracy: 0.5372 - val_loss: 2.6988 - val_accuracy: 0.3686\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4080 - accuracy: 0.5352 - val_loss: 2.6871 - val_accuracy: 0.3686\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4175 - accuracy: 0.5317 - val_loss: 2.6945 - val_accuracy: 0.3619\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4131 - accuracy: 0.5325 - val_loss: 2.6980 - val_accuracy: 0.3692\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4246 - accuracy: 0.5287 - val_loss: 2.6966 - val_accuracy: 0.3589\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.5285 - val_loss: 2.6953 - val_accuracy: 0.3650\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4107 - accuracy: 0.5364 - val_loss: 2.7014 - val_accuracy: 0.3668\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.5430 - val_loss: 2.7212 - val_accuracy: 0.3607\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3898 - accuracy: 0.5330 - val_loss: 2.7156 - val_accuracy: 0.3619\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4144 - accuracy: 0.5339 - val_loss: 2.7172 - val_accuracy: 0.3674\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4065 - accuracy: 0.5358 - val_loss: 2.7169 - val_accuracy: 0.3704\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.5362 - val_loss: 2.7304 - val_accuracy: 0.3698\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4094 - accuracy: 0.5282 - val_loss: 2.7201 - val_accuracy: 0.3674\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3957 - accuracy: 0.5355 - val_loss: 2.7192 - val_accuracy: 0.3686\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3958 - accuracy: 0.5378 - val_loss: 2.7221 - val_accuracy: 0.3607\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4030 - accuracy: 0.5319 - val_loss: 2.7254 - val_accuracy: 0.3723\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4131 - accuracy: 0.5321 - val_loss: 2.7253 - val_accuracy: 0.3680\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4015 - accuracy: 0.5287 - val_loss: 2.7377 - val_accuracy: 0.3631\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3844 - accuracy: 0.5318 - val_loss: 2.7409 - val_accuracy: 0.3613\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3805 - accuracy: 0.5480 - val_loss: 2.7570 - val_accuracy: 0.3607\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3841 - accuracy: 0.5412 - val_loss: 2.7446 - val_accuracy: 0.3619\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3915 - accuracy: 0.5416 - val_loss: 2.7504 - val_accuracy: 0.3619\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3689 - accuracy: 0.5455 - val_loss: 2.7576 - val_accuracy: 0.3589\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3768 - accuracy: 0.5341 - val_loss: 2.7551 - val_accuracy: 0.3637\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3800 - accuracy: 0.5426 - val_loss: 2.7522 - val_accuracy: 0.3692\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.4022 - accuracy: 0.5366 - val_loss: 2.7586 - val_accuracy: 0.3631\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3752 - accuracy: 0.5501 - val_loss: 2.7760 - val_accuracy: 0.3619\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3958 - accuracy: 0.5350 - val_loss: 2.7739 - val_accuracy: 0.3619\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3866 - accuracy: 0.5320 - val_loss: 2.7869 - val_accuracy: 0.3577\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3718 - accuracy: 0.5455 - val_loss: 2.7774 - val_accuracy: 0.3601\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3809 - accuracy: 0.5412 - val_loss: 2.7743 - val_accuracy: 0.3564\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3715 - accuracy: 0.5488 - val_loss: 2.7852 - val_accuracy: 0.3564\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3853 - accuracy: 0.5424 - val_loss: 2.7858 - val_accuracy: 0.3595\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3787 - accuracy: 0.5381 - val_loss: 2.7941 - val_accuracy: 0.3637\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3716 - accuracy: 0.5513 - val_loss: 2.7875 - val_accuracy: 0.3619\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3787 - accuracy: 0.5400 - val_loss: 2.7900 - val_accuracy: 0.3625\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3651 - accuracy: 0.5437 - val_loss: 2.7883 - val_accuracy: 0.3577\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3732 - accuracy: 0.5465 - val_loss: 2.7917 - val_accuracy: 0.3656\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.3625 - accuracy: 0.5595 - val_loss: 2.8069 - val_accuracy: 0.3473\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3714 - accuracy: 0.5463 - val_loss: 2.8181 - val_accuracy: 0.3589\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3775 - accuracy: 0.5519 - val_loss: 2.8135 - val_accuracy: 0.3613\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3619 - accuracy: 0.5401 - val_loss: 2.8030 - val_accuracy: 0.3637\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3610 - accuracy: 0.5502 - val_loss: 2.8054 - val_accuracy: 0.3674\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3657 - accuracy: 0.5486 - val_loss: 2.8156 - val_accuracy: 0.3528\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3804 - accuracy: 0.5418 - val_loss: 2.8107 - val_accuracy: 0.3686\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3710 - accuracy: 0.5416 - val_loss: 2.8184 - val_accuracy: 0.3625\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3833 - accuracy: 0.5391 - val_loss: 2.8171 - val_accuracy: 0.3644\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3695 - accuracy: 0.5388 - val_loss: 2.8224 - val_accuracy: 0.3534\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3574 - accuracy: 0.5526 - val_loss: 2.8218 - val_accuracy: 0.3540\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3684 - accuracy: 0.5474 - val_loss: 2.8226 - val_accuracy: 0.3583\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3642 - accuracy: 0.5476 - val_loss: 2.8198 - val_accuracy: 0.3564\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3468 - accuracy: 0.5489 - val_loss: 2.8277 - val_accuracy: 0.3589\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3685 - accuracy: 0.5452 - val_loss: 2.8248 - val_accuracy: 0.3625\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3601 - accuracy: 0.5318 - val_loss: 2.8369 - val_accuracy: 0.3558\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3511 - accuracy: 0.5504 - val_loss: 2.8388 - val_accuracy: 0.3546\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3646 - accuracy: 0.5467 - val_loss: 2.8390 - val_accuracy: 0.3528\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3641 - accuracy: 0.5424 - val_loss: 2.8369 - val_accuracy: 0.3607\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3457 - accuracy: 0.5478 - val_loss: 2.8362 - val_accuracy: 0.3619\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3548 - accuracy: 0.5452 - val_loss: 2.8498 - val_accuracy: 0.3564\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3414 - accuracy: 0.5473 - val_loss: 2.8378 - val_accuracy: 0.3601\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3380 - accuracy: 0.5512 - val_loss: 2.8441 - val_accuracy: 0.3558\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3619 - accuracy: 0.5442 - val_loss: 2.8413 - val_accuracy: 0.3577\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3450 - accuracy: 0.5480 - val_loss: 2.8485 - val_accuracy: 0.3540\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3521 - accuracy: 0.5432 - val_loss: 2.8375 - val_accuracy: 0.3595\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3488 - accuracy: 0.5501 - val_loss: 2.8545 - val_accuracy: 0.3546\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3584 - accuracy: 0.5404 - val_loss: 2.8477 - val_accuracy: 0.3558\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3324 - accuracy: 0.5515 - val_loss: 2.8500 - val_accuracy: 0.3558\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3436 - accuracy: 0.5445 - val_loss: 2.8624 - val_accuracy: 0.3504\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3565 - accuracy: 0.5371 - val_loss: 2.8589 - val_accuracy: 0.3522\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.5350 - val_loss: 2.8628 - val_accuracy: 0.3552\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3409 - accuracy: 0.5451 - val_loss: 2.8495 - val_accuracy: 0.3577\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3462 - accuracy: 0.5479 - val_loss: 2.8616 - val_accuracy: 0.3491\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3319 - accuracy: 0.5539 - val_loss: 2.8779 - val_accuracy: 0.3522\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3423 - accuracy: 0.5473 - val_loss: 2.8637 - val_accuracy: 0.3558\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3453 - accuracy: 0.5456 - val_loss: 2.8539 - val_accuracy: 0.3625\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3457 - accuracy: 0.5395 - val_loss: 2.8667 - val_accuracy: 0.3607\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3316 - accuracy: 0.5599 - val_loss: 2.8722 - val_accuracy: 0.3516\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3404 - accuracy: 0.5449 - val_loss: 2.8740 - val_accuracy: 0.3510\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3382 - accuracy: 0.5561 - val_loss: 2.8700 - val_accuracy: 0.3674\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3343 - accuracy: 0.5572 - val_loss: 2.8778 - val_accuracy: 0.3498\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3511 - accuracy: 0.5481 - val_loss: 2.8693 - val_accuracy: 0.3564\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3271 - accuracy: 0.5541 - val_loss: 2.8740 - val_accuracy: 0.3595\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3247 - accuracy: 0.5646 - val_loss: 2.8807 - val_accuracy: 0.3571\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3464 - accuracy: 0.5417 - val_loss: 2.8812 - val_accuracy: 0.3583\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3406 - accuracy: 0.5564 - val_loss: 2.8831 - val_accuracy: 0.3485\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3341 - accuracy: 0.5512 - val_loss: 2.9011 - val_accuracy: 0.3595\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3320 - accuracy: 0.5475 - val_loss: 2.8797 - val_accuracy: 0.3564\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3332 - accuracy: 0.5480 - val_loss: 2.9061 - val_accuracy: 0.3510\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3295 - accuracy: 0.5471 - val_loss: 2.9002 - val_accuracy: 0.3498\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3453 - accuracy: 0.5443 - val_loss: 2.8960 - val_accuracy: 0.3571\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3153 - accuracy: 0.5566 - val_loss: 2.8839 - val_accuracy: 0.3564\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3267 - accuracy: 0.5488 - val_loss: 2.9206 - val_accuracy: 0.3406\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3344 - accuracy: 0.5458 - val_loss: 2.8947 - val_accuracy: 0.3552\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3263 - accuracy: 0.5531 - val_loss: 2.8912 - val_accuracy: 0.3583\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3197 - accuracy: 0.5571 - val_loss: 2.9024 - val_accuracy: 0.3467\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3386 - accuracy: 0.5488 - val_loss: 2.8917 - val_accuracy: 0.3546\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.3472 - accuracy: 0.5523 - val_loss: 2.8975 - val_accuracy: 0.3504\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3308 - accuracy: 0.5505 - val_loss: 2.9048 - val_accuracy: 0.3528\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3292 - accuracy: 0.5512 - val_loss: 2.9040 - val_accuracy: 0.3564\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3350 - accuracy: 0.5470 - val_loss: 2.8944 - val_accuracy: 0.3619\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3384 - accuracy: 0.5380 - val_loss: 2.9120 - val_accuracy: 0.3449\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3266 - accuracy: 0.5570 - val_loss: 2.9023 - val_accuracy: 0.3583\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3165 - accuracy: 0.5488 - val_loss: 2.8991 - val_accuracy: 0.3595\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3385 - accuracy: 0.5567 - val_loss: 2.9058 - val_accuracy: 0.3595\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3214 - accuracy: 0.5460 - val_loss: 2.9026 - val_accuracy: 0.3589\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3393 - accuracy: 0.5515 - val_loss: 2.9279 - val_accuracy: 0.3516\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2978 - accuracy: 0.5599 - val_loss: 2.9128 - val_accuracy: 0.3516\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3390 - accuracy: 0.5437 - val_loss: 2.9044 - val_accuracy: 0.3589\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3232 - accuracy: 0.5562 - val_loss: 2.9269 - val_accuracy: 0.3425\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3090 - accuracy: 0.5636 - val_loss: 2.9090 - val_accuracy: 0.3443\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3433 - accuracy: 0.5444 - val_loss: 2.9217 - val_accuracy: 0.3589\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3193 - accuracy: 0.5471 - val_loss: 2.9243 - val_accuracy: 0.3540\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3120 - accuracy: 0.5550 - val_loss: 2.9122 - val_accuracy: 0.3564\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3246 - accuracy: 0.5585 - val_loss: 2.9230 - val_accuracy: 0.3534\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3227 - accuracy: 0.5495 - val_loss: 2.9346 - val_accuracy: 0.3552\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3277 - accuracy: 0.5465 - val_loss: 2.9186 - val_accuracy: 0.3534\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3066 - accuracy: 0.5627 - val_loss: 2.9294 - val_accuracy: 0.3583\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3128 - accuracy: 0.5561 - val_loss: 2.9267 - val_accuracy: 0.3546\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3239 - accuracy: 0.5486 - val_loss: 2.9432 - val_accuracy: 0.3571\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3144 - accuracy: 0.5565 - val_loss: 2.9344 - val_accuracy: 0.3534\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3267 - accuracy: 0.5545 - val_loss: 2.9559 - val_accuracy: 0.3491\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3242 - accuracy: 0.5567 - val_loss: 2.9455 - val_accuracy: 0.3528\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3251 - accuracy: 0.5574 - val_loss: 2.9372 - val_accuracy: 0.3546\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3121 - accuracy: 0.5593 - val_loss: 2.9493 - val_accuracy: 0.3498\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3235 - accuracy: 0.5497 - val_loss: 2.9413 - val_accuracy: 0.3540\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3332 - accuracy: 0.5366 - val_loss: 2.9312 - val_accuracy: 0.3589\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3266 - accuracy: 0.5575 - val_loss: 2.9414 - val_accuracy: 0.3449\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3325 - accuracy: 0.5484 - val_loss: 2.9400 - val_accuracy: 0.3510\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3162 - accuracy: 0.5601 - val_loss: 2.9497 - val_accuracy: 0.3473\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.5514 - val_loss: 2.9293 - val_accuracy: 0.3564\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3221 - accuracy: 0.5597 - val_loss: 2.9363 - val_accuracy: 0.3443\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3123 - accuracy: 0.5455 - val_loss: 2.9435 - val_accuracy: 0.3546\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2993 - accuracy: 0.5579 - val_loss: 2.9568 - val_accuracy: 0.3577\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3025 - accuracy: 0.5579 - val_loss: 2.9618 - val_accuracy: 0.3504\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3091 - accuracy: 0.5421 - val_loss: 2.9483 - val_accuracy: 0.3479\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3171 - accuracy: 0.5541 - val_loss: 2.9486 - val_accuracy: 0.3583\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3130 - accuracy: 0.5516 - val_loss: 2.9485 - val_accuracy: 0.3577\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3020 - accuracy: 0.5574 - val_loss: 2.9588 - val_accuracy: 0.3637\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5578 - val_loss: 2.9696 - val_accuracy: 0.3558\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5569 - val_loss: 2.9693 - val_accuracy: 0.3552\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.5582 - val_loss: 2.9615 - val_accuracy: 0.3498\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2899 - accuracy: 0.5628 - val_loss: 2.9636 - val_accuracy: 0.3504\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3188 - accuracy: 0.5578 - val_loss: 2.9741 - val_accuracy: 0.3552\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3218 - accuracy: 0.5513 - val_loss: 2.9700 - val_accuracy: 0.3589\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.3084 - accuracy: 0.5583 - val_loss: 2.9747 - val_accuracy: 0.3510\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3109 - accuracy: 0.5590 - val_loss: 2.9664 - val_accuracy: 0.3516\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3197 - accuracy: 0.5451 - val_loss: 2.9754 - val_accuracy: 0.3449\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3054 - accuracy: 0.5545 - val_loss: 2.9564 - val_accuracy: 0.3534\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3202 - accuracy: 0.5441 - val_loss: 2.9765 - val_accuracy: 0.3491\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3206 - accuracy: 0.5511 - val_loss: 2.9711 - val_accuracy: 0.3516\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2938 - accuracy: 0.5635 - val_loss: 2.9638 - val_accuracy: 0.3461\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3233 - accuracy: 0.5548 - val_loss: 2.9816 - val_accuracy: 0.3461\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3320 - accuracy: 0.5433 - val_loss: 2.9849 - val_accuracy: 0.3558\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3057 - accuracy: 0.5525 - val_loss: 2.9876 - val_accuracy: 0.3528\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3081 - accuracy: 0.5537 - val_loss: 2.9683 - val_accuracy: 0.3564\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3211 - accuracy: 0.5475 - val_loss: 2.9770 - val_accuracy: 0.3491\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2910 - accuracy: 0.5603 - val_loss: 2.9719 - val_accuracy: 0.3528\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3059 - accuracy: 0.5558 - val_loss: 2.9761 - val_accuracy: 0.3564\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3151 - accuracy: 0.5567 - val_loss: 2.9796 - val_accuracy: 0.3540\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3148 - accuracy: 0.5454 - val_loss: 2.9815 - val_accuracy: 0.3601\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2985 - accuracy: 0.5682 - val_loss: 2.9907 - val_accuracy: 0.3491\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3064 - accuracy: 0.5565 - val_loss: 2.9866 - val_accuracy: 0.3595\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3038 - accuracy: 0.5678 - val_loss: 2.9854 - val_accuracy: 0.3504\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3040 - accuracy: 0.5507 - val_loss: 2.9929 - val_accuracy: 0.3467\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3050 - accuracy: 0.5477 - val_loss: 2.9916 - val_accuracy: 0.3455\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2927 - accuracy: 0.5675 - val_loss: 2.9858 - val_accuracy: 0.3467\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5555 - val_loss: 2.9779 - val_accuracy: 0.3522\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3035 - accuracy: 0.5582 - val_loss: 3.0013 - val_accuracy: 0.3498\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2888 - accuracy: 0.5584 - val_loss: 2.9989 - val_accuracy: 0.3522\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3070 - accuracy: 0.5528 - val_loss: 2.9949 - val_accuracy: 0.3504\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2977 - accuracy: 0.5542 - val_loss: 2.9860 - val_accuracy: 0.3473\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3034 - accuracy: 0.5569 - val_loss: 2.9937 - val_accuracy: 0.3449\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3007 - accuracy: 0.5590 - val_loss: 2.9907 - val_accuracy: 0.3455\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3085 - accuracy: 0.5544 - val_loss: 2.9814 - val_accuracy: 0.3528\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3048 - accuracy: 0.5592 - val_loss: 3.0006 - val_accuracy: 0.3394\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3022 - accuracy: 0.5568 - val_loss: 3.0139 - val_accuracy: 0.3412\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2934 - accuracy: 0.5504 - val_loss: 2.9960 - val_accuracy: 0.3558\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2979 - accuracy: 0.5535 - val_loss: 2.9967 - val_accuracy: 0.3589\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3086 - accuracy: 0.5546 - val_loss: 2.9821 - val_accuracy: 0.3686\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2985 - accuracy: 0.5606 - val_loss: 3.0097 - val_accuracy: 0.3601\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3007 - accuracy: 0.5550 - val_loss: 3.0072 - val_accuracy: 0.3516\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3060 - accuracy: 0.5513 - val_loss: 2.9991 - val_accuracy: 0.3540\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2793 - accuracy: 0.5650 - val_loss: 3.0049 - val_accuracy: 0.3571\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3030 - accuracy: 0.5538 - val_loss: 3.0056 - val_accuracy: 0.3510\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2799 - accuracy: 0.5641 - val_loss: 3.0103 - val_accuracy: 0.3540\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3013 - accuracy: 0.5525 - val_loss: 3.0180 - val_accuracy: 0.3504\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2964 - accuracy: 0.5611 - val_loss: 3.0109 - val_accuracy: 0.3522\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3088 - accuracy: 0.5578 - val_loss: 3.0176 - val_accuracy: 0.3534\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2936 - accuracy: 0.5535 - val_loss: 3.0022 - val_accuracy: 0.3510\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2936 - accuracy: 0.5538 - val_loss: 3.0053 - val_accuracy: 0.3564\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2859 - accuracy: 0.5501 - val_loss: 3.0060 - val_accuracy: 0.3437\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2934 - accuracy: 0.5527 - val_loss: 3.0238 - val_accuracy: 0.3491\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.3065 - accuracy: 0.5511 - val_loss: 3.0097 - val_accuracy: 0.3577\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3003 - accuracy: 0.5586 - val_loss: 3.0190 - val_accuracy: 0.3467\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3008 - accuracy: 0.5541 - val_loss: 3.0166 - val_accuracy: 0.3540\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3002 - accuracy: 0.5552 - val_loss: 3.0312 - val_accuracy: 0.3510\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2885 - accuracy: 0.5543 - val_loss: 3.0134 - val_accuracy: 0.3577\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2923 - accuracy: 0.5585 - val_loss: 3.0200 - val_accuracy: 0.3522\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5551 - val_loss: 3.0062 - val_accuracy: 0.3644\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3053 - accuracy: 0.5508 - val_loss: 3.0252 - val_accuracy: 0.3564\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2986 - accuracy: 0.5531 - val_loss: 3.0309 - val_accuracy: 0.3516\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2961 - accuracy: 0.5475 - val_loss: 3.0237 - val_accuracy: 0.3522\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2954 - accuracy: 0.5595 - val_loss: 3.0372 - val_accuracy: 0.3510\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3060 - accuracy: 0.5606 - val_loss: 3.0191 - val_accuracy: 0.3540\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2938 - accuracy: 0.5550 - val_loss: 3.0418 - val_accuracy: 0.3491\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2839 - accuracy: 0.5616 - val_loss: 3.0346 - val_accuracy: 0.3418\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2796 - accuracy: 0.5539 - val_loss: 3.0372 - val_accuracy: 0.3540\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3017 - accuracy: 0.5615 - val_loss: 3.0280 - val_accuracy: 0.3540\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.5584 - val_loss: 3.0221 - val_accuracy: 0.3528\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3018 - accuracy: 0.5614 - val_loss: 3.0379 - val_accuracy: 0.3467\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2899 - accuracy: 0.5607 - val_loss: 3.0412 - val_accuracy: 0.3510\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5588 - val_loss: 3.0305 - val_accuracy: 0.3431\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2766 - accuracy: 0.5736 - val_loss: 3.0422 - val_accuracy: 0.3376\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2974 - accuracy: 0.5545 - val_loss: 3.0314 - val_accuracy: 0.3498\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2871 - accuracy: 0.5556 - val_loss: 3.0470 - val_accuracy: 0.3431\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2861 - accuracy: 0.5562 - val_loss: 3.0362 - val_accuracy: 0.3485\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2908 - accuracy: 0.5582 - val_loss: 3.0357 - val_accuracy: 0.3522\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2803 - accuracy: 0.5620 - val_loss: 3.0325 - val_accuracy: 0.3571\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3002 - accuracy: 0.5519 - val_loss: 3.0455 - val_accuracy: 0.3522\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2840 - accuracy: 0.5575 - val_loss: 3.0251 - val_accuracy: 0.3461\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2842 - accuracy: 0.5648 - val_loss: 3.0276 - val_accuracy: 0.3516\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2757 - accuracy: 0.5644 - val_loss: 3.0350 - val_accuracy: 0.3546\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2732 - accuracy: 0.5606 - val_loss: 3.0280 - val_accuracy: 0.3461\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2954 - accuracy: 0.5528 - val_loss: 3.0222 - val_accuracy: 0.3564\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.5686 - val_loss: 3.0398 - val_accuracy: 0.3546\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2896 - accuracy: 0.5555 - val_loss: 3.0382 - val_accuracy: 0.3637\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2778 - accuracy: 0.5625 - val_loss: 3.0338 - val_accuracy: 0.3577\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2745 - accuracy: 0.5721 - val_loss: 3.0365 - val_accuracy: 0.3485\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2924 - accuracy: 0.5658 - val_loss: 3.0533 - val_accuracy: 0.3461\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2954 - accuracy: 0.5618 - val_loss: 3.0380 - val_accuracy: 0.3491\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2910 - accuracy: 0.5583 - val_loss: 3.0527 - val_accuracy: 0.3431\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2753 - accuracy: 0.5645 - val_loss: 3.0413 - val_accuracy: 0.3479\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3006 - accuracy: 0.5610 - val_loss: 3.0628 - val_accuracy: 0.3443\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2892 - accuracy: 0.5629 - val_loss: 3.0485 - val_accuracy: 0.3595\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2811 - accuracy: 0.5638 - val_loss: 3.0507 - val_accuracy: 0.3558\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2878 - accuracy: 0.5543 - val_loss: 3.0571 - val_accuracy: 0.3564\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2859 - accuracy: 0.5575 - val_loss: 3.0563 - val_accuracy: 0.3443\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2969 - accuracy: 0.5567 - val_loss: 3.0617 - val_accuracy: 0.3467\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2883 - accuracy: 0.5626 - val_loss: 3.0516 - val_accuracy: 0.3418\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2830 - accuracy: 0.5611 - val_loss: 3.0679 - val_accuracy: 0.3479\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2903 - accuracy: 0.5622 - val_loss: 3.0565 - val_accuracy: 0.3425\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2723 - accuracy: 0.5640 - val_loss: 3.0560 - val_accuracy: 0.3552\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5535 - val_loss: 3.0555 - val_accuracy: 0.3540\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2889 - accuracy: 0.5534 - val_loss: 3.0568 - val_accuracy: 0.3504\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2783 - accuracy: 0.5618 - val_loss: 3.0734 - val_accuracy: 0.3485\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2872 - accuracy: 0.5576 - val_loss: 3.0594 - val_accuracy: 0.3473\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.3009 - accuracy: 0.5459 - val_loss: 3.0727 - val_accuracy: 0.3479\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2997 - accuracy: 0.5558 - val_loss: 3.0761 - val_accuracy: 0.3558\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2864 - accuracy: 0.5618 - val_loss: 3.0684 - val_accuracy: 0.3571\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2902 - accuracy: 0.5568 - val_loss: 3.0544 - val_accuracy: 0.3552\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2768 - accuracy: 0.5570 - val_loss: 3.0495 - val_accuracy: 0.3498\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.5539 - val_loss: 3.0644 - val_accuracy: 0.3491\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2749 - accuracy: 0.5599 - val_loss: 3.0669 - val_accuracy: 0.3558\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2801 - accuracy: 0.5599 - val_loss: 3.0588 - val_accuracy: 0.3479\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2999 - accuracy: 0.5493 - val_loss: 3.0572 - val_accuracy: 0.3552\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2941 - accuracy: 0.5521 - val_loss: 3.0743 - val_accuracy: 0.3491\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2721 - accuracy: 0.5563 - val_loss: 3.0626 - val_accuracy: 0.3589\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2892 - accuracy: 0.5487 - val_loss: 3.0567 - val_accuracy: 0.3595\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2711 - accuracy: 0.5690 - val_loss: 3.0714 - val_accuracy: 0.3528\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2781 - accuracy: 0.5687 - val_loss: 3.0648 - val_accuracy: 0.3516\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2819 - accuracy: 0.5588 - val_loss: 3.0712 - val_accuracy: 0.3564\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2721 - accuracy: 0.5655 - val_loss: 3.0632 - val_accuracy: 0.3564\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2909 - accuracy: 0.5602 - val_loss: 3.0690 - val_accuracy: 0.3540\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2831 - accuracy: 0.5576 - val_loss: 3.0661 - val_accuracy: 0.3540\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2878 - accuracy: 0.5580 - val_loss: 3.0595 - val_accuracy: 0.3564\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.5669 - val_loss: 3.0823 - val_accuracy: 0.3510\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2707 - accuracy: 0.5632 - val_loss: 3.0771 - val_accuracy: 0.3516\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2825 - accuracy: 0.5613 - val_loss: 3.0728 - val_accuracy: 0.3473\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.5587 - val_loss: 3.0820 - val_accuracy: 0.3504\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2683 - accuracy: 0.5618 - val_loss: 3.0779 - val_accuracy: 0.3479\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2723 - accuracy: 0.5643 - val_loss: 3.0731 - val_accuracy: 0.3382\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2669 - accuracy: 0.5543 - val_loss: 3.0734 - val_accuracy: 0.3425\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.5620 - val_loss: 3.0768 - val_accuracy: 0.3504\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2699 - accuracy: 0.5612 - val_loss: 3.0801 - val_accuracy: 0.3564\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2731 - accuracy: 0.5620 - val_loss: 3.0856 - val_accuracy: 0.3510\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2830 - accuracy: 0.5604 - val_loss: 3.0723 - val_accuracy: 0.3461\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5475 - val_loss: 3.0826 - val_accuracy: 0.3491\n",
      "Epoch 388/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2767 - accuracy: 0.5594 - val_loss: 3.0786 - val_accuracy: 0.3510\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2901 - accuracy: 0.5547 - val_loss: 3.0912 - val_accuracy: 0.3485\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2802 - accuracy: 0.5611 - val_loss: 3.0763 - val_accuracy: 0.3491\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2622 - accuracy: 0.5695 - val_loss: 3.0662 - val_accuracy: 0.3540\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2745 - accuracy: 0.5632 - val_loss: 3.0830 - val_accuracy: 0.3473\n",
      "Epoch 393/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2579 - accuracy: 0.5714 - val_loss: 3.0719 - val_accuracy: 0.3552\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2820 - accuracy: 0.5573 - val_loss: 3.0797 - val_accuracy: 0.3516\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2706 - accuracy: 0.5558 - val_loss: 3.0958 - val_accuracy: 0.3473\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2783 - accuracy: 0.5525 - val_loss: 3.0872 - val_accuracy: 0.3522\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2650 - accuracy: 0.5625 - val_loss: 3.0971 - val_accuracy: 0.3498\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2903 - accuracy: 0.5609 - val_loss: 3.0901 - val_accuracy: 0.3516\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2733 - accuracy: 0.5666 - val_loss: 3.1045 - val_accuracy: 0.3558\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2796 - accuracy: 0.5591 - val_loss: 3.0749 - val_accuracy: 0.3473\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2773 - accuracy: 0.5545 - val_loss: 3.0923 - val_accuracy: 0.3394\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2780 - accuracy: 0.5629 - val_loss: 3.0827 - val_accuracy: 0.3613\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2980 - accuracy: 0.5481 - val_loss: 3.0904 - val_accuracy: 0.3534\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2691 - accuracy: 0.5586 - val_loss: 3.0887 - val_accuracy: 0.3589\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2728 - accuracy: 0.5615 - val_loss: 3.0952 - val_accuracy: 0.3619\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2712 - accuracy: 0.5693 - val_loss: 3.0861 - val_accuracy: 0.3485\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2836 - accuracy: 0.5575 - val_loss: 3.0858 - val_accuracy: 0.3516\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2909 - accuracy: 0.5507 - val_loss: 3.0788 - val_accuracy: 0.3577\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2617 - accuracy: 0.5687 - val_loss: 3.0954 - val_accuracy: 0.3467\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2951 - accuracy: 0.5641 - val_loss: 3.0850 - val_accuracy: 0.3498\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2736 - accuracy: 0.5639 - val_loss: 3.0880 - val_accuracy: 0.3546\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2696 - accuracy: 0.5657 - val_loss: 3.0923 - val_accuracy: 0.3425\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.5542 - val_loss: 3.1088 - val_accuracy: 0.3498\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2684 - accuracy: 0.5655 - val_loss: 3.1144 - val_accuracy: 0.3528\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2560 - accuracy: 0.5618 - val_loss: 3.0957 - val_accuracy: 0.3583\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2824 - accuracy: 0.5606 - val_loss: 3.1048 - val_accuracy: 0.3485\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2720 - accuracy: 0.5645 - val_loss: 3.1300 - val_accuracy: 0.3479\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2500 - accuracy: 0.5585 - val_loss: 3.1089 - val_accuracy: 0.3479\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2670 - accuracy: 0.5481 - val_loss: 3.1074 - val_accuracy: 0.3564\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2694 - accuracy: 0.5557 - val_loss: 3.1019 - val_accuracy: 0.3431\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2727 - accuracy: 0.5573 - val_loss: 3.1124 - val_accuracy: 0.3534\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2594 - accuracy: 0.5627 - val_loss: 3.1043 - val_accuracy: 0.3528\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2773 - accuracy: 0.5587 - val_loss: 3.1197 - val_accuracy: 0.3540\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2658 - accuracy: 0.5573 - val_loss: 3.1116 - val_accuracy: 0.3522\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2816 - accuracy: 0.5572 - val_loss: 3.0860 - val_accuracy: 0.3522\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2721 - accuracy: 0.5598 - val_loss: 3.1148 - val_accuracy: 0.3558\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2901 - accuracy: 0.5546 - val_loss: 3.1106 - val_accuracy: 0.3546\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2691 - accuracy: 0.5662 - val_loss: 3.1090 - val_accuracy: 0.3491\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2677 - accuracy: 0.5537 - val_loss: 3.1078 - val_accuracy: 0.3491\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2708 - accuracy: 0.5623 - val_loss: 3.1051 - val_accuracy: 0.3546\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2803 - accuracy: 0.5609 - val_loss: 3.0977 - val_accuracy: 0.3437\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2939 - accuracy: 0.5588 - val_loss: 3.1269 - val_accuracy: 0.3455\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2670 - accuracy: 0.5619 - val_loss: 3.1144 - val_accuracy: 0.3504\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.5621 - val_loss: 3.1182 - val_accuracy: 0.3534\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2830 - accuracy: 0.5634 - val_loss: 3.1013 - val_accuracy: 0.3564\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2668 - accuracy: 0.5624 - val_loss: 3.1238 - val_accuracy: 0.3467\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2641 - accuracy: 0.5627 - val_loss: 3.1107 - val_accuracy: 0.3601\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2705 - accuracy: 0.5619 - val_loss: 3.1155 - val_accuracy: 0.3504\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2882 - accuracy: 0.5628 - val_loss: 3.1138 - val_accuracy: 0.3467\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2820 - accuracy: 0.5652 - val_loss: 3.1155 - val_accuracy: 0.3491\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2735 - accuracy: 0.5557 - val_loss: 3.1332 - val_accuracy: 0.3504\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2692 - accuracy: 0.5617 - val_loss: 3.1191 - val_accuracy: 0.3455\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2602 - accuracy: 0.5651 - val_loss: 3.1123 - val_accuracy: 0.3516\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2632 - accuracy: 0.5615 - val_loss: 3.1362 - val_accuracy: 0.3552\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2619 - accuracy: 0.5574 - val_loss: 3.1157 - val_accuracy: 0.3425\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2804 - accuracy: 0.5604 - val_loss: 3.1093 - val_accuracy: 0.3467\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2733 - accuracy: 0.5553 - val_loss: 3.1165 - val_accuracy: 0.3498\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2732 - accuracy: 0.5576 - val_loss: 3.1098 - val_accuracy: 0.3516\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2721 - accuracy: 0.5605 - val_loss: 3.1214 - val_accuracy: 0.3613\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2837 - accuracy: 0.5503 - val_loss: 3.1188 - val_accuracy: 0.3498\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2808 - accuracy: 0.5574 - val_loss: 3.1367 - val_accuracy: 0.3498\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2730 - accuracy: 0.5525 - val_loss: 3.1261 - val_accuracy: 0.3522\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2674 - accuracy: 0.5632 - val_loss: 3.1118 - val_accuracy: 0.3644\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2701 - accuracy: 0.5619 - val_loss: 3.1137 - val_accuracy: 0.3522\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2722 - accuracy: 0.5631 - val_loss: 3.1087 - val_accuracy: 0.3491\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2806 - accuracy: 0.5620 - val_loss: 3.1262 - val_accuracy: 0.3558\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2733 - accuracy: 0.5565 - val_loss: 3.1126 - val_accuracy: 0.3534\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2584 - accuracy: 0.5675 - val_loss: 3.1078 - val_accuracy: 0.3516\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2837 - accuracy: 0.5553 - val_loss: 3.1213 - val_accuracy: 0.3510\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2486 - accuracy: 0.5605 - val_loss: 3.1217 - val_accuracy: 0.3479\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2704 - accuracy: 0.5580 - val_loss: 3.1247 - val_accuracy: 0.3491\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.5616 - val_loss: 3.1235 - val_accuracy: 0.3491\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2623 - accuracy: 0.5633 - val_loss: 3.1313 - val_accuracy: 0.3552\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2628 - accuracy: 0.5655 - val_loss: 3.1167 - val_accuracy: 0.3431\n",
      "Epoch 465/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.5553 - val_loss: 3.1297 - val_accuracy: 0.3510\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2628 - accuracy: 0.5559 - val_loss: 3.1362 - val_accuracy: 0.3437\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2823 - accuracy: 0.5531 - val_loss: 3.1404 - val_accuracy: 0.3540\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2605 - accuracy: 0.5621 - val_loss: 3.1359 - val_accuracy: 0.3534\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2760 - accuracy: 0.5539 - val_loss: 3.1299 - val_accuracy: 0.3540\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2786 - accuracy: 0.5581 - val_loss: 3.1240 - val_accuracy: 0.3491\n",
      "Epoch 471/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2794 - accuracy: 0.5568 - val_loss: 3.1325 - val_accuracy: 0.3449\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2630 - accuracy: 0.5655 - val_loss: 3.1302 - val_accuracy: 0.3571\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2554 - accuracy: 0.5675 - val_loss: 3.1281 - val_accuracy: 0.3479\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2704 - accuracy: 0.5610 - val_loss: 3.1500 - val_accuracy: 0.3498\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2664 - accuracy: 0.5558 - val_loss: 3.1324 - val_accuracy: 0.3595\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2662 - accuracy: 0.5604 - val_loss: 3.1305 - val_accuracy: 0.3546\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2671 - accuracy: 0.5511 - val_loss: 3.1377 - val_accuracy: 0.3644\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2569 - accuracy: 0.5659 - val_loss: 3.1259 - val_accuracy: 0.3546\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2574 - accuracy: 0.5589 - val_loss: 3.1387 - val_accuracy: 0.3583\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2653 - accuracy: 0.5622 - val_loss: 3.1247 - val_accuracy: 0.3510\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2677 - accuracy: 0.5558 - val_loss: 3.1321 - val_accuracy: 0.3534\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2771 - accuracy: 0.5624 - val_loss: 3.1471 - val_accuracy: 0.3577\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2578 - accuracy: 0.5608 - val_loss: 3.1534 - val_accuracy: 0.3455\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2704 - accuracy: 0.5606 - val_loss: 3.1256 - val_accuracy: 0.3595\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2734 - accuracy: 0.5610 - val_loss: 3.1260 - val_accuracy: 0.3540\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2564 - accuracy: 0.5708 - val_loss: 3.1220 - val_accuracy: 0.3425\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2662 - accuracy: 0.5580 - val_loss: 3.1311 - val_accuracy: 0.3522\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2591 - accuracy: 0.5545 - val_loss: 3.1323 - val_accuracy: 0.3583\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2693 - accuracy: 0.5516 - val_loss: 3.1267 - val_accuracy: 0.3571\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2802 - accuracy: 0.5603 - val_loss: 3.1357 - val_accuracy: 0.3443\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2574 - accuracy: 0.5600 - val_loss: 3.1359 - val_accuracy: 0.3437\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2845 - accuracy: 0.5535 - val_loss: 3.1335 - val_accuracy: 0.3498\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2515 - accuracy: 0.5656 - val_loss: 3.1301 - val_accuracy: 0.3473\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2710 - accuracy: 0.5607 - val_loss: 3.1418 - val_accuracy: 0.3528\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2442 - accuracy: 0.5636 - val_loss: 3.1414 - val_accuracy: 0.3510\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2832 - accuracy: 0.5573 - val_loss: 3.1341 - val_accuracy: 0.3540\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2827 - accuracy: 0.5526 - val_loss: 3.1275 - val_accuracy: 0.3473\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2609 - accuracy: 0.5602 - val_loss: 3.1429 - val_accuracy: 0.3504\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2653 - accuracy: 0.5598 - val_loss: 3.1433 - val_accuracy: 0.3528\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.5663 - val_loss: 3.1374 - val_accuracy: 0.3558\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2608 - accuracy: 0.5622 - val_loss: 3.1415 - val_accuracy: 0.3449\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2557 - accuracy: 0.5679 - val_loss: 3.1412 - val_accuracy: 0.3540\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2623 - accuracy: 0.5543 - val_loss: 3.1457 - val_accuracy: 0.3540\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2704 - accuracy: 0.5627 - val_loss: 3.1572 - val_accuracy: 0.3431\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2674 - accuracy: 0.5561 - val_loss: 3.1456 - val_accuracy: 0.3498\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.5674 - val_loss: 3.1220 - val_accuracy: 0.3644\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2604 - accuracy: 0.5653 - val_loss: 3.1285 - val_accuracy: 0.3504\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2792 - accuracy: 0.5563 - val_loss: 3.1450 - val_accuracy: 0.3352\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2451 - accuracy: 0.5676 - val_loss: 3.1324 - val_accuracy: 0.3473\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2618 - accuracy: 0.5492 - val_loss: 3.1433 - val_accuracy: 0.3479\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2703 - accuracy: 0.5583 - val_loss: 3.1368 - val_accuracy: 0.3528\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2654 - accuracy: 0.5625 - val_loss: 3.1454 - val_accuracy: 0.3467\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2635 - accuracy: 0.5667 - val_loss: 3.1480 - val_accuracy: 0.3546\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2672 - accuracy: 0.5522 - val_loss: 3.1452 - val_accuracy: 0.3613\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2766 - accuracy: 0.5594 - val_loss: 3.1472 - val_accuracy: 0.3522\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2638 - accuracy: 0.5580 - val_loss: 3.1551 - val_accuracy: 0.3540\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2823 - accuracy: 0.5500 - val_loss: 3.1495 - val_accuracy: 0.3528\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2472 - accuracy: 0.5688 - val_loss: 3.1477 - val_accuracy: 0.3589\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2561 - accuracy: 0.5575 - val_loss: 3.1577 - val_accuracy: 0.3558\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2819 - accuracy: 0.5564 - val_loss: 3.1506 - val_accuracy: 0.3546\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2607 - accuracy: 0.5616 - val_loss: 3.1356 - val_accuracy: 0.3540\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2682 - accuracy: 0.5492 - val_loss: 3.1534 - val_accuracy: 0.3473\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2640 - accuracy: 0.5629 - val_loss: 3.1499 - val_accuracy: 0.3491\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2570 - accuracy: 0.5631 - val_loss: 3.1700 - val_accuracy: 0.3479\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2777 - accuracy: 0.5545 - val_loss: 3.1654 - val_accuracy: 0.3510\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.5549 - val_loss: 3.1462 - val_accuracy: 0.3388\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2487 - accuracy: 0.5686 - val_loss: 3.1532 - val_accuracy: 0.3601\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2687 - accuracy: 0.5584 - val_loss: 3.1598 - val_accuracy: 0.3504\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2535 - accuracy: 0.5634 - val_loss: 3.1505 - val_accuracy: 0.3534\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2625 - accuracy: 0.5621 - val_loss: 3.1673 - val_accuracy: 0.3437\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2702 - accuracy: 0.5599 - val_loss: 3.1622 - val_accuracy: 0.3431\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2753 - accuracy: 0.5559 - val_loss: 3.1622 - val_accuracy: 0.3449\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2642 - accuracy: 0.5649 - val_loss: 3.1560 - val_accuracy: 0.3491\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2592 - accuracy: 0.5633 - val_loss: 3.1718 - val_accuracy: 0.3467\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2608 - accuracy: 0.5562 - val_loss: 3.1685 - val_accuracy: 0.3510\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2759 - accuracy: 0.5523 - val_loss: 3.1630 - val_accuracy: 0.3504\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2609 - accuracy: 0.5561 - val_loss: 3.1584 - val_accuracy: 0.3522\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2715 - accuracy: 0.5557 - val_loss: 3.1545 - val_accuracy: 0.3516\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2583 - accuracy: 0.5647 - val_loss: 3.1625 - val_accuracy: 0.3418\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2511 - accuracy: 0.5629 - val_loss: 3.1676 - val_accuracy: 0.3437\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2732 - accuracy: 0.5641 - val_loss: 3.1792 - val_accuracy: 0.3473\n",
      "Epoch 542/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2617 - accuracy: 0.5670 - val_loss: 3.1816 - val_accuracy: 0.3443\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2570 - accuracy: 0.5668 - val_loss: 3.1702 - val_accuracy: 0.3528\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2536 - accuracy: 0.5588 - val_loss: 3.1636 - val_accuracy: 0.3485\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2657 - accuracy: 0.5606 - val_loss: 3.1763 - val_accuracy: 0.3510\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2547 - accuracy: 0.5575 - val_loss: 3.1739 - val_accuracy: 0.3473\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2749 - accuracy: 0.5525 - val_loss: 3.1684 - val_accuracy: 0.3540\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2521 - accuracy: 0.5596 - val_loss: 3.1662 - val_accuracy: 0.3461\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2735 - accuracy: 0.5606 - val_loss: 3.1593 - val_accuracy: 0.3504\n",
      "Epoch 550/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2516 - accuracy: 0.5653 - val_loss: 3.1673 - val_accuracy: 0.3461\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.5608 - val_loss: 3.1794 - val_accuracy: 0.3443\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2617 - accuracy: 0.5548 - val_loss: 3.1592 - val_accuracy: 0.3564\n",
      "Epoch 553/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2576 - accuracy: 0.5595 - val_loss: 3.1776 - val_accuracy: 0.3443\n",
      "Epoch 554/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2539 - accuracy: 0.5614 - val_loss: 3.1804 - val_accuracy: 0.3479\n",
      "Epoch 555/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2652 - accuracy: 0.5626 - val_loss: 3.1611 - val_accuracy: 0.3400\n",
      "Epoch 556/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2721 - accuracy: 0.5594 - val_loss: 3.1758 - val_accuracy: 0.3485\n",
      "Epoch 557/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2536 - accuracy: 0.5617 - val_loss: 3.1863 - val_accuracy: 0.3425\n",
      "Epoch 558/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2595 - accuracy: 0.5614 - val_loss: 3.1980 - val_accuracy: 0.3522\n",
      "Epoch 559/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2692 - accuracy: 0.5647 - val_loss: 3.1804 - val_accuracy: 0.3558\n",
      "Epoch 560/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2647 - accuracy: 0.5578 - val_loss: 3.1629 - val_accuracy: 0.3540\n",
      "Epoch 561/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2712 - accuracy: 0.5575 - val_loss: 3.1828 - val_accuracy: 0.3528\n",
      "Epoch 562/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2493 - accuracy: 0.5685 - val_loss: 3.1679 - val_accuracy: 0.3595\n",
      "Epoch 563/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2661 - accuracy: 0.5580 - val_loss: 3.1638 - val_accuracy: 0.3449\n",
      "Epoch 564/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.5622 - val_loss: 3.1626 - val_accuracy: 0.3595\n",
      "Epoch 565/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2611 - accuracy: 0.5619 - val_loss: 3.1800 - val_accuracy: 0.3546\n",
      "Epoch 566/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.5668 - val_loss: 3.1745 - val_accuracy: 0.3467\n",
      "Epoch 567/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2679 - accuracy: 0.5606 - val_loss: 3.1785 - val_accuracy: 0.3516\n",
      "Epoch 568/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2626 - accuracy: 0.5637 - val_loss: 3.1766 - val_accuracy: 0.3534\n",
      "Epoch 569/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2643 - accuracy: 0.5640 - val_loss: 3.1823 - val_accuracy: 0.3528\n",
      "Epoch 570/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2733 - accuracy: 0.5619 - val_loss: 3.1705 - val_accuracy: 0.3528\n",
      "Epoch 571/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2483 - accuracy: 0.5631 - val_loss: 3.1856 - val_accuracy: 0.3473\n",
      "Epoch 572/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2557 - accuracy: 0.5722 - val_loss: 3.1785 - val_accuracy: 0.3473\n",
      "Epoch 573/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2599 - accuracy: 0.5577 - val_loss: 3.1888 - val_accuracy: 0.3431\n",
      "Epoch 574/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2577 - accuracy: 0.5660 - val_loss: 3.1742 - val_accuracy: 0.3534\n",
      "Epoch 575/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2623 - accuracy: 0.5582 - val_loss: 3.1652 - val_accuracy: 0.3461\n",
      "Epoch 576/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2490 - accuracy: 0.5661 - val_loss: 3.1818 - val_accuracy: 0.3528\n",
      "Epoch 577/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2747 - accuracy: 0.5572 - val_loss: 3.1742 - val_accuracy: 0.3485\n",
      "Epoch 578/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2596 - accuracy: 0.5593 - val_loss: 3.1738 - val_accuracy: 0.3498\n",
      "Epoch 579/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.5641 - val_loss: 3.1823 - val_accuracy: 0.3443\n",
      "Epoch 580/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2735 - accuracy: 0.5575 - val_loss: 3.1853 - val_accuracy: 0.3467\n",
      "Epoch 581/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2708 - accuracy: 0.5493 - val_loss: 3.1828 - val_accuracy: 0.3437\n",
      "Epoch 582/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.5567 - val_loss: 3.1778 - val_accuracy: 0.3485\n",
      "Epoch 583/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2543 - accuracy: 0.5709 - val_loss: 3.1718 - val_accuracy: 0.3491\n",
      "Epoch 584/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2667 - accuracy: 0.5620 - val_loss: 3.1854 - val_accuracy: 0.3522\n",
      "Epoch 585/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2630 - accuracy: 0.5592 - val_loss: 3.1788 - val_accuracy: 0.3558\n",
      "Epoch 586/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2590 - accuracy: 0.5558 - val_loss: 3.1899 - val_accuracy: 0.3552\n",
      "Epoch 587/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2632 - accuracy: 0.5612 - val_loss: 3.1735 - val_accuracy: 0.3491\n",
      "Epoch 588/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.5590 - val_loss: 3.1971 - val_accuracy: 0.3528\n",
      "Epoch 589/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2622 - accuracy: 0.5627 - val_loss: 3.1962 - val_accuracy: 0.3461\n",
      "Epoch 590/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2711 - accuracy: 0.5543 - val_loss: 3.1936 - val_accuracy: 0.3589\n",
      "Epoch 591/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2595 - accuracy: 0.5526 - val_loss: 3.1985 - val_accuracy: 0.3449\n",
      "Epoch 592/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2485 - accuracy: 0.5680 - val_loss: 3.1905 - val_accuracy: 0.3461\n",
      "Epoch 593/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2697 - accuracy: 0.5585 - val_loss: 3.1880 - val_accuracy: 0.3516\n",
      "Epoch 594/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.5693 - val_loss: 3.1868 - val_accuracy: 0.3473\n",
      "Epoch 595/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2594 - accuracy: 0.5542 - val_loss: 3.1796 - val_accuracy: 0.3534\n",
      "Epoch 596/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2620 - accuracy: 0.5641 - val_loss: 3.1980 - val_accuracy: 0.3437\n",
      "Epoch 597/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2451 - accuracy: 0.5590 - val_loss: 3.1825 - val_accuracy: 0.3473\n",
      "Epoch 598/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2555 - accuracy: 0.5625 - val_loss: 3.2002 - val_accuracy: 0.3443\n",
      "Epoch 599/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2377 - accuracy: 0.5586 - val_loss: 3.1950 - val_accuracy: 0.3522\n",
      "Epoch 600/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2396 - accuracy: 0.5691 - val_loss: 3.1843 - val_accuracy: 0.3473\n",
      "Epoch 601/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2571 - accuracy: 0.5617 - val_loss: 3.1776 - val_accuracy: 0.3473\n",
      "Epoch 602/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2571 - accuracy: 0.5595 - val_loss: 3.1860 - val_accuracy: 0.3473\n",
      "Epoch 603/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.5565 - val_loss: 3.1827 - val_accuracy: 0.3644\n",
      "Epoch 604/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2685 - accuracy: 0.5502 - val_loss: 3.1946 - val_accuracy: 0.3510\n",
      "Epoch 605/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2530 - accuracy: 0.5551 - val_loss: 3.1909 - val_accuracy: 0.3534\n",
      "Epoch 606/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2488 - accuracy: 0.5554 - val_loss: 3.1771 - val_accuracy: 0.3625\n",
      "Epoch 607/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2646 - accuracy: 0.5632 - val_loss: 3.1956 - val_accuracy: 0.3522\n",
      "Epoch 608/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2667 - accuracy: 0.5595 - val_loss: 3.1797 - val_accuracy: 0.3504\n",
      "Epoch 609/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2647 - accuracy: 0.5575 - val_loss: 3.1964 - val_accuracy: 0.3540\n",
      "Epoch 610/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2643 - accuracy: 0.5592 - val_loss: 3.1792 - val_accuracy: 0.3571\n",
      "Epoch 611/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2445 - accuracy: 0.5636 - val_loss: 3.1999 - val_accuracy: 0.3467\n",
      "Epoch 612/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2424 - accuracy: 0.5587 - val_loss: 3.1988 - val_accuracy: 0.3467\n",
      "Epoch 613/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2611 - accuracy: 0.5577 - val_loss: 3.1839 - val_accuracy: 0.3485\n",
      "Epoch 614/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2599 - accuracy: 0.5593 - val_loss: 3.1937 - val_accuracy: 0.3449\n",
      "Epoch 615/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2566 - accuracy: 0.5613 - val_loss: 3.2033 - val_accuracy: 0.3516\n",
      "Epoch 616/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2634 - accuracy: 0.5587 - val_loss: 3.1965 - val_accuracy: 0.3583\n",
      "Epoch 617/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2610 - accuracy: 0.5596 - val_loss: 3.1967 - val_accuracy: 0.3449\n",
      "Epoch 618/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2509 - accuracy: 0.5603 - val_loss: 3.2012 - val_accuracy: 0.3473\n",
      "Epoch 619/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2629 - accuracy: 0.5638 - val_loss: 3.2062 - val_accuracy: 0.3491\n",
      "Epoch 620/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2585 - accuracy: 0.5615 - val_loss: 3.1955 - val_accuracy: 0.3455\n",
      "Epoch 621/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2487 - accuracy: 0.5676 - val_loss: 3.2043 - val_accuracy: 0.3479\n",
      "Epoch 622/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2710 - accuracy: 0.5521 - val_loss: 3.1831 - val_accuracy: 0.3534\n",
      "Epoch 623/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.5632 - val_loss: 3.2060 - val_accuracy: 0.3406\n",
      "Epoch 624/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2546 - accuracy: 0.5517 - val_loss: 3.2101 - val_accuracy: 0.3461\n",
      "Epoch 625/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2599 - accuracy: 0.5592 - val_loss: 3.1965 - val_accuracy: 0.3473\n",
      "Epoch 626/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.5695 - val_loss: 3.2093 - val_accuracy: 0.3449\n",
      "Epoch 627/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2465 - accuracy: 0.5666 - val_loss: 3.2103 - val_accuracy: 0.3571\n",
      "Epoch 628/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2607 - accuracy: 0.5667 - val_loss: 3.2241 - val_accuracy: 0.3485\n",
      "Epoch 629/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2553 - accuracy: 0.5652 - val_loss: 3.2005 - val_accuracy: 0.3522\n",
      "Epoch 630/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2575 - accuracy: 0.5598 - val_loss: 3.2041 - val_accuracy: 0.3546\n",
      "Epoch 631/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2673 - accuracy: 0.5555 - val_loss: 3.2035 - val_accuracy: 0.3473\n",
      "Epoch 632/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2465 - accuracy: 0.5636 - val_loss: 3.2148 - val_accuracy: 0.3498\n",
      "Epoch 633/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2543 - accuracy: 0.5549 - val_loss: 3.1865 - val_accuracy: 0.3577\n",
      "Epoch 634/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2674 - accuracy: 0.5547 - val_loss: 3.2099 - val_accuracy: 0.3516\n",
      "Epoch 635/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2677 - accuracy: 0.5599 - val_loss: 3.2029 - val_accuracy: 0.3412\n",
      "Epoch 636/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2506 - accuracy: 0.5620 - val_loss: 3.2050 - val_accuracy: 0.3443\n",
      "Epoch 637/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2522 - accuracy: 0.5633 - val_loss: 3.2090 - val_accuracy: 0.3528\n",
      "Epoch 638/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2525 - accuracy: 0.5571 - val_loss: 3.1940 - val_accuracy: 0.3449\n",
      "Epoch 639/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2645 - accuracy: 0.5577 - val_loss: 3.2118 - val_accuracy: 0.3473\n",
      "Epoch 640/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2562 - accuracy: 0.5583 - val_loss: 3.2052 - val_accuracy: 0.3498\n",
      "Epoch 641/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2402 - accuracy: 0.5654 - val_loss: 3.2101 - val_accuracy: 0.3479\n",
      "Epoch 642/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2674 - accuracy: 0.5502 - val_loss: 3.2162 - val_accuracy: 0.3467\n",
      "Epoch 643/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2565 - accuracy: 0.5690 - val_loss: 3.2200 - val_accuracy: 0.3558\n",
      "Epoch 644/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2470 - accuracy: 0.5640 - val_loss: 3.2154 - val_accuracy: 0.3479\n",
      "Epoch 645/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.5698 - val_loss: 3.2306 - val_accuracy: 0.3552\n",
      "Epoch 646/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2622 - accuracy: 0.5609 - val_loss: 3.2266 - val_accuracy: 0.3479\n",
      "Epoch 647/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2663 - accuracy: 0.5582 - val_loss: 3.2247 - val_accuracy: 0.3571\n",
      "Epoch 648/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2744 - accuracy: 0.5528 - val_loss: 3.2067 - val_accuracy: 0.3504\n",
      "Epoch 649/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5668 - val_loss: 3.2062 - val_accuracy: 0.3467\n",
      "Epoch 650/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2620 - accuracy: 0.5582 - val_loss: 3.2095 - val_accuracy: 0.3418\n",
      "Epoch 651/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2654 - accuracy: 0.5563 - val_loss: 3.2147 - val_accuracy: 0.3589\n",
      "Epoch 652/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2676 - accuracy: 0.5581 - val_loss: 3.2253 - val_accuracy: 0.3498\n",
      "Epoch 653/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 0.5690 - val_loss: 3.2022 - val_accuracy: 0.3516\n",
      "Epoch 654/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.5741 - val_loss: 3.2078 - val_accuracy: 0.3510\n",
      "Epoch 655/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2578 - accuracy: 0.5618 - val_loss: 3.2096 - val_accuracy: 0.3479\n",
      "Epoch 656/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2538 - accuracy: 0.5615 - val_loss: 3.2043 - val_accuracy: 0.3534\n",
      "Epoch 657/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2472 - accuracy: 0.5519 - val_loss: 3.2145 - val_accuracy: 0.3510\n",
      "Epoch 658/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2439 - accuracy: 0.5638 - val_loss: 3.2332 - val_accuracy: 0.3528\n",
      "Epoch 659/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2601 - accuracy: 0.5573 - val_loss: 3.2154 - val_accuracy: 0.3534\n",
      "Epoch 660/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2617 - accuracy: 0.5596 - val_loss: 3.2121 - val_accuracy: 0.3449\n",
      "Epoch 661/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2565 - accuracy: 0.5660 - val_loss: 3.2325 - val_accuracy: 0.3534\n",
      "Epoch 662/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2581 - accuracy: 0.5575 - val_loss: 3.2399 - val_accuracy: 0.3406\n",
      "Epoch 663/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2483 - accuracy: 0.5656 - val_loss: 3.2141 - val_accuracy: 0.3534\n",
      "Epoch 664/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2493 - accuracy: 0.5579 - val_loss: 3.2242 - val_accuracy: 0.3528\n",
      "Epoch 665/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2582 - accuracy: 0.5686 - val_loss: 3.2126 - val_accuracy: 0.3491\n",
      "Epoch 666/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2527 - accuracy: 0.5519 - val_loss: 3.2216 - val_accuracy: 0.3662\n",
      "Epoch 667/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2566 - accuracy: 0.5516 - val_loss: 3.2227 - val_accuracy: 0.3577\n",
      "Epoch 668/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2669 - accuracy: 0.5567 - val_loss: 3.2123 - val_accuracy: 0.3528\n",
      "Epoch 669/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2347 - accuracy: 0.5755 - val_loss: 3.2281 - val_accuracy: 0.3425\n",
      "Epoch 670/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.5601 - val_loss: 3.2202 - val_accuracy: 0.3437\n",
      "Epoch 671/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2551 - accuracy: 0.5681 - val_loss: 3.2180 - val_accuracy: 0.3461\n",
      "Epoch 672/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2601 - accuracy: 0.5621 - val_loss: 3.2446 - val_accuracy: 0.3400\n",
      "Epoch 673/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2419 - accuracy: 0.5618 - val_loss: 3.2196 - val_accuracy: 0.3431\n",
      "Epoch 674/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2529 - accuracy: 0.5620 - val_loss: 3.2249 - val_accuracy: 0.3455\n",
      "Epoch 675/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2623 - accuracy: 0.5621 - val_loss: 3.2121 - val_accuracy: 0.3589\n",
      "Epoch 676/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.5576 - val_loss: 3.2215 - val_accuracy: 0.3528\n",
      "Epoch 677/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2626 - accuracy: 0.5559 - val_loss: 3.2186 - val_accuracy: 0.3522\n",
      "Epoch 678/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.5594 - val_loss: 3.2222 - val_accuracy: 0.3583\n",
      "Epoch 679/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.5529 - val_loss: 3.2240 - val_accuracy: 0.3510\n",
      "Epoch 680/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.5624 - val_loss: 3.2305 - val_accuracy: 0.3571\n",
      "Epoch 681/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2541 - accuracy: 0.5620 - val_loss: 3.2132 - val_accuracy: 0.3479\n",
      "Epoch 682/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.5596 - val_loss: 3.2101 - val_accuracy: 0.3571\n",
      "Epoch 683/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2542 - accuracy: 0.5643 - val_loss: 3.2070 - val_accuracy: 0.3564\n",
      "Epoch 684/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2425 - accuracy: 0.5718 - val_loss: 3.2125 - val_accuracy: 0.3491\n",
      "Epoch 685/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2506 - accuracy: 0.5675 - val_loss: 3.2220 - val_accuracy: 0.3455\n",
      "Epoch 686/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2546 - accuracy: 0.5648 - val_loss: 3.2248 - val_accuracy: 0.3479\n",
      "Epoch 687/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2494 - accuracy: 0.5714 - val_loss: 3.2178 - val_accuracy: 0.3449\n",
      "Epoch 688/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2463 - accuracy: 0.5680 - val_loss: 3.2296 - val_accuracy: 0.3443\n",
      "Epoch 689/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2410 - accuracy: 0.5579 - val_loss: 3.2124 - val_accuracy: 0.3540\n",
      "Epoch 690/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.5597 - val_loss: 3.2250 - val_accuracy: 0.3534\n",
      "Epoch 691/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2574 - accuracy: 0.5555 - val_loss: 3.2269 - val_accuracy: 0.3461\n",
      "Epoch 692/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2524 - accuracy: 0.5606 - val_loss: 3.2259 - val_accuracy: 0.3589\n",
      "Epoch 693/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2507 - accuracy: 0.5624 - val_loss: 3.2336 - val_accuracy: 0.3498\n",
      "Epoch 694/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2443 - accuracy: 0.5753 - val_loss: 3.2395 - val_accuracy: 0.3431\n",
      "Epoch 695/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2532 - accuracy: 0.5643 - val_loss: 3.2289 - val_accuracy: 0.3583\n",
      "Epoch 696/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2624 - accuracy: 0.5561 - val_loss: 3.2297 - val_accuracy: 0.3540\n",
      "Epoch 697/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.5660 - val_loss: 3.2423 - val_accuracy: 0.3376\n",
      "Epoch 698/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2556 - accuracy: 0.5602 - val_loss: 3.2376 - val_accuracy: 0.3491\n",
      "Epoch 699/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2484 - accuracy: 0.5589 - val_loss: 3.2407 - val_accuracy: 0.3473\n",
      "Epoch 700/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2663 - accuracy: 0.5568 - val_loss: 3.2296 - val_accuracy: 0.3516\n",
      "Epoch 701/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2409 - accuracy: 0.5667 - val_loss: 3.2362 - val_accuracy: 0.3418\n",
      "Epoch 702/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2489 - accuracy: 0.5736 - val_loss: 3.2319 - val_accuracy: 0.3552\n",
      "Epoch 703/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2493 - accuracy: 0.5600 - val_loss: 3.2526 - val_accuracy: 0.3473\n",
      "Epoch 704/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2448 - accuracy: 0.5742 - val_loss: 3.2540 - val_accuracy: 0.3564\n",
      "Epoch 705/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2533 - accuracy: 0.5588 - val_loss: 3.2558 - val_accuracy: 0.3504\n",
      "Epoch 706/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2661 - accuracy: 0.5516 - val_loss: 3.2529 - val_accuracy: 0.3510\n",
      "Epoch 707/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2515 - accuracy: 0.5629 - val_loss: 3.2285 - val_accuracy: 0.3558\n",
      "Epoch 708/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2398 - accuracy: 0.5655 - val_loss: 3.2509 - val_accuracy: 0.3437\n",
      "Epoch 709/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.5562 - val_loss: 3.2465 - val_accuracy: 0.3498\n",
      "Epoch 710/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2346 - accuracy: 0.5681 - val_loss: 3.2276 - val_accuracy: 0.3431\n",
      "Epoch 711/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2498 - accuracy: 0.5573 - val_loss: 3.2450 - val_accuracy: 0.3406\n",
      "Epoch 712/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2400 - accuracy: 0.5646 - val_loss: 3.2406 - val_accuracy: 0.3491\n",
      "Epoch 713/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2244 - accuracy: 0.5727 - val_loss: 3.2436 - val_accuracy: 0.3564\n",
      "Epoch 714/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2431 - accuracy: 0.5595 - val_loss: 3.2363 - val_accuracy: 0.3485\n",
      "Epoch 715/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.5770 - val_loss: 3.2367 - val_accuracy: 0.3412\n",
      "Epoch 716/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2405 - accuracy: 0.5678 - val_loss: 3.2383 - val_accuracy: 0.3504\n",
      "Epoch 717/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2310 - accuracy: 0.5705 - val_loss: 3.2446 - val_accuracy: 0.3498\n",
      "Epoch 718/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2487 - accuracy: 0.5645 - val_loss: 3.2485 - val_accuracy: 0.3473\n",
      "Epoch 719/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2301 - accuracy: 0.5716 - val_loss: 3.2431 - val_accuracy: 0.3534\n",
      "Epoch 720/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2464 - accuracy: 0.5684 - val_loss: 3.2448 - val_accuracy: 0.3479\n",
      "Epoch 721/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2425 - accuracy: 0.5703 - val_loss: 3.2572 - val_accuracy: 0.3443\n",
      "Epoch 722/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2517 - accuracy: 0.5599 - val_loss: 3.2437 - val_accuracy: 0.3467\n",
      "Epoch 723/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2618 - accuracy: 0.5534 - val_loss: 3.2445 - val_accuracy: 0.3461\n",
      "Epoch 724/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2593 - accuracy: 0.5591 - val_loss: 3.2208 - val_accuracy: 0.3504\n",
      "Epoch 725/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2506 - accuracy: 0.5583 - val_loss: 3.2543 - val_accuracy: 0.3564\n",
      "Epoch 726/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2369 - accuracy: 0.5730 - val_loss: 3.2373 - val_accuracy: 0.3644\n",
      "Epoch 727/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2579 - accuracy: 0.5568 - val_loss: 3.2449 - val_accuracy: 0.3571\n",
      "Epoch 728/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2491 - accuracy: 0.5690 - val_loss: 3.2358 - val_accuracy: 0.3516\n",
      "Epoch 729/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2449 - accuracy: 0.5646 - val_loss: 3.2536 - val_accuracy: 0.3504\n",
      "Epoch 730/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2412 - accuracy: 0.5618 - val_loss: 3.2434 - val_accuracy: 0.3601\n",
      "Epoch 731/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2375 - accuracy: 0.5621 - val_loss: 3.2509 - val_accuracy: 0.3467\n",
      "Epoch 732/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2481 - accuracy: 0.5600 - val_loss: 3.2390 - val_accuracy: 0.3571\n",
      "Epoch 733/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2502 - accuracy: 0.5604 - val_loss: 3.2540 - val_accuracy: 0.3552\n",
      "Epoch 734/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2526 - accuracy: 0.5617 - val_loss: 3.2392 - val_accuracy: 0.3510\n",
      "Epoch 735/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2477 - accuracy: 0.5617 - val_loss: 3.2346 - val_accuracy: 0.3498\n",
      "Epoch 736/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2492 - accuracy: 0.5654 - val_loss: 3.2416 - val_accuracy: 0.3558\n",
      "Epoch 737/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2479 - accuracy: 0.5648 - val_loss: 3.2463 - val_accuracy: 0.3534\n",
      "Epoch 738/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2525 - accuracy: 0.5582 - val_loss: 3.2389 - val_accuracy: 0.3546\n",
      "Epoch 739/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2464 - accuracy: 0.5578 - val_loss: 3.2540 - val_accuracy: 0.3498\n",
      "Epoch 740/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2487 - accuracy: 0.5683 - val_loss: 3.2512 - val_accuracy: 0.3504\n",
      "Epoch 741/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2616 - accuracy: 0.5595 - val_loss: 3.2434 - val_accuracy: 0.3522\n",
      "Epoch 742/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2519 - accuracy: 0.5616 - val_loss: 3.2359 - val_accuracy: 0.3504\n",
      "Epoch 743/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2482 - accuracy: 0.5593 - val_loss: 3.2512 - val_accuracy: 0.3479\n",
      "Epoch 744/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2656 - accuracy: 0.5516 - val_loss: 3.2402 - val_accuracy: 0.3534\n",
      "Epoch 745/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2564 - accuracy: 0.5581 - val_loss: 3.2475 - val_accuracy: 0.3443\n",
      "Epoch 746/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2636 - accuracy: 0.5592 - val_loss: 3.2479 - val_accuracy: 0.3534\n",
      "Epoch 747/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2595 - accuracy: 0.5583 - val_loss: 3.2494 - val_accuracy: 0.3504\n",
      "Epoch 748/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.5648 - val_loss: 3.2487 - val_accuracy: 0.3491\n",
      "Epoch 749/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2584 - accuracy: 0.5549 - val_loss: 3.2419 - val_accuracy: 0.3522\n",
      "Epoch 750/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2449 - accuracy: 0.5622 - val_loss: 3.2374 - val_accuracy: 0.3467\n",
      "Epoch 751/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.5544 - val_loss: 3.2601 - val_accuracy: 0.3644\n",
      "Epoch 752/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2475 - accuracy: 0.5597 - val_loss: 3.2436 - val_accuracy: 0.3479\n",
      "Epoch 753/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2328 - accuracy: 0.5684 - val_loss: 3.2516 - val_accuracy: 0.3613\n",
      "Epoch 754/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2586 - accuracy: 0.5578 - val_loss: 3.2443 - val_accuracy: 0.3564\n",
      "Epoch 755/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2457 - accuracy: 0.5594 - val_loss: 3.2550 - val_accuracy: 0.3491\n",
      "Epoch 756/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2520 - accuracy: 0.5655 - val_loss: 3.2435 - val_accuracy: 0.3540\n",
      "Epoch 757/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2480 - accuracy: 0.5604 - val_loss: 3.2655 - val_accuracy: 0.3473\n",
      "Epoch 758/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2621 - accuracy: 0.5618 - val_loss: 3.2588 - val_accuracy: 0.3418\n",
      "Epoch 759/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2420 - accuracy: 0.5658 - val_loss: 3.2703 - val_accuracy: 0.3485\n",
      "Epoch 760/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2476 - accuracy: 0.5681 - val_loss: 3.2682 - val_accuracy: 0.3455\n",
      "Epoch 761/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2602 - accuracy: 0.5616 - val_loss: 3.2712 - val_accuracy: 0.3437\n",
      "Epoch 762/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2512 - accuracy: 0.5543 - val_loss: 3.2698 - val_accuracy: 0.3418\n",
      "Epoch 763/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2403 - accuracy: 0.5636 - val_loss: 3.2763 - val_accuracy: 0.3491\n",
      "Epoch 764/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2334 - accuracy: 0.5719 - val_loss: 3.2694 - val_accuracy: 0.3425\n",
      "Epoch 765/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2420 - accuracy: 0.5682 - val_loss: 3.2643 - val_accuracy: 0.3406\n",
      "Epoch 766/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2529 - accuracy: 0.5606 - val_loss: 3.2648 - val_accuracy: 0.3473\n",
      "Epoch 767/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2637 - accuracy: 0.5606 - val_loss: 3.2604 - val_accuracy: 0.3467\n",
      "Epoch 768/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2338 - accuracy: 0.5702 - val_loss: 3.2664 - val_accuracy: 0.3418\n",
      "Epoch 769/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2518 - accuracy: 0.5547 - val_loss: 3.2646 - val_accuracy: 0.3516\n",
      "Epoch 770/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2520 - accuracy: 0.5624 - val_loss: 3.2675 - val_accuracy: 0.3449\n",
      "Epoch 771/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.5647 - val_loss: 3.2650 - val_accuracy: 0.3528\n",
      "Epoch 772/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2437 - accuracy: 0.5669 - val_loss: 3.2625 - val_accuracy: 0.3449\n",
      "Epoch 773/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.5703 - val_loss: 3.2528 - val_accuracy: 0.3461\n",
      "Epoch 774/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2416 - accuracy: 0.5697 - val_loss: 3.2697 - val_accuracy: 0.3479\n",
      "Epoch 775/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2419 - accuracy: 0.5649 - val_loss: 3.2621 - val_accuracy: 0.3425\n",
      "Epoch 776/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2572 - accuracy: 0.5636 - val_loss: 3.2711 - val_accuracy: 0.3479\n",
      "Epoch 777/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.5693 - val_loss: 3.2499 - val_accuracy: 0.3491\n",
      "Epoch 778/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2337 - accuracy: 0.5549 - val_loss: 3.2783 - val_accuracy: 0.3467\n",
      "Epoch 779/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2404 - accuracy: 0.5637 - val_loss: 3.2590 - val_accuracy: 0.3613\n",
      "Epoch 780/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2557 - accuracy: 0.5582 - val_loss: 3.2683 - val_accuracy: 0.3455\n",
      "Epoch 781/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2324 - accuracy: 0.5642 - val_loss: 3.2566 - val_accuracy: 0.3625\n",
      "Epoch 782/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2420 - accuracy: 0.5647 - val_loss: 3.2621 - val_accuracy: 0.3491\n",
      "Epoch 783/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2522 - accuracy: 0.5656 - val_loss: 3.2620 - val_accuracy: 0.3583\n",
      "Epoch 784/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2410 - accuracy: 0.5632 - val_loss: 3.2802 - val_accuracy: 0.3461\n",
      "Epoch 785/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2402 - accuracy: 0.5651 - val_loss: 3.2469 - val_accuracy: 0.3485\n",
      "Epoch 786/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2421 - accuracy: 0.5619 - val_loss: 3.2710 - val_accuracy: 0.3461\n",
      "Epoch 787/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2512 - accuracy: 0.5574 - val_loss: 3.2579 - val_accuracy: 0.3516\n",
      "Epoch 788/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2512 - accuracy: 0.5626 - val_loss: 3.2730 - val_accuracy: 0.3473\n",
      "Epoch 789/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2471 - accuracy: 0.5585 - val_loss: 3.2660 - val_accuracy: 0.3491\n",
      "Epoch 790/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.5603 - val_loss: 3.2688 - val_accuracy: 0.3522\n",
      "Epoch 791/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2514 - accuracy: 0.5609 - val_loss: 3.2877 - val_accuracy: 0.3491\n",
      "Epoch 792/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2359 - accuracy: 0.5631 - val_loss: 3.2822 - val_accuracy: 0.3479\n",
      "Epoch 793/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2493 - accuracy: 0.5576 - val_loss: 3.2699 - val_accuracy: 0.3510\n",
      "Epoch 794/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2414 - accuracy: 0.5644 - val_loss: 3.2702 - val_accuracy: 0.3461\n",
      "Epoch 795/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2597 - accuracy: 0.5633 - val_loss: 3.2803 - val_accuracy: 0.3467\n",
      "Epoch 796/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2522 - accuracy: 0.5551 - val_loss: 3.2744 - val_accuracy: 0.3467\n",
      "Epoch 797/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2437 - accuracy: 0.5680 - val_loss: 3.2673 - val_accuracy: 0.3552\n",
      "Epoch 798/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2416 - accuracy: 0.5573 - val_loss: 3.2791 - val_accuracy: 0.3485\n",
      "Epoch 799/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2388 - accuracy: 0.5668 - val_loss: 3.2643 - val_accuracy: 0.3510\n",
      "Epoch 800/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2358 - accuracy: 0.5635 - val_loss: 3.2853 - val_accuracy: 0.3540\n",
      "Epoch 801/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2624 - accuracy: 0.5512 - val_loss: 3.2703 - val_accuracy: 0.3558\n",
      "Epoch 802/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2422 - accuracy: 0.5669 - val_loss: 3.2810 - val_accuracy: 0.3455\n",
      "Epoch 803/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2465 - accuracy: 0.5574 - val_loss: 3.2730 - val_accuracy: 0.3516\n",
      "Epoch 804/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2516 - accuracy: 0.5577 - val_loss: 3.2785 - val_accuracy: 0.3455\n",
      "Epoch 805/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2243 - accuracy: 0.5816 - val_loss: 3.2847 - val_accuracy: 0.3431\n",
      "Epoch 806/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2426 - accuracy: 0.5679 - val_loss: 3.2840 - val_accuracy: 0.3467\n",
      "Epoch 807/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2528 - accuracy: 0.5599 - val_loss: 3.2894 - val_accuracy: 0.3485\n",
      "Epoch 808/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2500 - accuracy: 0.5544 - val_loss: 3.2803 - val_accuracy: 0.3540\n",
      "Epoch 809/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2421 - accuracy: 0.5689 - val_loss: 3.2665 - val_accuracy: 0.3522\n",
      "Epoch 810/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2367 - accuracy: 0.5620 - val_loss: 3.2834 - val_accuracy: 0.3485\n",
      "Epoch 811/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2528 - accuracy: 0.5699 - val_loss: 3.2726 - val_accuracy: 0.3613\n",
      "Epoch 812/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2531 - accuracy: 0.5554 - val_loss: 3.2613 - val_accuracy: 0.3540\n",
      "Epoch 813/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2411 - accuracy: 0.5693 - val_loss: 3.2659 - val_accuracy: 0.3528\n",
      "Epoch 814/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.5567 - val_loss: 3.2774 - val_accuracy: 0.3528\n",
      "Epoch 815/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.5581 - val_loss: 3.2752 - val_accuracy: 0.3577\n",
      "Epoch 816/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2459 - accuracy: 0.5615 - val_loss: 3.2878 - val_accuracy: 0.3498\n",
      "Epoch 817/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2443 - accuracy: 0.5704 - val_loss: 3.2785 - val_accuracy: 0.3461\n",
      "Epoch 818/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.5507 - val_loss: 3.2826 - val_accuracy: 0.3479\n",
      "Epoch 819/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2503 - accuracy: 0.5569 - val_loss: 3.2952 - val_accuracy: 0.3473\n",
      "Epoch 820/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2516 - accuracy: 0.5548 - val_loss: 3.2921 - val_accuracy: 0.3449\n",
      "Epoch 821/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2529 - accuracy: 0.5616 - val_loss: 3.2902 - val_accuracy: 0.3449\n",
      "Epoch 822/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2424 - accuracy: 0.5646 - val_loss: 3.2792 - val_accuracy: 0.3431\n",
      "Epoch 823/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2514 - accuracy: 0.5586 - val_loss: 3.2839 - val_accuracy: 0.3449\n",
      "Epoch 824/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.5668 - val_loss: 3.2807 - val_accuracy: 0.3443\n",
      "Epoch 825/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2574 - accuracy: 0.5550 - val_loss: 3.2734 - val_accuracy: 0.3504\n",
      "Epoch 826/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2407 - accuracy: 0.5669 - val_loss: 3.2824 - val_accuracy: 0.3431\n",
      "Epoch 827/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2387 - accuracy: 0.5609 - val_loss: 3.2704 - val_accuracy: 0.3406\n",
      "Epoch 828/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2535 - accuracy: 0.5574 - val_loss: 3.2937 - val_accuracy: 0.3534\n",
      "Epoch 829/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.5546 - val_loss: 3.2868 - val_accuracy: 0.3552\n",
      "Epoch 830/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5802 - val_loss: 3.2937 - val_accuracy: 0.3418\n",
      "Epoch 831/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2526 - accuracy: 0.5615 - val_loss: 3.2875 - val_accuracy: 0.3455\n",
      "Epoch 832/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.5695 - val_loss: 3.3016 - val_accuracy: 0.3394\n",
      "Epoch 833/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.5674 - val_loss: 3.2901 - val_accuracy: 0.3473\n",
      "Epoch 834/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2283 - accuracy: 0.5629 - val_loss: 3.2834 - val_accuracy: 0.3406\n",
      "Epoch 835/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2304 - accuracy: 0.5740 - val_loss: 3.2894 - val_accuracy: 0.3504\n",
      "Epoch 836/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2353 - accuracy: 0.5620 - val_loss: 3.2894 - val_accuracy: 0.3516\n",
      "Epoch 837/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2527 - accuracy: 0.5614 - val_loss: 3.2986 - val_accuracy: 0.3473\n",
      "Epoch 838/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2288 - accuracy: 0.5676 - val_loss: 3.3023 - val_accuracy: 0.3516\n",
      "Epoch 839/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.5527 - val_loss: 3.2960 - val_accuracy: 0.3394\n",
      "Epoch 840/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2368 - accuracy: 0.5675 - val_loss: 3.2996 - val_accuracy: 0.3437\n",
      "Epoch 841/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2365 - accuracy: 0.5690 - val_loss: 3.2967 - val_accuracy: 0.3437\n",
      "Epoch 842/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2360 - accuracy: 0.5665 - val_loss: 3.2911 - val_accuracy: 0.3504\n",
      "Epoch 843/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2406 - accuracy: 0.5601 - val_loss: 3.2948 - val_accuracy: 0.3485\n",
      "Epoch 844/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.5538 - val_loss: 3.2930 - val_accuracy: 0.3491\n",
      "Epoch 845/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2654 - accuracy: 0.5582 - val_loss: 3.3016 - val_accuracy: 0.3412\n",
      "Epoch 846/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2462 - accuracy: 0.5564 - val_loss: 3.2906 - val_accuracy: 0.3583\n",
      "Epoch 847/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2314 - accuracy: 0.5645 - val_loss: 3.2851 - val_accuracy: 0.3412\n",
      "Epoch 848/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2473 - accuracy: 0.5647 - val_loss: 3.2840 - val_accuracy: 0.3498\n",
      "Epoch 849/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2252 - accuracy: 0.5677 - val_loss: 3.2820 - val_accuracy: 0.3461\n",
      "Epoch 850/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2371 - accuracy: 0.5628 - val_loss: 3.2865 - val_accuracy: 0.3485\n",
      "Epoch 851/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2396 - accuracy: 0.5718 - val_loss: 3.3163 - val_accuracy: 0.3437\n",
      "Epoch 852/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2354 - accuracy: 0.5681 - val_loss: 3.2947 - val_accuracy: 0.3455\n",
      "Epoch 853/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2495 - accuracy: 0.5651 - val_loss: 3.2944 - val_accuracy: 0.3418\n",
      "Epoch 854/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2322 - accuracy: 0.5771 - val_loss: 3.2927 - val_accuracy: 0.3467\n",
      "Epoch 855/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2240 - accuracy: 0.5677 - val_loss: 3.2866 - val_accuracy: 0.3412\n",
      "Epoch 856/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.5622 - val_loss: 3.2931 - val_accuracy: 0.3583\n",
      "Epoch 857/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2467 - accuracy: 0.5657 - val_loss: 3.2956 - val_accuracy: 0.3498\n",
      "Epoch 858/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2307 - accuracy: 0.5695 - val_loss: 3.3183 - val_accuracy: 0.3504\n",
      "Epoch 859/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2363 - accuracy: 0.5712 - val_loss: 3.2954 - val_accuracy: 0.3412\n",
      "Epoch 860/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2499 - accuracy: 0.5598 - val_loss: 3.2890 - val_accuracy: 0.3534\n",
      "Epoch 861/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2440 - accuracy: 0.5659 - val_loss: 3.3054 - val_accuracy: 0.3498\n",
      "Epoch 862/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2370 - accuracy: 0.5656 - val_loss: 3.2783 - val_accuracy: 0.3491\n",
      "Epoch 863/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2379 - accuracy: 0.5646 - val_loss: 3.3112 - val_accuracy: 0.3400\n",
      "Epoch 864/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.5725 - val_loss: 3.3086 - val_accuracy: 0.3473\n",
      "Epoch 865/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2537 - accuracy: 0.5658 - val_loss: 3.2937 - val_accuracy: 0.3443\n",
      "Epoch 866/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2438 - accuracy: 0.5662 - val_loss: 3.2986 - val_accuracy: 0.3437\n",
      "Epoch 867/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2527 - accuracy: 0.5590 - val_loss: 3.3069 - val_accuracy: 0.3583\n",
      "Epoch 868/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2462 - accuracy: 0.5565 - val_loss: 3.3043 - val_accuracy: 0.3534\n",
      "Epoch 869/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2346 - accuracy: 0.5648 - val_loss: 3.3003 - val_accuracy: 0.3504\n",
      "Epoch 870/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2335 - accuracy: 0.5613 - val_loss: 3.3090 - val_accuracy: 0.3382\n",
      "Epoch 871/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2488 - accuracy: 0.5583 - val_loss: 3.3131 - val_accuracy: 0.3491\n",
      "Epoch 872/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2550 - accuracy: 0.5561 - val_loss: 3.3005 - val_accuracy: 0.3552\n",
      "Epoch 873/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2393 - accuracy: 0.5658 - val_loss: 3.3115 - val_accuracy: 0.3491\n",
      "Epoch 874/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.5641 - val_loss: 3.3059 - val_accuracy: 0.3467\n",
      "Epoch 875/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2375 - accuracy: 0.5696 - val_loss: 3.2981 - val_accuracy: 0.3528\n",
      "Epoch 876/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2438 - accuracy: 0.5586 - val_loss: 3.2877 - val_accuracy: 0.3504\n",
      "Epoch 877/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.5617 - val_loss: 3.2913 - val_accuracy: 0.3473\n",
      "Epoch 878/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2157 - accuracy: 0.5731 - val_loss: 3.2969 - val_accuracy: 0.3479\n",
      "Epoch 879/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2469 - accuracy: 0.5576 - val_loss: 3.2912 - val_accuracy: 0.3473\n",
      "Epoch 880/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2351 - accuracy: 0.5663 - val_loss: 3.2885 - val_accuracy: 0.3455\n",
      "Epoch 881/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2509 - accuracy: 0.5559 - val_loss: 3.2996 - val_accuracy: 0.3491\n",
      "Epoch 882/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2479 - accuracy: 0.5632 - val_loss: 3.2964 - val_accuracy: 0.3479\n",
      "Epoch 883/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2359 - accuracy: 0.5679 - val_loss: 3.2942 - val_accuracy: 0.3461\n",
      "Epoch 884/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2444 - accuracy: 0.5562 - val_loss: 3.3155 - val_accuracy: 0.3394\n",
      "Epoch 885/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2556 - accuracy: 0.5635 - val_loss: 3.3025 - val_accuracy: 0.3485\n",
      "Epoch 886/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2470 - accuracy: 0.5630 - val_loss: 3.3149 - val_accuracy: 0.3418\n",
      "Epoch 887/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.2445 - accuracy: 0.5674 - val_loss: 3.3116 - val_accuracy: 0.3455\n",
      "Epoch 888/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2365 - accuracy: 0.5556 - val_loss: 3.3120 - val_accuracy: 0.3437\n",
      "Epoch 889/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.5729 - val_loss: 3.3058 - val_accuracy: 0.3485\n",
      "Epoch 890/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.5603 - val_loss: 3.3093 - val_accuracy: 0.3485\n",
      "Epoch 891/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2303 - accuracy: 0.5559 - val_loss: 3.3025 - val_accuracy: 0.3449\n",
      "Epoch 892/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2439 - accuracy: 0.5594 - val_loss: 3.2946 - val_accuracy: 0.3528\n",
      "Epoch 893/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2390 - accuracy: 0.5635 - val_loss: 3.2995 - val_accuracy: 0.3443\n",
      "Epoch 894/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2409 - accuracy: 0.5612 - val_loss: 3.3058 - val_accuracy: 0.3491\n",
      "Epoch 895/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2475 - accuracy: 0.5609 - val_loss: 3.3200 - val_accuracy: 0.3461\n",
      "Epoch 896/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2416 - accuracy: 0.5664 - val_loss: 3.3163 - val_accuracy: 0.3443\n",
      "Epoch 897/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2521 - accuracy: 0.5558 - val_loss: 3.3074 - val_accuracy: 0.3479\n",
      "Epoch 898/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2441 - accuracy: 0.5638 - val_loss: 3.3133 - val_accuracy: 0.3485\n",
      "Epoch 899/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2329 - accuracy: 0.5579 - val_loss: 3.3063 - val_accuracy: 0.3528\n",
      "Epoch 900/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2448 - accuracy: 0.5528 - val_loss: 3.3132 - val_accuracy: 0.3504\n",
      "Epoch 901/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2393 - accuracy: 0.5580 - val_loss: 3.3123 - val_accuracy: 0.3449\n",
      "Epoch 902/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2383 - accuracy: 0.5614 - val_loss: 3.3142 - val_accuracy: 0.3467\n",
      "Epoch 903/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2349 - accuracy: 0.5666 - val_loss: 3.3067 - val_accuracy: 0.3443\n",
      "Epoch 904/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2401 - accuracy: 0.5634 - val_loss: 3.2947 - val_accuracy: 0.3473\n",
      "Epoch 905/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2432 - accuracy: 0.5537 - val_loss: 3.3088 - val_accuracy: 0.3461\n",
      "Epoch 906/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5743 - val_loss: 3.3027 - val_accuracy: 0.3418\n",
      "Epoch 907/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2268 - accuracy: 0.5665 - val_loss: 3.3044 - val_accuracy: 0.3485\n",
      "Epoch 908/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2470 - accuracy: 0.5606 - val_loss: 3.2909 - val_accuracy: 0.3485\n",
      "Epoch 909/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2334 - accuracy: 0.5664 - val_loss: 3.3040 - val_accuracy: 0.3491\n",
      "Epoch 910/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2403 - accuracy: 0.5607 - val_loss: 3.3000 - val_accuracy: 0.3504\n",
      "Epoch 911/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2330 - accuracy: 0.5681 - val_loss: 3.2926 - val_accuracy: 0.3510\n",
      "Epoch 912/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2406 - accuracy: 0.5629 - val_loss: 3.2981 - val_accuracy: 0.3546\n",
      "Epoch 913/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2479 - accuracy: 0.5674 - val_loss: 3.3001 - val_accuracy: 0.3601\n",
      "Epoch 914/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2167 - accuracy: 0.5724 - val_loss: 3.3041 - val_accuracy: 0.3528\n",
      "Epoch 915/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2372 - accuracy: 0.5668 - val_loss: 3.3158 - val_accuracy: 0.3425\n",
      "Epoch 916/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2293 - accuracy: 0.5693 - val_loss: 3.3065 - val_accuracy: 0.3571\n",
      "Epoch 917/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2393 - accuracy: 0.5626 - val_loss: 3.3144 - val_accuracy: 0.3479\n",
      "Epoch 918/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.5608 - val_loss: 3.3330 - val_accuracy: 0.3461\n",
      "Epoch 919/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2210 - accuracy: 0.5675 - val_loss: 3.3152 - val_accuracy: 0.3479\n",
      "Epoch 920/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5699 - val_loss: 3.3074 - val_accuracy: 0.3583\n",
      "Epoch 921/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2536 - accuracy: 0.5634 - val_loss: 3.3192 - val_accuracy: 0.3540\n",
      "Epoch 922/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2425 - accuracy: 0.5661 - val_loss: 3.3023 - val_accuracy: 0.3619\n",
      "Epoch 923/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.5675 - val_loss: 3.3047 - val_accuracy: 0.3479\n",
      "Epoch 924/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2458 - accuracy: 0.5615 - val_loss: 3.3175 - val_accuracy: 0.3491\n",
      "Epoch 925/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2379 - accuracy: 0.5702 - val_loss: 3.3146 - val_accuracy: 0.3485\n",
      "Epoch 926/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2322 - accuracy: 0.5699 - val_loss: 3.3015 - val_accuracy: 0.3504\n",
      "Epoch 927/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2304 - accuracy: 0.5572 - val_loss: 3.3316 - val_accuracy: 0.3510\n",
      "Epoch 928/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2400 - accuracy: 0.5657 - val_loss: 3.3208 - val_accuracy: 0.3522\n",
      "Epoch 929/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2379 - accuracy: 0.5588 - val_loss: 3.2974 - val_accuracy: 0.3552\n",
      "Epoch 930/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2352 - accuracy: 0.5741 - val_loss: 3.3243 - val_accuracy: 0.3449\n",
      "Epoch 931/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2309 - accuracy: 0.5732 - val_loss: 3.3048 - val_accuracy: 0.3467\n",
      "Epoch 932/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2549 - accuracy: 0.5550 - val_loss: 3.3039 - val_accuracy: 0.3491\n",
      "Epoch 933/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2428 - accuracy: 0.5649 - val_loss: 3.3078 - val_accuracy: 0.3534\n",
      "Epoch 934/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2442 - accuracy: 0.5612 - val_loss: 3.3125 - val_accuracy: 0.3479\n",
      "Epoch 935/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2443 - accuracy: 0.5565 - val_loss: 3.3222 - val_accuracy: 0.3516\n",
      "Epoch 936/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2344 - accuracy: 0.5700 - val_loss: 3.3150 - val_accuracy: 0.3418\n",
      "Epoch 937/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2476 - accuracy: 0.5599 - val_loss: 3.3224 - val_accuracy: 0.3516\n",
      "Epoch 938/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2373 - accuracy: 0.5692 - val_loss: 3.3309 - val_accuracy: 0.3388\n",
      "Epoch 939/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2348 - accuracy: 0.5577 - val_loss: 3.3253 - val_accuracy: 0.3552\n",
      "Epoch 940/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2422 - accuracy: 0.5657 - val_loss: 3.3015 - val_accuracy: 0.3485\n",
      "Epoch 941/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.5621 - val_loss: 3.3079 - val_accuracy: 0.3498\n",
      "Epoch 942/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2435 - accuracy: 0.5588 - val_loss: 3.3216 - val_accuracy: 0.3388\n",
      "Epoch 943/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.5593 - val_loss: 3.3175 - val_accuracy: 0.3479\n",
      "Epoch 944/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2377 - accuracy: 0.5632 - val_loss: 3.3218 - val_accuracy: 0.3437\n",
      "Epoch 945/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5555 - val_loss: 3.3270 - val_accuracy: 0.3485\n",
      "Epoch 946/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2533 - accuracy: 0.5607 - val_loss: 3.3069 - val_accuracy: 0.3449\n",
      "Epoch 947/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2479 - accuracy: 0.5620 - val_loss: 3.3173 - val_accuracy: 0.3461\n",
      "Epoch 948/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2454 - accuracy: 0.5604 - val_loss: 3.3190 - val_accuracy: 0.3406\n",
      "Epoch 949/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2502 - accuracy: 0.5616 - val_loss: 3.3191 - val_accuracy: 0.3522\n",
      "Epoch 950/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2346 - accuracy: 0.5670 - val_loss: 3.3272 - val_accuracy: 0.3418\n",
      "Epoch 951/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2413 - accuracy: 0.5615 - val_loss: 3.3106 - val_accuracy: 0.3376\n",
      "Epoch 952/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2326 - accuracy: 0.5710 - val_loss: 3.3112 - val_accuracy: 0.3431\n",
      "Epoch 953/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2326 - accuracy: 0.5616 - val_loss: 3.3079 - val_accuracy: 0.3510\n",
      "Epoch 954/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2417 - accuracy: 0.5617 - val_loss: 3.3148 - val_accuracy: 0.3406\n",
      "Epoch 955/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2351 - accuracy: 0.5715 - val_loss: 3.3165 - val_accuracy: 0.3455\n",
      "Epoch 956/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.5749 - val_loss: 3.3291 - val_accuracy: 0.3491\n",
      "Epoch 957/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2428 - accuracy: 0.5649 - val_loss: 3.3121 - val_accuracy: 0.3491\n",
      "Epoch 958/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2304 - accuracy: 0.5673 - val_loss: 3.3093 - val_accuracy: 0.3528\n",
      "Epoch 959/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2431 - accuracy: 0.5662 - val_loss: 3.3060 - val_accuracy: 0.3461\n",
      "Epoch 960/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2420 - accuracy: 0.5563 - val_loss: 3.3271 - val_accuracy: 0.3406\n",
      "Epoch 961/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2440 - accuracy: 0.5619 - val_loss: 3.3166 - val_accuracy: 0.3479\n",
      "Epoch 962/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2430 - accuracy: 0.5627 - val_loss: 3.3296 - val_accuracy: 0.3461\n",
      "Epoch 963/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2378 - accuracy: 0.5560 - val_loss: 3.3246 - val_accuracy: 0.3601\n",
      "Epoch 964/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2389 - accuracy: 0.5592 - val_loss: 3.3371 - val_accuracy: 0.3485\n",
      "Epoch 965/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2449 - accuracy: 0.5534 - val_loss: 3.3359 - val_accuracy: 0.3443\n",
      "Epoch 966/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2462 - accuracy: 0.5629 - val_loss: 3.3364 - val_accuracy: 0.3528\n",
      "Epoch 967/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2397 - accuracy: 0.5634 - val_loss: 3.3277 - val_accuracy: 0.3510\n",
      "Epoch 968/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2447 - accuracy: 0.5580 - val_loss: 3.3425 - val_accuracy: 0.3449\n",
      "Epoch 969/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2360 - accuracy: 0.5685 - val_loss: 3.3230 - val_accuracy: 0.3522\n",
      "Epoch 970/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2520 - accuracy: 0.5547 - val_loss: 3.3030 - val_accuracy: 0.3564\n",
      "Epoch 971/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2503 - accuracy: 0.5602 - val_loss: 3.3339 - val_accuracy: 0.3510\n",
      "Epoch 972/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2308 - accuracy: 0.5655 - val_loss: 3.3334 - val_accuracy: 0.3431\n",
      "Epoch 973/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2225 - accuracy: 0.5765 - val_loss: 3.3352 - val_accuracy: 0.3425\n",
      "Epoch 974/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2517 - accuracy: 0.5655 - val_loss: 3.3370 - val_accuracy: 0.3400\n",
      "Epoch 975/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2409 - accuracy: 0.5644 - val_loss: 3.3400 - val_accuracy: 0.3431\n",
      "Epoch 976/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2470 - accuracy: 0.5639 - val_loss: 3.3232 - val_accuracy: 0.3498\n",
      "Epoch 977/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2474 - accuracy: 0.5636 - val_loss: 3.3345 - val_accuracy: 0.3449\n",
      "Epoch 978/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2312 - accuracy: 0.5621 - val_loss: 3.3400 - val_accuracy: 0.3449\n",
      "Epoch 979/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2269 - accuracy: 0.5696 - val_loss: 3.3408 - val_accuracy: 0.3449\n",
      "Epoch 980/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2425 - accuracy: 0.5568 - val_loss: 3.3264 - val_accuracy: 0.3449\n",
      "Epoch 981/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2319 - accuracy: 0.5716 - val_loss: 3.3394 - val_accuracy: 0.3418\n",
      "Epoch 982/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2303 - accuracy: 0.5622 - val_loss: 3.3411 - val_accuracy: 0.3479\n",
      "Epoch 983/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2414 - accuracy: 0.5597 - val_loss: 3.3486 - val_accuracy: 0.3504\n",
      "Epoch 984/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.5658 - val_loss: 3.3460 - val_accuracy: 0.3601\n",
      "Epoch 985/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.5653 - val_loss: 3.3436 - val_accuracy: 0.3558\n",
      "Epoch 986/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2337 - accuracy: 0.5623 - val_loss: 3.3365 - val_accuracy: 0.3595\n",
      "Epoch 987/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2436 - accuracy: 0.5652 - val_loss: 3.3330 - val_accuracy: 0.3431\n",
      "Epoch 988/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.5558 - val_loss: 3.3406 - val_accuracy: 0.3449\n",
      "Epoch 989/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2460 - accuracy: 0.5622 - val_loss: 3.3470 - val_accuracy: 0.3534\n",
      "Epoch 990/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2322 - accuracy: 0.5613 - val_loss: 3.3371 - val_accuracy: 0.3473\n",
      "Epoch 991/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2435 - accuracy: 0.5573 - val_loss: 3.3296 - val_accuracy: 0.3473\n",
      "Epoch 992/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2327 - accuracy: 0.5690 - val_loss: 3.3384 - val_accuracy: 0.3418\n",
      "Epoch 993/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2366 - accuracy: 0.5702 - val_loss: 3.3510 - val_accuracy: 0.3461\n",
      "Epoch 994/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2321 - accuracy: 0.5713 - val_loss: 3.3507 - val_accuracy: 0.3455\n",
      "Epoch 995/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2350 - accuracy: 0.5602 - val_loss: 3.3438 - val_accuracy: 0.3461\n",
      "Epoch 996/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2475 - accuracy: 0.5675 - val_loss: 3.3392 - val_accuracy: 0.3461\n",
      "Epoch 997/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2364 - accuracy: 0.5649 - val_loss: 3.3307 - val_accuracy: 0.3431\n",
      "Epoch 998/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5719 - val_loss: 3.3369 - val_accuracy: 0.3595\n",
      "Epoch 999/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2345 - accuracy: 0.5631 - val_loss: 3.3311 - val_accuracy: 0.3571\n",
      "Epoch 1000/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.2187 - accuracy: 0.5763 - val_loss: 3.3436 - val_accuracy: 0.3425\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 16)\n",
    "history_many_to_many_baseline = many_to_many_baseline_model.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  \n",
    "                                              batch_size=16, \n",
    "                                              validation_data=(xx_val, yy_val)\n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file = \"many_to_many_LSTM_baseline_model.h5\"  \n",
    "many_to_many_baseline_model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_baseline_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_baseline.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print metrics from the loaded history dictionary\n",
    "def print_metrics(history_dict):\n",
    "    val_accuracy_per_epoch = history_dict['val_accuracy']\n",
    "    train_accuracy_per_epoch = history_dict['accuracy']\n",
    "    train_loss_per_epoch = history_dict['loss']\n",
    "    val_loss_per_epoch = history_dict['val_loss']\n",
    "\n",
    "    best_epoch_val_accuracy = val_accuracy_per_epoch.index(max(val_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_accuracy = train_accuracy_per_epoch.index(max(train_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_loss = train_loss_per_epoch.index(min(train_loss_per_epoch)) + 1\n",
    "    best_epoch_val_loss = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "\n",
    "    print(f\"Best Epoch for Validation Accuracy: {best_epoch_val_accuracy} (Val Accuracy: {max(val_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Accuracy: {best_epoch_train_accuracy} (Train Accuracy: {max(train_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Loss: {best_epoch_train_loss} (Train Loss: {min(train_loss_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Validation Loss: {best_epoch_val_loss} (Val Loss: {min(val_loss_per_epoch)})\")\n",
    "    print(\"\\nOverall Best Performance Metrics:\")\n",
    "    print(f\"Maximum Validation Accuracy: {max(val_accuracy_per_epoch)}\")\n",
    "    print(f\"Maximum Training Accuracy: {max(train_accuracy_per_epoch)}\")\n",
    "    print(f\"Minimum Training Loss: {min(train_loss_per_epoch)}\")\n",
    "    print(f\"Minimum Validation Loss: {min(val_loss_per_epoch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print metrics from the history file\n",
    "def print_metrics_history(history):\n",
    "    val_accuracy_per_epoch = history.history['val_accuracy']\n",
    "    train_accuracy_per_epoch = history.history['accuracy']\n",
    "    train_loss_per_epoch = history.history['loss']\n",
    "    val_loss_per_epoch = history.history['val_loss']\n",
    "\n",
    "    best_epoch_val_accuracy = val_accuracy_per_epoch.index(max(val_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_accuracy = train_accuracy_per_epoch.index(max(train_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_loss = train_loss_per_epoch.index(min(train_loss_per_epoch)) + 1\n",
    "    best_epoch_val_loss = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "\n",
    "    print(f\"Best Epoch for Validation Accuracy: {best_epoch_val_accuracy} (Val Accuracy: {max(val_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Accuracy: {best_epoch_train_accuracy} (Train Accuracy: {max(train_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Loss: {best_epoch_train_loss} (Train Loss: {min(train_loss_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Validation Loss: {best_epoch_val_loss} (Val Loss: {min(val_loss_per_epoch)})\")\n",
    "    print(\"\\nOverall Best Performance Metrics:\")\n",
    "    print(f\"Maximum Validation Accuracy: {max(val_accuracy_per_epoch)}\")\n",
    "    print(f\"Maximum Training Accuracy: {max(train_accuracy_per_epoch)}\")\n",
    "    print(f\"Minimum Training Loss: {min(train_loss_per_epoch)}\")\n",
    "    print(f\"Minimum Validation Loss: {min(val_loss_per_epoch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 4 (Val Accuracy: 0.45377129316329956)\n",
      "Best Epoch for Training Accuracy: 858 (Train Accuracy: 0.566453754901886)\n",
      "Best Epoch for Training Loss: 979 (Train Loss: 1.2380450963974)\n",
      "Best Epoch for Validation Loss: 11 (Val Loss: 2.162454843521118)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.45377129316329956\n",
      "Maximum Training Accuracy: 0.566453754901886\n",
      "Minimum Training Loss: 1.2380450963974\n",
      "Minimum Validation Loss: 2.162454843521118\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# import the model´s history\n",
    "with open('many_to_many_LSTM_baseline_model_history_bs16.pkl', 'rb') as file:\n",
    "    history_many_to_many_baseline = pickle.load(file)\n",
    "\n",
    "# Access the history data\n",
    "#training_loss = loaded_history['loss']\n",
    "#validation_loss = loaded_history['val_loss']\n",
    "#training_accuracy = loaded_history.get('accuracy') \n",
    "#validation_accuracy = loaded_history.get('val_accuracy') \n",
    "\n",
    "print_metrics(history_many_to_many_baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     barrel_turn       0.00      0.00      0.00        36\n",
      "    basic_closed       0.55      0.34      0.42       143\n",
      "      basic_open       0.00      0.00      0.00        18\n",
      "           break       0.17      0.08      0.10       106\n",
      "       come_back       0.01      0.01      0.01        81\n",
      "        corridor       0.00      0.00      0.00        11\n",
      " frankie´s_sixes       0.20      0.07      0.11        41\n",
      "     groove_walk       0.00      0.00      0.00        10\n",
      "hallelujah_rocks       0.00      0.00      0.00         4\n",
      "    hand_to_hand       0.00      0.00      0.00         8\n",
      "     inside_spin       0.00      0.00      0.00         4\n",
      "     inside_turn       0.00      0.00      0.00        35\n",
      "    lindy_circle       0.00      0.00      0.00         4\n",
      "        mini_dip       0.00      0.00      0.00         0\n",
      "    outside_spin       0.00      0.00      0.00        40\n",
      "    outside_turn       0.00      0.00      0.00        24\n",
      "         pass_by       0.47      0.68      0.55       650\n",
      "        pop_turn       0.00      0.00      0.00         1\n",
      "       promenade       0.00      0.00      0.00        12\n",
      "          s_turn       0.00      0.00      0.00         4\n",
      "    sailor_kicks       0.00      0.00      0.00         4\n",
      "        send_out       0.00      0.00      0.00        16\n",
      "      sling_shot       0.00      0.00      0.00         8\n",
      "      sugar_push       0.08      0.03      0.04        64\n",
      "      sweetheart       0.00      0.00      0.00        54\n",
      "        swingout       0.17      0.17      0.17       163\n",
      "        switches       0.00      0.00      0.00         4\n",
      "          tandem       0.00      0.00      0.00         5\n",
      "       tuck_turn       0.28      0.32      0.30        94\n",
      "\n",
      "        accuracy                           0.34      1644\n",
      "       macro avg       0.07      0.06      0.06      1644\n",
      "    weighted avg       0.29      0.34      0.30      1644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict classes on the test set\n",
    "yy_pred = many_to_many_baseline_model.predict(xx_val)\n",
    "\n",
    "# Convert predictions from one-hot encoded back to label indices\n",
    "yy_pred_classes = np.argmax(yy_pred, axis=-1)\n",
    "yy_true_classes = np.argmax(yy_val, axis=-1)\n",
    "\n",
    "# Convert numeric classes to actual labels\n",
    "yy_pred_labels = [class_labels[i] for i in yy_pred_classes.flatten()]\n",
    "yy_true_labels = [class_labels[i] for i in yy_true_classes.flatten()]\n",
    "\n",
    "# Generate a confusion matrix\n",
    "#conf_matrix = confusion_matrix(yy_true_classes.flatten(), yy_pred_classes.flatten())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "class_report = classification_report(yy_true_labels, yy_pred_labels, zero_division=0)\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the string to a text file\n",
    "with open('rrrr.csv', 'w') as file:\n",
    "    file.write(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and axis to plot on\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # You can adjust the figure size as needed\n",
    "\n",
    "# Add the classification report text\n",
    "ax.text(0.5, 0.5, class_report, horizontalalignment='center', verticalalignment='center', \n",
    "        fontsize=12, family='monospace')\n",
    "\n",
    "# Remove the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure \n",
    "plt.savefig('classification_report_many_to_many_LSTM_baseline_model.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_baseline, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2374 - accuracy: 0.5646 - val_loss: 3.3484 - val_accuracy: 0.3467\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5619 - val_loss: 3.3500 - val_accuracy: 0.3461\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2430 - accuracy: 0.5610 - val_loss: 3.3529 - val_accuracy: 0.3443\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.5628 - val_loss: 3.3452 - val_accuracy: 0.3467\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2370 - accuracy: 0.5640 - val_loss: 3.3453 - val_accuracy: 0.3485\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5639 - val_loss: 3.3553 - val_accuracy: 0.3479\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2398 - accuracy: 0.5651 - val_loss: 3.3558 - val_accuracy: 0.3455\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2335 - accuracy: 0.5646 - val_loss: 3.3587 - val_accuracy: 0.3473\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5671 - val_loss: 3.3586 - val_accuracy: 0.3467\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2436 - accuracy: 0.5582 - val_loss: 3.3520 - val_accuracy: 0.3485\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2373 - accuracy: 0.5652 - val_loss: 3.3552 - val_accuracy: 0.3552\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5695 - val_loss: 3.3593 - val_accuracy: 0.3534\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5614 - val_loss: 3.3564 - val_accuracy: 0.3528\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.5627 - val_loss: 3.3503 - val_accuracy: 0.3528\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2373 - accuracy: 0.5634 - val_loss: 3.3580 - val_accuracy: 0.3491\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5643 - val_loss: 3.3536 - val_accuracy: 0.3449\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2414 - accuracy: 0.5633 - val_loss: 3.3606 - val_accuracy: 0.3473\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2407 - accuracy: 0.5625 - val_loss: 3.3574 - val_accuracy: 0.3449\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.5610 - val_loss: 3.3508 - val_accuracy: 0.3443\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5628 - val_loss: 3.3610 - val_accuracy: 0.3443\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5636 - val_loss: 3.3639 - val_accuracy: 0.3504\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2375 - accuracy: 0.5651 - val_loss: 3.3654 - val_accuracy: 0.3431\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.5663 - val_loss: 3.3722 - val_accuracy: 0.3449\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2320 - accuracy: 0.5687 - val_loss: 3.3709 - val_accuracy: 0.3498\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2381 - accuracy: 0.5668 - val_loss: 3.3687 - val_accuracy: 0.3485\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2450 - accuracy: 0.5584 - val_loss: 3.3716 - val_accuracy: 0.3546\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2350 - accuracy: 0.5622 - val_loss: 3.3599 - val_accuracy: 0.3522\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5658 - val_loss: 3.3673 - val_accuracy: 0.3455\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5642 - val_loss: 3.3750 - val_accuracy: 0.3467\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5651 - val_loss: 3.3743 - val_accuracy: 0.3504\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2340 - accuracy: 0.5634 - val_loss: 3.3699 - val_accuracy: 0.3491\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2369 - accuracy: 0.5657 - val_loss: 3.3728 - val_accuracy: 0.3418\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2359 - accuracy: 0.5620 - val_loss: 3.3744 - val_accuracy: 0.3449\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2432 - accuracy: 0.5604 - val_loss: 3.3701 - val_accuracy: 0.3473\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2406 - accuracy: 0.5622 - val_loss: 3.3684 - val_accuracy: 0.3571\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2397 - accuracy: 0.5608 - val_loss: 3.3703 - val_accuracy: 0.3491\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5669 - val_loss: 3.3657 - val_accuracy: 0.3510\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2407 - accuracy: 0.5608 - val_loss: 3.3764 - val_accuracy: 0.3485\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2361 - accuracy: 0.5649 - val_loss: 3.3650 - val_accuracy: 0.3534\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5634 - val_loss: 3.3687 - val_accuracy: 0.3510\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2369 - accuracy: 0.5614 - val_loss: 3.3687 - val_accuracy: 0.3522\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2253 - accuracy: 0.5672 - val_loss: 3.3685 - val_accuracy: 0.3425\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.5655 - val_loss: 3.3831 - val_accuracy: 0.3473\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2283 - accuracy: 0.5672 - val_loss: 3.3741 - val_accuracy: 0.3479\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.5596 - val_loss: 3.3748 - val_accuracy: 0.3455\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2388 - accuracy: 0.5619 - val_loss: 3.3646 - val_accuracy: 0.3455\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2393 - accuracy: 0.5627 - val_loss: 3.3707 - val_accuracy: 0.3498\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2333 - accuracy: 0.5630 - val_loss: 3.3795 - val_accuracy: 0.3461\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5625 - val_loss: 3.3710 - val_accuracy: 0.3516\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2363 - accuracy: 0.5654 - val_loss: 3.3778 - val_accuracy: 0.3455\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2392 - accuracy: 0.5582 - val_loss: 3.3645 - val_accuracy: 0.3467\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2359 - accuracy: 0.5640 - val_loss: 3.3716 - val_accuracy: 0.3467\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2376 - accuracy: 0.5661 - val_loss: 3.3779 - val_accuracy: 0.3473\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2404 - accuracy: 0.5599 - val_loss: 3.3715 - val_accuracy: 0.3455\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2392 - accuracy: 0.5620 - val_loss: 3.3817 - val_accuracy: 0.3473\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2374 - accuracy: 0.5625 - val_loss: 3.3628 - val_accuracy: 0.3534\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2365 - accuracy: 0.5610 - val_loss: 3.3785 - val_accuracy: 0.3498\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2408 - accuracy: 0.5622 - val_loss: 3.3703 - val_accuracy: 0.3528\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2353 - accuracy: 0.5640 - val_loss: 3.3790 - val_accuracy: 0.3485\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2386 - accuracy: 0.5654 - val_loss: 3.3793 - val_accuracy: 0.3406\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2372 - accuracy: 0.5649 - val_loss: 3.3774 - val_accuracy: 0.3461\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2384 - accuracy: 0.5661 - val_loss: 3.3809 - val_accuracy: 0.3437\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2350 - accuracy: 0.5619 - val_loss: 3.3787 - val_accuracy: 0.3479\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2349 - accuracy: 0.5613 - val_loss: 3.3766 - val_accuracy: 0.3485\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.5619 - val_loss: 3.3712 - val_accuracy: 0.3485\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2355 - accuracy: 0.5625 - val_loss: 3.3754 - val_accuracy: 0.3498\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2344 - accuracy: 0.5642 - val_loss: 3.3778 - val_accuracy: 0.3498\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2369 - accuracy: 0.5646 - val_loss: 3.3703 - val_accuracy: 0.3522\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2333 - accuracy: 0.5601 - val_loss: 3.3725 - val_accuracy: 0.3528\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2420 - accuracy: 0.5611 - val_loss: 3.3697 - val_accuracy: 0.3498\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2356 - accuracy: 0.5613 - val_loss: 3.3824 - val_accuracy: 0.3473\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2300 - accuracy: 0.5643 - val_loss: 3.3784 - val_accuracy: 0.3455\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2380 - accuracy: 0.5605 - val_loss: 3.3705 - val_accuracy: 0.3418\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2416 - accuracy: 0.5627 - val_loss: 3.3824 - val_accuracy: 0.3412\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2310 - accuracy: 0.5643 - val_loss: 3.3806 - val_accuracy: 0.3479\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2367 - accuracy: 0.5617 - val_loss: 3.3798 - val_accuracy: 0.3583\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.5617 - val_loss: 3.3706 - val_accuracy: 0.3485\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2386 - accuracy: 0.5617 - val_loss: 3.3712 - val_accuracy: 0.3583\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.5643 - val_loss: 3.3786 - val_accuracy: 0.3504\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.5651 - val_loss: 3.3810 - val_accuracy: 0.3522\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2402 - accuracy: 0.5582 - val_loss: 3.3767 - val_accuracy: 0.3558\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5675 - val_loss: 3.3719 - val_accuracy: 0.3485\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2358 - accuracy: 0.5630 - val_loss: 3.3796 - val_accuracy: 0.3577\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.5655 - val_loss: 3.3747 - val_accuracy: 0.3467\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5674 - val_loss: 3.3873 - val_accuracy: 0.3461\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2335 - accuracy: 0.5617 - val_loss: 3.3866 - val_accuracy: 0.3418\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2346 - accuracy: 0.5627 - val_loss: 3.3923 - val_accuracy: 0.3449\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2326 - accuracy: 0.5623 - val_loss: 3.3823 - val_accuracy: 0.3540\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2345 - accuracy: 0.5668 - val_loss: 3.3848 - val_accuracy: 0.3449\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.5616 - val_loss: 3.3905 - val_accuracy: 0.3479\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2397 - accuracy: 0.5596 - val_loss: 3.3867 - val_accuracy: 0.3540\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.5671 - val_loss: 3.3892 - val_accuracy: 0.3504\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5678 - val_loss: 3.3910 - val_accuracy: 0.3437\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2350 - accuracy: 0.5623 - val_loss: 3.3848 - val_accuracy: 0.3467\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2403 - accuracy: 0.5599 - val_loss: 3.3884 - val_accuracy: 0.3437\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2363 - accuracy: 0.5589 - val_loss: 3.3882 - val_accuracy: 0.3516\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2423 - accuracy: 0.5614 - val_loss: 3.3856 - val_accuracy: 0.3406\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2370 - accuracy: 0.5617 - val_loss: 3.3737 - val_accuracy: 0.3473\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5617 - val_loss: 3.3817 - val_accuracy: 0.3504\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2421 - accuracy: 0.5581 - val_loss: 3.3793 - val_accuracy: 0.3479\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2405 - accuracy: 0.5622 - val_loss: 3.3716 - val_accuracy: 0.3485\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.5599 - val_loss: 3.3838 - val_accuracy: 0.3485\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2343 - accuracy: 0.5637 - val_loss: 3.3796 - val_accuracy: 0.3528\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.5642 - val_loss: 3.3919 - val_accuracy: 0.3498\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5637 - val_loss: 3.3852 - val_accuracy: 0.3485\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.5613 - val_loss: 3.3803 - val_accuracy: 0.3467\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5660 - val_loss: 3.3895 - val_accuracy: 0.3522\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2353 - accuracy: 0.5616 - val_loss: 3.3974 - val_accuracy: 0.3510\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2448 - accuracy: 0.5598 - val_loss: 3.3907 - val_accuracy: 0.3418\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2386 - accuracy: 0.5595 - val_loss: 3.3979 - val_accuracy: 0.3467\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2412 - accuracy: 0.5584 - val_loss: 3.3869 - val_accuracy: 0.3479\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2388 - accuracy: 0.5584 - val_loss: 3.3910 - val_accuracy: 0.3431\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2363 - accuracy: 0.5605 - val_loss: 3.3875 - val_accuracy: 0.3461\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5640 - val_loss: 3.3929 - val_accuracy: 0.3431\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2323 - accuracy: 0.5627 - val_loss: 3.3984 - val_accuracy: 0.3510\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2411 - accuracy: 0.5598 - val_loss: 3.3816 - val_accuracy: 0.3510\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2368 - accuracy: 0.5651 - val_loss: 3.3900 - val_accuracy: 0.3473\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2299 - accuracy: 0.5634 - val_loss: 3.3869 - val_accuracy: 0.3449\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2349 - accuracy: 0.5620 - val_loss: 3.3850 - val_accuracy: 0.3467\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2384 - accuracy: 0.5623 - val_loss: 3.3894 - val_accuracy: 0.3528\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2355 - accuracy: 0.5602 - val_loss: 3.3881 - val_accuracy: 0.3504\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.5623 - val_loss: 3.4010 - val_accuracy: 0.3485\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5631 - val_loss: 3.3968 - val_accuracy: 0.3571\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2340 - accuracy: 0.5648 - val_loss: 3.3956 - val_accuracy: 0.3522\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2420 - accuracy: 0.5579 - val_loss: 3.3816 - val_accuracy: 0.3467\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2341 - accuracy: 0.5634 - val_loss: 3.3907 - val_accuracy: 0.3473\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5640 - val_loss: 3.4018 - val_accuracy: 0.3437\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2325 - accuracy: 0.5636 - val_loss: 3.3865 - val_accuracy: 0.3516\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2313 - accuracy: 0.5646 - val_loss: 3.3958 - val_accuracy: 0.3461\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2439 - accuracy: 0.5637 - val_loss: 3.3910 - val_accuracy: 0.3467\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2346 - accuracy: 0.5634 - val_loss: 3.3823 - val_accuracy: 0.3491\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2310 - accuracy: 0.5634 - val_loss: 3.3974 - val_accuracy: 0.3412\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2409 - accuracy: 0.5604 - val_loss: 3.4011 - val_accuracy: 0.3461\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2383 - accuracy: 0.5599 - val_loss: 3.3923 - val_accuracy: 0.3473\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2327 - accuracy: 0.5598 - val_loss: 3.3844 - val_accuracy: 0.3534\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2353 - accuracy: 0.5625 - val_loss: 3.3842 - val_accuracy: 0.3498\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2399 - accuracy: 0.5604 - val_loss: 3.3846 - val_accuracy: 0.3473\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.5619 - val_loss: 3.3945 - val_accuracy: 0.3479\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2401 - accuracy: 0.5598 - val_loss: 3.3891 - val_accuracy: 0.3534\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.5660 - val_loss: 3.3994 - val_accuracy: 0.3473\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2405 - accuracy: 0.5645 - val_loss: 3.3836 - val_accuracy: 0.3498\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2317 - accuracy: 0.5654 - val_loss: 3.3982 - val_accuracy: 0.3510\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2329 - accuracy: 0.5627 - val_loss: 3.3983 - val_accuracy: 0.3449\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.5637 - val_loss: 3.4048 - val_accuracy: 0.3479\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2337 - accuracy: 0.5665 - val_loss: 3.3936 - val_accuracy: 0.3479\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2418 - accuracy: 0.5620 - val_loss: 3.4031 - val_accuracy: 0.3455\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2322 - accuracy: 0.5627 - val_loss: 3.3996 - val_accuracy: 0.3455\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2332 - accuracy: 0.5581 - val_loss: 3.3992 - val_accuracy: 0.3485\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.5620 - val_loss: 3.4029 - val_accuracy: 0.3498\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2374 - accuracy: 0.5601 - val_loss: 3.4015 - val_accuracy: 0.3479\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2269 - accuracy: 0.5605 - val_loss: 3.4008 - val_accuracy: 0.3443\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5579 - val_loss: 3.4028 - val_accuracy: 0.3546\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5587 - val_loss: 3.3969 - val_accuracy: 0.3498\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2366 - accuracy: 0.5643 - val_loss: 3.4055 - val_accuracy: 0.3479\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2295 - accuracy: 0.5651 - val_loss: 3.4195 - val_accuracy: 0.3455\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2327 - accuracy: 0.5654 - val_loss: 3.4161 - val_accuracy: 0.3485\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2412 - accuracy: 0.5631 - val_loss: 3.4107 - val_accuracy: 0.3473\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.5652 - val_loss: 3.4064 - val_accuracy: 0.3491\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5620 - val_loss: 3.4169 - val_accuracy: 0.3412\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2357 - accuracy: 0.5640 - val_loss: 3.4152 - val_accuracy: 0.3510\n",
      "Epoch 161/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5675 - val_loss: 3.4050 - val_accuracy: 0.3473\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.5592 - val_loss: 3.4071 - val_accuracy: 0.3473\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5648 - val_loss: 3.4118 - val_accuracy: 0.3577\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2387 - accuracy: 0.5604 - val_loss: 3.3960 - val_accuracy: 0.3613\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2394 - accuracy: 0.5651 - val_loss: 3.4054 - val_accuracy: 0.3528\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2400 - accuracy: 0.5611 - val_loss: 3.3971 - val_accuracy: 0.3473\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2364 - accuracy: 0.5625 - val_loss: 3.4121 - val_accuracy: 0.3577\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2304 - accuracy: 0.5680 - val_loss: 3.4088 - val_accuracy: 0.3534\n",
      "Epoch 169/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2353 - accuracy: 0.5636 - val_loss: 3.4125 - val_accuracy: 0.3485\n",
      "Epoch 170/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2330 - accuracy: 0.5592 - val_loss: 3.4210 - val_accuracy: 0.3498\n",
      "Epoch 171/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2370 - accuracy: 0.5617 - val_loss: 3.4115 - val_accuracy: 0.3467\n",
      "Epoch 172/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2346 - accuracy: 0.5605 - val_loss: 3.4142 - val_accuracy: 0.3510\n",
      "Epoch 173/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2332 - accuracy: 0.5661 - val_loss: 3.4157 - val_accuracy: 0.3522\n",
      "Epoch 174/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2340 - accuracy: 0.5636 - val_loss: 3.4122 - val_accuracy: 0.3455\n",
      "Epoch 175/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2395 - accuracy: 0.5620 - val_loss: 3.4132 - val_accuracy: 0.3455\n",
      "Epoch 176/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.5617 - val_loss: 3.4135 - val_accuracy: 0.3473\n",
      "Epoch 177/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5620 - val_loss: 3.4093 - val_accuracy: 0.3455\n",
      "Epoch 178/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2367 - accuracy: 0.5595 - val_loss: 3.4137 - val_accuracy: 0.3467\n",
      "Epoch 179/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5648 - val_loss: 3.4136 - val_accuracy: 0.3449\n",
      "Epoch 180/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2392 - accuracy: 0.5584 - val_loss: 3.4094 - val_accuracy: 0.3449\n",
      "Epoch 181/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2311 - accuracy: 0.5633 - val_loss: 3.4119 - val_accuracy: 0.3485\n",
      "Epoch 182/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2381 - accuracy: 0.5566 - val_loss: 3.4122 - val_accuracy: 0.3522\n",
      "Epoch 183/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2366 - accuracy: 0.5642 - val_loss: 3.4190 - val_accuracy: 0.3461\n",
      "Epoch 184/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2365 - accuracy: 0.5613 - val_loss: 3.4244 - val_accuracy: 0.3455\n",
      "Epoch 185/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5649 - val_loss: 3.4129 - val_accuracy: 0.3522\n",
      "Epoch 186/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2352 - accuracy: 0.5665 - val_loss: 3.4169 - val_accuracy: 0.3540\n",
      "Epoch 187/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2329 - accuracy: 0.5652 - val_loss: 3.4145 - val_accuracy: 0.3467\n",
      "Epoch 188/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5652 - val_loss: 3.4167 - val_accuracy: 0.3564\n",
      "Epoch 189/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.5627 - val_loss: 3.4099 - val_accuracy: 0.3485\n",
      "Epoch 190/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2379 - accuracy: 0.5628 - val_loss: 3.4088 - val_accuracy: 0.3485\n",
      "Epoch 191/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5674 - val_loss: 3.4157 - val_accuracy: 0.3552\n",
      "Epoch 192/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2342 - accuracy: 0.5620 - val_loss: 3.4141 - val_accuracy: 0.3510\n",
      "Epoch 193/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2326 - accuracy: 0.5620 - val_loss: 3.4158 - val_accuracy: 0.3583\n",
      "Epoch 194/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5660 - val_loss: 3.4229 - val_accuracy: 0.3558\n",
      "Epoch 195/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2321 - accuracy: 0.5663 - val_loss: 3.4202 - val_accuracy: 0.3516\n",
      "Epoch 196/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2340 - accuracy: 0.5589 - val_loss: 3.4199 - val_accuracy: 0.3498\n",
      "Epoch 197/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2382 - accuracy: 0.5620 - val_loss: 3.4113 - val_accuracy: 0.3467\n",
      "Epoch 198/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2376 - accuracy: 0.5625 - val_loss: 3.4215 - val_accuracy: 0.3498\n",
      "Epoch 199/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.5636 - val_loss: 3.4297 - val_accuracy: 0.3455\n",
      "Epoch 200/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.5663 - val_loss: 3.4286 - val_accuracy: 0.3431\n",
      "Epoch 201/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2328 - accuracy: 0.5614 - val_loss: 3.4104 - val_accuracy: 0.3479\n",
      "Epoch 202/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2324 - accuracy: 0.5616 - val_loss: 3.4284 - val_accuracy: 0.3431\n",
      "Epoch 203/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.5657 - val_loss: 3.4229 - val_accuracy: 0.3498\n",
      "Epoch 204/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5651 - val_loss: 3.4272 - val_accuracy: 0.3467\n",
      "Epoch 205/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.5636 - val_loss: 3.4194 - val_accuracy: 0.3485\n",
      "Epoch 206/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2383 - accuracy: 0.5589 - val_loss: 3.4162 - val_accuracy: 0.3540\n",
      "Epoch 207/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2341 - accuracy: 0.5607 - val_loss: 3.4152 - val_accuracy: 0.3479\n",
      "Epoch 208/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.5628 - val_loss: 3.4176 - val_accuracy: 0.3449\n",
      "Epoch 209/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.5611 - val_loss: 3.4167 - val_accuracy: 0.3504\n",
      "Epoch 210/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2336 - accuracy: 0.5625 - val_loss: 3.4097 - val_accuracy: 0.3455\n",
      "Epoch 211/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2387 - accuracy: 0.5595 - val_loss: 3.4154 - val_accuracy: 0.3552\n",
      "Epoch 212/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2334 - accuracy: 0.5651 - val_loss: 3.4148 - val_accuracy: 0.3516\n",
      "Epoch 213/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2362 - accuracy: 0.5657 - val_loss: 3.4164 - val_accuracy: 0.3564\n",
      "Epoch 214/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5681 - val_loss: 3.4212 - val_accuracy: 0.3558\n",
      "Epoch 215/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2349 - accuracy: 0.5581 - val_loss: 3.4143 - val_accuracy: 0.3528\n",
      "Epoch 216/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2302 - accuracy: 0.5633 - val_loss: 3.4246 - val_accuracy: 0.3577\n",
      "Epoch 217/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2325 - accuracy: 0.5627 - val_loss: 3.4141 - val_accuracy: 0.3479\n",
      "Epoch 218/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5693 - val_loss: 3.4184 - val_accuracy: 0.3522\n",
      "Epoch 219/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2287 - accuracy: 0.5658 - val_loss: 3.4183 - val_accuracy: 0.3498\n",
      "Epoch 220/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2345 - accuracy: 0.5665 - val_loss: 3.4215 - val_accuracy: 0.3461\n",
      "Epoch 221/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2382 - accuracy: 0.5592 - val_loss: 3.4155 - val_accuracy: 0.3510\n",
      "Epoch 222/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2359 - accuracy: 0.5623 - val_loss: 3.4240 - val_accuracy: 0.3564\n",
      "Epoch 223/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2378 - accuracy: 0.5607 - val_loss: 3.4309 - val_accuracy: 0.3558\n",
      "Epoch 224/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5619 - val_loss: 3.4289 - val_accuracy: 0.3540\n",
      "Epoch 225/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2331 - accuracy: 0.5639 - val_loss: 3.4179 - val_accuracy: 0.3534\n",
      "Epoch 226/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2292 - accuracy: 0.5627 - val_loss: 3.4278 - val_accuracy: 0.3522\n",
      "Epoch 227/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2329 - accuracy: 0.5649 - val_loss: 3.4232 - val_accuracy: 0.3577\n",
      "Epoch 228/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2290 - accuracy: 0.5643 - val_loss: 3.4212 - val_accuracy: 0.3601\n",
      "Epoch 229/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5640 - val_loss: 3.4144 - val_accuracy: 0.3498\n",
      "Epoch 230/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2342 - accuracy: 0.5584 - val_loss: 3.4273 - val_accuracy: 0.3564\n",
      "Epoch 231/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2323 - accuracy: 0.5690 - val_loss: 3.4292 - val_accuracy: 0.3504\n",
      "Epoch 232/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2325 - accuracy: 0.5605 - val_loss: 3.4248 - val_accuracy: 0.3540\n",
      "Epoch 233/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.5661 - val_loss: 3.4278 - val_accuracy: 0.3491\n",
      "Epoch 234/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2337 - accuracy: 0.5643 - val_loss: 3.4301 - val_accuracy: 0.3479\n",
      "Epoch 235/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2318 - accuracy: 0.5652 - val_loss: 3.4241 - val_accuracy: 0.3479\n",
      "Epoch 236/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2276 - accuracy: 0.5675 - val_loss: 3.4404 - val_accuracy: 0.3540\n",
      "Epoch 237/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2376 - accuracy: 0.5602 - val_loss: 3.4302 - val_accuracy: 0.3485\n",
      "Epoch 238/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5640 - val_loss: 3.4278 - val_accuracy: 0.3479\n",
      "Epoch 239/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2334 - accuracy: 0.5610 - val_loss: 3.4236 - val_accuracy: 0.3534\n",
      "Epoch 240/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.5628 - val_loss: 3.4271 - val_accuracy: 0.3504\n",
      "Epoch 241/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2348 - accuracy: 0.5572 - val_loss: 3.4283 - val_accuracy: 0.3528\n",
      "Epoch 242/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5610 - val_loss: 3.4159 - val_accuracy: 0.3437\n",
      "Epoch 243/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2334 - accuracy: 0.5579 - val_loss: 3.4291 - val_accuracy: 0.3637\n",
      "Epoch 244/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5655 - val_loss: 3.4330 - val_accuracy: 0.3504\n",
      "Epoch 245/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5614 - val_loss: 3.4312 - val_accuracy: 0.3540\n",
      "Epoch 246/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2314 - accuracy: 0.5658 - val_loss: 3.4216 - val_accuracy: 0.3516\n",
      "Epoch 247/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.5658 - val_loss: 3.4334 - val_accuracy: 0.3577\n",
      "Epoch 248/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2330 - accuracy: 0.5610 - val_loss: 3.4289 - val_accuracy: 0.3546\n",
      "Epoch 249/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.5613 - val_loss: 3.4182 - val_accuracy: 0.3571\n",
      "Epoch 250/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2356 - accuracy: 0.5619 - val_loss: 3.4223 - val_accuracy: 0.3498\n",
      "Epoch 251/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5639 - val_loss: 3.4191 - val_accuracy: 0.3510\n",
      "Epoch 252/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.5640 - val_loss: 3.4271 - val_accuracy: 0.3528\n",
      "Epoch 253/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2332 - accuracy: 0.5581 - val_loss: 3.4272 - val_accuracy: 0.3449\n",
      "Epoch 254/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5627 - val_loss: 3.4324 - val_accuracy: 0.3449\n",
      "Epoch 255/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2320 - accuracy: 0.5605 - val_loss: 3.4295 - val_accuracy: 0.3534\n",
      "Epoch 256/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2363 - accuracy: 0.5602 - val_loss: 3.4283 - val_accuracy: 0.3516\n",
      "Epoch 257/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.5639 - val_loss: 3.4317 - val_accuracy: 0.3473\n",
      "Epoch 258/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.5639 - val_loss: 3.4217 - val_accuracy: 0.3485\n",
      "Epoch 259/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2343 - accuracy: 0.5610 - val_loss: 3.4251 - val_accuracy: 0.3534\n",
      "Epoch 260/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2346 - accuracy: 0.5620 - val_loss: 3.4351 - val_accuracy: 0.3504\n",
      "Epoch 261/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.5585 - val_loss: 3.4190 - val_accuracy: 0.3425\n",
      "Epoch 262/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2312 - accuracy: 0.5672 - val_loss: 3.4235 - val_accuracy: 0.3522\n",
      "Epoch 263/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.5669 - val_loss: 3.4348 - val_accuracy: 0.3522\n",
      "Epoch 264/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5634 - val_loss: 3.4352 - val_accuracy: 0.3479\n",
      "Epoch 265/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2345 - accuracy: 0.5654 - val_loss: 3.4335 - val_accuracy: 0.3516\n",
      "Epoch 266/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5614 - val_loss: 3.4389 - val_accuracy: 0.3540\n",
      "Epoch 267/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5593 - val_loss: 3.4248 - val_accuracy: 0.3540\n",
      "Epoch 268/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2328 - accuracy: 0.5663 - val_loss: 3.4364 - val_accuracy: 0.3552\n",
      "Epoch 269/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5658 - val_loss: 3.4313 - val_accuracy: 0.3571\n",
      "Epoch 270/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5633 - val_loss: 3.4357 - val_accuracy: 0.3540\n",
      "Epoch 271/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.5636 - val_loss: 3.4152 - val_accuracy: 0.3498\n",
      "Epoch 272/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.5627 - val_loss: 3.4299 - val_accuracy: 0.3485\n",
      "Epoch 273/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5623 - val_loss: 3.4389 - val_accuracy: 0.3498\n",
      "Epoch 274/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2375 - accuracy: 0.5617 - val_loss: 3.4311 - val_accuracy: 0.3516\n",
      "Epoch 275/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2319 - accuracy: 0.5693 - val_loss: 3.4318 - val_accuracy: 0.3485\n",
      "Epoch 276/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2295 - accuracy: 0.5660 - val_loss: 3.4304 - val_accuracy: 0.3504\n",
      "Epoch 277/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2339 - accuracy: 0.5611 - val_loss: 3.4341 - val_accuracy: 0.3510\n",
      "Epoch 278/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2291 - accuracy: 0.5651 - val_loss: 3.4342 - val_accuracy: 0.3473\n",
      "Epoch 279/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2367 - accuracy: 0.5576 - val_loss: 3.4330 - val_accuracy: 0.3461\n",
      "Epoch 280/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2345 - accuracy: 0.5639 - val_loss: 3.4290 - val_accuracy: 0.3473\n",
      "Epoch 281/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.5660 - val_loss: 3.4321 - val_accuracy: 0.3491\n",
      "Epoch 282/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2315 - accuracy: 0.5660 - val_loss: 3.4170 - val_accuracy: 0.3485\n",
      "Epoch 283/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2282 - accuracy: 0.5649 - val_loss: 3.4316 - val_accuracy: 0.3522\n",
      "Epoch 284/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5625 - val_loss: 3.4414 - val_accuracy: 0.3479\n",
      "Epoch 285/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.5619 - val_loss: 3.4365 - val_accuracy: 0.3431\n",
      "Epoch 286/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.5640 - val_loss: 3.4322 - val_accuracy: 0.3528\n",
      "Epoch 287/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.5643 - val_loss: 3.4299 - val_accuracy: 0.3449\n",
      "Epoch 288/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2358 - accuracy: 0.5564 - val_loss: 3.4345 - val_accuracy: 0.3546\n",
      "Epoch 289/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5620 - val_loss: 3.4400 - val_accuracy: 0.3528\n",
      "Epoch 290/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2294 - accuracy: 0.5665 - val_loss: 3.4512 - val_accuracy: 0.3443\n",
      "Epoch 291/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5666 - val_loss: 3.4472 - val_accuracy: 0.3522\n",
      "Epoch 292/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2314 - accuracy: 0.5620 - val_loss: 3.4428 - val_accuracy: 0.3485\n",
      "Epoch 293/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.5622 - val_loss: 3.4363 - val_accuracy: 0.3504\n",
      "Epoch 294/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2327 - accuracy: 0.5623 - val_loss: 3.4452 - val_accuracy: 0.3467\n",
      "Epoch 295/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2336 - accuracy: 0.5596 - val_loss: 3.4385 - val_accuracy: 0.3491\n",
      "Epoch 296/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.5607 - val_loss: 3.4459 - val_accuracy: 0.3443\n",
      "Epoch 297/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5604 - val_loss: 3.4460 - val_accuracy: 0.3455\n",
      "Epoch 298/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.5611 - val_loss: 3.4408 - val_accuracy: 0.3522\n",
      "Epoch 299/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.5610 - val_loss: 3.4389 - val_accuracy: 0.3534\n",
      "Epoch 300/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2331 - accuracy: 0.5581 - val_loss: 3.4383 - val_accuracy: 0.3455\n",
      "Epoch 301/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2364 - accuracy: 0.5623 - val_loss: 3.4355 - val_accuracy: 0.3449\n",
      "Epoch 302/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5675 - val_loss: 3.4482 - val_accuracy: 0.3449\n",
      "Epoch 303/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2349 - accuracy: 0.5607 - val_loss: 3.4434 - val_accuracy: 0.3455\n",
      "Epoch 304/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2260 - accuracy: 0.5634 - val_loss: 3.4386 - val_accuracy: 0.3504\n",
      "Epoch 305/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2321 - accuracy: 0.5640 - val_loss: 3.4416 - val_accuracy: 0.3443\n",
      "Epoch 306/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.5695 - val_loss: 3.4515 - val_accuracy: 0.3504\n",
      "Epoch 307/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2343 - accuracy: 0.5604 - val_loss: 3.4365 - val_accuracy: 0.3498\n",
      "Epoch 308/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2325 - accuracy: 0.5576 - val_loss: 3.4446 - val_accuracy: 0.3498\n",
      "Epoch 309/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5587 - val_loss: 3.4436 - val_accuracy: 0.3418\n",
      "Epoch 310/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2350 - accuracy: 0.5585 - val_loss: 3.4436 - val_accuracy: 0.3498\n",
      "Epoch 311/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2296 - accuracy: 0.5645 - val_loss: 3.4369 - val_accuracy: 0.3455\n",
      "Epoch 312/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2305 - accuracy: 0.5640 - val_loss: 3.4402 - val_accuracy: 0.3431\n",
      "Epoch 313/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2321 - accuracy: 0.5558 - val_loss: 3.4503 - val_accuracy: 0.3479\n",
      "Epoch 314/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2342 - accuracy: 0.5604 - val_loss: 3.4408 - val_accuracy: 0.3473\n",
      "Epoch 315/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2310 - accuracy: 0.5666 - val_loss: 3.4495 - val_accuracy: 0.3473\n",
      "Epoch 316/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2313 - accuracy: 0.5614 - val_loss: 3.4543 - val_accuracy: 0.3425\n",
      "Epoch 317/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2377 - accuracy: 0.5625 - val_loss: 3.4439 - val_accuracy: 0.3473\n",
      "Epoch 318/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2347 - accuracy: 0.5643 - val_loss: 3.4476 - val_accuracy: 0.3467\n",
      "Epoch 319/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2317 - accuracy: 0.5625 - val_loss: 3.4394 - val_accuracy: 0.3540\n",
      "Epoch 320/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2295 - accuracy: 0.5669 - val_loss: 3.4526 - val_accuracy: 0.3418\n",
      "Epoch 321/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.5589 - val_loss: 3.4411 - val_accuracy: 0.3528\n",
      "Epoch 322/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2365 - accuracy: 0.5601 - val_loss: 3.4423 - val_accuracy: 0.3437\n",
      "Epoch 323/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2291 - accuracy: 0.5684 - val_loss: 3.4465 - val_accuracy: 0.3412\n",
      "Epoch 324/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2310 - accuracy: 0.5660 - val_loss: 3.4450 - val_accuracy: 0.3467\n",
      "Epoch 325/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2354 - accuracy: 0.5620 - val_loss: 3.4498 - val_accuracy: 0.3479\n",
      "Epoch 326/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2304 - accuracy: 0.5643 - val_loss: 3.4490 - val_accuracy: 0.3479\n",
      "Epoch 327/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2326 - accuracy: 0.5589 - val_loss: 3.4639 - val_accuracy: 0.3455\n",
      "Epoch 328/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2397 - accuracy: 0.5575 - val_loss: 3.4618 - val_accuracy: 0.3425\n",
      "Epoch 329/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2317 - accuracy: 0.5645 - val_loss: 3.4558 - val_accuracy: 0.3467\n",
      "Epoch 330/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2375 - accuracy: 0.5613 - val_loss: 3.4481 - val_accuracy: 0.3467\n",
      "Epoch 331/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.5633 - val_loss: 3.4404 - val_accuracy: 0.3455\n",
      "Epoch 332/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2312 - accuracy: 0.5620 - val_loss: 3.4538 - val_accuracy: 0.3504\n",
      "Epoch 333/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2315 - accuracy: 0.5645 - val_loss: 3.4519 - val_accuracy: 0.3400\n",
      "Epoch 334/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.5648 - val_loss: 3.4410 - val_accuracy: 0.3491\n",
      "Epoch 335/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2389 - accuracy: 0.5627 - val_loss: 3.4379 - val_accuracy: 0.3510\n",
      "Epoch 336/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5610 - val_loss: 3.4471 - val_accuracy: 0.3467\n",
      "Epoch 337/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2316 - accuracy: 0.5637 - val_loss: 3.4454 - val_accuracy: 0.3571\n",
      "Epoch 338/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.5639 - val_loss: 3.4481 - val_accuracy: 0.3461\n",
      "Epoch 339/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2327 - accuracy: 0.5669 - val_loss: 3.4672 - val_accuracy: 0.3485\n",
      "Epoch 340/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5663 - val_loss: 3.4518 - val_accuracy: 0.3498\n",
      "Epoch 341/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5636 - val_loss: 3.4468 - val_accuracy: 0.3546\n",
      "Epoch 342/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.5649 - val_loss: 3.4517 - val_accuracy: 0.3516\n",
      "Epoch 343/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5608 - val_loss: 3.4582 - val_accuracy: 0.3467\n",
      "Epoch 344/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5646 - val_loss: 3.4571 - val_accuracy: 0.3504\n",
      "Epoch 345/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.5585 - val_loss: 3.4624 - val_accuracy: 0.3540\n",
      "Epoch 346/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.5599 - val_loss: 3.4662 - val_accuracy: 0.3491\n",
      "Epoch 347/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2363 - accuracy: 0.5628 - val_loss: 3.4634 - val_accuracy: 0.3504\n",
      "Epoch 348/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5619 - val_loss: 3.4596 - val_accuracy: 0.3491\n",
      "Epoch 349/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2360 - accuracy: 0.5651 - val_loss: 3.4504 - val_accuracy: 0.3467\n",
      "Epoch 350/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.5572 - val_loss: 3.4533 - val_accuracy: 0.3534\n",
      "Epoch 351/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5639 - val_loss: 3.4621 - val_accuracy: 0.3522\n",
      "Epoch 352/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2323 - accuracy: 0.5622 - val_loss: 3.4550 - val_accuracy: 0.3491\n",
      "Epoch 353/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5646 - val_loss: 3.4544 - val_accuracy: 0.3540\n",
      "Epoch 354/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.5633 - val_loss: 3.4629 - val_accuracy: 0.3528\n",
      "Epoch 355/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.5619 - val_loss: 3.4520 - val_accuracy: 0.3522\n",
      "Epoch 356/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2264 - accuracy: 0.5654 - val_loss: 3.4580 - val_accuracy: 0.3546\n",
      "Epoch 357/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5625 - val_loss: 3.4705 - val_accuracy: 0.3558\n",
      "Epoch 358/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5639 - val_loss: 3.4645 - val_accuracy: 0.3498\n",
      "Epoch 359/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5643 - val_loss: 3.4582 - val_accuracy: 0.3558\n",
      "Epoch 360/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.5701 - val_loss: 3.4556 - val_accuracy: 0.3540\n",
      "Epoch 361/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2345 - accuracy: 0.5634 - val_loss: 3.4572 - val_accuracy: 0.3473\n",
      "Epoch 362/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.5643 - val_loss: 3.4668 - val_accuracy: 0.3473\n",
      "Epoch 363/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.5589 - val_loss: 3.4609 - val_accuracy: 0.3522\n",
      "Epoch 364/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2331 - accuracy: 0.5633 - val_loss: 3.4586 - val_accuracy: 0.3522\n",
      "Epoch 365/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2305 - accuracy: 0.5576 - val_loss: 3.4595 - val_accuracy: 0.3534\n",
      "Epoch 366/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2294 - accuracy: 0.5634 - val_loss: 3.4641 - val_accuracy: 0.3504\n",
      "Epoch 367/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2293 - accuracy: 0.5649 - val_loss: 3.4558 - val_accuracy: 0.3546\n",
      "Epoch 368/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5622 - val_loss: 3.4601 - val_accuracy: 0.3498\n",
      "Epoch 369/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2311 - accuracy: 0.5611 - val_loss: 3.4646 - val_accuracy: 0.3498\n",
      "Epoch 370/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.5601 - val_loss: 3.4613 - val_accuracy: 0.3455\n",
      "Epoch 371/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2313 - accuracy: 0.5628 - val_loss: 3.4605 - val_accuracy: 0.3467\n",
      "Epoch 372/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2329 - accuracy: 0.5639 - val_loss: 3.4561 - val_accuracy: 0.3528\n",
      "Epoch 373/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2330 - accuracy: 0.5666 - val_loss: 3.4596 - val_accuracy: 0.3522\n",
      "Epoch 374/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2261 - accuracy: 0.5643 - val_loss: 3.4639 - val_accuracy: 0.3534\n",
      "Epoch 375/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2286 - accuracy: 0.5652 - val_loss: 3.4562 - val_accuracy: 0.3552\n",
      "Epoch 376/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5654 - val_loss: 3.4699 - val_accuracy: 0.3510\n",
      "Epoch 377/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2249 - accuracy: 0.5672 - val_loss: 3.4699 - val_accuracy: 0.3540\n",
      "Epoch 378/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2349 - accuracy: 0.5576 - val_loss: 3.4609 - val_accuracy: 0.3540\n",
      "Epoch 379/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.5642 - val_loss: 3.4689 - val_accuracy: 0.3552\n",
      "Epoch 380/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5630 - val_loss: 3.4674 - val_accuracy: 0.3504\n",
      "Epoch 381/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2345 - accuracy: 0.5602 - val_loss: 3.4584 - val_accuracy: 0.3498\n",
      "Epoch 382/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2326 - accuracy: 0.5595 - val_loss: 3.4650 - val_accuracy: 0.3473\n",
      "Epoch 383/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2352 - accuracy: 0.5651 - val_loss: 3.4577 - val_accuracy: 0.3461\n",
      "Epoch 384/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2352 - accuracy: 0.5558 - val_loss: 3.4639 - val_accuracy: 0.3431\n",
      "Epoch 385/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2346 - accuracy: 0.5616 - val_loss: 3.4594 - val_accuracy: 0.3479\n",
      "Epoch 386/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.5639 - val_loss: 3.4599 - val_accuracy: 0.3473\n",
      "Epoch 387/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2253 - accuracy: 0.5646 - val_loss: 3.4722 - val_accuracy: 0.3491\n",
      "Epoch 388/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5657 - val_loss: 3.4679 - val_accuracy: 0.3552\n",
      "Epoch 389/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2276 - accuracy: 0.5696 - val_loss: 3.4635 - val_accuracy: 0.3534\n",
      "Epoch 390/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.5614 - val_loss: 3.4728 - val_accuracy: 0.3485\n",
      "Epoch 391/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.5573 - val_loss: 3.4660 - val_accuracy: 0.3516\n",
      "Epoch 392/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5654 - val_loss: 3.4630 - val_accuracy: 0.3546\n",
      "Epoch 393/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2268 - accuracy: 0.5660 - val_loss: 3.4624 - val_accuracy: 0.3534\n",
      "Epoch 394/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2374 - accuracy: 0.5598 - val_loss: 3.4593 - val_accuracy: 0.3491\n",
      "Epoch 395/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2276 - accuracy: 0.5674 - val_loss: 3.4679 - val_accuracy: 0.3449\n",
      "Epoch 396/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2345 - accuracy: 0.5614 - val_loss: 3.4565 - val_accuracy: 0.3485\n",
      "Epoch 397/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5655 - val_loss: 3.4646 - val_accuracy: 0.3504\n",
      "Epoch 398/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5678 - val_loss: 3.4711 - val_accuracy: 0.3485\n",
      "Epoch 399/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2272 - accuracy: 0.5642 - val_loss: 3.4677 - val_accuracy: 0.3461\n",
      "Epoch 400/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5645 - val_loss: 3.4655 - val_accuracy: 0.3498\n",
      "Epoch 401/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.5572 - val_loss: 3.4627 - val_accuracy: 0.3425\n",
      "Epoch 402/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2400 - accuracy: 0.5592 - val_loss: 3.4627 - val_accuracy: 0.3504\n",
      "Epoch 403/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2261 - accuracy: 0.5675 - val_loss: 3.4648 - val_accuracy: 0.3449\n",
      "Epoch 404/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5684 - val_loss: 3.4653 - val_accuracy: 0.3485\n",
      "Epoch 405/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2297 - accuracy: 0.5637 - val_loss: 3.4760 - val_accuracy: 0.3498\n",
      "Epoch 406/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2296 - accuracy: 0.5625 - val_loss: 3.4697 - val_accuracy: 0.3504\n",
      "Epoch 407/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2294 - accuracy: 0.5658 - val_loss: 3.4730 - val_accuracy: 0.3491\n",
      "Epoch 408/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2326 - accuracy: 0.5622 - val_loss: 3.4690 - val_accuracy: 0.3455\n",
      "Epoch 409/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5630 - val_loss: 3.4706 - val_accuracy: 0.3522\n",
      "Epoch 410/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2362 - accuracy: 0.5578 - val_loss: 3.4709 - val_accuracy: 0.3522\n",
      "Epoch 411/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2311 - accuracy: 0.5636 - val_loss: 3.4742 - val_accuracy: 0.3516\n",
      "Epoch 412/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2235 - accuracy: 0.5642 - val_loss: 3.4790 - val_accuracy: 0.3522\n",
      "Epoch 413/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2347 - accuracy: 0.5643 - val_loss: 3.4780 - val_accuracy: 0.3461\n",
      "Epoch 414/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5665 - val_loss: 3.4758 - val_accuracy: 0.3491\n",
      "Epoch 415/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5648 - val_loss: 3.4738 - val_accuracy: 0.3504\n",
      "Epoch 416/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.5622 - val_loss: 3.4604 - val_accuracy: 0.3516\n",
      "Epoch 417/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5678 - val_loss: 3.4673 - val_accuracy: 0.3534\n",
      "Epoch 418/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5593 - val_loss: 3.4704 - val_accuracy: 0.3558\n",
      "Epoch 419/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2355 - accuracy: 0.5623 - val_loss: 3.4781 - val_accuracy: 0.3522\n",
      "Epoch 420/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2361 - accuracy: 0.5617 - val_loss: 3.4545 - val_accuracy: 0.3540\n",
      "Epoch 421/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5607 - val_loss: 3.4719 - val_accuracy: 0.3498\n",
      "Epoch 422/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2282 - accuracy: 0.5651 - val_loss: 3.4740 - val_accuracy: 0.3455\n",
      "Epoch 423/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5617 - val_loss: 3.4708 - val_accuracy: 0.3479\n",
      "Epoch 424/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2320 - accuracy: 0.5646 - val_loss: 3.4699 - val_accuracy: 0.3479\n",
      "Epoch 425/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2229 - accuracy: 0.5654 - val_loss: 3.4768 - val_accuracy: 0.3431\n",
      "Epoch 426/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5652 - val_loss: 3.4652 - val_accuracy: 0.3418\n",
      "Epoch 427/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.5630 - val_loss: 3.4654 - val_accuracy: 0.3528\n",
      "Epoch 428/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5675 - val_loss: 3.4779 - val_accuracy: 0.3461\n",
      "Epoch 429/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2275 - accuracy: 0.5640 - val_loss: 3.4708 - val_accuracy: 0.3467\n",
      "Epoch 430/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2256 - accuracy: 0.5655 - val_loss: 3.4764 - val_accuracy: 0.3431\n",
      "Epoch 431/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2274 - accuracy: 0.5661 - val_loss: 3.4777 - val_accuracy: 0.3467\n",
      "Epoch 432/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.5628 - val_loss: 3.4817 - val_accuracy: 0.3443\n",
      "Epoch 433/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5622 - val_loss: 3.4753 - val_accuracy: 0.3461\n",
      "Epoch 434/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2303 - accuracy: 0.5646 - val_loss: 3.4813 - val_accuracy: 0.3577\n",
      "Epoch 435/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5627 - val_loss: 3.4723 - val_accuracy: 0.3516\n",
      "Epoch 436/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5617 - val_loss: 3.4705 - val_accuracy: 0.3510\n",
      "Epoch 437/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5607 - val_loss: 3.4754 - val_accuracy: 0.3479\n",
      "Epoch 438/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5625 - val_loss: 3.4756 - val_accuracy: 0.3540\n",
      "Epoch 439/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5637 - val_loss: 3.4787 - val_accuracy: 0.3504\n",
      "Epoch 440/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.5616 - val_loss: 3.4751 - val_accuracy: 0.3522\n",
      "Epoch 441/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5639 - val_loss: 3.4790 - val_accuracy: 0.3491\n",
      "Epoch 442/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5576 - val_loss: 3.4753 - val_accuracy: 0.3467\n",
      "Epoch 443/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2294 - accuracy: 0.5642 - val_loss: 3.4689 - val_accuracy: 0.3449\n",
      "Epoch 444/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2256 - accuracy: 0.5640 - val_loss: 3.4717 - val_accuracy: 0.3510\n",
      "Epoch 445/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2310 - accuracy: 0.5643 - val_loss: 3.4651 - val_accuracy: 0.3455\n",
      "Epoch 446/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2301 - accuracy: 0.5634 - val_loss: 3.4652 - val_accuracy: 0.3443\n",
      "Epoch 447/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2274 - accuracy: 0.5654 - val_loss: 3.4746 - val_accuracy: 0.3467\n",
      "Epoch 448/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2293 - accuracy: 0.5640 - val_loss: 3.4805 - val_accuracy: 0.3516\n",
      "Epoch 449/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2256 - accuracy: 0.5674 - val_loss: 3.4705 - val_accuracy: 0.3461\n",
      "Epoch 450/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5627 - val_loss: 3.4704 - val_accuracy: 0.3491\n",
      "Epoch 451/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2277 - accuracy: 0.5640 - val_loss: 3.4794 - val_accuracy: 0.3455\n",
      "Epoch 452/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2289 - accuracy: 0.5652 - val_loss: 3.4706 - val_accuracy: 0.3485\n",
      "Epoch 453/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2260 - accuracy: 0.5660 - val_loss: 3.4640 - val_accuracy: 0.3485\n",
      "Epoch 454/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2269 - accuracy: 0.5628 - val_loss: 3.4773 - val_accuracy: 0.3522\n",
      "Epoch 455/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5639 - val_loss: 3.4723 - val_accuracy: 0.3473\n",
      "Epoch 456/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.5614 - val_loss: 3.4662 - val_accuracy: 0.3528\n",
      "Epoch 457/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2316 - accuracy: 0.5585 - val_loss: 3.4707 - val_accuracy: 0.3498\n",
      "Epoch 458/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5637 - val_loss: 3.4700 - val_accuracy: 0.3516\n",
      "Epoch 459/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.5642 - val_loss: 3.4867 - val_accuracy: 0.3479\n",
      "Epoch 460/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2305 - accuracy: 0.5640 - val_loss: 3.4773 - val_accuracy: 0.3425\n",
      "Epoch 461/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5639 - val_loss: 3.4704 - val_accuracy: 0.3425\n",
      "Epoch 462/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2312 - accuracy: 0.5611 - val_loss: 3.4813 - val_accuracy: 0.3522\n",
      "Epoch 463/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2228 - accuracy: 0.5681 - val_loss: 3.4906 - val_accuracy: 0.3504\n",
      "Epoch 464/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2265 - accuracy: 0.5642 - val_loss: 3.4962 - val_accuracy: 0.3467\n",
      "Epoch 465/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2286 - accuracy: 0.5640 - val_loss: 3.4992 - val_accuracy: 0.3498\n",
      "Epoch 466/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5668 - val_loss: 3.4865 - val_accuracy: 0.3540\n",
      "Epoch 467/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2296 - accuracy: 0.5637 - val_loss: 3.4951 - val_accuracy: 0.3461\n",
      "Epoch 468/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2287 - accuracy: 0.5616 - val_loss: 3.4944 - val_accuracy: 0.3449\n",
      "Epoch 469/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.5672 - val_loss: 3.4813 - val_accuracy: 0.3461\n",
      "Epoch 470/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2299 - accuracy: 0.5658 - val_loss: 3.4920 - val_accuracy: 0.3455\n",
      "Epoch 471/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2277 - accuracy: 0.5620 - val_loss: 3.4962 - val_accuracy: 0.3485\n",
      "Epoch 472/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5660 - val_loss: 3.4882 - val_accuracy: 0.3449\n",
      "Epoch 473/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.5646 - val_loss: 3.4918 - val_accuracy: 0.3467\n",
      "Epoch 474/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2224 - accuracy: 0.5634 - val_loss: 3.4955 - val_accuracy: 0.3431\n",
      "Epoch 475/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2259 - accuracy: 0.5684 - val_loss: 3.5096 - val_accuracy: 0.3473\n",
      "Epoch 476/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2250 - accuracy: 0.5651 - val_loss: 3.4919 - val_accuracy: 0.3516\n",
      "Epoch 477/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2292 - accuracy: 0.5634 - val_loss: 3.4963 - val_accuracy: 0.3498\n",
      "Epoch 478/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5628 - val_loss: 3.4884 - val_accuracy: 0.3449\n",
      "Epoch 479/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5628 - val_loss: 3.4845 - val_accuracy: 0.3516\n",
      "Epoch 480/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5669 - val_loss: 3.4840 - val_accuracy: 0.3485\n",
      "Epoch 481/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2207 - accuracy: 0.5683 - val_loss: 3.4887 - val_accuracy: 0.3473\n",
      "Epoch 482/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5636 - val_loss: 3.4928 - val_accuracy: 0.3491\n",
      "Epoch 483/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5625 - val_loss: 3.4961 - val_accuracy: 0.3522\n",
      "Epoch 484/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5599 - val_loss: 3.4795 - val_accuracy: 0.3479\n",
      "Epoch 485/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2281 - accuracy: 0.5625 - val_loss: 3.4809 - val_accuracy: 0.3498\n",
      "Epoch 486/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.5649 - val_loss: 3.4822 - val_accuracy: 0.3491\n",
      "Epoch 487/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5637 - val_loss: 3.4937 - val_accuracy: 0.3461\n",
      "Epoch 488/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5604 - val_loss: 3.4844 - val_accuracy: 0.3498\n",
      "Epoch 489/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5602 - val_loss: 3.4837 - val_accuracy: 0.3510\n",
      "Epoch 490/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5639 - val_loss: 3.4813 - val_accuracy: 0.3528\n",
      "Epoch 491/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2326 - accuracy: 0.5599 - val_loss: 3.4834 - val_accuracy: 0.3443\n",
      "Epoch 492/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5674 - val_loss: 3.4835 - val_accuracy: 0.3473\n",
      "Epoch 493/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.5611 - val_loss: 3.4851 - val_accuracy: 0.3491\n",
      "Epoch 494/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5628 - val_loss: 3.4820 - val_accuracy: 0.3528\n",
      "Epoch 495/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2269 - accuracy: 0.5642 - val_loss: 3.4950 - val_accuracy: 0.3491\n",
      "Epoch 496/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2261 - accuracy: 0.5636 - val_loss: 3.4986 - val_accuracy: 0.3473\n",
      "Epoch 497/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.5636 - val_loss: 3.5001 - val_accuracy: 0.3425\n",
      "Epoch 498/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.5649 - val_loss: 3.4883 - val_accuracy: 0.3449\n",
      "Epoch 499/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5625 - val_loss: 3.4849 - val_accuracy: 0.3467\n",
      "Epoch 500/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.5651 - val_loss: 3.4877 - val_accuracy: 0.3479\n",
      "Epoch 501/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.5630 - val_loss: 3.4910 - val_accuracy: 0.3485\n",
      "Epoch 502/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2202 - accuracy: 0.5680 - val_loss: 3.4912 - val_accuracy: 0.3510\n",
      "Epoch 503/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2242 - accuracy: 0.5658 - val_loss: 3.4941 - val_accuracy: 0.3504\n",
      "Epoch 504/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2244 - accuracy: 0.5625 - val_loss: 3.4911 - val_accuracy: 0.3522\n",
      "Epoch 505/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2262 - accuracy: 0.5601 - val_loss: 3.4955 - val_accuracy: 0.3498\n",
      "Epoch 506/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5634 - val_loss: 3.4939 - val_accuracy: 0.3485\n",
      "Epoch 507/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2268 - accuracy: 0.5645 - val_loss: 3.4890 - val_accuracy: 0.3473\n",
      "Epoch 508/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2273 - accuracy: 0.5628 - val_loss: 3.4959 - val_accuracy: 0.3406\n",
      "Epoch 509/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5607 - val_loss: 3.4855 - val_accuracy: 0.3485\n",
      "Epoch 510/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2260 - accuracy: 0.5608 - val_loss: 3.4796 - val_accuracy: 0.3467\n",
      "Epoch 511/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.5614 - val_loss: 3.4822 - val_accuracy: 0.3534\n",
      "Epoch 512/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2285 - accuracy: 0.5610 - val_loss: 3.4866 - val_accuracy: 0.3485\n",
      "Epoch 513/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2305 - accuracy: 0.5593 - val_loss: 3.4759 - val_accuracy: 0.3552\n",
      "Epoch 514/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.5648 - val_loss: 3.4790 - val_accuracy: 0.3564\n",
      "Epoch 515/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5668 - val_loss: 3.4905 - val_accuracy: 0.3504\n",
      "Epoch 516/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2268 - accuracy: 0.5668 - val_loss: 3.4976 - val_accuracy: 0.3534\n",
      "Epoch 517/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2329 - accuracy: 0.5666 - val_loss: 3.4893 - val_accuracy: 0.3528\n",
      "Epoch 518/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.5690 - val_loss: 3.4910 - val_accuracy: 0.3522\n",
      "Epoch 519/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2312 - accuracy: 0.5628 - val_loss: 3.4866 - val_accuracy: 0.3504\n",
      "Epoch 520/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5658 - val_loss: 3.5020 - val_accuracy: 0.3455\n",
      "Epoch 521/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2215 - accuracy: 0.5666 - val_loss: 3.4947 - val_accuracy: 0.3522\n",
      "Epoch 522/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2275 - accuracy: 0.5640 - val_loss: 3.4991 - val_accuracy: 0.3498\n",
      "Epoch 523/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2221 - accuracy: 0.5669 - val_loss: 3.4950 - val_accuracy: 0.3528\n",
      "Epoch 524/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2234 - accuracy: 0.5628 - val_loss: 3.5050 - val_accuracy: 0.3437\n",
      "Epoch 525/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2177 - accuracy: 0.5648 - val_loss: 3.4982 - val_accuracy: 0.3510\n",
      "Epoch 526/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2284 - accuracy: 0.5634 - val_loss: 3.4984 - val_accuracy: 0.3461\n",
      "Epoch 527/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2256 - accuracy: 0.5636 - val_loss: 3.4966 - val_accuracy: 0.3491\n",
      "Epoch 528/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.5617 - val_loss: 3.4960 - val_accuracy: 0.3516\n",
      "Epoch 529/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5584 - val_loss: 3.4906 - val_accuracy: 0.3522\n",
      "Epoch 530/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5677 - val_loss: 3.4894 - val_accuracy: 0.3467\n",
      "Epoch 531/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2321 - accuracy: 0.5614 - val_loss: 3.5014 - val_accuracy: 0.3455\n",
      "Epoch 532/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2315 - accuracy: 0.5611 - val_loss: 3.4777 - val_accuracy: 0.3528\n",
      "Epoch 533/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2328 - accuracy: 0.5631 - val_loss: 3.4791 - val_accuracy: 0.3516\n",
      "Epoch 534/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5628 - val_loss: 3.4808 - val_accuracy: 0.3473\n",
      "Epoch 535/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2273 - accuracy: 0.5640 - val_loss: 3.4847 - val_accuracy: 0.3449\n",
      "Epoch 536/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.5655 - val_loss: 3.4975 - val_accuracy: 0.3473\n",
      "Epoch 537/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5604 - val_loss: 3.4982 - val_accuracy: 0.3498\n",
      "Epoch 538/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2260 - accuracy: 0.5639 - val_loss: 3.4918 - val_accuracy: 0.3528\n",
      "Epoch 539/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5678 - val_loss: 3.4883 - val_accuracy: 0.3479\n",
      "Epoch 540/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5648 - val_loss: 3.4920 - val_accuracy: 0.3473\n",
      "Epoch 541/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2218 - accuracy: 0.5663 - val_loss: 3.4913 - val_accuracy: 0.3498\n",
      "Epoch 542/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2204 - accuracy: 0.5634 - val_loss: 3.5052 - val_accuracy: 0.3485\n",
      "Epoch 543/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2260 - accuracy: 0.5613 - val_loss: 3.5019 - val_accuracy: 0.3491\n",
      "Epoch 544/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5646 - val_loss: 3.5011 - val_accuracy: 0.3461\n",
      "Epoch 545/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2369 - accuracy: 0.5578 - val_loss: 3.4908 - val_accuracy: 0.3498\n",
      "Epoch 546/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2335 - accuracy: 0.5617 - val_loss: 3.4924 - val_accuracy: 0.3522\n",
      "Epoch 547/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.5592 - val_loss: 3.5016 - val_accuracy: 0.3479\n",
      "Epoch 548/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2255 - accuracy: 0.5668 - val_loss: 3.5089 - val_accuracy: 0.3455\n",
      "Epoch 549/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.5639 - val_loss: 3.4995 - val_accuracy: 0.3485\n",
      "Epoch 550/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2278 - accuracy: 0.5637 - val_loss: 3.4914 - val_accuracy: 0.3479\n",
      "Epoch 551/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2287 - accuracy: 0.5625 - val_loss: 3.5012 - val_accuracy: 0.3455\n",
      "Epoch 552/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2261 - accuracy: 0.5623 - val_loss: 3.5051 - val_accuracy: 0.3437\n",
      "Epoch 553/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5620 - val_loss: 3.4951 - val_accuracy: 0.3498\n",
      "Epoch 554/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2211 - accuracy: 0.5631 - val_loss: 3.4962 - val_accuracy: 0.3455\n",
      "Epoch 555/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2301 - accuracy: 0.5627 - val_loss: 3.4877 - val_accuracy: 0.3504\n",
      "Epoch 556/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2238 - accuracy: 0.5651 - val_loss: 3.4902 - val_accuracy: 0.3491\n",
      "Epoch 557/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2320 - accuracy: 0.5610 - val_loss: 3.4996 - val_accuracy: 0.3522\n",
      "Epoch 558/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.5620 - val_loss: 3.4910 - val_accuracy: 0.3467\n",
      "Epoch 559/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2277 - accuracy: 0.5602 - val_loss: 3.4954 - val_accuracy: 0.3461\n",
      "Epoch 560/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2333 - accuracy: 0.5640 - val_loss: 3.5006 - val_accuracy: 0.3504\n",
      "Epoch 561/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2349 - accuracy: 0.5601 - val_loss: 3.4882 - val_accuracy: 0.3504\n",
      "Epoch 562/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2339 - accuracy: 0.5633 - val_loss: 3.4959 - val_accuracy: 0.3516\n",
      "Epoch 563/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.5643 - val_loss: 3.4907 - val_accuracy: 0.3449\n",
      "Epoch 564/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2281 - accuracy: 0.5634 - val_loss: 3.4878 - val_accuracy: 0.3491\n",
      "Epoch 565/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5611 - val_loss: 3.4953 - val_accuracy: 0.3528\n",
      "Epoch 566/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2297 - accuracy: 0.5608 - val_loss: 3.4950 - val_accuracy: 0.3504\n",
      "Epoch 567/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.5643 - val_loss: 3.4921 - val_accuracy: 0.3504\n",
      "Epoch 568/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5625 - val_loss: 3.4888 - val_accuracy: 0.3528\n",
      "Epoch 569/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5687 - val_loss: 3.4937 - val_accuracy: 0.3485\n",
      "Epoch 570/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2297 - accuracy: 0.5665 - val_loss: 3.4889 - val_accuracy: 0.3510\n",
      "Epoch 571/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2233 - accuracy: 0.5637 - val_loss: 3.4992 - val_accuracy: 0.3485\n",
      "Epoch 572/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5636 - val_loss: 3.5022 - val_accuracy: 0.3461\n",
      "Epoch 573/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2287 - accuracy: 0.5674 - val_loss: 3.4959 - val_accuracy: 0.3504\n",
      "Epoch 574/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.5668 - val_loss: 3.5052 - val_accuracy: 0.3455\n",
      "Epoch 575/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2211 - accuracy: 0.5674 - val_loss: 3.4950 - val_accuracy: 0.3498\n",
      "Epoch 576/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.5625 - val_loss: 3.5044 - val_accuracy: 0.3485\n",
      "Epoch 577/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5572 - val_loss: 3.4953 - val_accuracy: 0.3516\n",
      "Epoch 578/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2237 - accuracy: 0.5648 - val_loss: 3.4932 - val_accuracy: 0.3479\n",
      "Epoch 579/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2249 - accuracy: 0.5620 - val_loss: 3.5066 - val_accuracy: 0.3504\n",
      "Epoch 580/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2302 - accuracy: 0.5655 - val_loss: 3.5044 - val_accuracy: 0.3473\n",
      "Epoch 581/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.5657 - val_loss: 3.5135 - val_accuracy: 0.3479\n",
      "Epoch 582/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2250 - accuracy: 0.5672 - val_loss: 3.4988 - val_accuracy: 0.3504\n",
      "Epoch 583/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2269 - accuracy: 0.5587 - val_loss: 3.4950 - val_accuracy: 0.3504\n",
      "Epoch 584/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.5674 - val_loss: 3.4959 - val_accuracy: 0.3491\n",
      "Epoch 585/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.5652 - val_loss: 3.4955 - val_accuracy: 0.3540\n",
      "Epoch 586/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2303 - accuracy: 0.5634 - val_loss: 3.5016 - val_accuracy: 0.3485\n",
      "Epoch 587/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2237 - accuracy: 0.5658 - val_loss: 3.4927 - val_accuracy: 0.3485\n",
      "Epoch 588/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.5639 - val_loss: 3.5048 - val_accuracy: 0.3485\n",
      "Epoch 589/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.5611 - val_loss: 3.5073 - val_accuracy: 0.3473\n",
      "Epoch 590/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2292 - accuracy: 0.5634 - val_loss: 3.4959 - val_accuracy: 0.3473\n",
      "Epoch 591/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2201 - accuracy: 0.5695 - val_loss: 3.5152 - val_accuracy: 0.3522\n",
      "Epoch 592/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2297 - accuracy: 0.5646 - val_loss: 3.5056 - val_accuracy: 0.3473\n",
      "Epoch 593/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5646 - val_loss: 3.4996 - val_accuracy: 0.3455\n",
      "Epoch 594/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2274 - accuracy: 0.5680 - val_loss: 3.5020 - val_accuracy: 0.3437\n",
      "Epoch 595/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2351 - accuracy: 0.5581 - val_loss: 3.4940 - val_accuracy: 0.3552\n",
      "Epoch 596/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.5661 - val_loss: 3.4964 - val_accuracy: 0.3558\n",
      "Epoch 597/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5616 - val_loss: 3.4884 - val_accuracy: 0.3455\n",
      "Epoch 598/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.5616 - val_loss: 3.4990 - val_accuracy: 0.3528\n",
      "Epoch 599/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5649 - val_loss: 3.4987 - val_accuracy: 0.3522\n",
      "Epoch 600/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5642 - val_loss: 3.5063 - val_accuracy: 0.3479\n",
      "Epoch 601/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5625 - val_loss: 3.5024 - val_accuracy: 0.3479\n",
      "Epoch 602/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2316 - accuracy: 0.5596 - val_loss: 3.5039 - val_accuracy: 0.3443\n",
      "Epoch 603/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5544 - val_loss: 3.5041 - val_accuracy: 0.3498\n",
      "Epoch 604/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.5661 - val_loss: 3.4951 - val_accuracy: 0.3601\n",
      "Epoch 605/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2204 - accuracy: 0.5633 - val_loss: 3.4937 - val_accuracy: 0.3516\n",
      "Epoch 606/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2272 - accuracy: 0.5620 - val_loss: 3.4952 - val_accuracy: 0.3516\n",
      "Epoch 607/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5598 - val_loss: 3.5051 - val_accuracy: 0.3437\n",
      "Epoch 608/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2278 - accuracy: 0.5599 - val_loss: 3.4981 - val_accuracy: 0.3455\n",
      "Epoch 609/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5630 - val_loss: 3.5005 - val_accuracy: 0.3546\n",
      "Epoch 610/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2237 - accuracy: 0.5681 - val_loss: 3.5000 - val_accuracy: 0.3504\n",
      "Epoch 611/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.5613 - val_loss: 3.5010 - val_accuracy: 0.3437\n",
      "Epoch 612/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5639 - val_loss: 3.5170 - val_accuracy: 0.3437\n",
      "Epoch 613/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2302 - accuracy: 0.5642 - val_loss: 3.5116 - val_accuracy: 0.3412\n",
      "Epoch 614/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5628 - val_loss: 3.5136 - val_accuracy: 0.3516\n",
      "Epoch 615/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5631 - val_loss: 3.5153 - val_accuracy: 0.3461\n",
      "Epoch 616/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2228 - accuracy: 0.5627 - val_loss: 3.5147 - val_accuracy: 0.3528\n",
      "Epoch 617/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5646 - val_loss: 3.5174 - val_accuracy: 0.3461\n",
      "Epoch 618/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.5640 - val_loss: 3.5109 - val_accuracy: 0.3522\n",
      "Epoch 619/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.5646 - val_loss: 3.5113 - val_accuracy: 0.3498\n",
      "Epoch 620/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.5642 - val_loss: 3.5087 - val_accuracy: 0.3485\n",
      "Epoch 621/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.5680 - val_loss: 3.5131 - val_accuracy: 0.3491\n",
      "Epoch 622/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2325 - accuracy: 0.5593 - val_loss: 3.4989 - val_accuracy: 0.3522\n",
      "Epoch 623/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5639 - val_loss: 3.5047 - val_accuracy: 0.3522\n",
      "Epoch 624/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5619 - val_loss: 3.5125 - val_accuracy: 0.3461\n",
      "Epoch 625/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2286 - accuracy: 0.5625 - val_loss: 3.5039 - val_accuracy: 0.3461\n",
      "Epoch 626/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2332 - accuracy: 0.5623 - val_loss: 3.5018 - val_accuracy: 0.3455\n",
      "Epoch 627/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2229 - accuracy: 0.5631 - val_loss: 3.5117 - val_accuracy: 0.3412\n",
      "Epoch 628/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2243 - accuracy: 0.5623 - val_loss: 3.5209 - val_accuracy: 0.3437\n",
      "Epoch 629/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.5690 - val_loss: 3.5188 - val_accuracy: 0.3431\n",
      "Epoch 630/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.5619 - val_loss: 3.5194 - val_accuracy: 0.3510\n",
      "Epoch 631/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5625 - val_loss: 3.5108 - val_accuracy: 0.3467\n",
      "Epoch 632/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.5616 - val_loss: 3.5270 - val_accuracy: 0.3455\n",
      "Epoch 633/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2335 - accuracy: 0.5589 - val_loss: 3.5126 - val_accuracy: 0.3528\n",
      "Epoch 634/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2246 - accuracy: 0.5646 - val_loss: 3.5181 - val_accuracy: 0.3516\n",
      "Epoch 635/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5665 - val_loss: 3.5201 - val_accuracy: 0.3455\n",
      "Epoch 636/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.5639 - val_loss: 3.5253 - val_accuracy: 0.3467\n",
      "Epoch 637/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2227 - accuracy: 0.5633 - val_loss: 3.5272 - val_accuracy: 0.3491\n",
      "Epoch 638/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5611 - val_loss: 3.5249 - val_accuracy: 0.3491\n",
      "Epoch 639/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5622 - val_loss: 3.5314 - val_accuracy: 0.3449\n",
      "Epoch 640/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5658 - val_loss: 3.5231 - val_accuracy: 0.3479\n",
      "Epoch 641/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2246 - accuracy: 0.5607 - val_loss: 3.5185 - val_accuracy: 0.3485\n",
      "Epoch 642/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.5620 - val_loss: 3.5118 - val_accuracy: 0.3449\n",
      "Epoch 643/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.5666 - val_loss: 3.5136 - val_accuracy: 0.3455\n",
      "Epoch 644/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5648 - val_loss: 3.5235 - val_accuracy: 0.3473\n",
      "Epoch 645/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2302 - accuracy: 0.5623 - val_loss: 3.5145 - val_accuracy: 0.3418\n",
      "Epoch 646/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.5643 - val_loss: 3.5159 - val_accuracy: 0.3534\n",
      "Epoch 647/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2260 - accuracy: 0.5645 - val_loss: 3.5143 - val_accuracy: 0.3467\n",
      "Epoch 648/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5655 - val_loss: 3.5180 - val_accuracy: 0.3431\n",
      "Epoch 649/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5608 - val_loss: 3.5077 - val_accuracy: 0.3431\n",
      "Epoch 650/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2306 - accuracy: 0.5628 - val_loss: 3.5144 - val_accuracy: 0.3473\n",
      "Epoch 651/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2248 - accuracy: 0.5622 - val_loss: 3.5258 - val_accuracy: 0.3455\n",
      "Epoch 652/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5655 - val_loss: 3.5264 - val_accuracy: 0.3479\n",
      "Epoch 653/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5651 - val_loss: 3.5113 - val_accuracy: 0.3461\n",
      "Epoch 654/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.5616 - val_loss: 3.5249 - val_accuracy: 0.3437\n",
      "Epoch 655/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5595 - val_loss: 3.5174 - val_accuracy: 0.3479\n",
      "Epoch 656/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.5692 - val_loss: 3.5109 - val_accuracy: 0.3479\n",
      "Epoch 657/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.5619 - val_loss: 3.5109 - val_accuracy: 0.3498\n",
      "Epoch 658/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2239 - accuracy: 0.5637 - val_loss: 3.5203 - val_accuracy: 0.3516\n",
      "Epoch 659/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5665 - val_loss: 3.5137 - val_accuracy: 0.3498\n",
      "Epoch 660/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.5578 - val_loss: 3.5160 - val_accuracy: 0.3504\n",
      "Epoch 661/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2245 - accuracy: 0.5622 - val_loss: 3.5242 - val_accuracy: 0.3504\n",
      "Epoch 662/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2216 - accuracy: 0.5655 - val_loss: 3.5240 - val_accuracy: 0.3491\n",
      "Epoch 663/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2323 - accuracy: 0.5581 - val_loss: 3.5099 - val_accuracy: 0.3504\n",
      "Epoch 664/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2323 - accuracy: 0.5598 - val_loss: 3.5112 - val_accuracy: 0.3522\n",
      "Epoch 665/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2236 - accuracy: 0.5703 - val_loss: 3.5167 - val_accuracy: 0.3528\n",
      "Epoch 666/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2324 - accuracy: 0.5549 - val_loss: 3.5198 - val_accuracy: 0.3498\n",
      "Epoch 667/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.5639 - val_loss: 3.5179 - val_accuracy: 0.3534\n",
      "Epoch 668/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2270 - accuracy: 0.5669 - val_loss: 3.5147 - val_accuracy: 0.3491\n",
      "Epoch 669/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2244 - accuracy: 0.5636 - val_loss: 3.5269 - val_accuracy: 0.3485\n",
      "Epoch 670/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5623 - val_loss: 3.5182 - val_accuracy: 0.3498\n",
      "Epoch 671/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5661 - val_loss: 3.5208 - val_accuracy: 0.3473\n",
      "Epoch 672/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5649 - val_loss: 3.5322 - val_accuracy: 0.3504\n",
      "Epoch 673/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5672 - val_loss: 3.5296 - val_accuracy: 0.3388\n",
      "Epoch 674/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2209 - accuracy: 0.5665 - val_loss: 3.5331 - val_accuracy: 0.3485\n",
      "Epoch 675/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2271 - accuracy: 0.5663 - val_loss: 3.5195 - val_accuracy: 0.3498\n",
      "Epoch 676/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2291 - accuracy: 0.5648 - val_loss: 3.5085 - val_accuracy: 0.3528\n",
      "Epoch 677/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2235 - accuracy: 0.5683 - val_loss: 3.5207 - val_accuracy: 0.3455\n",
      "Epoch 678/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2249 - accuracy: 0.5646 - val_loss: 3.5142 - val_accuracy: 0.3522\n",
      "Epoch 679/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5640 - val_loss: 3.5187 - val_accuracy: 0.3510\n",
      "Epoch 680/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5666 - val_loss: 3.5213 - val_accuracy: 0.3431\n",
      "Epoch 681/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5646 - val_loss: 3.5183 - val_accuracy: 0.3510\n",
      "Epoch 682/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2262 - accuracy: 0.5619 - val_loss: 3.5153 - val_accuracy: 0.3534\n",
      "Epoch 683/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2242 - accuracy: 0.5634 - val_loss: 3.5164 - val_accuracy: 0.3510\n",
      "Epoch 684/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2269 - accuracy: 0.5674 - val_loss: 3.5255 - val_accuracy: 0.3485\n",
      "Epoch 685/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5614 - val_loss: 3.5176 - val_accuracy: 0.3504\n",
      "Epoch 686/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2246 - accuracy: 0.5668 - val_loss: 3.5177 - val_accuracy: 0.3528\n",
      "Epoch 687/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2286 - accuracy: 0.5611 - val_loss: 3.5119 - val_accuracy: 0.3437\n",
      "Epoch 688/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2263 - accuracy: 0.5651 - val_loss: 3.5212 - val_accuracy: 0.3461\n",
      "Epoch 689/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2333 - accuracy: 0.5633 - val_loss: 3.5069 - val_accuracy: 0.3467\n",
      "Epoch 690/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2270 - accuracy: 0.5613 - val_loss: 3.5111 - val_accuracy: 0.3455\n",
      "Epoch 691/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2226 - accuracy: 0.5620 - val_loss: 3.5203 - val_accuracy: 0.3388\n",
      "Epoch 692/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5655 - val_loss: 3.5192 - val_accuracy: 0.3443\n",
      "Epoch 693/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2210 - accuracy: 0.5640 - val_loss: 3.5243 - val_accuracy: 0.3467\n",
      "Epoch 694/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2284 - accuracy: 0.5663 - val_loss: 3.5188 - val_accuracy: 0.3455\n",
      "Epoch 695/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2284 - accuracy: 0.5633 - val_loss: 3.5157 - val_accuracy: 0.3467\n",
      "Epoch 696/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2240 - accuracy: 0.5703 - val_loss: 3.5199 - val_accuracy: 0.3510\n",
      "Epoch 697/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.5671 - val_loss: 3.5236 - val_accuracy: 0.3473\n",
      "Epoch 698/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5576 - val_loss: 3.5269 - val_accuracy: 0.3485\n",
      "Epoch 699/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5607 - val_loss: 3.5229 - val_accuracy: 0.3516\n",
      "Epoch 700/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5622 - val_loss: 3.5293 - val_accuracy: 0.3467\n",
      "Epoch 701/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5654 - val_loss: 3.5249 - val_accuracy: 0.3449\n",
      "Epoch 702/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2205 - accuracy: 0.5628 - val_loss: 3.5179 - val_accuracy: 0.3491\n",
      "Epoch 703/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2333 - accuracy: 0.5613 - val_loss: 3.5212 - val_accuracy: 0.3522\n",
      "Epoch 704/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.5645 - val_loss: 3.5156 - val_accuracy: 0.3491\n",
      "Epoch 705/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2297 - accuracy: 0.5585 - val_loss: 3.5274 - val_accuracy: 0.3443\n",
      "Epoch 706/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5585 - val_loss: 3.5213 - val_accuracy: 0.3467\n",
      "Epoch 707/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2278 - accuracy: 0.5593 - val_loss: 3.5140 - val_accuracy: 0.3510\n",
      "Epoch 708/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5620 - val_loss: 3.5130 - val_accuracy: 0.3504\n",
      "Epoch 709/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5665 - val_loss: 3.5224 - val_accuracy: 0.3467\n",
      "Epoch 710/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2259 - accuracy: 0.5601 - val_loss: 3.5105 - val_accuracy: 0.3449\n",
      "Epoch 711/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2252 - accuracy: 0.5630 - val_loss: 3.5345 - val_accuracy: 0.3449\n",
      "Epoch 712/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2248 - accuracy: 0.5625 - val_loss: 3.5208 - val_accuracy: 0.3516\n",
      "Epoch 713/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2275 - accuracy: 0.5654 - val_loss: 3.5223 - val_accuracy: 0.3510\n",
      "Epoch 714/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2253 - accuracy: 0.5671 - val_loss: 3.5236 - val_accuracy: 0.3479\n",
      "Epoch 715/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5671 - val_loss: 3.5233 - val_accuracy: 0.3522\n",
      "Epoch 716/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5655 - val_loss: 3.5231 - val_accuracy: 0.3455\n",
      "Epoch 717/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2262 - accuracy: 0.5613 - val_loss: 3.5325 - val_accuracy: 0.3394\n",
      "Epoch 718/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5631 - val_loss: 3.5252 - val_accuracy: 0.3455\n",
      "Epoch 719/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2281 - accuracy: 0.5658 - val_loss: 3.5225 - val_accuracy: 0.3418\n",
      "Epoch 720/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2219 - accuracy: 0.5633 - val_loss: 3.5323 - val_accuracy: 0.3443\n",
      "Epoch 721/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2238 - accuracy: 0.5675 - val_loss: 3.5269 - val_accuracy: 0.3449\n",
      "Epoch 722/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2257 - accuracy: 0.5619 - val_loss: 3.5213 - val_accuracy: 0.3437\n",
      "Epoch 723/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2228 - accuracy: 0.5620 - val_loss: 3.5187 - val_accuracy: 0.3467\n",
      "Epoch 724/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2248 - accuracy: 0.5649 - val_loss: 3.5183 - val_accuracy: 0.3504\n",
      "Epoch 725/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2215 - accuracy: 0.5649 - val_loss: 3.5240 - val_accuracy: 0.3491\n",
      "Epoch 726/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2233 - accuracy: 0.5649 - val_loss: 3.5235 - val_accuracy: 0.3485\n",
      "Epoch 727/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2255 - accuracy: 0.5660 - val_loss: 3.5200 - val_accuracy: 0.3473\n",
      "Epoch 728/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2281 - accuracy: 0.5589 - val_loss: 3.5168 - val_accuracy: 0.3516\n",
      "Epoch 729/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2232 - accuracy: 0.5666 - val_loss: 3.5213 - val_accuracy: 0.3522\n",
      "Epoch 730/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2227 - accuracy: 0.5617 - val_loss: 3.5266 - val_accuracy: 0.3546\n",
      "Epoch 731/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2245 - accuracy: 0.5625 - val_loss: 3.5252 - val_accuracy: 0.3510\n",
      "Epoch 732/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2215 - accuracy: 0.5661 - val_loss: 3.5289 - val_accuracy: 0.3491\n",
      "Epoch 733/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.5631 - val_loss: 3.5240 - val_accuracy: 0.3510\n",
      "Epoch 734/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5645 - val_loss: 3.5279 - val_accuracy: 0.3491\n",
      "Epoch 735/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5660 - val_loss: 3.5257 - val_accuracy: 0.3498\n",
      "Epoch 736/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.5660 - val_loss: 3.5191 - val_accuracy: 0.3534\n",
      "Epoch 737/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.5655 - val_loss: 3.5246 - val_accuracy: 0.3479\n",
      "Epoch 738/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2274 - accuracy: 0.5587 - val_loss: 3.5219 - val_accuracy: 0.3498\n",
      "Epoch 739/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.5623 - val_loss: 3.5204 - val_accuracy: 0.3479\n",
      "Epoch 740/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5637 - val_loss: 3.5098 - val_accuracy: 0.3522\n",
      "Epoch 741/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5665 - val_loss: 3.5258 - val_accuracy: 0.3558\n",
      "Epoch 742/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2217 - accuracy: 0.5628 - val_loss: 3.5159 - val_accuracy: 0.3491\n",
      "Epoch 743/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5643 - val_loss: 3.5230 - val_accuracy: 0.3498\n",
      "Epoch 744/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.5698 - val_loss: 3.5165 - val_accuracy: 0.3467\n",
      "Epoch 745/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2241 - accuracy: 0.5628 - val_loss: 3.5384 - val_accuracy: 0.3485\n",
      "Epoch 746/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5661 - val_loss: 3.5364 - val_accuracy: 0.3461\n",
      "Epoch 747/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2256 - accuracy: 0.5625 - val_loss: 3.5209 - val_accuracy: 0.3449\n",
      "Epoch 748/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.5555 - val_loss: 3.5207 - val_accuracy: 0.3467\n",
      "Epoch 749/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2315 - accuracy: 0.5661 - val_loss: 3.5161 - val_accuracy: 0.3473\n",
      "Epoch 750/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2218 - accuracy: 0.5683 - val_loss: 3.5355 - val_accuracy: 0.3418\n",
      "Epoch 751/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.5625 - val_loss: 3.5320 - val_accuracy: 0.3528\n",
      "Epoch 752/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2244 - accuracy: 0.5669 - val_loss: 3.5249 - val_accuracy: 0.3461\n",
      "Epoch 753/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2253 - accuracy: 0.5631 - val_loss: 3.5292 - val_accuracy: 0.3491\n",
      "Epoch 754/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5628 - val_loss: 3.5147 - val_accuracy: 0.3510\n",
      "Epoch 755/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.5601 - val_loss: 3.5215 - val_accuracy: 0.3461\n",
      "Epoch 756/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2249 - accuracy: 0.5669 - val_loss: 3.5173 - val_accuracy: 0.3485\n",
      "Epoch 757/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2272 - accuracy: 0.5619 - val_loss: 3.5245 - val_accuracy: 0.3473\n",
      "Epoch 758/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5677 - val_loss: 3.5154 - val_accuracy: 0.3534\n",
      "Epoch 759/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.5642 - val_loss: 3.5176 - val_accuracy: 0.3485\n",
      "Epoch 760/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5623 - val_loss: 3.5183 - val_accuracy: 0.3516\n",
      "Epoch 761/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2238 - accuracy: 0.5630 - val_loss: 3.5270 - val_accuracy: 0.3528\n",
      "Epoch 762/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5658 - val_loss: 3.5225 - val_accuracy: 0.3510\n",
      "Epoch 763/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2212 - accuracy: 0.5654 - val_loss: 3.5294 - val_accuracy: 0.3498\n",
      "Epoch 764/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5663 - val_loss: 3.5164 - val_accuracy: 0.3528\n",
      "Epoch 765/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2261 - accuracy: 0.5654 - val_loss: 3.5232 - val_accuracy: 0.3437\n",
      "Epoch 766/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2244 - accuracy: 0.5630 - val_loss: 3.5202 - val_accuracy: 0.3528\n",
      "Epoch 767/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2261 - accuracy: 0.5627 - val_loss: 3.5215 - val_accuracy: 0.3510\n",
      "Epoch 768/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5640 - val_loss: 3.5224 - val_accuracy: 0.3437\n",
      "Epoch 769/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.5602 - val_loss: 3.5152 - val_accuracy: 0.3437\n",
      "Epoch 770/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2270 - accuracy: 0.5642 - val_loss: 3.5245 - val_accuracy: 0.3485\n",
      "Epoch 771/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5681 - val_loss: 3.5280 - val_accuracy: 0.3504\n",
      "Epoch 772/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.5660 - val_loss: 3.5162 - val_accuracy: 0.3479\n",
      "Epoch 773/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.5674 - val_loss: 3.5208 - val_accuracy: 0.3479\n",
      "Epoch 774/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.5599 - val_loss: 3.5330 - val_accuracy: 0.3498\n",
      "Epoch 775/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2218 - accuracy: 0.5652 - val_loss: 3.5348 - val_accuracy: 0.3449\n",
      "Epoch 776/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2294 - accuracy: 0.5631 - val_loss: 3.5342 - val_accuracy: 0.3431\n",
      "Epoch 777/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2197 - accuracy: 0.5692 - val_loss: 3.5320 - val_accuracy: 0.3491\n",
      "Epoch 778/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2276 - accuracy: 0.5617 - val_loss: 3.5356 - val_accuracy: 0.3522\n",
      "Epoch 779/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2206 - accuracy: 0.5660 - val_loss: 3.5239 - val_accuracy: 0.3437\n",
      "Epoch 780/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2236 - accuracy: 0.5654 - val_loss: 3.5305 - val_accuracy: 0.3504\n",
      "Epoch 781/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2341 - accuracy: 0.5604 - val_loss: 3.5228 - val_accuracy: 0.3498\n",
      "Epoch 782/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2214 - accuracy: 0.5620 - val_loss: 3.5337 - val_accuracy: 0.3479\n",
      "Epoch 783/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5627 - val_loss: 3.5367 - val_accuracy: 0.3455\n",
      "Epoch 784/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2235 - accuracy: 0.5613 - val_loss: 3.5314 - val_accuracy: 0.3589\n",
      "Epoch 785/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2210 - accuracy: 0.5675 - val_loss: 3.5278 - val_accuracy: 0.3498\n",
      "Epoch 786/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.5671 - val_loss: 3.5298 - val_accuracy: 0.3510\n",
      "Epoch 787/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5651 - val_loss: 3.5289 - val_accuracy: 0.3485\n",
      "Epoch 788/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5645 - val_loss: 3.5281 - val_accuracy: 0.3516\n",
      "Epoch 789/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.5619 - val_loss: 3.5349 - val_accuracy: 0.3467\n",
      "Epoch 790/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5652 - val_loss: 3.5330 - val_accuracy: 0.3485\n",
      "Epoch 791/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2214 - accuracy: 0.5686 - val_loss: 3.5410 - val_accuracy: 0.3504\n",
      "Epoch 792/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2259 - accuracy: 0.5657 - val_loss: 3.5412 - val_accuracy: 0.3449\n",
      "Epoch 793/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.5630 - val_loss: 3.5443 - val_accuracy: 0.3510\n",
      "Epoch 794/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2206 - accuracy: 0.5634 - val_loss: 3.5510 - val_accuracy: 0.3455\n",
      "Epoch 795/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2243 - accuracy: 0.5640 - val_loss: 3.5468 - val_accuracy: 0.3552\n",
      "Epoch 796/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2228 - accuracy: 0.5649 - val_loss: 3.5514 - val_accuracy: 0.3516\n",
      "Epoch 797/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.5587 - val_loss: 3.5461 - val_accuracy: 0.3485\n",
      "Epoch 798/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.5634 - val_loss: 3.5437 - val_accuracy: 0.3510\n",
      "Epoch 799/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5634 - val_loss: 3.5452 - val_accuracy: 0.3485\n",
      "Epoch 800/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.5582 - val_loss: 3.5437 - val_accuracy: 0.3516\n",
      "Epoch 801/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2248 - accuracy: 0.5669 - val_loss: 3.5352 - val_accuracy: 0.3504\n",
      "Epoch 802/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5642 - val_loss: 3.5315 - val_accuracy: 0.3425\n",
      "Epoch 803/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5637 - val_loss: 3.5361 - val_accuracy: 0.3534\n",
      "Epoch 804/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5639 - val_loss: 3.5288 - val_accuracy: 0.3498\n",
      "Epoch 805/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.5622 - val_loss: 3.5407 - val_accuracy: 0.3552\n",
      "Epoch 806/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2209 - accuracy: 0.5680 - val_loss: 3.5358 - val_accuracy: 0.3498\n",
      "Epoch 807/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2164 - accuracy: 0.5663 - val_loss: 3.5508 - val_accuracy: 0.3467\n",
      "Epoch 808/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2250 - accuracy: 0.5642 - val_loss: 3.5453 - val_accuracy: 0.3498\n",
      "Epoch 809/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2246 - accuracy: 0.5623 - val_loss: 3.5426 - val_accuracy: 0.3552\n",
      "Epoch 810/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2192 - accuracy: 0.5637 - val_loss: 3.5466 - val_accuracy: 0.3473\n",
      "Epoch 811/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5660 - val_loss: 3.5456 - val_accuracy: 0.3522\n",
      "Epoch 812/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2239 - accuracy: 0.5665 - val_loss: 3.5392 - val_accuracy: 0.3522\n",
      "Epoch 813/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2241 - accuracy: 0.5642 - val_loss: 3.5437 - val_accuracy: 0.3534\n",
      "Epoch 814/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2244 - accuracy: 0.5660 - val_loss: 3.5416 - val_accuracy: 0.3491\n",
      "Epoch 815/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2191 - accuracy: 0.5645 - val_loss: 3.5495 - val_accuracy: 0.3583\n",
      "Epoch 816/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.5651 - val_loss: 3.5488 - val_accuracy: 0.3461\n",
      "Epoch 817/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2203 - accuracy: 0.5643 - val_loss: 3.5512 - val_accuracy: 0.3461\n",
      "Epoch 818/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.5585 - val_loss: 3.5422 - val_accuracy: 0.3443\n",
      "Epoch 819/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.5628 - val_loss: 3.5516 - val_accuracy: 0.3449\n",
      "Epoch 820/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2287 - accuracy: 0.5648 - val_loss: 3.5379 - val_accuracy: 0.3491\n",
      "Epoch 821/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2207 - accuracy: 0.5693 - val_loss: 3.5469 - val_accuracy: 0.3449\n",
      "Epoch 822/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.5649 - val_loss: 3.5233 - val_accuracy: 0.3528\n",
      "Epoch 823/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2233 - accuracy: 0.5608 - val_loss: 3.5348 - val_accuracy: 0.3491\n",
      "Epoch 824/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5601 - val_loss: 3.5535 - val_accuracy: 0.3443\n",
      "Epoch 825/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2215 - accuracy: 0.5633 - val_loss: 3.5413 - val_accuracy: 0.3449\n",
      "Epoch 826/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2159 - accuracy: 0.5657 - val_loss: 3.5444 - val_accuracy: 0.3425\n",
      "Epoch 827/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2231 - accuracy: 0.5671 - val_loss: 3.5483 - val_accuracy: 0.3425\n",
      "Epoch 828/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5605 - val_loss: 3.5455 - val_accuracy: 0.3498\n",
      "Epoch 829/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.5598 - val_loss: 3.5460 - val_accuracy: 0.3504\n",
      "Epoch 830/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2256 - accuracy: 0.5649 - val_loss: 3.5513 - val_accuracy: 0.3510\n",
      "Epoch 831/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.5614 - val_loss: 3.5434 - val_accuracy: 0.3534\n",
      "Epoch 832/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2242 - accuracy: 0.5657 - val_loss: 3.5509 - val_accuracy: 0.3449\n",
      "Epoch 833/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5660 - val_loss: 3.5414 - val_accuracy: 0.3510\n",
      "Epoch 834/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2224 - accuracy: 0.5655 - val_loss: 3.5457 - val_accuracy: 0.3546\n",
      "Epoch 835/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.5592 - val_loss: 3.5400 - val_accuracy: 0.3516\n",
      "Epoch 836/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2275 - accuracy: 0.5604 - val_loss: 3.5353 - val_accuracy: 0.3467\n",
      "Epoch 837/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2254 - accuracy: 0.5663 - val_loss: 3.5394 - val_accuracy: 0.3491\n",
      "Epoch 838/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5652 - val_loss: 3.5417 - val_accuracy: 0.3491\n",
      "Epoch 839/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2189 - accuracy: 0.5696 - val_loss: 3.5471 - val_accuracy: 0.3437\n",
      "Epoch 840/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.5573 - val_loss: 3.5422 - val_accuracy: 0.3491\n",
      "Epoch 841/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5607 - val_loss: 3.5463 - val_accuracy: 0.3449\n",
      "Epoch 842/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5672 - val_loss: 3.5576 - val_accuracy: 0.3443\n",
      "Epoch 843/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5622 - val_loss: 3.5452 - val_accuracy: 0.3455\n",
      "Epoch 844/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5625 - val_loss: 3.5420 - val_accuracy: 0.3431\n",
      "Epoch 845/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2235 - accuracy: 0.5654 - val_loss: 3.5477 - val_accuracy: 0.3425\n",
      "Epoch 846/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2222 - accuracy: 0.5657 - val_loss: 3.5402 - val_accuracy: 0.3479\n",
      "Epoch 847/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5637 - val_loss: 3.5465 - val_accuracy: 0.3528\n",
      "Epoch 848/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2205 - accuracy: 0.5636 - val_loss: 3.5516 - val_accuracy: 0.3522\n",
      "Epoch 849/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.5671 - val_loss: 3.5522 - val_accuracy: 0.3479\n",
      "Epoch 850/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5643 - val_loss: 3.5570 - val_accuracy: 0.3510\n",
      "Epoch 851/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2208 - accuracy: 0.5652 - val_loss: 3.5657 - val_accuracy: 0.3534\n",
      "Epoch 852/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.5636 - val_loss: 3.5445 - val_accuracy: 0.3510\n",
      "Epoch 853/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2191 - accuracy: 0.5652 - val_loss: 3.5534 - val_accuracy: 0.3449\n",
      "Epoch 854/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2176 - accuracy: 0.5651 - val_loss: 3.5550 - val_accuracy: 0.3485\n",
      "Epoch 855/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5652 - val_loss: 3.5445 - val_accuracy: 0.3455\n",
      "Epoch 856/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5611 - val_loss: 3.5406 - val_accuracy: 0.3461\n",
      "Epoch 857/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.5622 - val_loss: 3.5543 - val_accuracy: 0.3412\n",
      "Epoch 858/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2256 - accuracy: 0.5605 - val_loss: 3.5536 - val_accuracy: 0.3473\n",
      "Epoch 859/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5657 - val_loss: 3.5460 - val_accuracy: 0.3412\n",
      "Epoch 860/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2201 - accuracy: 0.5636 - val_loss: 3.5490 - val_accuracy: 0.3504\n",
      "Epoch 861/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2207 - accuracy: 0.5648 - val_loss: 3.5604 - val_accuracy: 0.3528\n",
      "Epoch 862/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5630 - val_loss: 3.5343 - val_accuracy: 0.3522\n",
      "Epoch 863/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.5649 - val_loss: 3.5449 - val_accuracy: 0.3510\n",
      "Epoch 864/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2224 - accuracy: 0.5649 - val_loss: 3.5546 - val_accuracy: 0.3473\n",
      "Epoch 865/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5645 - val_loss: 3.5487 - val_accuracy: 0.3504\n",
      "Epoch 866/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2239 - accuracy: 0.5642 - val_loss: 3.5450 - val_accuracy: 0.3534\n",
      "Epoch 867/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.5587 - val_loss: 3.5556 - val_accuracy: 0.3516\n",
      "Epoch 868/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2232 - accuracy: 0.5628 - val_loss: 3.5454 - val_accuracy: 0.3510\n",
      "Epoch 869/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2212 - accuracy: 0.5663 - val_loss: 3.5557 - val_accuracy: 0.3491\n",
      "Epoch 870/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.5623 - val_loss: 3.5614 - val_accuracy: 0.3473\n",
      "Epoch 871/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2234 - accuracy: 0.5630 - val_loss: 3.5618 - val_accuracy: 0.3540\n",
      "Epoch 872/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5608 - val_loss: 3.5432 - val_accuracy: 0.3564\n",
      "Epoch 873/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2269 - accuracy: 0.5619 - val_loss: 3.5528 - val_accuracy: 0.3534\n",
      "Epoch 874/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2225 - accuracy: 0.5613 - val_loss: 3.5508 - val_accuracy: 0.3522\n",
      "Epoch 875/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2263 - accuracy: 0.5628 - val_loss: 3.5585 - val_accuracy: 0.3473\n",
      "Epoch 876/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5620 - val_loss: 3.5512 - val_accuracy: 0.3449\n",
      "Epoch 877/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2183 - accuracy: 0.5648 - val_loss: 3.5480 - val_accuracy: 0.3534\n",
      "Epoch 878/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.5652 - val_loss: 3.5561 - val_accuracy: 0.3504\n",
      "Epoch 879/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2267 - accuracy: 0.5628 - val_loss: 3.5497 - val_accuracy: 0.3491\n",
      "Epoch 880/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.5614 - val_loss: 3.5489 - val_accuracy: 0.3540\n",
      "Epoch 881/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2202 - accuracy: 0.5654 - val_loss: 3.5479 - val_accuracy: 0.3540\n",
      "Epoch 882/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.5636 - val_loss: 3.5527 - val_accuracy: 0.3516\n",
      "Epoch 883/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.5623 - val_loss: 3.5509 - val_accuracy: 0.3516\n",
      "Epoch 884/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2241 - accuracy: 0.5663 - val_loss: 3.5581 - val_accuracy: 0.3534\n",
      "Epoch 885/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5661 - val_loss: 3.5534 - val_accuracy: 0.3504\n",
      "Epoch 886/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5593 - val_loss: 3.5558 - val_accuracy: 0.3479\n",
      "Epoch 887/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2238 - accuracy: 0.5628 - val_loss: 3.5600 - val_accuracy: 0.3510\n",
      "Epoch 888/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2189 - accuracy: 0.5663 - val_loss: 3.5707 - val_accuracy: 0.3437\n",
      "Epoch 889/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.5643 - val_loss: 3.5557 - val_accuracy: 0.3473\n",
      "Epoch 890/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.5573 - val_loss: 3.5466 - val_accuracy: 0.3534\n",
      "Epoch 891/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2226 - accuracy: 0.5657 - val_loss: 3.5480 - val_accuracy: 0.3455\n",
      "Epoch 892/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5613 - val_loss: 3.5619 - val_accuracy: 0.3498\n",
      "Epoch 893/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.5627 - val_loss: 3.5538 - val_accuracy: 0.3498\n",
      "Epoch 894/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2222 - accuracy: 0.5616 - val_loss: 3.5651 - val_accuracy: 0.3510\n",
      "Epoch 895/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2163 - accuracy: 0.5665 - val_loss: 3.5572 - val_accuracy: 0.3455\n",
      "Epoch 896/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.5604 - val_loss: 3.5760 - val_accuracy: 0.3467\n",
      "Epoch 897/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2287 - accuracy: 0.5617 - val_loss: 3.5661 - val_accuracy: 0.3461\n",
      "Epoch 898/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5642 - val_loss: 3.5674 - val_accuracy: 0.3498\n",
      "Epoch 899/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5590 - val_loss: 3.5552 - val_accuracy: 0.3425\n",
      "Epoch 900/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.5665 - val_loss: 3.5587 - val_accuracy: 0.3528\n",
      "Epoch 901/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.5585 - val_loss: 3.5644 - val_accuracy: 0.3437\n",
      "Epoch 902/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.5622 - val_loss: 3.5501 - val_accuracy: 0.3504\n",
      "Epoch 903/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2228 - accuracy: 0.5601 - val_loss: 3.5439 - val_accuracy: 0.3479\n",
      "Epoch 904/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5631 - val_loss: 3.5596 - val_accuracy: 0.3461\n",
      "Epoch 905/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2207 - accuracy: 0.5645 - val_loss: 3.5588 - val_accuracy: 0.3504\n",
      "Epoch 906/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2204 - accuracy: 0.5649 - val_loss: 3.5667 - val_accuracy: 0.3431\n",
      "Epoch 907/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2193 - accuracy: 0.5611 - val_loss: 3.5610 - val_accuracy: 0.3455\n",
      "Epoch 908/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2164 - accuracy: 0.5654 - val_loss: 3.5679 - val_accuracy: 0.3473\n",
      "Epoch 909/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2268 - accuracy: 0.5642 - val_loss: 3.5632 - val_accuracy: 0.3552\n",
      "Epoch 910/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5633 - val_loss: 3.5590 - val_accuracy: 0.3522\n",
      "Epoch 911/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.5623 - val_loss: 3.5525 - val_accuracy: 0.3516\n",
      "Epoch 912/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.5610 - val_loss: 3.5648 - val_accuracy: 0.3558\n",
      "Epoch 913/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2214 - accuracy: 0.5608 - val_loss: 3.5612 - val_accuracy: 0.3485\n",
      "Epoch 914/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2196 - accuracy: 0.5678 - val_loss: 3.5595 - val_accuracy: 0.3522\n",
      "Epoch 915/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2303 - accuracy: 0.5637 - val_loss: 3.5522 - val_accuracy: 0.3485\n",
      "Epoch 916/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2174 - accuracy: 0.5628 - val_loss: 3.5602 - val_accuracy: 0.3467\n",
      "Epoch 917/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2241 - accuracy: 0.5579 - val_loss: 3.5519 - val_accuracy: 0.3516\n",
      "Epoch 918/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2268 - accuracy: 0.5581 - val_loss: 3.5527 - val_accuracy: 0.3577\n",
      "Epoch 919/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5616 - val_loss: 3.5441 - val_accuracy: 0.3540\n",
      "Epoch 920/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2223 - accuracy: 0.5677 - val_loss: 3.5564 - val_accuracy: 0.3504\n",
      "Epoch 921/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.5610 - val_loss: 3.5596 - val_accuracy: 0.3491\n",
      "Epoch 922/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2197 - accuracy: 0.5605 - val_loss: 3.5515 - val_accuracy: 0.3473\n",
      "Epoch 923/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5654 - val_loss: 3.5553 - val_accuracy: 0.3498\n",
      "Epoch 924/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5668 - val_loss: 3.5650 - val_accuracy: 0.3528\n",
      "Epoch 925/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2176 - accuracy: 0.5692 - val_loss: 3.5768 - val_accuracy: 0.3443\n",
      "Epoch 926/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.5599 - val_loss: 3.5542 - val_accuracy: 0.3479\n",
      "Epoch 927/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5623 - val_loss: 3.5582 - val_accuracy: 0.3491\n",
      "Epoch 928/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2222 - accuracy: 0.5610 - val_loss: 3.5664 - val_accuracy: 0.3516\n",
      "Epoch 929/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2238 - accuracy: 0.5601 - val_loss: 3.5620 - val_accuracy: 0.3473\n",
      "Epoch 930/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2240 - accuracy: 0.5642 - val_loss: 3.5627 - val_accuracy: 0.3479\n",
      "Epoch 931/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.5614 - val_loss: 3.5556 - val_accuracy: 0.3546\n",
      "Epoch 932/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5648 - val_loss: 3.5555 - val_accuracy: 0.3571\n",
      "Epoch 933/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2235 - accuracy: 0.5613 - val_loss: 3.5516 - val_accuracy: 0.3540\n",
      "Epoch 934/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.5666 - val_loss: 3.5558 - val_accuracy: 0.3528\n",
      "Epoch 935/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2284 - accuracy: 0.5631 - val_loss: 3.5528 - val_accuracy: 0.3522\n",
      "Epoch 936/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2179 - accuracy: 0.5652 - val_loss: 3.5579 - val_accuracy: 0.3498\n",
      "Epoch 937/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.5595 - val_loss: 3.5599 - val_accuracy: 0.3564\n",
      "Epoch 938/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2212 - accuracy: 0.5684 - val_loss: 3.5605 - val_accuracy: 0.3510\n",
      "Epoch 939/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.5646 - val_loss: 3.5578 - val_accuracy: 0.3546\n",
      "Epoch 940/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2226 - accuracy: 0.5672 - val_loss: 3.5455 - val_accuracy: 0.3558\n",
      "Epoch 941/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.5623 - val_loss: 3.5541 - val_accuracy: 0.3558\n",
      "Epoch 942/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2211 - accuracy: 0.5610 - val_loss: 3.5594 - val_accuracy: 0.3546\n",
      "Epoch 943/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2251 - accuracy: 0.5654 - val_loss: 3.5648 - val_accuracy: 0.3558\n",
      "Epoch 944/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2195 - accuracy: 0.5654 - val_loss: 3.5692 - val_accuracy: 0.3510\n",
      "Epoch 945/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.5625 - val_loss: 3.5647 - val_accuracy: 0.3485\n",
      "Epoch 946/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2249 - accuracy: 0.5625 - val_loss: 3.5650 - val_accuracy: 0.3546\n",
      "Epoch 947/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2194 - accuracy: 0.5666 - val_loss: 3.5638 - val_accuracy: 0.3546\n",
      "Epoch 948/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2206 - accuracy: 0.5636 - val_loss: 3.5801 - val_accuracy: 0.3473\n",
      "Epoch 949/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2174 - accuracy: 0.5666 - val_loss: 3.5724 - val_accuracy: 0.3467\n",
      "Epoch 950/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2241 - accuracy: 0.5654 - val_loss: 3.5672 - val_accuracy: 0.3552\n",
      "Epoch 951/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2194 - accuracy: 0.5648 - val_loss: 3.5698 - val_accuracy: 0.3552\n",
      "Epoch 952/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.5636 - val_loss: 3.5638 - val_accuracy: 0.3479\n",
      "Epoch 953/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5658 - val_loss: 3.5501 - val_accuracy: 0.3540\n",
      "Epoch 954/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2262 - accuracy: 0.5623 - val_loss: 3.5735 - val_accuracy: 0.3552\n",
      "Epoch 955/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.5608 - val_loss: 3.5610 - val_accuracy: 0.3528\n",
      "Epoch 956/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2253 - accuracy: 0.5617 - val_loss: 3.5691 - val_accuracy: 0.3540\n",
      "Epoch 957/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2261 - accuracy: 0.5611 - val_loss: 3.5570 - val_accuracy: 0.3485\n",
      "Epoch 958/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.5634 - val_loss: 3.5694 - val_accuracy: 0.3552\n",
      "Epoch 959/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5660 - val_loss: 3.5763 - val_accuracy: 0.3473\n",
      "Epoch 960/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2217 - accuracy: 0.5668 - val_loss: 3.5721 - val_accuracy: 0.3467\n",
      "Epoch 961/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2209 - accuracy: 0.5651 - val_loss: 3.5823 - val_accuracy: 0.3431\n",
      "Epoch 962/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2274 - accuracy: 0.5645 - val_loss: 3.5742 - val_accuracy: 0.3467\n",
      "Epoch 963/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.5587 - val_loss: 3.5649 - val_accuracy: 0.3504\n",
      "Epoch 964/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2223 - accuracy: 0.5619 - val_loss: 3.5680 - val_accuracy: 0.3522\n",
      "Epoch 965/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2226 - accuracy: 0.5628 - val_loss: 3.5664 - val_accuracy: 0.3461\n",
      "Epoch 966/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2170 - accuracy: 0.5637 - val_loss: 3.5758 - val_accuracy: 0.3491\n",
      "Epoch 967/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2187 - accuracy: 0.5671 - val_loss: 3.5721 - val_accuracy: 0.3522\n",
      "Epoch 968/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5666 - val_loss: 3.5734 - val_accuracy: 0.3485\n",
      "Epoch 969/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2218 - accuracy: 0.5622 - val_loss: 3.5675 - val_accuracy: 0.3534\n",
      "Epoch 970/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2175 - accuracy: 0.5660 - val_loss: 3.5665 - val_accuracy: 0.3534\n",
      "Epoch 971/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.5631 - val_loss: 3.5677 - val_accuracy: 0.3534\n",
      "Epoch 972/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.5660 - val_loss: 3.5733 - val_accuracy: 0.3522\n",
      "Epoch 973/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2176 - accuracy: 0.5646 - val_loss: 3.5777 - val_accuracy: 0.3516\n",
      "Epoch 974/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5619 - val_loss: 3.5797 - val_accuracy: 0.3431\n",
      "Epoch 975/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2237 - accuracy: 0.5620 - val_loss: 3.5736 - val_accuracy: 0.3491\n",
      "Epoch 976/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2198 - accuracy: 0.5671 - val_loss: 3.5860 - val_accuracy: 0.3528\n",
      "Epoch 977/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.5655 - val_loss: 3.5787 - val_accuracy: 0.3522\n",
      "Epoch 978/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2239 - accuracy: 0.5654 - val_loss: 3.5748 - val_accuracy: 0.3437\n",
      "Epoch 979/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.5648 - val_loss: 3.5822 - val_accuracy: 0.3461\n",
      "Epoch 980/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2191 - accuracy: 0.5640 - val_loss: 3.5811 - val_accuracy: 0.3540\n",
      "Epoch 981/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.5643 - val_loss: 3.5833 - val_accuracy: 0.3498\n",
      "Epoch 982/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.5648 - val_loss: 3.5709 - val_accuracy: 0.3485\n",
      "Epoch 983/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2252 - accuracy: 0.5642 - val_loss: 3.5762 - val_accuracy: 0.3455\n",
      "Epoch 984/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2198 - accuracy: 0.5642 - val_loss: 3.5826 - val_accuracy: 0.3479\n",
      "Epoch 985/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.5593 - val_loss: 3.5776 - val_accuracy: 0.3473\n",
      "Epoch 986/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2246 - accuracy: 0.5684 - val_loss: 3.5747 - val_accuracy: 0.3437\n",
      "Epoch 987/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2227 - accuracy: 0.5654 - val_loss: 3.5871 - val_accuracy: 0.3418\n",
      "Epoch 988/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2161 - accuracy: 0.5665 - val_loss: 3.5769 - val_accuracy: 0.3479\n",
      "Epoch 989/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5623 - val_loss: 3.5767 - val_accuracy: 0.3449\n",
      "Epoch 990/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.5639 - val_loss: 3.5746 - val_accuracy: 0.3443\n",
      "Epoch 991/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2172 - accuracy: 0.5703 - val_loss: 3.5720 - val_accuracy: 0.3522\n",
      "Epoch 992/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2237 - accuracy: 0.5623 - val_loss: 3.5725 - val_accuracy: 0.3443\n",
      "Epoch 993/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2207 - accuracy: 0.5651 - val_loss: 3.5754 - val_accuracy: 0.3528\n",
      "Epoch 994/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5608 - val_loss: 3.5696 - val_accuracy: 0.3528\n",
      "Epoch 995/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.5666 - val_loss: 3.5745 - val_accuracy: 0.3498\n",
      "Epoch 996/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.5625 - val_loss: 3.5805 - val_accuracy: 0.3516\n",
      "Epoch 997/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2211 - accuracy: 0.5575 - val_loss: 3.5767 - val_accuracy: 0.3504\n",
      "Epoch 998/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2196 - accuracy: 0.5622 - val_loss: 3.5708 - val_accuracy: 0.3510\n",
      "Epoch 999/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2179 - accuracy: 0.5661 - val_loss: 3.5629 - val_accuracy: 0.3473\n",
      "Epoch 1000/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2234 - accuracy: 0.5605 - val_loss: 3.5730 - val_accuracy: 0.3467\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 32)\n",
    "history_many_to_many_baseline_32 = many_to_many_baseline_model.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=32, \n",
    "                                              validation_data=(xx_test, yy_test)  # Validation data\n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_baseline_32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_baseline_model_history_bs32.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_baseline_32.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.2166 - accuracy: 0.5672 - val_loss: 3.5698 - val_accuracy: 0.3443\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2217 - accuracy: 0.5627 - val_loss: 3.5758 - val_accuracy: 0.3479\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.5648 - val_loss: 3.5837 - val_accuracy: 0.3443\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2175 - accuracy: 0.5654 - val_loss: 3.5885 - val_accuracy: 0.3461\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5669 - val_loss: 3.5799 - val_accuracy: 0.3467\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2169 - accuracy: 0.5645 - val_loss: 3.5788 - val_accuracy: 0.3431\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5663 - val_loss: 3.5835 - val_accuracy: 0.3443\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2185 - accuracy: 0.5693 - val_loss: 3.5878 - val_accuracy: 0.3479\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5661 - val_loss: 3.5894 - val_accuracy: 0.3473\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2212 - accuracy: 0.5590 - val_loss: 3.5880 - val_accuracy: 0.3461\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5684 - val_loss: 3.5841 - val_accuracy: 0.3485\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2209 - accuracy: 0.5623 - val_loss: 3.5832 - val_accuracy: 0.3479\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.5666 - val_loss: 3.5809 - val_accuracy: 0.3485\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5713 - val_loss: 3.5787 - val_accuracy: 0.3485\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5649 - val_loss: 3.5861 - val_accuracy: 0.3418\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5689 - val_loss: 3.5875 - val_accuracy: 0.3455\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5651 - val_loss: 3.5883 - val_accuracy: 0.3455\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5693 - val_loss: 3.5932 - val_accuracy: 0.3461\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5695 - val_loss: 3.5891 - val_accuracy: 0.3449\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5658 - val_loss: 3.5896 - val_accuracy: 0.3425\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5658 - val_loss: 3.5859 - val_accuracy: 0.3479\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.5633 - val_loss: 3.5954 - val_accuracy: 0.3479\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2153 - accuracy: 0.5636 - val_loss: 3.5931 - val_accuracy: 0.3510\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2267 - accuracy: 0.5646 - val_loss: 3.5957 - val_accuracy: 0.3479\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5645 - val_loss: 3.5909 - val_accuracy: 0.3510\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.5671 - val_loss: 3.5950 - val_accuracy: 0.3473\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5651 - val_loss: 3.5887 - val_accuracy: 0.3431\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2177 - accuracy: 0.5651 - val_loss: 3.5981 - val_accuracy: 0.3461\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2117 - accuracy: 0.5678 - val_loss: 3.5972 - val_accuracy: 0.3491\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2173 - accuracy: 0.5683 - val_loss: 3.5957 - val_accuracy: 0.3467\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2223 - accuracy: 0.5610 - val_loss: 3.5967 - val_accuracy: 0.3479\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2190 - accuracy: 0.5634 - val_loss: 3.6057 - val_accuracy: 0.3455\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5674 - val_loss: 3.6027 - val_accuracy: 0.3540\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2181 - accuracy: 0.5645 - val_loss: 3.5993 - val_accuracy: 0.3504\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.5712 - val_loss: 3.5970 - val_accuracy: 0.3479\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.5725 - val_loss: 3.5998 - val_accuracy: 0.3443\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5657 - val_loss: 3.5981 - val_accuracy: 0.3449\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5674 - val_loss: 3.6022 - val_accuracy: 0.3461\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5669 - val_loss: 3.6021 - val_accuracy: 0.3473\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2202 - accuracy: 0.5637 - val_loss: 3.6027 - val_accuracy: 0.3498\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5628 - val_loss: 3.6008 - val_accuracy: 0.3461\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5678 - val_loss: 3.6041 - val_accuracy: 0.3516\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5616 - val_loss: 3.6136 - val_accuracy: 0.3455\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2212 - accuracy: 0.5669 - val_loss: 3.6037 - val_accuracy: 0.3449\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2132 - accuracy: 0.5687 - val_loss: 3.6033 - val_accuracy: 0.3461\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5690 - val_loss: 3.6066 - val_accuracy: 0.3455\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5636 - val_loss: 3.6086 - val_accuracy: 0.3467\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2208 - accuracy: 0.5636 - val_loss: 3.6063 - val_accuracy: 0.3455\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5637 - val_loss: 3.6017 - val_accuracy: 0.3504\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2222 - accuracy: 0.5639 - val_loss: 3.6028 - val_accuracy: 0.3491\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5652 - val_loss: 3.6044 - val_accuracy: 0.3473\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5668 - val_loss: 3.6024 - val_accuracy: 0.3455\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5630 - val_loss: 3.6065 - val_accuracy: 0.3443\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5690 - val_loss: 3.6092 - val_accuracy: 0.3510\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5674 - val_loss: 3.6079 - val_accuracy: 0.3455\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5637 - val_loss: 3.6003 - val_accuracy: 0.3455\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2207 - accuracy: 0.5627 - val_loss: 3.6073 - val_accuracy: 0.3455\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5669 - val_loss: 3.6074 - val_accuracy: 0.3504\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2210 - accuracy: 0.5655 - val_loss: 3.5996 - val_accuracy: 0.3467\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2200 - accuracy: 0.5654 - val_loss: 3.6033 - val_accuracy: 0.3412\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5651 - val_loss: 3.6081 - val_accuracy: 0.3491\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5677 - val_loss: 3.6121 - val_accuracy: 0.3467\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5649 - val_loss: 3.6064 - val_accuracy: 0.3418\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2185 - accuracy: 0.5628 - val_loss: 3.6061 - val_accuracy: 0.3467\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5658 - val_loss: 3.6176 - val_accuracy: 0.3485\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2196 - accuracy: 0.5654 - val_loss: 3.6133 - val_accuracy: 0.3498\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2214 - accuracy: 0.5631 - val_loss: 3.6191 - val_accuracy: 0.3473\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2189 - accuracy: 0.5651 - val_loss: 3.6150 - val_accuracy: 0.3504\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2226 - accuracy: 0.5599 - val_loss: 3.6109 - val_accuracy: 0.3473\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.5665 - val_loss: 3.6110 - val_accuracy: 0.3485\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5684 - val_loss: 3.6100 - val_accuracy: 0.3473\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5698 - val_loss: 3.6158 - val_accuracy: 0.3498\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5642 - val_loss: 3.6143 - val_accuracy: 0.3510\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5683 - val_loss: 3.6175 - val_accuracy: 0.3473\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2193 - accuracy: 0.5605 - val_loss: 3.6119 - val_accuracy: 0.3467\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5693 - val_loss: 3.6090 - val_accuracy: 0.3504\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2144 - accuracy: 0.5674 - val_loss: 3.6154 - val_accuracy: 0.3485\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5622 - val_loss: 3.6065 - val_accuracy: 0.3522\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5657 - val_loss: 3.6123 - val_accuracy: 0.3485\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5690 - val_loss: 3.6147 - val_accuracy: 0.3491\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5617 - val_loss: 3.6120 - val_accuracy: 0.3540\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5657 - val_loss: 3.6108 - val_accuracy: 0.3455\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5677 - val_loss: 3.6133 - val_accuracy: 0.3479\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5651 - val_loss: 3.6031 - val_accuracy: 0.3522\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.5646 - val_loss: 3.6075 - val_accuracy: 0.3479\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2188 - accuracy: 0.5652 - val_loss: 3.6160 - val_accuracy: 0.3437\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5674 - val_loss: 3.6099 - val_accuracy: 0.3479\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5666 - val_loss: 3.6048 - val_accuracy: 0.3498\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.5652 - val_loss: 3.6090 - val_accuracy: 0.3504\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5654 - val_loss: 3.6060 - val_accuracy: 0.3528\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5696 - val_loss: 3.6082 - val_accuracy: 0.3491\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2211 - accuracy: 0.5611 - val_loss: 3.6079 - val_accuracy: 0.3485\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2096 - accuracy: 0.5674 - val_loss: 3.6103 - val_accuracy: 0.3498\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2074 - accuracy: 0.5661 - val_loss: 3.6135 - val_accuracy: 0.3473\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5683 - val_loss: 3.6135 - val_accuracy: 0.3546\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5657 - val_loss: 3.6198 - val_accuracy: 0.3516\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2155 - accuracy: 0.5660 - val_loss: 3.6244 - val_accuracy: 0.3443\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5660 - val_loss: 3.6113 - val_accuracy: 0.3485\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5666 - val_loss: 3.6063 - val_accuracy: 0.3455\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2157 - accuracy: 0.5700 - val_loss: 3.6142 - val_accuracy: 0.3485\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5637 - val_loss: 3.6105 - val_accuracy: 0.3455\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5684 - val_loss: 3.6185 - val_accuracy: 0.3461\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5651 - val_loss: 3.6183 - val_accuracy: 0.3431\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2214 - accuracy: 0.5637 - val_loss: 3.6182 - val_accuracy: 0.3437\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5666 - val_loss: 3.6186 - val_accuracy: 0.3461\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2200 - accuracy: 0.5640 - val_loss: 3.6097 - val_accuracy: 0.3491\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5613 - val_loss: 3.6149 - val_accuracy: 0.3467\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5669 - val_loss: 3.6090 - val_accuracy: 0.3485\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5663 - val_loss: 3.6148 - val_accuracy: 0.3510\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5680 - val_loss: 3.6152 - val_accuracy: 0.3510\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5646 - val_loss: 3.6172 - val_accuracy: 0.3498\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2209 - accuracy: 0.5613 - val_loss: 3.6108 - val_accuracy: 0.3479\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5665 - val_loss: 3.6102 - val_accuracy: 0.3528\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5672 - val_loss: 3.6098 - val_accuracy: 0.3540\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2195 - accuracy: 0.5646 - val_loss: 3.6113 - val_accuracy: 0.3485\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2144 - accuracy: 0.5722 - val_loss: 3.6057 - val_accuracy: 0.3522\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5677 - val_loss: 3.6131 - val_accuracy: 0.3504\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.5660 - val_loss: 3.6091 - val_accuracy: 0.3498\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5674 - val_loss: 3.6137 - val_accuracy: 0.3498\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5706 - val_loss: 3.6189 - val_accuracy: 0.3491\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5643 - val_loss: 3.6236 - val_accuracy: 0.3485\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2201 - accuracy: 0.5651 - val_loss: 3.6172 - val_accuracy: 0.3473\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2186 - accuracy: 0.5665 - val_loss: 3.6153 - val_accuracy: 0.3528\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2219 - accuracy: 0.5634 - val_loss: 3.6088 - val_accuracy: 0.3522\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2180 - accuracy: 0.5637 - val_loss: 3.6110 - val_accuracy: 0.3491\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5683 - val_loss: 3.6098 - val_accuracy: 0.3534\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5693 - val_loss: 3.6185 - val_accuracy: 0.3491\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5686 - val_loss: 3.6112 - val_accuracy: 0.3516\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2211 - accuracy: 0.5634 - val_loss: 3.6168 - val_accuracy: 0.3498\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5739 - val_loss: 3.6139 - val_accuracy: 0.3498\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5675 - val_loss: 3.6141 - val_accuracy: 0.3516\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2186 - accuracy: 0.5677 - val_loss: 3.6136 - val_accuracy: 0.3467\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2182 - accuracy: 0.5668 - val_loss: 3.6183 - val_accuracy: 0.3473\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5648 - val_loss: 3.6182 - val_accuracy: 0.3504\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5684 - val_loss: 3.6166 - val_accuracy: 0.3540\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5701 - val_loss: 3.6223 - val_accuracy: 0.3540\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5636 - val_loss: 3.6174 - val_accuracy: 0.3564\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2245 - accuracy: 0.5625 - val_loss: 3.6248 - val_accuracy: 0.3498\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2204 - accuracy: 0.5675 - val_loss: 3.6221 - val_accuracy: 0.3504\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5652 - val_loss: 3.6308 - val_accuracy: 0.3437\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5646 - val_loss: 3.6267 - val_accuracy: 0.3485\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2216 - accuracy: 0.5669 - val_loss: 3.6217 - val_accuracy: 0.3443\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5646 - val_loss: 3.6217 - val_accuracy: 0.3443\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5616 - val_loss: 3.6223 - val_accuracy: 0.3479\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5661 - val_loss: 3.6241 - val_accuracy: 0.3498\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2212 - accuracy: 0.5625 - val_loss: 3.6177 - val_accuracy: 0.3425\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2210 - accuracy: 0.5654 - val_loss: 3.6115 - val_accuracy: 0.3485\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5660 - val_loss: 3.6149 - val_accuracy: 0.3449\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2192 - accuracy: 0.5649 - val_loss: 3.6100 - val_accuracy: 0.3461\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5651 - val_loss: 3.6076 - val_accuracy: 0.3485\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5649 - val_loss: 3.6088 - val_accuracy: 0.3473\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5616 - val_loss: 3.6086 - val_accuracy: 0.3449\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2193 - accuracy: 0.5601 - val_loss: 3.6108 - val_accuracy: 0.3449\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5658 - val_loss: 3.6159 - val_accuracy: 0.3498\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2152 - accuracy: 0.5678 - val_loss: 3.6158 - val_accuracy: 0.3443\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2124 - accuracy: 0.5666 - val_loss: 3.6134 - val_accuracy: 0.3485\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5663 - val_loss: 3.6183 - val_accuracy: 0.3516\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5674 - val_loss: 3.6226 - val_accuracy: 0.3546\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2177 - accuracy: 0.5683 - val_loss: 3.6213 - val_accuracy: 0.3455\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2190 - accuracy: 0.5681 - val_loss: 3.6197 - val_accuracy: 0.3461\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2171 - accuracy: 0.5651 - val_loss: 3.6252 - val_accuracy: 0.3491\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2175 - accuracy: 0.5671 - val_loss: 3.6205 - val_accuracy: 0.3498\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5646 - val_loss: 3.6127 - val_accuracy: 0.3504\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5643 - val_loss: 3.6146 - val_accuracy: 0.3510\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5658 - val_loss: 3.6114 - val_accuracy: 0.3473\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.5639 - val_loss: 3.6146 - val_accuracy: 0.3467\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5646 - val_loss: 3.6179 - val_accuracy: 0.3558\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2150 - accuracy: 0.5712 - val_loss: 3.6179 - val_accuracy: 0.3534\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5643 - val_loss: 3.6151 - val_accuracy: 0.3540\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2175 - accuracy: 0.5677 - val_loss: 3.6179 - val_accuracy: 0.3516\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5658 - val_loss: 3.6174 - val_accuracy: 0.3498\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2121 - accuracy: 0.5642 - val_loss: 3.6217 - val_accuracy: 0.3534\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2208 - accuracy: 0.5631 - val_loss: 3.6214 - val_accuracy: 0.3473\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2173 - accuracy: 0.5627 - val_loss: 3.6232 - val_accuracy: 0.3437\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5623 - val_loss: 3.6160 - val_accuracy: 0.3558\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5674 - val_loss: 3.6145 - val_accuracy: 0.3504\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5675 - val_loss: 3.6188 - val_accuracy: 0.3528\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5668 - val_loss: 3.6246 - val_accuracy: 0.3516\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5669 - val_loss: 3.6217 - val_accuracy: 0.3491\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2144 - accuracy: 0.5669 - val_loss: 3.6253 - val_accuracy: 0.3467\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5700 - val_loss: 3.6296 - val_accuracy: 0.3504\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5698 - val_loss: 3.6237 - val_accuracy: 0.3449\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2113 - accuracy: 0.5692 - val_loss: 3.6236 - val_accuracy: 0.3479\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5654 - val_loss: 3.6249 - val_accuracy: 0.3467\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5677 - val_loss: 3.6251 - val_accuracy: 0.3491\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5663 - val_loss: 3.6270 - val_accuracy: 0.3546\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5665 - val_loss: 3.6264 - val_accuracy: 0.3461\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5675 - val_loss: 3.6311 - val_accuracy: 0.3510\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2171 - accuracy: 0.5652 - val_loss: 3.6290 - val_accuracy: 0.3522\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5669 - val_loss: 3.6290 - val_accuracy: 0.3388\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5668 - val_loss: 3.6247 - val_accuracy: 0.3467\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5665 - val_loss: 3.6261 - val_accuracy: 0.3431\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5721 - val_loss: 3.6279 - val_accuracy: 0.3449\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5590 - val_loss: 3.6218 - val_accuracy: 0.3528\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2191 - accuracy: 0.5642 - val_loss: 3.6194 - val_accuracy: 0.3498\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5742 - val_loss: 3.6286 - val_accuracy: 0.3443\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.5680 - val_loss: 3.6219 - val_accuracy: 0.3467\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5672 - val_loss: 3.6148 - val_accuracy: 0.3516\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2152 - accuracy: 0.5665 - val_loss: 3.6241 - val_accuracy: 0.3491\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5674 - val_loss: 3.6292 - val_accuracy: 0.3498\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2208 - accuracy: 0.5607 - val_loss: 3.6176 - val_accuracy: 0.3443\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5652 - val_loss: 3.6127 - val_accuracy: 0.3461\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5652 - val_loss: 3.6298 - val_accuracy: 0.3485\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2169 - accuracy: 0.5637 - val_loss: 3.6265 - val_accuracy: 0.3461\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2195 - accuracy: 0.5654 - val_loss: 3.6182 - val_accuracy: 0.3449\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5668 - val_loss: 3.6220 - val_accuracy: 0.3498\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2231 - accuracy: 0.5625 - val_loss: 3.6151 - val_accuracy: 0.3473\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5689 - val_loss: 3.6217 - val_accuracy: 0.3412\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5652 - val_loss: 3.6167 - val_accuracy: 0.3479\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5672 - val_loss: 3.6236 - val_accuracy: 0.3528\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5668 - val_loss: 3.6227 - val_accuracy: 0.3504\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5692 - val_loss: 3.6286 - val_accuracy: 0.3461\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5678 - val_loss: 3.6203 - val_accuracy: 0.3540\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5637 - val_loss: 3.6260 - val_accuracy: 0.3534\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.5707 - val_loss: 3.6241 - val_accuracy: 0.3504\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5669 - val_loss: 3.6276 - val_accuracy: 0.3528\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5674 - val_loss: 3.6357 - val_accuracy: 0.3473\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2203 - accuracy: 0.5648 - val_loss: 3.6333 - val_accuracy: 0.3491\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2171 - accuracy: 0.5657 - val_loss: 3.6270 - val_accuracy: 0.3552\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2216 - accuracy: 0.5605 - val_loss: 3.6231 - val_accuracy: 0.3504\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5675 - val_loss: 3.6210 - val_accuracy: 0.3443\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5652 - val_loss: 3.6257 - val_accuracy: 0.3467\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5684 - val_loss: 3.6291 - val_accuracy: 0.3485\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2152 - accuracy: 0.5674 - val_loss: 3.6254 - val_accuracy: 0.3473\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5654 - val_loss: 3.6292 - val_accuracy: 0.3516\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2220 - accuracy: 0.5630 - val_loss: 3.6332 - val_accuracy: 0.3443\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5689 - val_loss: 3.6162 - val_accuracy: 0.3491\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5690 - val_loss: 3.6223 - val_accuracy: 0.3473\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5671 - val_loss: 3.6126 - val_accuracy: 0.3461\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2147 - accuracy: 0.5625 - val_loss: 3.6238 - val_accuracy: 0.3473\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5660 - val_loss: 3.6214 - val_accuracy: 0.3540\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5593 - val_loss: 3.6255 - val_accuracy: 0.3558\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2181 - accuracy: 0.5619 - val_loss: 3.6259 - val_accuracy: 0.3510\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5652 - val_loss: 3.6305 - val_accuracy: 0.3498\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5655 - val_loss: 3.6182 - val_accuracy: 0.3504\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5645 - val_loss: 3.6272 - val_accuracy: 0.3498\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5627 - val_loss: 3.6269 - val_accuracy: 0.3498\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2159 - accuracy: 0.5672 - val_loss: 3.6287 - val_accuracy: 0.3479\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5672 - val_loss: 3.6316 - val_accuracy: 0.3546\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5661 - val_loss: 3.6332 - val_accuracy: 0.3473\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2197 - accuracy: 0.5631 - val_loss: 3.6379 - val_accuracy: 0.3418\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2168 - accuracy: 0.5627 - val_loss: 3.6309 - val_accuracy: 0.3412\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2181 - accuracy: 0.5616 - val_loss: 3.6248 - val_accuracy: 0.3485\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2175 - accuracy: 0.5642 - val_loss: 3.6274 - val_accuracy: 0.3546\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2186 - accuracy: 0.5665 - val_loss: 3.6210 - val_accuracy: 0.3540\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5701 - val_loss: 3.6215 - val_accuracy: 0.3516\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5642 - val_loss: 3.6237 - val_accuracy: 0.3534\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5680 - val_loss: 3.6217 - val_accuracy: 0.3467\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2164 - accuracy: 0.5668 - val_loss: 3.6222 - val_accuracy: 0.3534\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2201 - accuracy: 0.5602 - val_loss: 3.6240 - val_accuracy: 0.3443\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2129 - accuracy: 0.5665 - val_loss: 3.6234 - val_accuracy: 0.3491\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2171 - accuracy: 0.5620 - val_loss: 3.6191 - val_accuracy: 0.3425\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5658 - val_loss: 3.6233 - val_accuracy: 0.3443\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2221 - accuracy: 0.5674 - val_loss: 3.6247 - val_accuracy: 0.3461\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5710 - val_loss: 3.6225 - val_accuracy: 0.3473\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2193 - accuracy: 0.5648 - val_loss: 3.6210 - val_accuracy: 0.3528\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5622 - val_loss: 3.6188 - val_accuracy: 0.3504\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5649 - val_loss: 3.6262 - val_accuracy: 0.3437\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5693 - val_loss: 3.6218 - val_accuracy: 0.3485\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5620 - val_loss: 3.6276 - val_accuracy: 0.3485\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2155 - accuracy: 0.5675 - val_loss: 3.6235 - val_accuracy: 0.3485\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5643 - val_loss: 3.6224 - val_accuracy: 0.3473\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5674 - val_loss: 3.6355 - val_accuracy: 0.3461\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5706 - val_loss: 3.6356 - val_accuracy: 0.3431\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5637 - val_loss: 3.6308 - val_accuracy: 0.3491\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5663 - val_loss: 3.6256 - val_accuracy: 0.3504\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5636 - val_loss: 3.6274 - val_accuracy: 0.3491\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5693 - val_loss: 3.6261 - val_accuracy: 0.3504\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5648 - val_loss: 3.6282 - val_accuracy: 0.3473\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5698 - val_loss: 3.6318 - val_accuracy: 0.3479\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2206 - accuracy: 0.5610 - val_loss: 3.6324 - val_accuracy: 0.3485\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5690 - val_loss: 3.6305 - val_accuracy: 0.3534\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.5630 - val_loss: 3.6344 - val_accuracy: 0.3498\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5675 - val_loss: 3.6380 - val_accuracy: 0.3479\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5648 - val_loss: 3.6375 - val_accuracy: 0.3467\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2102 - accuracy: 0.5657 - val_loss: 3.6369 - val_accuracy: 0.3516\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2212 - accuracy: 0.5655 - val_loss: 3.6332 - val_accuracy: 0.3516\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5681 - val_loss: 3.6326 - val_accuracy: 0.3491\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5646 - val_loss: 3.6303 - val_accuracy: 0.3491\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5620 - val_loss: 3.6296 - val_accuracy: 0.3528\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5671 - val_loss: 3.6323 - val_accuracy: 0.3546\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2201 - accuracy: 0.5655 - val_loss: 3.6249 - val_accuracy: 0.3516\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5643 - val_loss: 3.6282 - val_accuracy: 0.3558\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2093 - accuracy: 0.5674 - val_loss: 3.6368 - val_accuracy: 0.3449\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2175 - accuracy: 0.5634 - val_loss: 3.6361 - val_accuracy: 0.3485\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5604 - val_loss: 3.6295 - val_accuracy: 0.3479\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5640 - val_loss: 3.6335 - val_accuracy: 0.3504\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5639 - val_loss: 3.6252 - val_accuracy: 0.3498\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5637 - val_loss: 3.6293 - val_accuracy: 0.3498\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2208 - accuracy: 0.5654 - val_loss: 3.6280 - val_accuracy: 0.3455\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2209 - accuracy: 0.5649 - val_loss: 3.6259 - val_accuracy: 0.3522\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2169 - accuracy: 0.5630 - val_loss: 3.6415 - val_accuracy: 0.3449\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2184 - accuracy: 0.5648 - val_loss: 3.6357 - val_accuracy: 0.3467\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5652 - val_loss: 3.6364 - val_accuracy: 0.3473\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5631 - val_loss: 3.6327 - val_accuracy: 0.3467\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5655 - val_loss: 3.6295 - val_accuracy: 0.3522\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2197 - accuracy: 0.5683 - val_loss: 3.6230 - val_accuracy: 0.3394\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5646 - val_loss: 3.6223 - val_accuracy: 0.3473\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5646 - val_loss: 3.6327 - val_accuracy: 0.3516\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2119 - accuracy: 0.5651 - val_loss: 3.6352 - val_accuracy: 0.3461\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5700 - val_loss: 3.6312 - val_accuracy: 0.3467\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2166 - accuracy: 0.5677 - val_loss: 3.6338 - val_accuracy: 0.3491\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2184 - accuracy: 0.5646 - val_loss: 3.6309 - val_accuracy: 0.3443\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5655 - val_loss: 3.6229 - val_accuracy: 0.3516\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2133 - accuracy: 0.5651 - val_loss: 3.6349 - val_accuracy: 0.3498\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5642 - val_loss: 3.6363 - val_accuracy: 0.3516\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5655 - val_loss: 3.6411 - val_accuracy: 0.3467\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5663 - val_loss: 3.6342 - val_accuracy: 0.3455\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5655 - val_loss: 3.6408 - val_accuracy: 0.3504\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5666 - val_loss: 3.6277 - val_accuracy: 0.3516\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5704 - val_loss: 3.6254 - val_accuracy: 0.3601\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5665 - val_loss: 3.6240 - val_accuracy: 0.3528\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2231 - accuracy: 0.5634 - val_loss: 3.6325 - val_accuracy: 0.3552\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5627 - val_loss: 3.6331 - val_accuracy: 0.3467\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5620 - val_loss: 3.6350 - val_accuracy: 0.3467\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5654 - val_loss: 3.6375 - val_accuracy: 0.3491\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5681 - val_loss: 3.6323 - val_accuracy: 0.3540\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5683 - val_loss: 3.6375 - val_accuracy: 0.3473\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5666 - val_loss: 3.6426 - val_accuracy: 0.3522\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5687 - val_loss: 3.6365 - val_accuracy: 0.3485\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2182 - accuracy: 0.5622 - val_loss: 3.6370 - val_accuracy: 0.3546\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5663 - val_loss: 3.6475 - val_accuracy: 0.3461\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5660 - val_loss: 3.6386 - val_accuracy: 0.3479\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5680 - val_loss: 3.6372 - val_accuracy: 0.3431\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2185 - accuracy: 0.5622 - val_loss: 3.6282 - val_accuracy: 0.3473\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5665 - val_loss: 3.6337 - val_accuracy: 0.3498\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5668 - val_loss: 3.6359 - val_accuracy: 0.3437\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5639 - val_loss: 3.6392 - val_accuracy: 0.3491\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2182 - accuracy: 0.5665 - val_loss: 3.6349 - val_accuracy: 0.3461\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5712 - val_loss: 3.6397 - val_accuracy: 0.3449\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2186 - accuracy: 0.5661 - val_loss: 3.6382 - val_accuracy: 0.3510\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2140 - accuracy: 0.5657 - val_loss: 3.6430 - val_accuracy: 0.3491\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2164 - accuracy: 0.5660 - val_loss: 3.6445 - val_accuracy: 0.3522\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2133 - accuracy: 0.5633 - val_loss: 3.6417 - val_accuracy: 0.3479\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2188 - accuracy: 0.5617 - val_loss: 3.6420 - val_accuracy: 0.3546\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2220 - accuracy: 0.5627 - val_loss: 3.6421 - val_accuracy: 0.3546\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5680 - val_loss: 3.6371 - val_accuracy: 0.3516\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5678 - val_loss: 3.6371 - val_accuracy: 0.3516\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2206 - accuracy: 0.5613 - val_loss: 3.6335 - val_accuracy: 0.3491\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5681 - val_loss: 3.6424 - val_accuracy: 0.3431\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5680 - val_loss: 3.6349 - val_accuracy: 0.3412\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5630 - val_loss: 3.6342 - val_accuracy: 0.3479\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5655 - val_loss: 3.6356 - val_accuracy: 0.3504\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2220 - accuracy: 0.5695 - val_loss: 3.6307 - val_accuracy: 0.3485\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5646 - val_loss: 3.6397 - val_accuracy: 0.3510\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5640 - val_loss: 3.6304 - val_accuracy: 0.3510\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5669 - val_loss: 3.6414 - val_accuracy: 0.3546\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5669 - val_loss: 3.6324 - val_accuracy: 0.3498\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2203 - accuracy: 0.5661 - val_loss: 3.6361 - val_accuracy: 0.3491\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5684 - val_loss: 3.6392 - val_accuracy: 0.3479\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.5654 - val_loss: 3.6386 - val_accuracy: 0.3498\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5646 - val_loss: 3.6293 - val_accuracy: 0.3443\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5686 - val_loss: 3.6319 - val_accuracy: 0.3467\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2210 - accuracy: 0.5648 - val_loss: 3.6397 - val_accuracy: 0.3522\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2189 - accuracy: 0.5642 - val_loss: 3.6320 - val_accuracy: 0.3485\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2090 - accuracy: 0.5721 - val_loss: 3.6380 - val_accuracy: 0.3510\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5643 - val_loss: 3.6396 - val_accuracy: 0.3510\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5666 - val_loss: 3.6347 - val_accuracy: 0.3522\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5651 - val_loss: 3.6363 - val_accuracy: 0.3491\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2183 - accuracy: 0.5654 - val_loss: 3.6431 - val_accuracy: 0.3510\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5649 - val_loss: 3.6368 - val_accuracy: 0.3467\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2193 - accuracy: 0.5651 - val_loss: 3.6476 - val_accuracy: 0.3485\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5671 - val_loss: 3.6423 - val_accuracy: 0.3485\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5684 - val_loss: 3.6495 - val_accuracy: 0.3491\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2236 - accuracy: 0.5602 - val_loss: 3.6481 - val_accuracy: 0.3473\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5669 - val_loss: 3.6384 - val_accuracy: 0.3467\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2215 - accuracy: 0.5671 - val_loss: 3.6275 - val_accuracy: 0.3510\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2155 - accuracy: 0.5666 - val_loss: 3.6321 - val_accuracy: 0.3510\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5652 - val_loss: 3.6404 - val_accuracy: 0.3455\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.5681 - val_loss: 3.6372 - val_accuracy: 0.3479\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5652 - val_loss: 3.6307 - val_accuracy: 0.3485\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5645 - val_loss: 3.6352 - val_accuracy: 0.3425\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5684 - val_loss: 3.6375 - val_accuracy: 0.3504\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5602 - val_loss: 3.6487 - val_accuracy: 0.3467\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5639 - val_loss: 3.6485 - val_accuracy: 0.3510\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5630 - val_loss: 3.6444 - val_accuracy: 0.3479\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2191 - accuracy: 0.5633 - val_loss: 3.6482 - val_accuracy: 0.3479\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2190 - accuracy: 0.5627 - val_loss: 3.6473 - val_accuracy: 0.3467\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2170 - accuracy: 0.5671 - val_loss: 3.6386 - val_accuracy: 0.3467\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2169 - accuracy: 0.5666 - val_loss: 3.6461 - val_accuracy: 0.3522\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2198 - accuracy: 0.5604 - val_loss: 3.6394 - val_accuracy: 0.3467\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5675 - val_loss: 3.6391 - val_accuracy: 0.3461\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2148 - accuracy: 0.5655 - val_loss: 3.6399 - val_accuracy: 0.3473\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2128 - accuracy: 0.5649 - val_loss: 3.6405 - val_accuracy: 0.3473\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2189 - accuracy: 0.5631 - val_loss: 3.6405 - val_accuracy: 0.3461\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5627 - val_loss: 3.6455 - val_accuracy: 0.3431\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5703 - val_loss: 3.6417 - val_accuracy: 0.3425\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5651 - val_loss: 3.6450 - val_accuracy: 0.3479\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2072 - accuracy: 0.5715 - val_loss: 3.6526 - val_accuracy: 0.3461\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2136 - accuracy: 0.5660 - val_loss: 3.6497 - val_accuracy: 0.3455\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2181 - accuracy: 0.5661 - val_loss: 3.6507 - val_accuracy: 0.3412\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5634 - val_loss: 3.6516 - val_accuracy: 0.3400\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5661 - val_loss: 3.6534 - val_accuracy: 0.3479\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2191 - accuracy: 0.5628 - val_loss: 3.6422 - val_accuracy: 0.3491\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5683 - val_loss: 3.6467 - val_accuracy: 0.3455\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5654 - val_loss: 3.6513 - val_accuracy: 0.3425\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2099 - accuracy: 0.5648 - val_loss: 3.6433 - val_accuracy: 0.3479\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5665 - val_loss: 3.6567 - val_accuracy: 0.3473\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5628 - val_loss: 3.6468 - val_accuracy: 0.3516\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5637 - val_loss: 3.6539 - val_accuracy: 0.3504\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5695 - val_loss: 3.6475 - val_accuracy: 0.3522\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2177 - accuracy: 0.5646 - val_loss: 3.6411 - val_accuracy: 0.3528\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5649 - val_loss: 3.6384 - val_accuracy: 0.3510\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2120 - accuracy: 0.5628 - val_loss: 3.6319 - val_accuracy: 0.3473\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2093 - accuracy: 0.5658 - val_loss: 3.6437 - val_accuracy: 0.3552\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5677 - val_loss: 3.6551 - val_accuracy: 0.3540\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5684 - val_loss: 3.6486 - val_accuracy: 0.3522\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5642 - val_loss: 3.6524 - val_accuracy: 0.3528\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5657 - val_loss: 3.6512 - val_accuracy: 0.3467\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5683 - val_loss: 3.6569 - val_accuracy: 0.3455\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2132 - accuracy: 0.5649 - val_loss: 3.6588 - val_accuracy: 0.3455\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5652 - val_loss: 3.6594 - val_accuracy: 0.3443\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5651 - val_loss: 3.6548 - val_accuracy: 0.3473\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5663 - val_loss: 3.6585 - val_accuracy: 0.3498\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5663 - val_loss: 3.6533 - val_accuracy: 0.3540\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5678 - val_loss: 3.6562 - val_accuracy: 0.3498\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2164 - accuracy: 0.5627 - val_loss: 3.6483 - val_accuracy: 0.3485\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5608 - val_loss: 3.6537 - val_accuracy: 0.3485\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2171 - accuracy: 0.5636 - val_loss: 3.6532 - val_accuracy: 0.3467\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2101 - accuracy: 0.5619 - val_loss: 3.6463 - val_accuracy: 0.3516\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5651 - val_loss: 3.6531 - val_accuracy: 0.3449\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2151 - accuracy: 0.5648 - val_loss: 3.6646 - val_accuracy: 0.3449\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5695 - val_loss: 3.6556 - val_accuracy: 0.3491\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5648 - val_loss: 3.6521 - val_accuracy: 0.3479\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.5666 - val_loss: 3.6605 - val_accuracy: 0.3485\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2151 - accuracy: 0.5663 - val_loss: 3.6446 - val_accuracy: 0.3485\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.2091 - accuracy: 0.5690 - val_loss: 3.6489 - val_accuracy: 0.3522\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.2147 - accuracy: 0.5669 - val_loss: 3.6554 - val_accuracy: 0.3589\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2131 - accuracy: 0.5652 - val_loss: 3.6516 - val_accuracy: 0.3522\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2167 - accuracy: 0.5623 - val_loss: 3.6547 - val_accuracy: 0.3479\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2206 - accuracy: 0.5625 - val_loss: 3.6562 - val_accuracy: 0.3510\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2123 - accuracy: 0.5700 - val_loss: 3.6683 - val_accuracy: 0.3449\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2145 - accuracy: 0.5677 - val_loss: 3.6606 - val_accuracy: 0.3467\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2158 - accuracy: 0.5693 - val_loss: 3.6510 - val_accuracy: 0.3455\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2183 - accuracy: 0.5617 - val_loss: 3.6562 - val_accuracy: 0.3485\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2121 - accuracy: 0.5677 - val_loss: 3.6480 - val_accuracy: 0.3510\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.5672 - val_loss: 3.6523 - val_accuracy: 0.3516\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2120 - accuracy: 0.5693 - val_loss: 3.6533 - val_accuracy: 0.3522\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2123 - accuracy: 0.5657 - val_loss: 3.6602 - val_accuracy: 0.3461\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5671 - val_loss: 3.6562 - val_accuracy: 0.3473\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5598 - val_loss: 3.6549 - val_accuracy: 0.3491\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5684 - val_loss: 3.6569 - val_accuracy: 0.3485\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5669 - val_loss: 3.6636 - val_accuracy: 0.3498\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5666 - val_loss: 3.6517 - val_accuracy: 0.3418\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5681 - val_loss: 3.6593 - val_accuracy: 0.3455\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5649 - val_loss: 3.6547 - val_accuracy: 0.3498\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5692 - val_loss: 3.6554 - val_accuracy: 0.3498\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5674 - val_loss: 3.6538 - val_accuracy: 0.3437\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5607 - val_loss: 3.6506 - val_accuracy: 0.3431\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5643 - val_loss: 3.6494 - val_accuracy: 0.3461\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2195 - accuracy: 0.5674 - val_loss: 3.6434 - val_accuracy: 0.3473\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5658 - val_loss: 3.6477 - val_accuracy: 0.3412\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5695 - val_loss: 3.6483 - val_accuracy: 0.3467\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2163 - accuracy: 0.5675 - val_loss: 3.6461 - val_accuracy: 0.3498\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5675 - val_loss: 3.6549 - val_accuracy: 0.3455\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2069 - accuracy: 0.5665 - val_loss: 3.6559 - val_accuracy: 0.3449\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5661 - val_loss: 3.6600 - val_accuracy: 0.3425\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.5698 - val_loss: 3.6536 - val_accuracy: 0.3467\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5634 - val_loss: 3.6609 - val_accuracy: 0.3473\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5687 - val_loss: 3.6621 - val_accuracy: 0.3485\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5655 - val_loss: 3.6555 - val_accuracy: 0.3479\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5661 - val_loss: 3.6596 - val_accuracy: 0.3491\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5649 - val_loss: 3.6610 - val_accuracy: 0.3455\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2117 - accuracy: 0.5709 - val_loss: 3.6574 - val_accuracy: 0.3498\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5646 - val_loss: 3.6592 - val_accuracy: 0.3516\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5599 - val_loss: 3.6539 - val_accuracy: 0.3510\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5684 - val_loss: 3.6604 - val_accuracy: 0.3522\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5655 - val_loss: 3.6602 - val_accuracy: 0.3473\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5652 - val_loss: 3.6493 - val_accuracy: 0.3473\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5672 - val_loss: 3.6534 - val_accuracy: 0.3418\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5668 - val_loss: 3.6578 - val_accuracy: 0.3443\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5637 - val_loss: 3.6578 - val_accuracy: 0.3479\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5663 - val_loss: 3.6622 - val_accuracy: 0.3467\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5677 - val_loss: 3.6566 - val_accuracy: 0.3479\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5642 - val_loss: 3.6550 - val_accuracy: 0.3425\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2214 - accuracy: 0.5652 - val_loss: 3.6471 - val_accuracy: 0.3473\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5645 - val_loss: 3.6606 - val_accuracy: 0.3473\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2133 - accuracy: 0.5634 - val_loss: 3.6578 - val_accuracy: 0.3516\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5665 - val_loss: 3.6522 - val_accuracy: 0.3485\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5658 - val_loss: 3.6575 - val_accuracy: 0.3504\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2173 - accuracy: 0.5627 - val_loss: 3.6590 - val_accuracy: 0.3485\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5668 - val_loss: 3.6625 - val_accuracy: 0.3461\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5628 - val_loss: 3.6592 - val_accuracy: 0.3491\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2130 - accuracy: 0.5690 - val_loss: 3.6605 - val_accuracy: 0.3461\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5666 - val_loss: 3.6537 - val_accuracy: 0.3491\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5669 - val_loss: 3.6530 - val_accuracy: 0.3504\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.5628 - val_loss: 3.6543 - val_accuracy: 0.3467\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5677 - val_loss: 3.6558 - val_accuracy: 0.3455\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5622 - val_loss: 3.6552 - val_accuracy: 0.3437\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2108 - accuracy: 0.5677 - val_loss: 3.6584 - val_accuracy: 0.3437\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5677 - val_loss: 3.6571 - val_accuracy: 0.3406\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5627 - val_loss: 3.6535 - val_accuracy: 0.3479\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2181 - accuracy: 0.5661 - val_loss: 3.6633 - val_accuracy: 0.3425\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5651 - val_loss: 3.6597 - val_accuracy: 0.3491\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2095 - accuracy: 0.5649 - val_loss: 3.6648 - val_accuracy: 0.3504\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5671 - val_loss: 3.6710 - val_accuracy: 0.3461\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2102 - accuracy: 0.5661 - val_loss: 3.6654 - val_accuracy: 0.3479\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5666 - val_loss: 3.6687 - val_accuracy: 0.3473\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5604 - val_loss: 3.6622 - val_accuracy: 0.3491\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2088 - accuracy: 0.5686 - val_loss: 3.6726 - val_accuracy: 0.3491\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2200 - accuracy: 0.5630 - val_loss: 3.6616 - val_accuracy: 0.3498\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5642 - val_loss: 3.6541 - val_accuracy: 0.3443\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5645 - val_loss: 3.6638 - val_accuracy: 0.3449\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5625 - val_loss: 3.6500 - val_accuracy: 0.3504\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5663 - val_loss: 3.6638 - val_accuracy: 0.3522\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5666 - val_loss: 3.6608 - val_accuracy: 0.3528\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5645 - val_loss: 3.6547 - val_accuracy: 0.3504\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5695 - val_loss: 3.6609 - val_accuracy: 0.3491\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2070 - accuracy: 0.5683 - val_loss: 3.6614 - val_accuracy: 0.3504\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2116 - accuracy: 0.5652 - val_loss: 3.6585 - val_accuracy: 0.3437\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2185 - accuracy: 0.5652 - val_loss: 3.6609 - val_accuracy: 0.3510\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2211 - accuracy: 0.5651 - val_loss: 3.6521 - val_accuracy: 0.3498\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5661 - val_loss: 3.6569 - val_accuracy: 0.3455\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.5646 - val_loss: 3.6576 - val_accuracy: 0.3534\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2169 - accuracy: 0.5643 - val_loss: 3.6652 - val_accuracy: 0.3510\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5639 - val_loss: 3.6612 - val_accuracy: 0.3558\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5684 - val_loss: 3.6616 - val_accuracy: 0.3534\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2131 - accuracy: 0.5643 - val_loss: 3.6603 - val_accuracy: 0.3546\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2066 - accuracy: 0.5715 - val_loss: 3.6682 - val_accuracy: 0.3455\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2125 - accuracy: 0.5614 - val_loss: 3.6693 - val_accuracy: 0.3534\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2112 - accuracy: 0.5687 - val_loss: 3.6637 - val_accuracy: 0.3552\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2168 - accuracy: 0.5657 - val_loss: 3.6611 - val_accuracy: 0.3571\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2155 - accuracy: 0.5630 - val_loss: 3.6624 - val_accuracy: 0.3552\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5687 - val_loss: 3.6602 - val_accuracy: 0.3473\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2147 - accuracy: 0.5623 - val_loss: 3.6566 - val_accuracy: 0.3510\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2129 - accuracy: 0.5680 - val_loss: 3.6589 - val_accuracy: 0.3516\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5669 - val_loss: 3.6654 - val_accuracy: 0.3491\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5692 - val_loss: 3.6548 - val_accuracy: 0.3504\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.5669 - val_loss: 3.6626 - val_accuracy: 0.3431\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5661 - val_loss: 3.6657 - val_accuracy: 0.3467\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5652 - val_loss: 3.6648 - val_accuracy: 0.3461\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5678 - val_loss: 3.6672 - val_accuracy: 0.3485\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5648 - val_loss: 3.6633 - val_accuracy: 0.3498\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2085 - accuracy: 0.5698 - val_loss: 3.6677 - val_accuracy: 0.3473\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5661 - val_loss: 3.6607 - val_accuracy: 0.3412\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2181 - accuracy: 0.5660 - val_loss: 3.6634 - val_accuracy: 0.3498\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5616 - val_loss: 3.6643 - val_accuracy: 0.3564\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2140 - accuracy: 0.5672 - val_loss: 3.6669 - val_accuracy: 0.3552\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2071 - accuracy: 0.5687 - val_loss: 3.6627 - val_accuracy: 0.3540\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5614 - val_loss: 3.6683 - val_accuracy: 0.3516\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5646 - val_loss: 3.6657 - val_accuracy: 0.3461\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5654 - val_loss: 3.6674 - val_accuracy: 0.3516\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5675 - val_loss: 3.6701 - val_accuracy: 0.3516\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.5698 - val_loss: 3.6730 - val_accuracy: 0.3467\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5681 - val_loss: 3.6680 - val_accuracy: 0.3504\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5681 - val_loss: 3.6630 - val_accuracy: 0.3546\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5668 - val_loss: 3.6632 - val_accuracy: 0.3528\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5654 - val_loss: 3.6664 - val_accuracy: 0.3498\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5605 - val_loss: 3.6624 - val_accuracy: 0.3504\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2155 - accuracy: 0.5625 - val_loss: 3.6614 - val_accuracy: 0.3461\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5661 - val_loss: 3.6615 - val_accuracy: 0.3461\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5634 - val_loss: 3.6692 - val_accuracy: 0.3461\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5681 - val_loss: 3.6617 - val_accuracy: 0.3504\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2194 - accuracy: 0.5637 - val_loss: 3.6677 - val_accuracy: 0.3473\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.5674 - val_loss: 3.6666 - val_accuracy: 0.3498\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5633 - val_loss: 3.6559 - val_accuracy: 0.3473\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5631 - val_loss: 3.6621 - val_accuracy: 0.3510\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2103 - accuracy: 0.5655 - val_loss: 3.6667 - val_accuracy: 0.3522\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2090 - accuracy: 0.5669 - val_loss: 3.6694 - val_accuracy: 0.3485\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2080 - accuracy: 0.5678 - val_loss: 3.6691 - val_accuracy: 0.3510\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5607 - val_loss: 3.6640 - val_accuracy: 0.3485\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5690 - val_loss: 3.6727 - val_accuracy: 0.3540\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5649 - val_loss: 3.6616 - val_accuracy: 0.3510\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5620 - val_loss: 3.6605 - val_accuracy: 0.3498\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2117 - accuracy: 0.5646 - val_loss: 3.6607 - val_accuracy: 0.3461\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5695 - val_loss: 3.6646 - val_accuracy: 0.3479\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5675 - val_loss: 3.6681 - val_accuracy: 0.3491\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.5709 - val_loss: 3.6705 - val_accuracy: 0.3504\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5660 - val_loss: 3.6658 - val_accuracy: 0.3504\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5639 - val_loss: 3.6614 - val_accuracy: 0.3522\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5666 - val_loss: 3.6588 - val_accuracy: 0.3510\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5654 - val_loss: 3.6629 - val_accuracy: 0.3516\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5698 - val_loss: 3.6605 - val_accuracy: 0.3504\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5617 - val_loss: 3.6716 - val_accuracy: 0.3516\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5674 - val_loss: 3.6647 - val_accuracy: 0.3485\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5695 - val_loss: 3.6638 - val_accuracy: 0.3479\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5658 - val_loss: 3.6702 - val_accuracy: 0.3473\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5686 - val_loss: 3.6694 - val_accuracy: 0.3455\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5660 - val_loss: 3.6658 - val_accuracy: 0.3443\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5617 - val_loss: 3.6633 - val_accuracy: 0.3455\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.5709 - val_loss: 3.6679 - val_accuracy: 0.3455\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5672 - val_loss: 3.6676 - val_accuracy: 0.3455\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.5692 - val_loss: 3.6778 - val_accuracy: 0.3412\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5645 - val_loss: 3.6732 - val_accuracy: 0.3431\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2118 - accuracy: 0.5631 - val_loss: 3.6623 - val_accuracy: 0.3461\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5652 - val_loss: 3.6697 - val_accuracy: 0.3479\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5649 - val_loss: 3.6732 - val_accuracy: 0.3455\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2183 - accuracy: 0.5648 - val_loss: 3.6760 - val_accuracy: 0.3449\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5665 - val_loss: 3.6695 - val_accuracy: 0.3455\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5645 - val_loss: 3.6740 - val_accuracy: 0.3418\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5680 - val_loss: 3.6676 - val_accuracy: 0.3485\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5637 - val_loss: 3.6658 - val_accuracy: 0.3504\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5633 - val_loss: 3.6671 - val_accuracy: 0.3467\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2094 - accuracy: 0.5674 - val_loss: 3.6698 - val_accuracy: 0.3546\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2232 - accuracy: 0.5592 - val_loss: 3.6626 - val_accuracy: 0.3583\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.2107 - accuracy: 0.5660 - val_loss: 3.6662 - val_accuracy: 0.3504\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2104 - accuracy: 0.5668 - val_loss: 3.6780 - val_accuracy: 0.3534\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5666 - val_loss: 3.6848 - val_accuracy: 0.3449\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5628 - val_loss: 3.6732 - val_accuracy: 0.3485\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5677 - val_loss: 3.6705 - val_accuracy: 0.3485\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5640 - val_loss: 3.6583 - val_accuracy: 0.3491\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5671 - val_loss: 3.6714 - val_accuracy: 0.3443\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5639 - val_loss: 3.6688 - val_accuracy: 0.3467\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2092 - accuracy: 0.5686 - val_loss: 3.6597 - val_accuracy: 0.3504\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5627 - val_loss: 3.6591 - val_accuracy: 0.3510\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.5620 - val_loss: 3.6670 - val_accuracy: 0.3577\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2113 - accuracy: 0.5642 - val_loss: 3.6702 - val_accuracy: 0.3473\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5613 - val_loss: 3.6762 - val_accuracy: 0.3522\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5663 - val_loss: 3.6707 - val_accuracy: 0.3479\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5703 - val_loss: 3.6726 - val_accuracy: 0.3473\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5681 - val_loss: 3.6697 - val_accuracy: 0.3461\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2138 - accuracy: 0.5680 - val_loss: 3.6731 - val_accuracy: 0.3528\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.5696 - val_loss: 3.6777 - val_accuracy: 0.3467\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2057 - accuracy: 0.5671 - val_loss: 3.6691 - val_accuracy: 0.3510\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5654 - val_loss: 3.6705 - val_accuracy: 0.3522\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5654 - val_loss: 3.6748 - val_accuracy: 0.3467\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5652 - val_loss: 3.6707 - val_accuracy: 0.3552\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5652 - val_loss: 3.6763 - val_accuracy: 0.3491\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5654 - val_loss: 3.6773 - val_accuracy: 0.3516\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5654 - val_loss: 3.6780 - val_accuracy: 0.3491\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5649 - val_loss: 3.6723 - val_accuracy: 0.3425\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5668 - val_loss: 3.6704 - val_accuracy: 0.3491\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2200 - accuracy: 0.5613 - val_loss: 3.6725 - val_accuracy: 0.3491\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5698 - val_loss: 3.6729 - val_accuracy: 0.3498\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5666 - val_loss: 3.6682 - val_accuracy: 0.3485\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5669 - val_loss: 3.6657 - val_accuracy: 0.3461\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5710 - val_loss: 3.6673 - val_accuracy: 0.3522\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2117 - accuracy: 0.5617 - val_loss: 3.6675 - val_accuracy: 0.3467\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5655 - val_loss: 3.6691 - val_accuracy: 0.3485\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2142 - accuracy: 0.5663 - val_loss: 3.6670 - val_accuracy: 0.3485\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5658 - val_loss: 3.6581 - val_accuracy: 0.3473\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5645 - val_loss: 3.6677 - val_accuracy: 0.3491\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5660 - val_loss: 3.6744 - val_accuracy: 0.3443\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.5689 - val_loss: 3.6705 - val_accuracy: 0.3479\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2140 - accuracy: 0.5651 - val_loss: 3.6656 - val_accuracy: 0.3504\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5649 - val_loss: 3.6735 - val_accuracy: 0.3455\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5628 - val_loss: 3.6712 - val_accuracy: 0.3455\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5634 - val_loss: 3.6702 - val_accuracy: 0.3510\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5628 - val_loss: 3.6668 - val_accuracy: 0.3467\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2102 - accuracy: 0.5684 - val_loss: 3.6726 - val_accuracy: 0.3467\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2113 - accuracy: 0.5640 - val_loss: 3.6734 - val_accuracy: 0.3491\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2096 - accuracy: 0.5663 - val_loss: 3.6755 - val_accuracy: 0.3479\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5655 - val_loss: 3.6675 - val_accuracy: 0.3522\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.5678 - val_loss: 3.6842 - val_accuracy: 0.3479\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5715 - val_loss: 3.6836 - val_accuracy: 0.3443\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5628 - val_loss: 3.6795 - val_accuracy: 0.3449\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.5648 - val_loss: 3.6818 - val_accuracy: 0.3449\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5683 - val_loss: 3.6853 - val_accuracy: 0.3473\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5716 - val_loss: 3.6834 - val_accuracy: 0.3455\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5627 - val_loss: 3.6778 - val_accuracy: 0.3479\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5674 - val_loss: 3.6825 - val_accuracy: 0.3437\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5657 - val_loss: 3.6734 - val_accuracy: 0.3516\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5655 - val_loss: 3.6736 - val_accuracy: 0.3546\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5622 - val_loss: 3.6758 - val_accuracy: 0.3455\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5649 - val_loss: 3.6726 - val_accuracy: 0.3455\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2190 - accuracy: 0.5643 - val_loss: 3.6799 - val_accuracy: 0.3461\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5672 - val_loss: 3.6782 - val_accuracy: 0.3431\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5663 - val_loss: 3.6802 - val_accuracy: 0.3418\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2100 - accuracy: 0.5681 - val_loss: 3.6803 - val_accuracy: 0.3455\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5666 - val_loss: 3.6737 - val_accuracy: 0.3455\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5674 - val_loss: 3.6719 - val_accuracy: 0.3461\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5608 - val_loss: 3.6732 - val_accuracy: 0.3467\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5658 - val_loss: 3.6732 - val_accuracy: 0.3412\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5658 - val_loss: 3.6710 - val_accuracy: 0.3467\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5675 - val_loss: 3.6745 - val_accuracy: 0.3406\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5669 - val_loss: 3.6765 - val_accuracy: 0.3425\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5663 - val_loss: 3.6782 - val_accuracy: 0.3449\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5696 - val_loss: 3.6747 - val_accuracy: 0.3510\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5651 - val_loss: 3.6778 - val_accuracy: 0.3467\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.5703 - val_loss: 3.6781 - val_accuracy: 0.3431\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5639 - val_loss: 3.6788 - val_accuracy: 0.3516\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5640 - val_loss: 3.6785 - val_accuracy: 0.3467\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5675 - val_loss: 3.6740 - val_accuracy: 0.3455\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5663 - val_loss: 3.6768 - val_accuracy: 0.3510\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5660 - val_loss: 3.6727 - val_accuracy: 0.3485\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.5622 - val_loss: 3.6639 - val_accuracy: 0.3516\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2168 - accuracy: 0.5636 - val_loss: 3.6748 - val_accuracy: 0.3479\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5687 - val_loss: 3.6705 - val_accuracy: 0.3498\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5689 - val_loss: 3.6742 - val_accuracy: 0.3491\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5627 - val_loss: 3.6754 - val_accuracy: 0.3418\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5668 - val_loss: 3.6760 - val_accuracy: 0.3510\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5672 - val_loss: 3.6636 - val_accuracy: 0.3504\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.5665 - val_loss: 3.6693 - val_accuracy: 0.3485\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5698 - val_loss: 3.6739 - val_accuracy: 0.3498\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5669 - val_loss: 3.6691 - val_accuracy: 0.3467\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5715 - val_loss: 3.6796 - val_accuracy: 0.3473\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2157 - accuracy: 0.5658 - val_loss: 3.6778 - val_accuracy: 0.3504\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5672 - val_loss: 3.6708 - val_accuracy: 0.3455\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2144 - accuracy: 0.5668 - val_loss: 3.6737 - val_accuracy: 0.3437\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2125 - accuracy: 0.5677 - val_loss: 3.6797 - val_accuracy: 0.3425\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5657 - val_loss: 3.6746 - val_accuracy: 0.3412\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5665 - val_loss: 3.6805 - val_accuracy: 0.3449\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2086 - accuracy: 0.5678 - val_loss: 3.6827 - val_accuracy: 0.3406\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5630 - val_loss: 3.6836 - val_accuracy: 0.3443\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5649 - val_loss: 3.6882 - val_accuracy: 0.3461\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5620 - val_loss: 3.6749 - val_accuracy: 0.3528\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2154 - accuracy: 0.5649 - val_loss: 3.6680 - val_accuracy: 0.3522\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2114 - accuracy: 0.5683 - val_loss: 3.6754 - val_accuracy: 0.3437\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5684 - val_loss: 3.6765 - val_accuracy: 0.3485\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5610 - val_loss: 3.6816 - val_accuracy: 0.3485\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5648 - val_loss: 3.6766 - val_accuracy: 0.3473\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.5633 - val_loss: 3.6872 - val_accuracy: 0.3418\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5616 - val_loss: 3.6839 - val_accuracy: 0.3449\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5649 - val_loss: 3.6774 - val_accuracy: 0.3449\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2079 - accuracy: 0.5683 - val_loss: 3.6832 - val_accuracy: 0.3504\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2159 - accuracy: 0.5642 - val_loss: 3.6748 - val_accuracy: 0.3449\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2137 - accuracy: 0.5663 - val_loss: 3.6760 - val_accuracy: 0.3516\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2221 - accuracy: 0.5623 - val_loss: 3.6782 - val_accuracy: 0.3467\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2104 - accuracy: 0.5672 - val_loss: 3.6811 - val_accuracy: 0.3418\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5666 - val_loss: 3.6761 - val_accuracy: 0.3455\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5692 - val_loss: 3.6772 - val_accuracy: 0.3400\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.5663 - val_loss: 3.6823 - val_accuracy: 0.3461\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5628 - val_loss: 3.6849 - val_accuracy: 0.3491\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5637 - val_loss: 3.6833 - val_accuracy: 0.3467\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2115 - accuracy: 0.5671 - val_loss: 3.6797 - val_accuracy: 0.3443\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2093 - accuracy: 0.5617 - val_loss: 3.6801 - val_accuracy: 0.3443\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5668 - val_loss: 3.6887 - val_accuracy: 0.3467\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2154 - accuracy: 0.5622 - val_loss: 3.6828 - val_accuracy: 0.3498\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.5684 - val_loss: 3.6815 - val_accuracy: 0.3461\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5666 - val_loss: 3.6817 - val_accuracy: 0.3461\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5658 - val_loss: 3.6693 - val_accuracy: 0.3455\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5613 - val_loss: 3.6742 - val_accuracy: 0.3479\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2161 - accuracy: 0.5665 - val_loss: 3.6748 - val_accuracy: 0.3461\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5649 - val_loss: 3.6698 - val_accuracy: 0.3498\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5642 - val_loss: 3.6654 - val_accuracy: 0.3473\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2157 - accuracy: 0.5652 - val_loss: 3.6728 - val_accuracy: 0.3528\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5672 - val_loss: 3.6772 - val_accuracy: 0.3485\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.5640 - val_loss: 3.6822 - val_accuracy: 0.3498\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5665 - val_loss: 3.6772 - val_accuracy: 0.3461\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5636 - val_loss: 3.6747 - val_accuracy: 0.3449\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5687 - val_loss: 3.6745 - val_accuracy: 0.3504\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.5643 - val_loss: 3.6791 - val_accuracy: 0.3443\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5628 - val_loss: 3.6661 - val_accuracy: 0.3449\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5630 - val_loss: 3.6746 - val_accuracy: 0.3473\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.5620 - val_loss: 3.6664 - val_accuracy: 0.3485\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5701 - val_loss: 3.6713 - val_accuracy: 0.3437\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2073 - accuracy: 0.5680 - val_loss: 3.6803 - val_accuracy: 0.3437\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5654 - val_loss: 3.6931 - val_accuracy: 0.3498\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5625 - val_loss: 3.6820 - val_accuracy: 0.3498\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5630 - val_loss: 3.6805 - val_accuracy: 0.3473\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5661 - val_loss: 3.6782 - val_accuracy: 0.3552\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5674 - val_loss: 3.6812 - val_accuracy: 0.3491\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.2068 - accuracy: 0.5713 - val_loss: 3.6855 - val_accuracy: 0.3461\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2144 - accuracy: 0.5674 - val_loss: 3.6846 - val_accuracy: 0.3479\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2062 - accuracy: 0.5716 - val_loss: 3.6950 - val_accuracy: 0.3479\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5687 - val_loss: 3.6982 - val_accuracy: 0.3491\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5675 - val_loss: 3.6858 - val_accuracy: 0.3485\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5671 - val_loss: 3.6857 - val_accuracy: 0.3558\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5689 - val_loss: 3.6869 - val_accuracy: 0.3558\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5671 - val_loss: 3.6946 - val_accuracy: 0.3516\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5678 - val_loss: 3.6913 - val_accuracy: 0.3485\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5693 - val_loss: 3.6901 - val_accuracy: 0.3479\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5671 - val_loss: 3.6950 - val_accuracy: 0.3467\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5639 - val_loss: 3.6890 - val_accuracy: 0.3504\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5619 - val_loss: 3.6899 - val_accuracy: 0.3467\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2074 - accuracy: 0.5725 - val_loss: 3.6885 - val_accuracy: 0.3522\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5646 - val_loss: 3.6852 - val_accuracy: 0.3510\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2113 - accuracy: 0.5637 - val_loss: 3.6854 - val_accuracy: 0.3534\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2099 - accuracy: 0.5634 - val_loss: 3.6957 - val_accuracy: 0.3455\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2085 - accuracy: 0.5696 - val_loss: 3.6936 - val_accuracy: 0.3467\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5655 - val_loss: 3.6987 - val_accuracy: 0.3479\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2170 - accuracy: 0.5619 - val_loss: 3.6909 - val_accuracy: 0.3510\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5706 - val_loss: 3.6994 - val_accuracy: 0.3449\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.5672 - val_loss: 3.6980 - val_accuracy: 0.3504\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2124 - accuracy: 0.5640 - val_loss: 3.6981 - val_accuracy: 0.3437\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5669 - val_loss: 3.7039 - val_accuracy: 0.3467\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5661 - val_loss: 3.6976 - val_accuracy: 0.3540\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5660 - val_loss: 3.6907 - val_accuracy: 0.3504\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5633 - val_loss: 3.6901 - val_accuracy: 0.3431\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2157 - accuracy: 0.5622 - val_loss: 3.6957 - val_accuracy: 0.3498\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5666 - val_loss: 3.6916 - val_accuracy: 0.3479\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5651 - val_loss: 3.6908 - val_accuracy: 0.3461\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5655 - val_loss: 3.6888 - val_accuracy: 0.3528\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5666 - val_loss: 3.6855 - val_accuracy: 0.3479\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5661 - val_loss: 3.6793 - val_accuracy: 0.3467\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.5648 - val_loss: 3.6936 - val_accuracy: 0.3437\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5652 - val_loss: 3.6909 - val_accuracy: 0.3485\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5642 - val_loss: 3.6850 - val_accuracy: 0.3467\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2077 - accuracy: 0.5715 - val_loss: 3.6808 - val_accuracy: 0.3449\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2157 - accuracy: 0.5623 - val_loss: 3.6885 - val_accuracy: 0.3479\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2090 - accuracy: 0.5674 - val_loss: 3.6857 - val_accuracy: 0.3522\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2190 - accuracy: 0.5672 - val_loss: 3.6894 - val_accuracy: 0.3540\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2123 - accuracy: 0.5652 - val_loss: 3.6963 - val_accuracy: 0.3406\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5669 - val_loss: 3.6932 - val_accuracy: 0.3431\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5678 - val_loss: 3.7041 - val_accuracy: 0.3461\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.5696 - val_loss: 3.6884 - val_accuracy: 0.3522\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5668 - val_loss: 3.6879 - val_accuracy: 0.3455\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2133 - accuracy: 0.5701 - val_loss: 3.6839 - val_accuracy: 0.3516\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2118 - accuracy: 0.5665 - val_loss: 3.6993 - val_accuracy: 0.3504\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2101 - accuracy: 0.5654 - val_loss: 3.6894 - val_accuracy: 0.3498\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2094 - accuracy: 0.5661 - val_loss: 3.6911 - val_accuracy: 0.3528\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5704 - val_loss: 3.6975 - val_accuracy: 0.3498\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5658 - val_loss: 3.6898 - val_accuracy: 0.3528\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5646 - val_loss: 3.6958 - val_accuracy: 0.3467\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5630 - val_loss: 3.6898 - val_accuracy: 0.3437\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5692 - val_loss: 3.6937 - val_accuracy: 0.3516\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2171 - accuracy: 0.5660 - val_loss: 3.6977 - val_accuracy: 0.3473\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5649 - val_loss: 3.6872 - val_accuracy: 0.3498\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2151 - accuracy: 0.5639 - val_loss: 3.6841 - val_accuracy: 0.3522\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5716 - val_loss: 3.6901 - val_accuracy: 0.3504\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5602 - val_loss: 3.6871 - val_accuracy: 0.3498\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5680 - val_loss: 3.6916 - val_accuracy: 0.3479\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5707 - val_loss: 3.6899 - val_accuracy: 0.3461\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5622 - val_loss: 3.6800 - val_accuracy: 0.3498\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5645 - val_loss: 3.6902 - val_accuracy: 0.3479\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.5703 - val_loss: 3.6848 - val_accuracy: 0.3443\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5666 - val_loss: 3.6990 - val_accuracy: 0.3479\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.5690 - val_loss: 3.7012 - val_accuracy: 0.3431\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2103 - accuracy: 0.5657 - val_loss: 3.7076 - val_accuracy: 0.3498\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.5677 - val_loss: 3.7022 - val_accuracy: 0.3522\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5665 - val_loss: 3.7046 - val_accuracy: 0.3516\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2056 - accuracy: 0.5657 - val_loss: 3.7095 - val_accuracy: 0.3467\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5652 - val_loss: 3.7005 - val_accuracy: 0.3498\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5683 - val_loss: 3.6974 - val_accuracy: 0.3473\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2094 - accuracy: 0.5633 - val_loss: 3.7056 - val_accuracy: 0.3437\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2091 - accuracy: 0.5695 - val_loss: 3.7034 - val_accuracy: 0.3504\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2180 - accuracy: 0.5643 - val_loss: 3.7013 - val_accuracy: 0.3504\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2051 - accuracy: 0.5666 - val_loss: 3.6973 - val_accuracy: 0.3522\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2081 - accuracy: 0.5678 - val_loss: 3.6923 - val_accuracy: 0.3479\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2107 - accuracy: 0.5666 - val_loss: 3.6987 - val_accuracy: 0.3516\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5637 - val_loss: 3.7052 - val_accuracy: 0.3485\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5683 - val_loss: 3.6910 - val_accuracy: 0.3485\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2088 - accuracy: 0.5651 - val_loss: 3.6900 - val_accuracy: 0.3485\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5637 - val_loss: 3.6982 - val_accuracy: 0.3473\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5649 - val_loss: 3.6966 - val_accuracy: 0.3498\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5652 - val_loss: 3.6880 - val_accuracy: 0.3516\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5633 - val_loss: 3.6991 - val_accuracy: 0.3540\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5642 - val_loss: 3.6931 - val_accuracy: 0.3534\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2113 - accuracy: 0.5657 - val_loss: 3.6976 - val_accuracy: 0.3498\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.5608 - val_loss: 3.6965 - val_accuracy: 0.3528\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5646 - val_loss: 3.6969 - val_accuracy: 0.3498\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5692 - val_loss: 3.6957 - val_accuracy: 0.3461\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5661 - val_loss: 3.6957 - val_accuracy: 0.3485\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.5698 - val_loss: 3.7025 - val_accuracy: 0.3491\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5671 - val_loss: 3.6973 - val_accuracy: 0.3479\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2185 - accuracy: 0.5652 - val_loss: 3.6983 - val_accuracy: 0.3491\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5661 - val_loss: 3.6993 - val_accuracy: 0.3510\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5652 - val_loss: 3.6970 - val_accuracy: 0.3546\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2141 - accuracy: 0.5616 - val_loss: 3.6996 - val_accuracy: 0.3479\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5684 - val_loss: 3.7024 - val_accuracy: 0.3467\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5658 - val_loss: 3.6964 - val_accuracy: 0.3479\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5651 - val_loss: 3.7074 - val_accuracy: 0.3412\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5642 - val_loss: 3.6992 - val_accuracy: 0.3473\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5616 - val_loss: 3.6942 - val_accuracy: 0.3449\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5652 - val_loss: 3.6914 - val_accuracy: 0.3467\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2054 - accuracy: 0.5678 - val_loss: 3.6986 - val_accuracy: 0.3449\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5652 - val_loss: 3.6962 - val_accuracy: 0.3498\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2122 - accuracy: 0.5660 - val_loss: 3.6928 - val_accuracy: 0.3449\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5646 - val_loss: 3.6921 - val_accuracy: 0.3473\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5671 - val_loss: 3.7034 - val_accuracy: 0.3491\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2097 - accuracy: 0.5637 - val_loss: 3.6974 - val_accuracy: 0.3534\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5646 - val_loss: 3.6978 - val_accuracy: 0.3479\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5665 - val_loss: 3.7045 - val_accuracy: 0.3491\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5657 - val_loss: 3.7042 - val_accuracy: 0.3491\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5643 - val_loss: 3.7056 - val_accuracy: 0.3461\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5646 - val_loss: 3.7001 - val_accuracy: 0.3516\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5640 - val_loss: 3.7068 - val_accuracy: 0.3498\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5643 - val_loss: 3.7069 - val_accuracy: 0.3467\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2096 - accuracy: 0.5674 - val_loss: 3.7116 - val_accuracy: 0.3461\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5639 - val_loss: 3.7017 - val_accuracy: 0.3485\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5646 - val_loss: 3.7017 - val_accuracy: 0.3516\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.5681 - val_loss: 3.7048 - val_accuracy: 0.3498\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2137 - accuracy: 0.5645 - val_loss: 3.6945 - val_accuracy: 0.3461\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5660 - val_loss: 3.7001 - val_accuracy: 0.3449\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2065 - accuracy: 0.5663 - val_loss: 3.7063 - val_accuracy: 0.3516\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2094 - accuracy: 0.5657 - val_loss: 3.6985 - val_accuracy: 0.3516\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5649 - val_loss: 3.6958 - val_accuracy: 0.3504\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5658 - val_loss: 3.7013 - val_accuracy: 0.3516\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5700 - val_loss: 3.6994 - val_accuracy: 0.3516\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.5695 - val_loss: 3.6992 - val_accuracy: 0.3491\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5660 - val_loss: 3.7058 - val_accuracy: 0.3485\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.5666 - val_loss: 3.7020 - val_accuracy: 0.3485\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5648 - val_loss: 3.6974 - val_accuracy: 0.3504\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5672 - val_loss: 3.6929 - val_accuracy: 0.3473\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2176 - accuracy: 0.5636 - val_loss: 3.6981 - val_accuracy: 0.3491\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2135 - accuracy: 0.5666 - val_loss: 3.6918 - val_accuracy: 0.3467\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5663 - val_loss: 3.6909 - val_accuracy: 0.3510\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5648 - val_loss: 3.6983 - val_accuracy: 0.3498\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2093 - accuracy: 0.5678 - val_loss: 3.7073 - val_accuracy: 0.3498\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5628 - val_loss: 3.7034 - val_accuracy: 0.3504\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5689 - val_loss: 3.6946 - val_accuracy: 0.3504\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2117 - accuracy: 0.5710 - val_loss: 3.6923 - val_accuracy: 0.3473\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2060 - accuracy: 0.5651 - val_loss: 3.6977 - val_accuracy: 0.3504\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.5672 - val_loss: 3.7005 - val_accuracy: 0.3516\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5627 - val_loss: 3.6977 - val_accuracy: 0.3522\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.5683 - val_loss: 3.7003 - val_accuracy: 0.3491\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5690 - val_loss: 3.7018 - val_accuracy: 0.3449\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5640 - val_loss: 3.7070 - val_accuracy: 0.3400\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5616 - val_loss: 3.6993 - val_accuracy: 0.3491\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2152 - accuracy: 0.5634 - val_loss: 3.6918 - val_accuracy: 0.3467\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2095 - accuracy: 0.5654 - val_loss: 3.6964 - val_accuracy: 0.3491\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5627 - val_loss: 3.6950 - val_accuracy: 0.3485\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2075 - accuracy: 0.5683 - val_loss: 3.6936 - val_accuracy: 0.3485\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2147 - accuracy: 0.5634 - val_loss: 3.7038 - val_accuracy: 0.3504\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2091 - accuracy: 0.5724 - val_loss: 3.6957 - val_accuracy: 0.3485\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.5668 - val_loss: 3.7032 - val_accuracy: 0.3443\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5684 - val_loss: 3.7016 - val_accuracy: 0.3473\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5651 - val_loss: 3.7004 - val_accuracy: 0.3473\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5658 - val_loss: 3.7051 - val_accuracy: 0.3461\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.5610 - val_loss: 3.6872 - val_accuracy: 0.3485\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2140 - accuracy: 0.5657 - val_loss: 3.7012 - val_accuracy: 0.3479\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2184 - accuracy: 0.5654 - val_loss: 3.6993 - val_accuracy: 0.3479\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2143 - accuracy: 0.5622 - val_loss: 3.6973 - val_accuracy: 0.3467\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5678 - val_loss: 3.6967 - val_accuracy: 0.3516\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2094 - accuracy: 0.5646 - val_loss: 3.6972 - val_accuracy: 0.3479\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2122 - accuracy: 0.5652 - val_loss: 3.7036 - val_accuracy: 0.3491\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2069 - accuracy: 0.5636 - val_loss: 3.7022 - val_accuracy: 0.3516\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.5643 - val_loss: 3.7040 - val_accuracy: 0.3522\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2065 - accuracy: 0.5672 - val_loss: 3.7025 - val_accuracy: 0.3534\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5686 - val_loss: 3.7006 - val_accuracy: 0.3491\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5645 - val_loss: 3.7078 - val_accuracy: 0.3498\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5687 - val_loss: 3.7033 - val_accuracy: 0.3552\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5648 - val_loss: 3.7004 - val_accuracy: 0.3546\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2100 - accuracy: 0.5665 - val_loss: 3.7086 - val_accuracy: 0.3473\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2119 - accuracy: 0.5690 - val_loss: 3.7068 - val_accuracy: 0.3504\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.5645 - val_loss: 3.7024 - val_accuracy: 0.3491\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5684 - val_loss: 3.7039 - val_accuracy: 0.3528\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5645 - val_loss: 3.7084 - val_accuracy: 0.3528\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2096 - accuracy: 0.5649 - val_loss: 3.7110 - val_accuracy: 0.3498\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2043 - accuracy: 0.5681 - val_loss: 3.7141 - val_accuracy: 0.3491\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2149 - accuracy: 0.5645 - val_loss: 3.7103 - val_accuracy: 0.3479\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5675 - val_loss: 3.7076 - val_accuracy: 0.3491\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5669 - val_loss: 3.6969 - val_accuracy: 0.3522\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5649 - val_loss: 3.7000 - val_accuracy: 0.3510\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5628 - val_loss: 3.7115 - val_accuracy: 0.3534\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5639 - val_loss: 3.7031 - val_accuracy: 0.3491\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5696 - val_loss: 3.7002 - val_accuracy: 0.3546\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5706 - val_loss: 3.7013 - val_accuracy: 0.3534\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2103 - accuracy: 0.5666 - val_loss: 3.7048 - val_accuracy: 0.3552\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.5721 - val_loss: 3.7028 - val_accuracy: 0.3546\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5712 - val_loss: 3.7130 - val_accuracy: 0.3540\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2106 - accuracy: 0.5642 - val_loss: 3.7108 - val_accuracy: 0.3516\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2127 - accuracy: 0.5651 - val_loss: 3.7026 - val_accuracy: 0.3546\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2070 - accuracy: 0.5690 - val_loss: 3.7023 - val_accuracy: 0.3552\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.5674 - val_loss: 3.7075 - val_accuracy: 0.3528\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.5655 - val_loss: 3.7049 - val_accuracy: 0.3534\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2090 - accuracy: 0.5678 - val_loss: 3.7080 - val_accuracy: 0.3516\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2121 - accuracy: 0.5730 - val_loss: 3.7109 - val_accuracy: 0.3479\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2091 - accuracy: 0.5663 - val_loss: 3.7043 - val_accuracy: 0.3461\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.5646 - val_loss: 3.7104 - val_accuracy: 0.3534\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2082 - accuracy: 0.5692 - val_loss: 3.7130 - val_accuracy: 0.3485\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2097 - accuracy: 0.5642 - val_loss: 3.7103 - val_accuracy: 0.3510\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5672 - val_loss: 3.7047 - val_accuracy: 0.3510\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.5658 - val_loss: 3.7212 - val_accuracy: 0.3467\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5678 - val_loss: 3.7151 - val_accuracy: 0.3498\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2125 - accuracy: 0.5642 - val_loss: 3.7160 - val_accuracy: 0.3516\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2080 - accuracy: 0.5686 - val_loss: 3.7122 - val_accuracy: 0.3437\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2158 - accuracy: 0.5657 - val_loss: 3.7194 - val_accuracy: 0.3467\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2060 - accuracy: 0.5654 - val_loss: 3.7128 - val_accuracy: 0.3461\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2094 - accuracy: 0.5689 - val_loss: 3.7056 - val_accuracy: 0.3485\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2110 - accuracy: 0.5658 - val_loss: 3.7025 - val_accuracy: 0.3504\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2152 - accuracy: 0.5628 - val_loss: 3.7057 - val_accuracy: 0.3473\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2081 - accuracy: 0.5648 - val_loss: 3.7009 - val_accuracy: 0.3473\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5654 - val_loss: 3.7149 - val_accuracy: 0.3467\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2136 - accuracy: 0.5690 - val_loss: 3.7203 - val_accuracy: 0.3467\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5680 - val_loss: 3.7128 - val_accuracy: 0.3455\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.5665 - val_loss: 3.7109 - val_accuracy: 0.3546\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.5665 - val_loss: 3.7085 - val_accuracy: 0.3546\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2115 - accuracy: 0.5686 - val_loss: 3.7088 - val_accuracy: 0.3510\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2131 - accuracy: 0.5672 - val_loss: 3.7087 - val_accuracy: 0.3498\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2157 - accuracy: 0.5645 - val_loss: 3.7076 - val_accuracy: 0.3528\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2049 - accuracy: 0.5707 - val_loss: 3.7061 - val_accuracy: 0.3498\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.5658 - val_loss: 3.7066 - val_accuracy: 0.3528\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2183 - accuracy: 0.5655 - val_loss: 3.7009 - val_accuracy: 0.3516\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5663 - val_loss: 3.6975 - val_accuracy: 0.3498\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2091 - accuracy: 0.5637 - val_loss: 3.7034 - val_accuracy: 0.3498\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2088 - accuracy: 0.5734 - val_loss: 3.7043 - val_accuracy: 0.3504\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2088 - accuracy: 0.5657 - val_loss: 3.7053 - val_accuracy: 0.3522\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2160 - accuracy: 0.5665 - val_loss: 3.7058 - val_accuracy: 0.3528\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5678 - val_loss: 3.7115 - val_accuracy: 0.3528\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5654 - val_loss: 3.6975 - val_accuracy: 0.3534\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.5622 - val_loss: 3.7040 - val_accuracy: 0.3491\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.5648 - val_loss: 3.6968 - val_accuracy: 0.3540\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2213 - accuracy: 0.5630 - val_loss: 3.6977 - val_accuracy: 0.3510\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.5690 - val_loss: 3.6928 - val_accuracy: 0.3522\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2123 - accuracy: 0.5661 - val_loss: 3.6982 - val_accuracy: 0.3510\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2099 - accuracy: 0.5671 - val_loss: 3.6954 - val_accuracy: 0.3522\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2105 - accuracy: 0.5734 - val_loss: 3.7004 - val_accuracy: 0.3479\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2082 - accuracy: 0.5678 - val_loss: 3.7036 - val_accuracy: 0.3516\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.5672 - val_loss: 3.7047 - val_accuracy: 0.3510\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2102 - accuracy: 0.5672 - val_loss: 3.7056 - val_accuracy: 0.3485\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2155 - accuracy: 0.5669 - val_loss: 3.7052 - val_accuracy: 0.3510\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2095 - accuracy: 0.5690 - val_loss: 3.7045 - val_accuracy: 0.3534\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.5642 - val_loss: 3.7096 - val_accuracy: 0.3516\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5619 - val_loss: 3.7064 - val_accuracy: 0.3528\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2107 - accuracy: 0.5654 - val_loss: 3.7133 - val_accuracy: 0.3540\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2178 - accuracy: 0.5674 - val_loss: 3.7176 - val_accuracy: 0.3491\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.5651 - val_loss: 3.7113 - val_accuracy: 0.3461\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.5669 - val_loss: 3.7084 - val_accuracy: 0.3461\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5668 - val_loss: 3.7077 - val_accuracy: 0.3455\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2117 - accuracy: 0.5655 - val_loss: 3.7066 - val_accuracy: 0.3528\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5642 - val_loss: 3.7073 - val_accuracy: 0.3498\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2126 - accuracy: 0.5700 - val_loss: 3.7134 - val_accuracy: 0.3473\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5636 - val_loss: 3.7221 - val_accuracy: 0.3504\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2120 - accuracy: 0.5680 - val_loss: 3.7221 - val_accuracy: 0.3528\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.2118 - accuracy: 0.5666 - val_loss: 3.7214 - val_accuracy: 0.3522\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.5657 - val_loss: 3.7147 - val_accuracy: 0.3491\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2084 - accuracy: 0.5689 - val_loss: 3.7154 - val_accuracy: 0.3510\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.5704 - val_loss: 3.7179 - val_accuracy: 0.3473\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.2092 - accuracy: 0.5645 - val_loss: 3.7181 - val_accuracy: 0.3461\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 64)\n",
    "history_many_to_many_baseline_64 = many_to_many_baseline_model.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=64, \n",
    "                                              validation_data=(xx_test, yy_test)  # Validation data\n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_baseline_64, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_baseline_model_history_bs64.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_baseline_64.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracies for individual moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.33747044917257685\n",
      "Accuracy for Label barrel_turn: 0.0\n",
      "Accuracy for Label basic_charleston: nan\n",
      "Accuracy for Label basic_closed: 0.28\n",
      "Accuracy for Label basic_open: 0.0\n",
      "Accuracy for Label bounce: nan\n",
      "Accuracy for Label break: 0.037037037037037035\n",
      "Accuracy for Label breakaway: 0.0\n",
      "Accuracy for Label come_back: 0.027777777777777776\n",
      "Accuracy for Label corridor: 0.0\n",
      "Accuracy for Label follow_takes_over: nan\n",
      "Accuracy for Label frankie´s_points: nan\n",
      "Accuracy for Label frankie´s_sixes: 0.046511627906976744\n",
      "Accuracy for Label groove_walk: 0.6363636363636364\n",
      "Accuracy for Label hallelujah_rocks: 0.0\n",
      "Accuracy for Label hand_to_hand: 0.0\n",
      "Accuracy for Label hand_to_hand_charleston: nan\n",
      "Accuracy for Label inside_spin: 0.0\n",
      "Accuracy for Label inside_turn: 0.0\n",
      "Accuracy for Label lindy_circle: 0.0\n",
      "Accuracy for Label mini_dip: nan\n",
      "Accuracy for Label mistake: 0.0\n",
      "Accuracy for Label music_start: nan\n",
      "Accuracy for Label music_stop: 0.0\n",
      "Accuracy for Label one_hand: 0.0\n",
      "Accuracy for Label outside_spin: 0.0\n",
      "Accuracy for Label outside_turn: 0.0\n",
      "Accuracy for Label pass_by: 0.6666666666666666\n",
      "Accuracy for Label pop_turn: nan\n",
      "Accuracy for Label promenade: 0.0\n",
      "Accuracy for Label redirection: 0.0\n",
      "Accuracy for Label rock_step: 0.0\n",
      "Accuracy for Label s_turn: 0.0\n",
      "Accuracy for Label sailor_kicks: 0.0\n",
      "Accuracy for Label send_out: 0.0\n",
      "Accuracy for Label sling_shot: 0.0\n",
      "Accuracy for Label sugar_push: 0.3283582089552239\n",
      "Accuracy for Label sweetheart: 0.02631578947368421\n",
      "Accuracy for Label swingout: 0.17880794701986755\n",
      "Accuracy for Label switches: 0.0\n",
      "Accuracy for Label tandem: 0.0\n",
      "Accuracy for Label texas_tommy: nan\n",
      "Accuracy for Label tuck_turn: 0.42857142857142855\n",
      "Accuracy for Label underarm_pass_by: nan\n",
      "Accuracy for Label unknown: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Predict labels on the test data\n",
    "predictions = many_to_many_model.predict(xx_test)\n",
    "\n",
    "# Convert one-hot encoded predictions to single labels using TensorFlow's argmax\n",
    "predicted_labels_encoded = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Flatten the arrays for label-wise accuracy calculation\n",
    "predicted_labels_encoded = predicted_labels_encoded.flatten()\n",
    "\n",
    "# Convert one-hot encoded true labels to single labels using TensorFlow's argmax\n",
    "true_labels_encoded = tf.argmax(yy_test, axis=-1).numpy().flatten()\n",
    "\n",
    "# Map predicted labels to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "# Map true labels to original labels\n",
    "true_labels = label_encoder.inverse_transform(true_labels_encoded)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Display label-wise accuracy\n",
    "unique_labels = label_encoder.classes_\n",
    "for label in unique_labels:\n",
    "    label_indices = true_labels == label\n",
    "    label_accuracy = accuracy_score(true_labels[label_indices], predicted_labels[label_indices])\n",
    "    print(f'Accuracy for Label {label}: {label_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Predict classes on the test set\n",
    "yy_pred = many_to_many_model.predict(xx_test)\n",
    "\n",
    "# Convert predictions from one-hot encoded back to label indices\n",
    "yy_pred_classes = np.argmax(yy_pred, axis=-1)\n",
    "yy_true_classes = np.argmax(yy_test, axis=-1)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(yy_true_classes.flatten(), yy_pred_classes.flatten())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "class_report = classification_report(yy_true_classes.flatten(), yy_pred_classes.flatten())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(15, 15))  # Figure size\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "ax = sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                 annot_kws={\"size\": 8})  # Adjust annotation font size\n",
    "\n",
    "# Rotating labels for better readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)  # Rotate the x labels and set their alignment\n",
    "plt.yticks(fontsize=10)  # Set y labels font size\n",
    "plt.xlabel('Predicted labels', fontsize=12)\n",
    "plt.ylabel('True labels', fontsize=12)\n",
    "plt.title('Normalized Confusion Matrix', fontsize=15)\n",
    "\n",
    "# Adding a colorbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=10)  # Set colorbar label size\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class-wise Accuracy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           2       0.45      0.15      0.22       150\n",
      "           3       0.00      0.00      0.00        20\n",
      "           5       0.03      0.01      0.02        81\n",
      "           6       0.00      0.00      0.00        12\n",
      "           7       0.03      0.03      0.03        72\n",
      "           8       0.00      0.00      0.00        12\n",
      "          11       0.14      0.05      0.07        43\n",
      "          12       0.58      0.64      0.61        11\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00        36\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         4\n",
      "          22       0.50      0.12      0.20         8\n",
      "          23       0.00      0.00      0.00        18\n",
      "          24       0.00      0.00      0.00        36\n",
      "          25       0.00      0.00      0.00        24\n",
      "          26       0.47      0.68      0.55       639\n",
      "          28       0.00      0.00      0.00        12\n",
      "          29       0.00      0.00      0.00        42\n",
      "          30       0.25      0.06      0.09        18\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         4\n",
      "          33       0.04      0.08      0.05        12\n",
      "          34       0.00      0.00      0.00         8\n",
      "          35       0.61      0.33      0.43        67\n",
      "          36       0.23      0.08      0.12        38\n",
      "          37       0.20      0.21      0.20       151\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.26      0.52      0.35        91\n",
      "          43       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.34      1692\n",
      "   macro avg       0.11      0.08      0.08      1692\n",
      "weighted avg       0.29      0.34      0.29      1692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass-wise Accuracy:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex Many-to-Many LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 4, 64)             24832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4, 64)             2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 41,440\n",
      "Trainable params: 41,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "import random\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set a new random seed\n",
    "new_seed = 75\n",
    "tf.random.set_seed(new_seed)\n",
    "np.random.seed(new_seed)\n",
    "random.seed(new_seed)\n",
    "\n",
    "# Define a more complex LSTM model\n",
    "many_to_many_model_complex = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(4, 32)), \n",
    "    Dropout(0.4),\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    Dense(32, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the simplified model\n",
    "many_to_many_model_complex.compile(optimizer='adam', \n",
    "                         loss='categorical_crossentropy', \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Summary of the simplified model\n",
    "many_to_many_model_complex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "103/103 [==============================] - 4s 13ms/step - loss: 3.2186 - accuracy: 0.2891 - val_loss: 2.5690 - val_accuracy: 0.3954\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4771 - accuracy: 0.3171 - val_loss: 2.4113 - val_accuracy: 0.4002\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3292 - accuracy: 0.3345 - val_loss: 2.2602 - val_accuracy: 0.4294\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.1254 - accuracy: 0.3853 - val_loss: 2.2024 - val_accuracy: 0.4294\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 2.0420 - accuracy: 0.4024 - val_loss: 2.1823 - val_accuracy: 0.4446\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 2.0594 - accuracy: 0.3952 - val_loss: 2.2077 - val_accuracy: 0.4373\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0062 - accuracy: 0.4076 - val_loss: 2.1852 - val_accuracy: 0.4422\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9712 - accuracy: 0.4157 - val_loss: 2.1938 - val_accuracy: 0.4416\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.9703 - accuracy: 0.4201 - val_loss: 2.2026 - val_accuracy: 0.4319\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.9645 - accuracy: 0.4213 - val_loss: 2.2099 - val_accuracy: 0.4380\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9440 - accuracy: 0.4268 - val_loss: 2.2043 - val_accuracy: 0.4471\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.9663 - accuracy: 0.4235 - val_loss: 2.2115 - val_accuracy: 0.4428\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9464 - accuracy: 0.4290 - val_loss: 2.2056 - val_accuracy: 0.4495\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9487 - accuracy: 0.4226 - val_loss: 2.2231 - val_accuracy: 0.4483\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9290 - accuracy: 0.4295 - val_loss: 2.2113 - val_accuracy: 0.4495\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.9104 - accuracy: 0.4302 - val_loss: 2.2348 - val_accuracy: 0.4440\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9197 - accuracy: 0.4258 - val_loss: 2.2108 - val_accuracy: 0.4392\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9119 - accuracy: 0.4386 - val_loss: 2.2153 - val_accuracy: 0.4392\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8940 - accuracy: 0.4329 - val_loss: 2.2182 - val_accuracy: 0.4507\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8768 - accuracy: 0.4353 - val_loss: 2.2340 - val_accuracy: 0.4392\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8754 - accuracy: 0.4366 - val_loss: 2.2316 - val_accuracy: 0.4319\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8764 - accuracy: 0.4333 - val_loss: 2.2117 - val_accuracy: 0.4325\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8743 - accuracy: 0.4339 - val_loss: 2.2521 - val_accuracy: 0.4331\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8737 - accuracy: 0.4382 - val_loss: 2.2293 - val_accuracy: 0.4404\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8464 - accuracy: 0.4317 - val_loss: 2.2305 - val_accuracy: 0.4313\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8309 - accuracy: 0.4360 - val_loss: 2.2278 - val_accuracy: 0.4331\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8519 - accuracy: 0.4312 - val_loss: 2.2327 - val_accuracy: 0.4325\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8416 - accuracy: 0.4330 - val_loss: 2.2301 - val_accuracy: 0.4331\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8175 - accuracy: 0.4513 - val_loss: 2.2412 - val_accuracy: 0.4282\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8478 - accuracy: 0.4345 - val_loss: 2.2451 - val_accuracy: 0.4300\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8256 - accuracy: 0.4365 - val_loss: 2.2606 - val_accuracy: 0.4276\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8193 - accuracy: 0.4492 - val_loss: 2.2791 - val_accuracy: 0.4155\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8305 - accuracy: 0.4320 - val_loss: 2.2744 - val_accuracy: 0.4009\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8153 - accuracy: 0.4327 - val_loss: 2.2603 - val_accuracy: 0.4313\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8054 - accuracy: 0.4450 - val_loss: 2.2408 - val_accuracy: 0.4337\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8125 - accuracy: 0.4448 - val_loss: 2.2670 - val_accuracy: 0.4234\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8132 - accuracy: 0.4477 - val_loss: 2.2869 - val_accuracy: 0.4142\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7910 - accuracy: 0.4450 - val_loss: 2.2721 - val_accuracy: 0.4221\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7709 - accuracy: 0.4500 - val_loss: 2.2916 - val_accuracy: 0.4088\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8047 - accuracy: 0.4384 - val_loss: 2.2938 - val_accuracy: 0.4185\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7776 - accuracy: 0.4561 - val_loss: 2.2822 - val_accuracy: 0.4246\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7661 - accuracy: 0.4534 - val_loss: 2.2976 - val_accuracy: 0.4124\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7821 - accuracy: 0.4535 - val_loss: 2.3028 - val_accuracy: 0.4209\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7774 - accuracy: 0.4484 - val_loss: 2.3095 - val_accuracy: 0.4118\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7602 - accuracy: 0.4544 - val_loss: 2.2999 - val_accuracy: 0.4142\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7812 - accuracy: 0.4438 - val_loss: 2.3390 - val_accuracy: 0.4051\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7635 - accuracy: 0.4559 - val_loss: 2.3215 - val_accuracy: 0.4002\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7472 - accuracy: 0.4556 - val_loss: 2.3190 - val_accuracy: 0.4161\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7313 - accuracy: 0.4639 - val_loss: 2.3326 - val_accuracy: 0.4106\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7469 - accuracy: 0.4530 - val_loss: 2.3275 - val_accuracy: 0.4027\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7601 - accuracy: 0.4536 - val_loss: 2.3460 - val_accuracy: 0.4033\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7425 - accuracy: 0.4643 - val_loss: 2.3478 - val_accuracy: 0.3990\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7466 - accuracy: 0.4626 - val_loss: 2.3610 - val_accuracy: 0.3948\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7542 - accuracy: 0.4531 - val_loss: 2.3433 - val_accuracy: 0.4088\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7418 - accuracy: 0.4588 - val_loss: 2.3659 - val_accuracy: 0.4082\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7373 - accuracy: 0.4646 - val_loss: 2.4004 - val_accuracy: 0.4002\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7243 - accuracy: 0.4616 - val_loss: 2.3733 - val_accuracy: 0.4130\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7278 - accuracy: 0.4510 - val_loss: 2.3854 - val_accuracy: 0.4069\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7186 - accuracy: 0.4636 - val_loss: 2.3717 - val_accuracy: 0.4148\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7129 - accuracy: 0.4648 - val_loss: 2.4046 - val_accuracy: 0.3966\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7381 - accuracy: 0.4551 - val_loss: 2.4267 - val_accuracy: 0.3978\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7338 - accuracy: 0.4523 - val_loss: 2.3792 - val_accuracy: 0.4045\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7193 - accuracy: 0.4604 - val_loss: 2.3682 - val_accuracy: 0.4094\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7034 - accuracy: 0.4722 - val_loss: 2.3800 - val_accuracy: 0.4075\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7444 - accuracy: 0.4473 - val_loss: 2.3716 - val_accuracy: 0.4142\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7092 - accuracy: 0.4639 - val_loss: 2.4111 - val_accuracy: 0.4027\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7135 - accuracy: 0.4615 - val_loss: 2.3906 - val_accuracy: 0.4094\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7015 - accuracy: 0.4579 - val_loss: 2.4170 - val_accuracy: 0.4082\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6938 - accuracy: 0.4684 - val_loss: 2.4205 - val_accuracy: 0.4021\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6662 - accuracy: 0.4748 - val_loss: 2.4084 - val_accuracy: 0.4015\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6852 - accuracy: 0.4703 - val_loss: 2.4111 - val_accuracy: 0.4045\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6868 - accuracy: 0.4598 - val_loss: 2.4084 - val_accuracy: 0.4069\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6724 - accuracy: 0.4683 - val_loss: 2.4082 - val_accuracy: 0.4045\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6982 - accuracy: 0.4673 - val_loss: 2.4331 - val_accuracy: 0.3978\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7102 - accuracy: 0.4589 - val_loss: 2.4565 - val_accuracy: 0.3881\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6843 - accuracy: 0.4676 - val_loss: 2.4324 - val_accuracy: 0.3936\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6708 - accuracy: 0.4745 - val_loss: 2.4490 - val_accuracy: 0.3960\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6984 - accuracy: 0.4577 - val_loss: 2.4695 - val_accuracy: 0.3923\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6642 - accuracy: 0.4695 - val_loss: 2.4555 - val_accuracy: 0.3911\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6577 - accuracy: 0.4742 - val_loss: 2.4581 - val_accuracy: 0.4045\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6523 - accuracy: 0.4747 - val_loss: 2.4885 - val_accuracy: 0.3954\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6931 - accuracy: 0.4615 - val_loss: 2.4955 - val_accuracy: 0.3917\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6518 - accuracy: 0.4775 - val_loss: 2.4856 - val_accuracy: 0.3911\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6798 - accuracy: 0.4679 - val_loss: 2.4868 - val_accuracy: 0.3954\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6645 - accuracy: 0.4726 - val_loss: 2.4996 - val_accuracy: 0.3966\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6711 - accuracy: 0.4696 - val_loss: 2.4810 - val_accuracy: 0.3948\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6588 - accuracy: 0.4780 - val_loss: 2.4896 - val_accuracy: 0.4069\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6822 - accuracy: 0.4674 - val_loss: 2.4772 - val_accuracy: 0.4063\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6615 - accuracy: 0.4771 - val_loss: 2.4899 - val_accuracy: 0.4027\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6628 - accuracy: 0.4742 - val_loss: 2.4788 - val_accuracy: 0.4039\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6634 - accuracy: 0.4704 - val_loss: 2.5167 - val_accuracy: 0.3911\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6573 - accuracy: 0.4701 - val_loss: 2.4996 - val_accuracy: 0.4069\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6363 - accuracy: 0.4786 - val_loss: 2.5176 - val_accuracy: 0.3844\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6713 - accuracy: 0.4722 - val_loss: 2.5264 - val_accuracy: 0.3948\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6343 - accuracy: 0.4847 - val_loss: 2.5093 - val_accuracy: 0.3984\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6398 - accuracy: 0.4741 - val_loss: 2.5176 - val_accuracy: 0.3875\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6284 - accuracy: 0.4825 - val_loss: 2.5248 - val_accuracy: 0.3929\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6252 - accuracy: 0.4867 - val_loss: 2.5069 - val_accuracy: 0.3899\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6412 - accuracy: 0.4818 - val_loss: 2.5113 - val_accuracy: 0.3984\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6492 - accuracy: 0.4742 - val_loss: 2.5169 - val_accuracy: 0.4039\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6235 - accuracy: 0.4742 - val_loss: 2.5379 - val_accuracy: 0.3905\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6372 - accuracy: 0.4687 - val_loss: 2.5459 - val_accuracy: 0.3881\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6301 - accuracy: 0.4846 - val_loss: 2.5398 - val_accuracy: 0.3948\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6389 - accuracy: 0.4776 - val_loss: 2.5558 - val_accuracy: 0.3911\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6210 - accuracy: 0.4776 - val_loss: 2.5463 - val_accuracy: 0.3929\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6352 - accuracy: 0.4806 - val_loss: 2.5632 - val_accuracy: 0.3948\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6239 - accuracy: 0.4749 - val_loss: 2.5451 - val_accuracy: 0.3966\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6368 - accuracy: 0.4846 - val_loss: 2.5218 - val_accuracy: 0.4063\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6308 - accuracy: 0.4846 - val_loss: 2.5631 - val_accuracy: 0.3929\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6305 - accuracy: 0.4823 - val_loss: 2.5735 - val_accuracy: 0.3911\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6557 - accuracy: 0.4679 - val_loss: 2.5519 - val_accuracy: 0.3887\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6274 - accuracy: 0.4805 - val_loss: 2.5717 - val_accuracy: 0.3887\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6322 - accuracy: 0.4782 - val_loss: 2.5770 - val_accuracy: 0.3923\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5890 - accuracy: 0.4942 - val_loss: 2.5804 - val_accuracy: 0.3717\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6209 - accuracy: 0.4814 - val_loss: 2.5972 - val_accuracy: 0.3790\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6201 - accuracy: 0.4831 - val_loss: 2.5881 - val_accuracy: 0.3747\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6362 - accuracy: 0.4682 - val_loss: 2.5904 - val_accuracy: 0.3844\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6151 - accuracy: 0.4829 - val_loss: 2.6112 - val_accuracy: 0.3753\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6265 - accuracy: 0.4921 - val_loss: 2.5743 - val_accuracy: 0.3917\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6163 - accuracy: 0.4869 - val_loss: 2.5735 - val_accuracy: 0.3820\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6026 - accuracy: 0.4901 - val_loss: 2.6058 - val_accuracy: 0.3832\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6007 - accuracy: 0.4960 - val_loss: 2.6001 - val_accuracy: 0.3753\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6006 - accuracy: 0.4850 - val_loss: 2.6027 - val_accuracy: 0.3844\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6120 - accuracy: 0.4690 - val_loss: 2.6009 - val_accuracy: 0.3777\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6129 - accuracy: 0.4924 - val_loss: 2.6197 - val_accuracy: 0.3844\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6166 - accuracy: 0.4878 - val_loss: 2.5852 - val_accuracy: 0.3893\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6060 - accuracy: 0.4856 - val_loss: 2.6077 - val_accuracy: 0.3826\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6061 - accuracy: 0.4896 - val_loss: 2.6192 - val_accuracy: 0.3765\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5913 - accuracy: 0.4909 - val_loss: 2.6302 - val_accuracy: 0.3735\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6013 - accuracy: 0.4816 - val_loss: 2.6235 - val_accuracy: 0.3790\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6154 - accuracy: 0.4836 - val_loss: 2.6262 - val_accuracy: 0.3863\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6119 - accuracy: 0.4745 - val_loss: 2.6229 - val_accuracy: 0.3723\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6196 - accuracy: 0.4833 - val_loss: 2.6131 - val_accuracy: 0.3729\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5899 - accuracy: 0.4904 - val_loss: 2.6310 - val_accuracy: 0.3729\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5672 - accuracy: 0.4931 - val_loss: 2.6167 - val_accuracy: 0.3759\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5996 - accuracy: 0.4973 - val_loss: 2.6241 - val_accuracy: 0.3710\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6058 - accuracy: 0.4922 - val_loss: 2.6277 - val_accuracy: 0.3832\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5979 - accuracy: 0.4861 - val_loss: 2.6277 - val_accuracy: 0.3704\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5858 - accuracy: 0.4959 - val_loss: 2.6132 - val_accuracy: 0.3911\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5748 - accuracy: 0.5031 - val_loss: 2.6523 - val_accuracy: 0.3771\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5883 - accuracy: 0.4893 - val_loss: 2.6402 - val_accuracy: 0.3741\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6100 - accuracy: 0.4860 - val_loss: 2.6451 - val_accuracy: 0.3759\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5815 - accuracy: 0.4949 - val_loss: 2.5957 - val_accuracy: 0.3911\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5737 - accuracy: 0.4875 - val_loss: 2.6485 - val_accuracy: 0.3729\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6022 - accuracy: 0.4929 - val_loss: 2.6559 - val_accuracy: 0.3729\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5829 - accuracy: 0.4893 - val_loss: 2.6328 - val_accuracy: 0.3783\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5941 - accuracy: 0.4935 - val_loss: 2.6512 - val_accuracy: 0.3765\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5734 - accuracy: 0.5000 - val_loss: 2.6258 - val_accuracy: 0.3808\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5855 - accuracy: 0.4917 - val_loss: 2.6782 - val_accuracy: 0.3723\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5949 - accuracy: 0.4947 - val_loss: 2.6579 - val_accuracy: 0.3790\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5829 - accuracy: 0.4932 - val_loss: 2.6804 - val_accuracy: 0.3704\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5937 - accuracy: 0.4915 - val_loss: 2.6952 - val_accuracy: 0.3704\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5570 - accuracy: 0.4987 - val_loss: 2.6643 - val_accuracy: 0.3650\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5746 - accuracy: 0.4886 - val_loss: 2.6521 - val_accuracy: 0.3765\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5814 - accuracy: 0.4884 - val_loss: 2.7068 - val_accuracy: 0.3747\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5559 - accuracy: 0.5067 - val_loss: 2.6972 - val_accuracy: 0.3759\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5614 - accuracy: 0.5051 - val_loss: 2.6657 - val_accuracy: 0.3783\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5560 - accuracy: 0.5119 - val_loss: 2.6880 - val_accuracy: 0.3735\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5710 - accuracy: 0.4873 - val_loss: 2.6865 - val_accuracy: 0.3735\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5399 - accuracy: 0.5038 - val_loss: 2.7163 - val_accuracy: 0.3704\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5685 - accuracy: 0.4927 - val_loss: 2.6758 - val_accuracy: 0.3796\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5535 - accuracy: 0.5050 - val_loss: 2.6724 - val_accuracy: 0.3747\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5853 - accuracy: 0.4896 - val_loss: 2.6472 - val_accuracy: 0.3820\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5654 - accuracy: 0.4883 - val_loss: 2.6803 - val_accuracy: 0.3802\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5485 - accuracy: 0.5130 - val_loss: 2.7013 - val_accuracy: 0.3747\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5732 - accuracy: 0.4908 - val_loss: 2.6852 - val_accuracy: 0.3881\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5816 - accuracy: 0.4989 - val_loss: 2.7440 - val_accuracy: 0.3741\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5711 - accuracy: 0.4891 - val_loss: 2.6989 - val_accuracy: 0.3777\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5457 - accuracy: 0.5012 - val_loss: 2.7230 - val_accuracy: 0.3656\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5816 - accuracy: 0.4875 - val_loss: 2.7366 - val_accuracy: 0.3704\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5466 - accuracy: 0.5052 - val_loss: 2.6875 - val_accuracy: 0.3741\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5533 - accuracy: 0.4995 - val_loss: 2.7333 - val_accuracy: 0.3680\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5660 - accuracy: 0.5148 - val_loss: 2.7604 - val_accuracy: 0.3710\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5758 - accuracy: 0.4901 - val_loss: 2.7260 - val_accuracy: 0.3735\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5537 - accuracy: 0.5111 - val_loss: 2.7221 - val_accuracy: 0.3686\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5504 - accuracy: 0.5005 - val_loss: 2.7029 - val_accuracy: 0.3814\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5749 - accuracy: 0.4980 - val_loss: 2.7447 - val_accuracy: 0.3668\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5374 - accuracy: 0.5008 - val_loss: 2.7273 - val_accuracy: 0.3704\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5592 - accuracy: 0.4975 - val_loss: 2.7261 - val_accuracy: 0.3783\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5583 - accuracy: 0.5075 - val_loss: 2.7467 - val_accuracy: 0.3753\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5577 - accuracy: 0.4917 - val_loss: 2.7396 - val_accuracy: 0.3777\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.5340 - accuracy: 0.5138 - val_loss: 2.7043 - val_accuracy: 0.3759\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5339 - accuracy: 0.5161 - val_loss: 2.7379 - val_accuracy: 0.3771\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5760 - accuracy: 0.4907 - val_loss: 2.7362 - val_accuracy: 0.3808\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5632 - accuracy: 0.4948 - val_loss: 2.7443 - val_accuracy: 0.3723\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5737 - accuracy: 0.4978 - val_loss: 2.7324 - val_accuracy: 0.3656\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5638 - accuracy: 0.5041 - val_loss: 2.7534 - val_accuracy: 0.3680\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5548 - accuracy: 0.4959 - val_loss: 2.7467 - val_accuracy: 0.3668\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5438 - accuracy: 0.4998 - val_loss: 2.7573 - val_accuracy: 0.3704\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5381 - accuracy: 0.5011 - val_loss: 2.7647 - val_accuracy: 0.3662\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5482 - accuracy: 0.5044 - val_loss: 2.7368 - val_accuracy: 0.3656\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5666 - accuracy: 0.5050 - val_loss: 2.7517 - val_accuracy: 0.3717\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5277 - accuracy: 0.5111 - val_loss: 2.7531 - val_accuracy: 0.3674\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5768 - accuracy: 0.4907 - val_loss: 2.7944 - val_accuracy: 0.3686\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5278 - accuracy: 0.5158 - val_loss: 2.7403 - val_accuracy: 0.3637\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5405 - accuracy: 0.5018 - val_loss: 2.7317 - val_accuracy: 0.3850\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5459 - accuracy: 0.5023 - val_loss: 2.7737 - val_accuracy: 0.3747\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5573 - accuracy: 0.4999 - val_loss: 2.7587 - val_accuracy: 0.3735\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5469 - accuracy: 0.4959 - val_loss: 2.7459 - val_accuracy: 0.3717\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5399 - accuracy: 0.5059 - val_loss: 2.7570 - val_accuracy: 0.3704\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5277 - accuracy: 0.5103 - val_loss: 2.7366 - val_accuracy: 0.3808\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5477 - accuracy: 0.4985 - val_loss: 2.7519 - val_accuracy: 0.3698\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5632 - accuracy: 0.4982 - val_loss: 2.7607 - val_accuracy: 0.3777\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5360 - accuracy: 0.5052 - val_loss: 2.7887 - val_accuracy: 0.3698\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5404 - accuracy: 0.5068 - val_loss: 2.7717 - val_accuracy: 0.3783\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5248 - accuracy: 0.5053 - val_loss: 2.7996 - val_accuracy: 0.3735\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5471 - accuracy: 0.5038 - val_loss: 2.8123 - val_accuracy: 0.3662\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5451 - accuracy: 0.5024 - val_loss: 2.8067 - val_accuracy: 0.3704\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5348 - accuracy: 0.5044 - val_loss: 2.7880 - val_accuracy: 0.3735\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5366 - accuracy: 0.5054 - val_loss: 2.7823 - val_accuracy: 0.3765\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5262 - accuracy: 0.5117 - val_loss: 2.7966 - val_accuracy: 0.3710\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5305 - accuracy: 0.4992 - val_loss: 2.7978 - val_accuracy: 0.3704\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5303 - accuracy: 0.5080 - val_loss: 2.8223 - val_accuracy: 0.3717\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5382 - accuracy: 0.4972 - val_loss: 2.8031 - val_accuracy: 0.3790\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5152 - accuracy: 0.5211 - val_loss: 2.7977 - val_accuracy: 0.3674\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5251 - accuracy: 0.5154 - val_loss: 2.7990 - val_accuracy: 0.3729\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5118 - accuracy: 0.5154 - val_loss: 2.8324 - val_accuracy: 0.3808\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5265 - accuracy: 0.5128 - val_loss: 2.8317 - val_accuracy: 0.3735\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5376 - accuracy: 0.5061 - val_loss: 2.8166 - val_accuracy: 0.3717\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5400 - accuracy: 0.5069 - val_loss: 2.8427 - val_accuracy: 0.3680\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5403 - accuracy: 0.4981 - val_loss: 2.7900 - val_accuracy: 0.3850\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5392 - accuracy: 0.5094 - val_loss: 2.8318 - val_accuracy: 0.3698\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5351 - accuracy: 0.5065 - val_loss: 2.8301 - val_accuracy: 0.3656\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5270 - accuracy: 0.5018 - val_loss: 2.8103 - val_accuracy: 0.3692\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5221 - accuracy: 0.5108 - val_loss: 2.8117 - val_accuracy: 0.3625\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5222 - accuracy: 0.5174 - val_loss: 2.8328 - val_accuracy: 0.3704\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5452 - accuracy: 0.5079 - val_loss: 2.8421 - val_accuracy: 0.3710\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5224 - accuracy: 0.5162 - val_loss: 2.8205 - val_accuracy: 0.3796\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5317 - accuracy: 0.5067 - val_loss: 2.8617 - val_accuracy: 0.3607\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5137 - accuracy: 0.5139 - val_loss: 2.8434 - val_accuracy: 0.3674\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5192 - accuracy: 0.5094 - val_loss: 2.7915 - val_accuracy: 0.3796\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5151 - accuracy: 0.5093 - val_loss: 2.7904 - val_accuracy: 0.3710\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5238 - accuracy: 0.5086 - val_loss: 2.8374 - val_accuracy: 0.3717\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5324 - accuracy: 0.5038 - val_loss: 2.8581 - val_accuracy: 0.3717\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5374 - accuracy: 0.5023 - val_loss: 2.8561 - val_accuracy: 0.3704\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5123 - accuracy: 0.5131 - val_loss: 2.8195 - val_accuracy: 0.3607\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5268 - accuracy: 0.5017 - val_loss: 2.8773 - val_accuracy: 0.3637\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5239 - accuracy: 0.5084 - val_loss: 2.8549 - val_accuracy: 0.3656\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5223 - accuracy: 0.5000 - val_loss: 2.8533 - val_accuracy: 0.3637\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5258 - accuracy: 0.5120 - val_loss: 2.8823 - val_accuracy: 0.3552\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5173 - accuracy: 0.5109 - val_loss: 2.8476 - val_accuracy: 0.3704\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5424 - accuracy: 0.5002 - val_loss: 2.8297 - val_accuracy: 0.3674\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5075 - accuracy: 0.5118 - val_loss: 2.8475 - val_accuracy: 0.3656\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4933 - accuracy: 0.5188 - val_loss: 2.8247 - val_accuracy: 0.3765\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5341 - accuracy: 0.5043 - val_loss: 2.8769 - val_accuracy: 0.3631\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5116 - accuracy: 0.5205 - val_loss: 2.8458 - val_accuracy: 0.3710\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5024 - accuracy: 0.5134 - val_loss: 2.8637 - val_accuracy: 0.3717\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4980 - accuracy: 0.5200 - val_loss: 2.8630 - val_accuracy: 0.3686\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5135 - accuracy: 0.5109 - val_loss: 2.8759 - val_accuracy: 0.3601\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5088 - accuracy: 0.5179 - val_loss: 2.8738 - val_accuracy: 0.3674\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5196 - accuracy: 0.5097 - val_loss: 2.8666 - val_accuracy: 0.3753\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5107 - accuracy: 0.5175 - val_loss: 2.8689 - val_accuracy: 0.3723\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5350 - accuracy: 0.5090 - val_loss: 2.8549 - val_accuracy: 0.3698\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5375 - accuracy: 0.5065 - val_loss: 2.8822 - val_accuracy: 0.3753\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5090 - accuracy: 0.5091 - val_loss: 2.8551 - val_accuracy: 0.3771\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5147 - accuracy: 0.5066 - val_loss: 2.8687 - val_accuracy: 0.3741\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5007 - accuracy: 0.5177 - val_loss: 2.8574 - val_accuracy: 0.3613\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5144 - accuracy: 0.5067 - val_loss: 2.8679 - val_accuracy: 0.3729\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5066 - accuracy: 0.5112 - val_loss: 2.8374 - val_accuracy: 0.3771\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5063 - accuracy: 0.5129 - val_loss: 2.8636 - val_accuracy: 0.3625\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5271 - accuracy: 0.5047 - val_loss: 2.8921 - val_accuracy: 0.3668\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5162 - accuracy: 0.5136 - val_loss: 2.8856 - val_accuracy: 0.3674\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5116 - accuracy: 0.5128 - val_loss: 2.8823 - val_accuracy: 0.3686\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5146 - accuracy: 0.5107 - val_loss: 2.8703 - val_accuracy: 0.3765\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5148 - accuracy: 0.5089 - val_loss: 2.9180 - val_accuracy: 0.3680\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4904 - accuracy: 0.5194 - val_loss: 2.8737 - val_accuracy: 0.3692\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5113 - accuracy: 0.5062 - val_loss: 2.9071 - val_accuracy: 0.3613\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5022 - accuracy: 0.5124 - val_loss: 2.8908 - val_accuracy: 0.3729\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5053 - accuracy: 0.5118 - val_loss: 2.8993 - val_accuracy: 0.3668\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5172 - accuracy: 0.5175 - val_loss: 2.9158 - val_accuracy: 0.3601\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5036 - accuracy: 0.5173 - val_loss: 2.9213 - val_accuracy: 0.3613\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4805 - accuracy: 0.5090 - val_loss: 2.8647 - val_accuracy: 0.3650\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5048 - accuracy: 0.5081 - val_loss: 2.8697 - val_accuracy: 0.3710\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5028 - accuracy: 0.5162 - val_loss: 2.8665 - val_accuracy: 0.3686\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5185 - accuracy: 0.5073 - val_loss: 2.8579 - val_accuracy: 0.3656\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5090 - accuracy: 0.5135 - val_loss: 2.9095 - val_accuracy: 0.3680\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5046 - accuracy: 0.5188 - val_loss: 2.9010 - val_accuracy: 0.3723\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5196 - accuracy: 0.5043 - val_loss: 2.9126 - val_accuracy: 0.3698\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5118 - accuracy: 0.5062 - val_loss: 2.9133 - val_accuracy: 0.3656\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4956 - accuracy: 0.5203 - val_loss: 2.8794 - val_accuracy: 0.3729\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5035 - accuracy: 0.5092 - val_loss: 2.8595 - val_accuracy: 0.3796\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5060 - accuracy: 0.5155 - val_loss: 2.9235 - val_accuracy: 0.3680\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5048 - accuracy: 0.5181 - val_loss: 2.9154 - val_accuracy: 0.3644\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4969 - accuracy: 0.5156 - val_loss: 2.9358 - val_accuracy: 0.3698\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4844 - accuracy: 0.5254 - val_loss: 2.9776 - val_accuracy: 0.3571\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5144 - accuracy: 0.5131 - val_loss: 2.8987 - val_accuracy: 0.3601\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5012 - accuracy: 0.5158 - val_loss: 2.9213 - val_accuracy: 0.3765\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4815 - accuracy: 0.5165 - val_loss: 2.9414 - val_accuracy: 0.3698\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5196 - accuracy: 0.5047 - val_loss: 2.9219 - val_accuracy: 0.3814\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4913 - accuracy: 0.5146 - val_loss: 2.9194 - val_accuracy: 0.3759\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4868 - accuracy: 0.5135 - val_loss: 2.9705 - val_accuracy: 0.3583\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.4951 - accuracy: 0.5259 - val_loss: 2.9681 - val_accuracy: 0.3656\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4839 - accuracy: 0.5181 - val_loss: 2.9542 - val_accuracy: 0.3717\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5029 - accuracy: 0.5188 - val_loss: 2.9255 - val_accuracy: 0.3601\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4766 - accuracy: 0.5234 - val_loss: 2.9193 - val_accuracy: 0.3704\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4842 - accuracy: 0.5181 - val_loss: 2.9317 - val_accuracy: 0.3680\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5182 - accuracy: 0.5047 - val_loss: 2.9162 - val_accuracy: 0.3729\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5086 - accuracy: 0.5109 - val_loss: 2.9269 - val_accuracy: 0.3692\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4954 - accuracy: 0.5152 - val_loss: 2.9029 - val_accuracy: 0.3668\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5001 - accuracy: 0.5123 - val_loss: 2.9287 - val_accuracy: 0.3753\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5111 - accuracy: 0.5070 - val_loss: 2.9455 - val_accuracy: 0.3741\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4915 - accuracy: 0.5186 - val_loss: 2.9410 - val_accuracy: 0.3680\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4854 - accuracy: 0.5252 - val_loss: 2.9720 - val_accuracy: 0.3680\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4858 - accuracy: 0.5141 - val_loss: 2.9183 - val_accuracy: 0.3771\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4813 - accuracy: 0.5178 - val_loss: 2.9269 - val_accuracy: 0.3631\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4770 - accuracy: 0.5139 - val_loss: 2.9325 - val_accuracy: 0.3729\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4733 - accuracy: 0.5184 - val_loss: 2.9565 - val_accuracy: 0.3747\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5104 - accuracy: 0.5152 - val_loss: 2.9080 - val_accuracy: 0.3777\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4977 - accuracy: 0.5188 - val_loss: 2.9030 - val_accuracy: 0.3735\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5005 - accuracy: 0.5097 - val_loss: 2.9549 - val_accuracy: 0.3631\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4668 - accuracy: 0.5199 - val_loss: 2.9350 - val_accuracy: 0.3783\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4839 - accuracy: 0.5240 - val_loss: 2.9496 - val_accuracy: 0.3710\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4857 - accuracy: 0.5254 - val_loss: 2.9680 - val_accuracy: 0.3753\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5004 - accuracy: 0.5148 - val_loss: 2.9880 - val_accuracy: 0.3802\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4711 - accuracy: 0.5256 - val_loss: 2.9202 - val_accuracy: 0.3729\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4779 - accuracy: 0.5335 - val_loss: 2.9547 - val_accuracy: 0.3613\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4621 - accuracy: 0.5292 - val_loss: 2.9497 - val_accuracy: 0.3771\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5084 - accuracy: 0.5203 - val_loss: 2.9586 - val_accuracy: 0.3717\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4819 - accuracy: 0.5237 - val_loss: 2.9581 - val_accuracy: 0.3771\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4703 - accuracy: 0.5346 - val_loss: 2.9726 - val_accuracy: 0.3656\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4865 - accuracy: 0.5158 - val_loss: 2.9711 - val_accuracy: 0.3631\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4913 - accuracy: 0.5158 - val_loss: 3.0060 - val_accuracy: 0.3631\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4623 - accuracy: 0.5328 - val_loss: 2.9960 - val_accuracy: 0.3674\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4885 - accuracy: 0.5191 - val_loss: 2.9713 - val_accuracy: 0.3656\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5007 - accuracy: 0.5115 - val_loss: 2.9953 - val_accuracy: 0.3698\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4896 - accuracy: 0.5209 - val_loss: 2.9442 - val_accuracy: 0.3710\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4831 - accuracy: 0.5135 - val_loss: 2.9724 - val_accuracy: 0.3717\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5023 - accuracy: 0.5016 - val_loss: 2.9895 - val_accuracy: 0.3662\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4818 - accuracy: 0.5311 - val_loss: 2.9759 - val_accuracy: 0.3674\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4962 - accuracy: 0.5075 - val_loss: 3.0156 - val_accuracy: 0.3735\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4791 - accuracy: 0.5192 - val_loss: 3.0252 - val_accuracy: 0.3741\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4750 - accuracy: 0.5236 - val_loss: 3.0231 - val_accuracy: 0.3595\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4870 - accuracy: 0.5127 - val_loss: 2.9792 - val_accuracy: 0.3674\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4726 - accuracy: 0.5278 - val_loss: 2.9717 - val_accuracy: 0.3650\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4623 - accuracy: 0.5203 - val_loss: 3.0249 - val_accuracy: 0.3698\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4857 - accuracy: 0.5217 - val_loss: 3.0164 - val_accuracy: 0.3680\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4658 - accuracy: 0.5242 - val_loss: 2.9947 - val_accuracy: 0.3783\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4597 - accuracy: 0.5294 - val_loss: 2.9927 - val_accuracy: 0.3692\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4694 - accuracy: 0.5335 - val_loss: 3.0077 - val_accuracy: 0.3729\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4493 - accuracy: 0.5330 - val_loss: 3.0207 - val_accuracy: 0.3595\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4685 - accuracy: 0.5144 - val_loss: 3.0214 - val_accuracy: 0.3704\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4570 - accuracy: 0.5272 - val_loss: 2.9945 - val_accuracy: 0.3692\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4623 - accuracy: 0.5238 - val_loss: 3.0099 - val_accuracy: 0.3729\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4857 - accuracy: 0.5148 - val_loss: 3.0154 - val_accuracy: 0.3717\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4586 - accuracy: 0.5243 - val_loss: 3.0266 - val_accuracy: 0.3723\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.4791 - accuracy: 0.5208 - val_loss: 3.0328 - val_accuracy: 0.3698\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4810 - accuracy: 0.5230 - val_loss: 3.0296 - val_accuracy: 0.3625\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4769 - accuracy: 0.5163 - val_loss: 3.0325 - val_accuracy: 0.3717\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4885 - accuracy: 0.5246 - val_loss: 3.0497 - val_accuracy: 0.3656\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4639 - accuracy: 0.5223 - val_loss: 3.0102 - val_accuracy: 0.3710\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4731 - accuracy: 0.5249 - val_loss: 3.0918 - val_accuracy: 0.3607\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4805 - accuracy: 0.5178 - val_loss: 3.0960 - val_accuracy: 0.3735\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4593 - accuracy: 0.5269 - val_loss: 3.0324 - val_accuracy: 0.3650\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4549 - accuracy: 0.5266 - val_loss: 3.0285 - val_accuracy: 0.3729\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4711 - accuracy: 0.5205 - val_loss: 3.0535 - val_accuracy: 0.3717\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4697 - accuracy: 0.5241 - val_loss: 3.0256 - val_accuracy: 0.3674\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4878 - accuracy: 0.5080 - val_loss: 3.0411 - val_accuracy: 0.3735\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4645 - accuracy: 0.5299 - val_loss: 3.0323 - val_accuracy: 0.3735\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4786 - accuracy: 0.5101 - val_loss: 2.9955 - val_accuracy: 0.3808\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4663 - accuracy: 0.5137 - val_loss: 3.0116 - val_accuracy: 0.3771\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4724 - accuracy: 0.5219 - val_loss: 3.0139 - val_accuracy: 0.3741\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4807 - accuracy: 0.5245 - val_loss: 3.0482 - val_accuracy: 0.3747\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4525 - accuracy: 0.5285 - val_loss: 3.0386 - val_accuracy: 0.3783\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4853 - accuracy: 0.5175 - val_loss: 2.9946 - val_accuracy: 0.3674\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4792 - accuracy: 0.5205 - val_loss: 3.0131 - val_accuracy: 0.3790\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4562 - accuracy: 0.5353 - val_loss: 3.0380 - val_accuracy: 0.3698\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4758 - accuracy: 0.5173 - val_loss: 3.0397 - val_accuracy: 0.3704\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4693 - accuracy: 0.5244 - val_loss: 3.0297 - val_accuracy: 0.3674\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4682 - accuracy: 0.5253 - val_loss: 3.0310 - val_accuracy: 0.3680\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4710 - accuracy: 0.5221 - val_loss: 3.0785 - val_accuracy: 0.3644\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4846 - accuracy: 0.5224 - val_loss: 3.0449 - val_accuracy: 0.3753\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4638 - accuracy: 0.5215 - val_loss: 3.0552 - val_accuracy: 0.3704\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4768 - accuracy: 0.5115 - val_loss: 3.0565 - val_accuracy: 0.3704\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4499 - accuracy: 0.5324 - val_loss: 3.0536 - val_accuracy: 0.3729\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4410 - accuracy: 0.5282 - val_loss: 3.0685 - val_accuracy: 0.3777\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4656 - accuracy: 0.5123 - val_loss: 3.0484 - val_accuracy: 0.3625\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4481 - accuracy: 0.5278 - val_loss: 3.0444 - val_accuracy: 0.3729\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4837 - accuracy: 0.5248 - val_loss: 3.0438 - val_accuracy: 0.3735\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4832 - accuracy: 0.5196 - val_loss: 3.0140 - val_accuracy: 0.3747\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4846 - accuracy: 0.5137 - val_loss: 3.0448 - val_accuracy: 0.3723\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4637 - accuracy: 0.5249 - val_loss: 3.0238 - val_accuracy: 0.3637\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4571 - accuracy: 0.5156 - val_loss: 3.0250 - val_accuracy: 0.3680\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4665 - accuracy: 0.5233 - val_loss: 3.0640 - val_accuracy: 0.3710\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4739 - accuracy: 0.5212 - val_loss: 3.0568 - val_accuracy: 0.3686\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4674 - accuracy: 0.5228 - val_loss: 3.0775 - val_accuracy: 0.3631\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4596 - accuracy: 0.5307 - val_loss: 3.0603 - val_accuracy: 0.3783\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4699 - accuracy: 0.5215 - val_loss: 3.0295 - val_accuracy: 0.3735\n",
      "Epoch 388/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4589 - accuracy: 0.5269 - val_loss: 3.0805 - val_accuracy: 0.3704\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4457 - accuracy: 0.5376 - val_loss: 3.1017 - val_accuracy: 0.3698\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4590 - accuracy: 0.5300 - val_loss: 3.0352 - val_accuracy: 0.3753\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4419 - accuracy: 0.5196 - val_loss: 3.0440 - val_accuracy: 0.3741\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4510 - accuracy: 0.5247 - val_loss: 3.1117 - val_accuracy: 0.3637\n",
      "Epoch 393/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4634 - accuracy: 0.5182 - val_loss: 3.0509 - val_accuracy: 0.3735\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4510 - accuracy: 0.5327 - val_loss: 3.0514 - val_accuracy: 0.3729\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4747 - accuracy: 0.5161 - val_loss: 3.0584 - val_accuracy: 0.3710\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4785 - accuracy: 0.5145 - val_loss: 3.0151 - val_accuracy: 0.3844\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4475 - accuracy: 0.5249 - val_loss: 3.0605 - val_accuracy: 0.3735\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4655 - accuracy: 0.5176 - val_loss: 3.0745 - val_accuracy: 0.3759\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4613 - accuracy: 0.5260 - val_loss: 3.0903 - val_accuracy: 0.3650\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.4635 - accuracy: 0.5250 - val_loss: 3.0641 - val_accuracy: 0.3777\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4720 - accuracy: 0.5248 - val_loss: 3.0642 - val_accuracy: 0.3680\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4789 - accuracy: 0.5150 - val_loss: 3.1049 - val_accuracy: 0.3668\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4565 - accuracy: 0.5248 - val_loss: 3.0669 - val_accuracy: 0.3704\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4573 - accuracy: 0.5325 - val_loss: 3.0954 - val_accuracy: 0.3717\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4595 - accuracy: 0.5161 - val_loss: 3.0982 - val_accuracy: 0.3759\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4647 - accuracy: 0.5284 - val_loss: 3.0877 - val_accuracy: 0.3710\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4675 - accuracy: 0.5263 - val_loss: 3.1038 - val_accuracy: 0.3656\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4633 - accuracy: 0.5174 - val_loss: 3.1151 - val_accuracy: 0.3680\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4350 - accuracy: 0.5262 - val_loss: 3.0852 - val_accuracy: 0.3546\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4448 - accuracy: 0.5300 - val_loss: 3.0939 - val_accuracy: 0.3710\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4381 - accuracy: 0.5340 - val_loss: 3.0556 - val_accuracy: 0.3589\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4485 - accuracy: 0.5306 - val_loss: 3.0735 - val_accuracy: 0.3704\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4700 - accuracy: 0.5212 - val_loss: 3.1360 - val_accuracy: 0.3382\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4697 - accuracy: 0.5212 - val_loss: 3.1045 - val_accuracy: 0.3650\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4627 - accuracy: 0.5252 - val_loss: 3.1497 - val_accuracy: 0.3662\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4539 - accuracy: 0.5297 - val_loss: 3.1397 - val_accuracy: 0.3589\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4652 - accuracy: 0.5225 - val_loss: 3.1314 - val_accuracy: 0.3662\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4666 - accuracy: 0.5216 - val_loss: 3.1427 - val_accuracy: 0.3552\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4624 - accuracy: 0.5275 - val_loss: 3.1002 - val_accuracy: 0.3723\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4548 - accuracy: 0.5296 - val_loss: 3.1303 - val_accuracy: 0.3680\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4612 - accuracy: 0.5247 - val_loss: 3.1179 - val_accuracy: 0.3637\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4457 - accuracy: 0.5274 - val_loss: 3.1374 - val_accuracy: 0.3704\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4521 - accuracy: 0.5296 - val_loss: 3.1420 - val_accuracy: 0.3631\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4554 - accuracy: 0.5250 - val_loss: 3.1142 - val_accuracy: 0.3729\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4202 - accuracy: 0.5319 - val_loss: 3.1268 - val_accuracy: 0.3710\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4359 - accuracy: 0.5292 - val_loss: 3.1415 - val_accuracy: 0.3686\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4603 - accuracy: 0.5353 - val_loss: 3.1505 - val_accuracy: 0.3704\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4402 - accuracy: 0.5366 - val_loss: 3.1293 - val_accuracy: 0.3692\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4492 - accuracy: 0.5381 - val_loss: 3.1506 - val_accuracy: 0.3735\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4499 - accuracy: 0.5313 - val_loss: 3.1406 - val_accuracy: 0.3704\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4643 - accuracy: 0.5337 - val_loss: 3.1439 - val_accuracy: 0.3698\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4488 - accuracy: 0.5278 - val_loss: 3.1511 - val_accuracy: 0.3668\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4406 - accuracy: 0.5364 - val_loss: 3.1205 - val_accuracy: 0.3729\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4375 - accuracy: 0.5280 - val_loss: 3.1179 - val_accuracy: 0.3637\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4514 - accuracy: 0.5290 - val_loss: 3.1299 - val_accuracy: 0.3692\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4477 - accuracy: 0.5274 - val_loss: 3.0961 - val_accuracy: 0.3723\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4623 - accuracy: 0.5253 - val_loss: 3.1046 - val_accuracy: 0.3674\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4325 - accuracy: 0.5374 - val_loss: 3.1448 - val_accuracy: 0.3735\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4615 - accuracy: 0.5243 - val_loss: 3.1086 - val_accuracy: 0.3759\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4488 - accuracy: 0.5270 - val_loss: 3.1393 - val_accuracy: 0.3656\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4534 - accuracy: 0.5188 - val_loss: 3.1290 - val_accuracy: 0.3650\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4577 - accuracy: 0.5217 - val_loss: 3.1449 - val_accuracy: 0.3674\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4472 - accuracy: 0.5274 - val_loss: 3.1167 - val_accuracy: 0.3710\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4537 - accuracy: 0.5278 - val_loss: 3.1612 - val_accuracy: 0.3668\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4391 - accuracy: 0.5428 - val_loss: 3.1428 - val_accuracy: 0.3662\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4664 - accuracy: 0.5191 - val_loss: 3.1971 - val_accuracy: 0.3662\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4448 - accuracy: 0.5275 - val_loss: 3.1369 - val_accuracy: 0.3692\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4377 - accuracy: 0.5374 - val_loss: 3.1533 - val_accuracy: 0.3668\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4445 - accuracy: 0.5311 - val_loss: 3.1470 - val_accuracy: 0.3729\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4632 - accuracy: 0.5259 - val_loss: 3.1337 - val_accuracy: 0.3759\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4572 - accuracy: 0.5277 - val_loss: 3.1297 - val_accuracy: 0.3692\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4433 - accuracy: 0.5280 - val_loss: 3.1484 - val_accuracy: 0.3656\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4451 - accuracy: 0.5285 - val_loss: 3.1785 - val_accuracy: 0.3698\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4274 - accuracy: 0.5411 - val_loss: 3.1306 - val_accuracy: 0.3625\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4406 - accuracy: 0.5321 - val_loss: 3.1330 - val_accuracy: 0.3583\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4436 - accuracy: 0.5269 - val_loss: 3.1529 - val_accuracy: 0.3692\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4546 - accuracy: 0.5160 - val_loss: 3.1730 - val_accuracy: 0.3717\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4428 - accuracy: 0.5355 - val_loss: 3.1653 - val_accuracy: 0.3577\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4644 - accuracy: 0.5261 - val_loss: 3.1486 - val_accuracy: 0.3625\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4464 - accuracy: 0.5272 - val_loss: 3.1524 - val_accuracy: 0.3704\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4387 - accuracy: 0.5380 - val_loss: 3.1745 - val_accuracy: 0.3619\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4237 - accuracy: 0.5296 - val_loss: 3.1697 - val_accuracy: 0.3692\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4398 - accuracy: 0.5283 - val_loss: 3.1339 - val_accuracy: 0.3552\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4532 - accuracy: 0.5217 - val_loss: 3.1570 - val_accuracy: 0.3717\n",
      "Epoch 465/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4496 - accuracy: 0.5201 - val_loss: 3.1693 - val_accuracy: 0.3637\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4437 - accuracy: 0.5243 - val_loss: 3.1401 - val_accuracy: 0.3674\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4484 - accuracy: 0.5259 - val_loss: 3.1569 - val_accuracy: 0.3528\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4471 - accuracy: 0.5306 - val_loss: 3.1303 - val_accuracy: 0.3619\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4487 - accuracy: 0.5250 - val_loss: 3.1064 - val_accuracy: 0.3680\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4621 - accuracy: 0.5314 - val_loss: 3.1382 - val_accuracy: 0.3601\n",
      "Epoch 471/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4442 - accuracy: 0.5337 - val_loss: 3.1213 - val_accuracy: 0.3668\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4203 - accuracy: 0.5382 - val_loss: 3.1330 - val_accuracy: 0.3668\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4446 - accuracy: 0.5249 - val_loss: 3.1320 - val_accuracy: 0.3717\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4430 - accuracy: 0.5238 - val_loss: 3.1762 - val_accuracy: 0.3637\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4573 - accuracy: 0.5252 - val_loss: 3.2115 - val_accuracy: 0.3644\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4484 - accuracy: 0.5232 - val_loss: 3.1859 - val_accuracy: 0.3680\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4422 - accuracy: 0.5267 - val_loss: 3.1733 - val_accuracy: 0.3522\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4330 - accuracy: 0.5195 - val_loss: 3.1067 - val_accuracy: 0.3589\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4251 - accuracy: 0.5349 - val_loss: 3.1349 - val_accuracy: 0.3674\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4338 - accuracy: 0.5314 - val_loss: 3.1667 - val_accuracy: 0.3595\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4471 - accuracy: 0.5305 - val_loss: 3.2091 - val_accuracy: 0.3650\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4407 - accuracy: 0.5254 - val_loss: 3.1685 - val_accuracy: 0.3662\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4564 - accuracy: 0.5310 - val_loss: 3.1378 - val_accuracy: 0.3759\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4510 - accuracy: 0.5247 - val_loss: 3.1695 - val_accuracy: 0.3680\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4590 - accuracy: 0.5236 - val_loss: 3.1900 - val_accuracy: 0.3540\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4254 - accuracy: 0.5280 - val_loss: 3.1825 - val_accuracy: 0.3552\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4569 - accuracy: 0.5283 - val_loss: 3.1279 - val_accuracy: 0.3644\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4533 - accuracy: 0.5223 - val_loss: 3.1785 - val_accuracy: 0.3704\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4542 - accuracy: 0.5245 - val_loss: 3.1925 - val_accuracy: 0.3601\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4287 - accuracy: 0.5359 - val_loss: 3.1968 - val_accuracy: 0.3650\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4355 - accuracy: 0.5315 - val_loss: 3.1491 - val_accuracy: 0.3704\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4392 - accuracy: 0.5379 - val_loss: 3.2036 - val_accuracy: 0.3747\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4275 - accuracy: 0.5326 - val_loss: 3.1503 - val_accuracy: 0.3759\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4411 - accuracy: 0.5386 - val_loss: 3.1747 - val_accuracy: 0.3662\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4478 - accuracy: 0.5374 - val_loss: 3.1650 - val_accuracy: 0.3631\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4409 - accuracy: 0.5272 - val_loss: 3.2070 - val_accuracy: 0.3644\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4416 - accuracy: 0.5388 - val_loss: 3.1971 - val_accuracy: 0.3668\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4526 - accuracy: 0.5309 - val_loss: 3.1647 - val_accuracy: 0.3704\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4360 - accuracy: 0.5306 - val_loss: 3.1328 - val_accuracy: 0.3698\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4297 - accuracy: 0.5316 - val_loss: 3.1593 - val_accuracy: 0.3735\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4473 - accuracy: 0.5327 - val_loss: 3.1890 - val_accuracy: 0.3704\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4315 - accuracy: 0.5324 - val_loss: 3.1993 - val_accuracy: 0.3644\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4375 - accuracy: 0.5320 - val_loss: 3.1532 - val_accuracy: 0.3692\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4183 - accuracy: 0.5355 - val_loss: 3.1797 - val_accuracy: 0.3692\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4448 - accuracy: 0.5270 - val_loss: 3.2013 - val_accuracy: 0.3692\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4431 - accuracy: 0.5330 - val_loss: 3.2024 - val_accuracy: 0.3619\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4258 - accuracy: 0.5348 - val_loss: 3.1682 - val_accuracy: 0.3692\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4503 - accuracy: 0.5288 - val_loss: 3.2375 - val_accuracy: 0.3516\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4418 - accuracy: 0.5255 - val_loss: 3.2127 - val_accuracy: 0.3650\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4397 - accuracy: 0.5275 - val_loss: 3.2030 - val_accuracy: 0.3607\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4217 - accuracy: 0.5357 - val_loss: 3.2480 - val_accuracy: 0.3698\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4267 - accuracy: 0.5314 - val_loss: 3.2250 - val_accuracy: 0.3674\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4270 - accuracy: 0.5337 - val_loss: 3.1761 - val_accuracy: 0.3692\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4266 - accuracy: 0.5321 - val_loss: 3.1895 - val_accuracy: 0.3723\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4471 - accuracy: 0.5338 - val_loss: 3.2092 - val_accuracy: 0.3656\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4325 - accuracy: 0.5255 - val_loss: 3.1825 - val_accuracy: 0.3674\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4220 - accuracy: 0.5386 - val_loss: 3.1959 - val_accuracy: 0.3686\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4396 - accuracy: 0.5342 - val_loss: 3.2031 - val_accuracy: 0.3625\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4344 - accuracy: 0.5373 - val_loss: 3.2017 - val_accuracy: 0.3613\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4425 - accuracy: 0.5314 - val_loss: 3.1939 - val_accuracy: 0.3577\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4596 - accuracy: 0.5261 - val_loss: 3.2366 - val_accuracy: 0.3674\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4477 - accuracy: 0.5325 - val_loss: 3.1516 - val_accuracy: 0.3686\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4415 - accuracy: 0.5365 - val_loss: 3.1522 - val_accuracy: 0.3729\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4346 - accuracy: 0.5406 - val_loss: 3.1867 - val_accuracy: 0.3686\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4504 - accuracy: 0.5267 - val_loss: 3.1481 - val_accuracy: 0.3698\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4346 - accuracy: 0.5288 - val_loss: 3.1735 - val_accuracy: 0.3552\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4435 - accuracy: 0.5286 - val_loss: 3.1995 - val_accuracy: 0.3729\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4551 - accuracy: 0.5252 - val_loss: 3.2505 - val_accuracy: 0.3668\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4254 - accuracy: 0.5316 - val_loss: 3.2101 - val_accuracy: 0.3698\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4185 - accuracy: 0.5360 - val_loss: 3.2066 - val_accuracy: 0.3723\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4452 - accuracy: 0.5291 - val_loss: 3.2613 - val_accuracy: 0.3704\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4494 - accuracy: 0.5195 - val_loss: 3.1657 - val_accuracy: 0.3729\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4329 - accuracy: 0.5280 - val_loss: 3.2550 - val_accuracy: 0.3698\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4449 - accuracy: 0.5263 - val_loss: 3.2324 - val_accuracy: 0.3692\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4087 - accuracy: 0.5379 - val_loss: 3.1821 - val_accuracy: 0.3692\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4269 - accuracy: 0.5328 - val_loss: 3.2255 - val_accuracy: 0.3680\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4191 - accuracy: 0.5367 - val_loss: 3.2348 - val_accuracy: 0.3741\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4255 - accuracy: 0.5371 - val_loss: 3.2603 - val_accuracy: 0.3668\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4293 - accuracy: 0.5416 - val_loss: 3.3043 - val_accuracy: 0.3613\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4131 - accuracy: 0.5411 - val_loss: 3.2564 - val_accuracy: 0.3704\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4270 - accuracy: 0.5358 - val_loss: 3.2968 - val_accuracy: 0.3552\n",
      "Epoch 542/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4506 - accuracy: 0.5216 - val_loss: 3.2642 - val_accuracy: 0.3644\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4401 - accuracy: 0.5300 - val_loss: 3.2470 - val_accuracy: 0.3680\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4362 - accuracy: 0.5310 - val_loss: 3.2752 - val_accuracy: 0.3595\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4128 - accuracy: 0.5352 - val_loss: 3.2295 - val_accuracy: 0.3558\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4317 - accuracy: 0.5312 - val_loss: 3.2917 - val_accuracy: 0.3692\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4280 - accuracy: 0.5406 - val_loss: 3.2726 - val_accuracy: 0.3625\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4363 - accuracy: 0.5284 - val_loss: 3.2433 - val_accuracy: 0.3619\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4268 - accuracy: 0.5330 - val_loss: 3.2386 - val_accuracy: 0.3717\n",
      "Epoch 550/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4310 - accuracy: 0.5295 - val_loss: 3.2409 - val_accuracy: 0.3686\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4045 - accuracy: 0.5382 - val_loss: 3.2263 - val_accuracy: 0.3704\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4290 - accuracy: 0.5295 - val_loss: 3.2422 - val_accuracy: 0.3577\n",
      "Epoch 553/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4446 - accuracy: 0.5299 - val_loss: 3.2066 - val_accuracy: 0.3650\n",
      "Epoch 554/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4312 - accuracy: 0.5402 - val_loss: 3.2339 - val_accuracy: 0.3619\n",
      "Epoch 555/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4374 - accuracy: 0.5317 - val_loss: 3.2397 - val_accuracy: 0.3668\n",
      "Epoch 556/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4288 - accuracy: 0.5382 - val_loss: 3.2412 - val_accuracy: 0.3583\n",
      "Epoch 557/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4174 - accuracy: 0.5443 - val_loss: 3.2502 - val_accuracy: 0.3656\n",
      "Epoch 558/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4405 - accuracy: 0.5334 - val_loss: 3.2583 - val_accuracy: 0.3686\n",
      "Epoch 559/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4336 - accuracy: 0.5315 - val_loss: 3.1991 - val_accuracy: 0.3747\n",
      "Epoch 560/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4390 - accuracy: 0.5395 - val_loss: 3.2649 - val_accuracy: 0.3674\n",
      "Epoch 561/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4240 - accuracy: 0.5416 - val_loss: 3.2761 - val_accuracy: 0.3607\n",
      "Epoch 562/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4247 - accuracy: 0.5343 - val_loss: 3.2612 - val_accuracy: 0.3662\n",
      "Epoch 563/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4128 - accuracy: 0.5412 - val_loss: 3.2593 - val_accuracy: 0.3674\n",
      "Epoch 564/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4133 - accuracy: 0.5361 - val_loss: 3.2757 - val_accuracy: 0.3698\n",
      "Epoch 565/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4187 - accuracy: 0.5391 - val_loss: 3.2315 - val_accuracy: 0.3631\n",
      "Epoch 566/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4281 - accuracy: 0.5393 - val_loss: 3.2683 - val_accuracy: 0.3704\n",
      "Epoch 567/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4176 - accuracy: 0.5282 - val_loss: 3.2142 - val_accuracy: 0.3644\n",
      "Epoch 568/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4366 - accuracy: 0.5172 - val_loss: 3.2867 - val_accuracy: 0.3662\n",
      "Epoch 569/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4403 - accuracy: 0.5264 - val_loss: 3.2438 - val_accuracy: 0.3710\n",
      "Epoch 570/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4343 - accuracy: 0.5308 - val_loss: 3.2349 - val_accuracy: 0.3674\n",
      "Epoch 571/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4206 - accuracy: 0.5323 - val_loss: 3.2417 - val_accuracy: 0.3717\n",
      "Epoch 572/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4379 - accuracy: 0.5309 - val_loss: 3.2866 - val_accuracy: 0.3619\n",
      "Epoch 573/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.4295 - accuracy: 0.5338 - val_loss: 3.2456 - val_accuracy: 0.3601\n",
      "Epoch 574/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4228 - accuracy: 0.5360 - val_loss: 3.3066 - val_accuracy: 0.3558\n",
      "Epoch 575/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4143 - accuracy: 0.5362 - val_loss: 3.2712 - val_accuracy: 0.3674\n",
      "Epoch 576/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4187 - accuracy: 0.5346 - val_loss: 3.2304 - val_accuracy: 0.3674\n",
      "Epoch 577/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4304 - accuracy: 0.5312 - val_loss: 3.2406 - val_accuracy: 0.3692\n",
      "Epoch 578/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4296 - accuracy: 0.5376 - val_loss: 3.2559 - val_accuracy: 0.3637\n",
      "Epoch 579/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4251 - accuracy: 0.5285 - val_loss: 3.2728 - val_accuracy: 0.3741\n",
      "Epoch 580/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4109 - accuracy: 0.5323 - val_loss: 3.2539 - val_accuracy: 0.3686\n",
      "Epoch 581/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4255 - accuracy: 0.5283 - val_loss: 3.3102 - val_accuracy: 0.3571\n",
      "Epoch 582/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4258 - accuracy: 0.5240 - val_loss: 3.2742 - val_accuracy: 0.3668\n",
      "Epoch 583/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4102 - accuracy: 0.5368 - val_loss: 3.2934 - val_accuracy: 0.3668\n",
      "Epoch 584/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4055 - accuracy: 0.5378 - val_loss: 3.3006 - val_accuracy: 0.3607\n",
      "Epoch 585/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4056 - accuracy: 0.5453 - val_loss: 3.2370 - val_accuracy: 0.3637\n",
      "Epoch 586/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4273 - accuracy: 0.5309 - val_loss: 3.2303 - val_accuracy: 0.3674\n",
      "Epoch 587/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4325 - accuracy: 0.5388 - val_loss: 3.2859 - val_accuracy: 0.3564\n",
      "Epoch 588/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4295 - accuracy: 0.5256 - val_loss: 3.2435 - val_accuracy: 0.3674\n",
      "Epoch 589/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4299 - accuracy: 0.5314 - val_loss: 3.2632 - val_accuracy: 0.3650\n",
      "Epoch 590/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4454 - accuracy: 0.5245 - val_loss: 3.3026 - val_accuracy: 0.3631\n",
      "Epoch 591/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4321 - accuracy: 0.5310 - val_loss: 3.2617 - val_accuracy: 0.3619\n",
      "Epoch 592/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4206 - accuracy: 0.5301 - val_loss: 3.2678 - val_accuracy: 0.3625\n",
      "Epoch 593/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4273 - accuracy: 0.5237 - val_loss: 3.2914 - val_accuracy: 0.3564\n",
      "Epoch 594/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4387 - accuracy: 0.5353 - val_loss: 3.2667 - val_accuracy: 0.3723\n",
      "Epoch 595/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4373 - accuracy: 0.5288 - val_loss: 3.3118 - val_accuracy: 0.3613\n",
      "Epoch 596/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4172 - accuracy: 0.5350 - val_loss: 3.2141 - val_accuracy: 0.3741\n",
      "Epoch 597/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4082 - accuracy: 0.5332 - val_loss: 3.2788 - val_accuracy: 0.3680\n",
      "Epoch 598/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4000 - accuracy: 0.5341 - val_loss: 3.2654 - val_accuracy: 0.3704\n",
      "Epoch 599/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4063 - accuracy: 0.5295 - val_loss: 3.2792 - val_accuracy: 0.3625\n",
      "Epoch 600/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4230 - accuracy: 0.5345 - val_loss: 3.2731 - val_accuracy: 0.3704\n",
      "Epoch 601/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4107 - accuracy: 0.5387 - val_loss: 3.3301 - val_accuracy: 0.3710\n",
      "Epoch 602/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4317 - accuracy: 0.5320 - val_loss: 3.2639 - val_accuracy: 0.3723\n",
      "Epoch 603/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4196 - accuracy: 0.5260 - val_loss: 3.3080 - val_accuracy: 0.3656\n",
      "Epoch 604/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4244 - accuracy: 0.5270 - val_loss: 3.2689 - val_accuracy: 0.3692\n",
      "Epoch 605/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4255 - accuracy: 0.5240 - val_loss: 3.2999 - val_accuracy: 0.3686\n",
      "Epoch 606/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4235 - accuracy: 0.5348 - val_loss: 3.2857 - val_accuracy: 0.3668\n",
      "Epoch 607/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4135 - accuracy: 0.5388 - val_loss: 3.2621 - val_accuracy: 0.3698\n",
      "Epoch 608/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4167 - accuracy: 0.5332 - val_loss: 3.2866 - val_accuracy: 0.3613\n",
      "Epoch 609/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4168 - accuracy: 0.5350 - val_loss: 3.2793 - val_accuracy: 0.3698\n",
      "Epoch 610/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4186 - accuracy: 0.5238 - val_loss: 3.2808 - val_accuracy: 0.3662\n",
      "Epoch 611/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4172 - accuracy: 0.5313 - val_loss: 3.3172 - val_accuracy: 0.3650\n",
      "Epoch 612/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4240 - accuracy: 0.5293 - val_loss: 3.2319 - val_accuracy: 0.3735\n",
      "Epoch 613/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4241 - accuracy: 0.5294 - val_loss: 3.2827 - val_accuracy: 0.3692\n",
      "Epoch 614/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4130 - accuracy: 0.5325 - val_loss: 3.2245 - val_accuracy: 0.3717\n",
      "Epoch 615/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4403 - accuracy: 0.5177 - val_loss: 3.2610 - val_accuracy: 0.3680\n",
      "Epoch 616/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4152 - accuracy: 0.5362 - val_loss: 3.3114 - val_accuracy: 0.3662\n",
      "Epoch 617/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4318 - accuracy: 0.5338 - val_loss: 3.2795 - val_accuracy: 0.3704\n",
      "Epoch 618/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4277 - accuracy: 0.5315 - val_loss: 3.2841 - val_accuracy: 0.3644\n",
      "Epoch 619/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4137 - accuracy: 0.5375 - val_loss: 3.2461 - val_accuracy: 0.3729\n",
      "Epoch 620/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4199 - accuracy: 0.5403 - val_loss: 3.2414 - val_accuracy: 0.3692\n",
      "Epoch 621/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4014 - accuracy: 0.5410 - val_loss: 3.2619 - val_accuracy: 0.3631\n",
      "Epoch 622/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4229 - accuracy: 0.5282 - val_loss: 3.3324 - val_accuracy: 0.3546\n",
      "Epoch 623/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3994 - accuracy: 0.5372 - val_loss: 3.3171 - val_accuracy: 0.3619\n",
      "Epoch 624/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4259 - accuracy: 0.5310 - val_loss: 3.3229 - val_accuracy: 0.3650\n",
      "Epoch 625/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4129 - accuracy: 0.5369 - val_loss: 3.3569 - val_accuracy: 0.3577\n",
      "Epoch 626/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4163 - accuracy: 0.5360 - val_loss: 3.3022 - val_accuracy: 0.3625\n",
      "Epoch 627/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4341 - accuracy: 0.5309 - val_loss: 3.3405 - val_accuracy: 0.3637\n",
      "Epoch 628/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4302 - accuracy: 0.5330 - val_loss: 3.3267 - val_accuracy: 0.3504\n",
      "Epoch 629/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4078 - accuracy: 0.5416 - val_loss: 3.3072 - val_accuracy: 0.3637\n",
      "Epoch 630/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3997 - accuracy: 0.5477 - val_loss: 3.3535 - val_accuracy: 0.3619\n",
      "Epoch 631/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4165 - accuracy: 0.5396 - val_loss: 3.3554 - val_accuracy: 0.3510\n",
      "Epoch 632/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3981 - accuracy: 0.5516 - val_loss: 3.3526 - val_accuracy: 0.3644\n",
      "Epoch 633/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4223 - accuracy: 0.5354 - val_loss: 3.3056 - val_accuracy: 0.3674\n",
      "Epoch 634/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4120 - accuracy: 0.5265 - val_loss: 3.3405 - val_accuracy: 0.3589\n",
      "Epoch 635/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4327 - accuracy: 0.5230 - val_loss: 3.3365 - val_accuracy: 0.3625\n",
      "Epoch 636/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4134 - accuracy: 0.5340 - val_loss: 3.3296 - val_accuracy: 0.3650\n",
      "Epoch 637/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4142 - accuracy: 0.5417 - val_loss: 3.3511 - val_accuracy: 0.3498\n",
      "Epoch 638/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4190 - accuracy: 0.5388 - val_loss: 3.2871 - val_accuracy: 0.3510\n",
      "Epoch 639/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4278 - accuracy: 0.5317 - val_loss: 3.2857 - val_accuracy: 0.3674\n",
      "Epoch 640/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4178 - accuracy: 0.5332 - val_loss: 3.3271 - val_accuracy: 0.3613\n",
      "Epoch 641/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4148 - accuracy: 0.5374 - val_loss: 3.3086 - val_accuracy: 0.3552\n",
      "Epoch 642/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4154 - accuracy: 0.5264 - val_loss: 3.3526 - val_accuracy: 0.3717\n",
      "Epoch 643/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3968 - accuracy: 0.5472 - val_loss: 3.2724 - val_accuracy: 0.3637\n",
      "Epoch 644/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4142 - accuracy: 0.5426 - val_loss: 3.2971 - val_accuracy: 0.3589\n",
      "Epoch 645/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4151 - accuracy: 0.5269 - val_loss: 3.3389 - val_accuracy: 0.3668\n",
      "Epoch 646/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4133 - accuracy: 0.5303 - val_loss: 3.3277 - val_accuracy: 0.3656\n",
      "Epoch 647/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4214 - accuracy: 0.5352 - val_loss: 3.2964 - val_accuracy: 0.3644\n",
      "Epoch 648/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4295 - accuracy: 0.5328 - val_loss: 3.3203 - val_accuracy: 0.3528\n",
      "Epoch 649/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4069 - accuracy: 0.5454 - val_loss: 3.2973 - val_accuracy: 0.3516\n",
      "Epoch 650/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4148 - accuracy: 0.5306 - val_loss: 3.3091 - val_accuracy: 0.3504\n",
      "Epoch 651/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4100 - accuracy: 0.5339 - val_loss: 3.3690 - val_accuracy: 0.3504\n",
      "Epoch 652/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4276 - accuracy: 0.5269 - val_loss: 3.3394 - val_accuracy: 0.3510\n",
      "Epoch 653/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4279 - accuracy: 0.5300 - val_loss: 3.3539 - val_accuracy: 0.3637\n",
      "Epoch 654/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4045 - accuracy: 0.5383 - val_loss: 3.3688 - val_accuracy: 0.3613\n",
      "Epoch 655/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4117 - accuracy: 0.5341 - val_loss: 3.3598 - val_accuracy: 0.3613\n",
      "Epoch 656/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4217 - accuracy: 0.5283 - val_loss: 3.3523 - val_accuracy: 0.3595\n",
      "Epoch 657/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4156 - accuracy: 0.5351 - val_loss: 3.3164 - val_accuracy: 0.3662\n",
      "Epoch 658/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4052 - accuracy: 0.5390 - val_loss: 3.3526 - val_accuracy: 0.3528\n",
      "Epoch 659/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4117 - accuracy: 0.5305 - val_loss: 3.3474 - val_accuracy: 0.3656\n",
      "Epoch 660/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4112 - accuracy: 0.5281 - val_loss: 3.3306 - val_accuracy: 0.3674\n",
      "Epoch 661/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4222 - accuracy: 0.5276 - val_loss: 3.3575 - val_accuracy: 0.3528\n",
      "Epoch 662/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4110 - accuracy: 0.5378 - val_loss: 3.2980 - val_accuracy: 0.3674\n",
      "Epoch 663/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4216 - accuracy: 0.5320 - val_loss: 3.3537 - val_accuracy: 0.3589\n",
      "Epoch 664/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4161 - accuracy: 0.5325 - val_loss: 3.3346 - val_accuracy: 0.3583\n",
      "Epoch 665/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4087 - accuracy: 0.5282 - val_loss: 3.3412 - val_accuracy: 0.3583\n",
      "Epoch 666/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4120 - accuracy: 0.5349 - val_loss: 3.3335 - val_accuracy: 0.3631\n",
      "Epoch 667/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4168 - accuracy: 0.5343 - val_loss: 3.3533 - val_accuracy: 0.3558\n",
      "Epoch 668/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4233 - accuracy: 0.5410 - val_loss: 3.3358 - val_accuracy: 0.3680\n",
      "Epoch 669/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3995 - accuracy: 0.5349 - val_loss: 3.3720 - val_accuracy: 0.3650\n",
      "Epoch 670/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3951 - accuracy: 0.5467 - val_loss: 3.4137 - val_accuracy: 0.3625\n",
      "Epoch 671/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4192 - accuracy: 0.5415 - val_loss: 3.3742 - val_accuracy: 0.3528\n",
      "Epoch 672/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4022 - accuracy: 0.5439 - val_loss: 3.3122 - val_accuracy: 0.3613\n",
      "Epoch 673/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4005 - accuracy: 0.5462 - val_loss: 3.3449 - val_accuracy: 0.3656\n",
      "Epoch 674/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4176 - accuracy: 0.5378 - val_loss: 3.3432 - val_accuracy: 0.3613\n",
      "Epoch 675/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4256 - accuracy: 0.5255 - val_loss: 3.3339 - val_accuracy: 0.3619\n",
      "Epoch 676/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4245 - accuracy: 0.5311 - val_loss: 3.3214 - val_accuracy: 0.3668\n",
      "Epoch 677/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4225 - accuracy: 0.5368 - val_loss: 3.3432 - val_accuracy: 0.3644\n",
      "Epoch 678/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4061 - accuracy: 0.5350 - val_loss: 3.3212 - val_accuracy: 0.3686\n",
      "Epoch 679/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4243 - accuracy: 0.5361 - val_loss: 3.4168 - val_accuracy: 0.3528\n",
      "Epoch 680/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4155 - accuracy: 0.5360 - val_loss: 3.3081 - val_accuracy: 0.3674\n",
      "Epoch 681/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4274 - accuracy: 0.5262 - val_loss: 3.3772 - val_accuracy: 0.3546\n",
      "Epoch 682/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4059 - accuracy: 0.5374 - val_loss: 3.3455 - val_accuracy: 0.3491\n",
      "Epoch 683/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4215 - accuracy: 0.5418 - val_loss: 3.3973 - val_accuracy: 0.3625\n",
      "Epoch 684/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4130 - accuracy: 0.5350 - val_loss: 3.3318 - val_accuracy: 0.3625\n",
      "Epoch 685/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3894 - accuracy: 0.5459 - val_loss: 3.3633 - val_accuracy: 0.3461\n",
      "Epoch 686/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3894 - accuracy: 0.5524 - val_loss: 3.3853 - val_accuracy: 0.3534\n",
      "Epoch 687/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4021 - accuracy: 0.5365 - val_loss: 3.4027 - val_accuracy: 0.3571\n",
      "Epoch 688/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4158 - accuracy: 0.5446 - val_loss: 3.3187 - val_accuracy: 0.3613\n",
      "Epoch 689/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4112 - accuracy: 0.5467 - val_loss: 3.3287 - val_accuracy: 0.3473\n",
      "Epoch 690/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3967 - accuracy: 0.5416 - val_loss: 3.3603 - val_accuracy: 0.3637\n",
      "Epoch 691/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4135 - accuracy: 0.5330 - val_loss: 3.4339 - val_accuracy: 0.3473\n",
      "Epoch 692/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4151 - accuracy: 0.5350 - val_loss: 3.4542 - val_accuracy: 0.3498\n",
      "Epoch 693/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4092 - accuracy: 0.5309 - val_loss: 3.3920 - val_accuracy: 0.3583\n",
      "Epoch 694/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4102 - accuracy: 0.5434 - val_loss: 3.3723 - val_accuracy: 0.3473\n",
      "Epoch 695/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3995 - accuracy: 0.5534 - val_loss: 3.3706 - val_accuracy: 0.3552\n",
      "Epoch 696/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4063 - accuracy: 0.5368 - val_loss: 3.3577 - val_accuracy: 0.3607\n",
      "Epoch 697/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3853 - accuracy: 0.5392 - val_loss: 3.3369 - val_accuracy: 0.3656\n",
      "Epoch 698/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4307 - accuracy: 0.5296 - val_loss: 3.3695 - val_accuracy: 0.3637\n",
      "Epoch 699/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4259 - accuracy: 0.5352 - val_loss: 3.3584 - val_accuracy: 0.3692\n",
      "Epoch 700/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4179 - accuracy: 0.5298 - val_loss: 3.4045 - val_accuracy: 0.3589\n",
      "Epoch 701/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4191 - accuracy: 0.5345 - val_loss: 3.4476 - val_accuracy: 0.3589\n",
      "Epoch 702/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4246 - accuracy: 0.5326 - val_loss: 3.3787 - val_accuracy: 0.3625\n",
      "Epoch 703/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4056 - accuracy: 0.5310 - val_loss: 3.3410 - val_accuracy: 0.3625\n",
      "Epoch 704/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4042 - accuracy: 0.5398 - val_loss: 3.4136 - val_accuracy: 0.3577\n",
      "Epoch 705/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4208 - accuracy: 0.5363 - val_loss: 3.3884 - val_accuracy: 0.3613\n",
      "Epoch 706/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4092 - accuracy: 0.5436 - val_loss: 3.3258 - val_accuracy: 0.3637\n",
      "Epoch 707/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3990 - accuracy: 0.5372 - val_loss: 3.3558 - val_accuracy: 0.3613\n",
      "Epoch 708/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4262 - accuracy: 0.5350 - val_loss: 3.3704 - val_accuracy: 0.3461\n",
      "Epoch 709/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4150 - accuracy: 0.5389 - val_loss: 3.3205 - val_accuracy: 0.3479\n",
      "Epoch 710/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4115 - accuracy: 0.5345 - val_loss: 3.3625 - val_accuracy: 0.3686\n",
      "Epoch 711/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4021 - accuracy: 0.5381 - val_loss: 3.4069 - val_accuracy: 0.3455\n",
      "Epoch 712/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3923 - accuracy: 0.5416 - val_loss: 3.4072 - val_accuracy: 0.3491\n",
      "Epoch 713/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4173 - accuracy: 0.5430 - val_loss: 3.3748 - val_accuracy: 0.3631\n",
      "Epoch 714/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4016 - accuracy: 0.5465 - val_loss: 3.4154 - val_accuracy: 0.3516\n",
      "Epoch 715/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4198 - accuracy: 0.5303 - val_loss: 3.3755 - val_accuracy: 0.3583\n",
      "Epoch 716/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4034 - accuracy: 0.5424 - val_loss: 3.3662 - val_accuracy: 0.3577\n",
      "Epoch 717/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4005 - accuracy: 0.5291 - val_loss: 3.3762 - val_accuracy: 0.3571\n",
      "Epoch 718/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3850 - accuracy: 0.5510 - val_loss: 3.3356 - val_accuracy: 0.3583\n",
      "Epoch 719/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4042 - accuracy: 0.5323 - val_loss: 3.3511 - val_accuracy: 0.3589\n",
      "Epoch 720/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4035 - accuracy: 0.5382 - val_loss: 3.3319 - val_accuracy: 0.3625\n",
      "Epoch 721/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4038 - accuracy: 0.5392 - val_loss: 3.3948 - val_accuracy: 0.3583\n",
      "Epoch 722/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4112 - accuracy: 0.5401 - val_loss: 3.3875 - val_accuracy: 0.3510\n",
      "Epoch 723/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3985 - accuracy: 0.5511 - val_loss: 3.3925 - val_accuracy: 0.3461\n",
      "Epoch 724/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4032 - accuracy: 0.5378 - val_loss: 3.4125 - val_accuracy: 0.3601\n",
      "Epoch 725/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4020 - accuracy: 0.5308 - val_loss: 3.3674 - val_accuracy: 0.3619\n",
      "Epoch 726/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4000 - accuracy: 0.5376 - val_loss: 3.3533 - val_accuracy: 0.3637\n",
      "Epoch 727/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3848 - accuracy: 0.5452 - val_loss: 3.4563 - val_accuracy: 0.3522\n",
      "Epoch 728/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3860 - accuracy: 0.5458 - val_loss: 3.3959 - val_accuracy: 0.3571\n",
      "Epoch 729/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3989 - accuracy: 0.5429 - val_loss: 3.4061 - val_accuracy: 0.3552\n",
      "Epoch 730/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3932 - accuracy: 0.5447 - val_loss: 3.3968 - val_accuracy: 0.3631\n",
      "Epoch 731/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4205 - accuracy: 0.5285 - val_loss: 3.4369 - val_accuracy: 0.3631\n",
      "Epoch 732/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4220 - accuracy: 0.5419 - val_loss: 3.4237 - val_accuracy: 0.3607\n",
      "Epoch 733/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4037 - accuracy: 0.5349 - val_loss: 3.3824 - val_accuracy: 0.3601\n",
      "Epoch 734/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4211 - accuracy: 0.5328 - val_loss: 3.4074 - val_accuracy: 0.3644\n",
      "Epoch 735/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4064 - accuracy: 0.5388 - val_loss: 3.4309 - val_accuracy: 0.3577\n",
      "Epoch 736/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3905 - accuracy: 0.5441 - val_loss: 3.3887 - val_accuracy: 0.3534\n",
      "Epoch 737/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4002 - accuracy: 0.5355 - val_loss: 3.3603 - val_accuracy: 0.3668\n",
      "Epoch 738/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4081 - accuracy: 0.5345 - val_loss: 3.4084 - val_accuracy: 0.3668\n",
      "Epoch 739/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4072 - accuracy: 0.5364 - val_loss: 3.3994 - val_accuracy: 0.3656\n",
      "Epoch 740/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3994 - accuracy: 0.5411 - val_loss: 3.4251 - val_accuracy: 0.3656\n",
      "Epoch 741/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4147 - accuracy: 0.5292 - val_loss: 3.4494 - val_accuracy: 0.3589\n",
      "Epoch 742/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4028 - accuracy: 0.5395 - val_loss: 3.4013 - val_accuracy: 0.3546\n",
      "Epoch 743/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4171 - accuracy: 0.5323 - val_loss: 3.4076 - val_accuracy: 0.3644\n",
      "Epoch 744/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4150 - accuracy: 0.5373 - val_loss: 3.4076 - val_accuracy: 0.3637\n",
      "Epoch 745/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4304 - accuracy: 0.5217 - val_loss: 3.4196 - val_accuracy: 0.3558\n",
      "Epoch 746/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4066 - accuracy: 0.5370 - val_loss: 3.4125 - val_accuracy: 0.3534\n",
      "Epoch 747/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3937 - accuracy: 0.5401 - val_loss: 3.4115 - val_accuracy: 0.3546\n",
      "Epoch 748/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3843 - accuracy: 0.5365 - val_loss: 3.3698 - val_accuracy: 0.3504\n",
      "Epoch 749/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4059 - accuracy: 0.5356 - val_loss: 3.3689 - val_accuracy: 0.3473\n",
      "Epoch 750/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4153 - accuracy: 0.5319 - val_loss: 3.3973 - val_accuracy: 0.3425\n",
      "Epoch 751/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.3987 - accuracy: 0.5418 - val_loss: 3.4655 - val_accuracy: 0.3540\n",
      "Epoch 752/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3976 - accuracy: 0.5414 - val_loss: 3.4150 - val_accuracy: 0.3467\n",
      "Epoch 753/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4201 - accuracy: 0.5287 - val_loss: 3.4694 - val_accuracy: 0.3455\n",
      "Epoch 754/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4083 - accuracy: 0.5331 - val_loss: 3.3863 - val_accuracy: 0.3546\n",
      "Epoch 755/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4014 - accuracy: 0.5453 - val_loss: 3.4252 - val_accuracy: 0.3388\n",
      "Epoch 756/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4022 - accuracy: 0.5376 - val_loss: 3.4080 - val_accuracy: 0.3607\n",
      "Epoch 757/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3880 - accuracy: 0.5497 - val_loss: 3.4861 - val_accuracy: 0.3412\n",
      "Epoch 758/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4041 - accuracy: 0.5328 - val_loss: 3.4393 - val_accuracy: 0.3455\n",
      "Epoch 759/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4316 - accuracy: 0.5397 - val_loss: 3.4212 - val_accuracy: 0.3418\n",
      "Epoch 760/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3991 - accuracy: 0.5339 - val_loss: 3.4603 - val_accuracy: 0.3516\n",
      "Epoch 761/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4080 - accuracy: 0.5425 - val_loss: 3.4537 - val_accuracy: 0.3528\n",
      "Epoch 762/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3852 - accuracy: 0.5512 - val_loss: 3.4151 - val_accuracy: 0.3571\n",
      "Epoch 763/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4084 - accuracy: 0.5403 - val_loss: 3.4264 - val_accuracy: 0.3564\n",
      "Epoch 764/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4042 - accuracy: 0.5343 - val_loss: 3.4266 - val_accuracy: 0.3607\n",
      "Epoch 765/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3989 - accuracy: 0.5418 - val_loss: 3.4428 - val_accuracy: 0.3571\n",
      "Epoch 766/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4154 - accuracy: 0.5368 - val_loss: 3.3882 - val_accuracy: 0.3540\n",
      "Epoch 767/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3892 - accuracy: 0.5345 - val_loss: 3.4080 - val_accuracy: 0.3589\n",
      "Epoch 768/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4202 - accuracy: 0.5269 - val_loss: 3.4143 - val_accuracy: 0.3589\n",
      "Epoch 769/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4003 - accuracy: 0.5329 - val_loss: 3.3662 - val_accuracy: 0.3650\n",
      "Epoch 770/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3850 - accuracy: 0.5469 - val_loss: 3.4023 - val_accuracy: 0.3564\n",
      "Epoch 771/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4103 - accuracy: 0.5431 - val_loss: 3.3865 - val_accuracy: 0.3692\n",
      "Epoch 772/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3997 - accuracy: 0.5406 - val_loss: 3.3754 - val_accuracy: 0.3644\n",
      "Epoch 773/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3757 - accuracy: 0.5509 - val_loss: 3.4241 - val_accuracy: 0.3589\n",
      "Epoch 774/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3928 - accuracy: 0.5371 - val_loss: 3.3737 - val_accuracy: 0.3625\n",
      "Epoch 775/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3937 - accuracy: 0.5558 - val_loss: 3.4067 - val_accuracy: 0.3613\n",
      "Epoch 776/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4119 - accuracy: 0.5319 - val_loss: 3.3985 - val_accuracy: 0.3613\n",
      "Epoch 777/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4031 - accuracy: 0.5339 - val_loss: 3.4389 - val_accuracy: 0.3577\n",
      "Epoch 778/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3929 - accuracy: 0.5310 - val_loss: 3.4751 - val_accuracy: 0.3540\n",
      "Epoch 779/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4035 - accuracy: 0.5375 - val_loss: 3.3989 - val_accuracy: 0.3625\n",
      "Epoch 780/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4188 - accuracy: 0.5249 - val_loss: 3.4036 - val_accuracy: 0.3637\n",
      "Epoch 781/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3934 - accuracy: 0.5403 - val_loss: 3.4664 - val_accuracy: 0.3607\n",
      "Epoch 782/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4191 - accuracy: 0.5376 - val_loss: 3.3769 - val_accuracy: 0.3485\n",
      "Epoch 783/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4016 - accuracy: 0.5412 - val_loss: 3.3786 - val_accuracy: 0.3637\n",
      "Epoch 784/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4241 - accuracy: 0.5341 - val_loss: 3.4214 - val_accuracy: 0.3522\n",
      "Epoch 785/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3991 - accuracy: 0.5373 - val_loss: 3.4025 - val_accuracy: 0.3467\n",
      "Epoch 786/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3989 - accuracy: 0.5404 - val_loss: 3.4312 - val_accuracy: 0.3613\n",
      "Epoch 787/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4001 - accuracy: 0.5284 - val_loss: 3.4865 - val_accuracy: 0.3510\n",
      "Epoch 788/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4055 - accuracy: 0.5376 - val_loss: 3.4172 - val_accuracy: 0.3504\n",
      "Epoch 789/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4090 - accuracy: 0.5394 - val_loss: 3.3767 - val_accuracy: 0.3485\n",
      "Epoch 790/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4058 - accuracy: 0.5368 - val_loss: 3.4102 - val_accuracy: 0.3467\n",
      "Epoch 791/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4036 - accuracy: 0.5386 - val_loss: 3.4332 - val_accuracy: 0.3491\n",
      "Epoch 792/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4141 - accuracy: 0.5382 - val_loss: 3.4141 - val_accuracy: 0.3613\n",
      "Epoch 793/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4057 - accuracy: 0.5398 - val_loss: 3.5042 - val_accuracy: 0.3552\n",
      "Epoch 794/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4210 - accuracy: 0.5402 - val_loss: 3.4148 - val_accuracy: 0.3625\n",
      "Epoch 795/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4209 - accuracy: 0.5337 - val_loss: 3.3764 - val_accuracy: 0.3656\n",
      "Epoch 796/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3960 - accuracy: 0.5429 - val_loss: 3.4198 - val_accuracy: 0.3589\n",
      "Epoch 797/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4070 - accuracy: 0.5420 - val_loss: 3.3779 - val_accuracy: 0.3589\n",
      "Epoch 798/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3801 - accuracy: 0.5390 - val_loss: 3.4328 - val_accuracy: 0.3479\n",
      "Epoch 799/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4210 - accuracy: 0.5386 - val_loss: 3.3814 - val_accuracy: 0.3558\n",
      "Epoch 800/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3975 - accuracy: 0.5373 - val_loss: 3.4505 - val_accuracy: 0.3491\n",
      "Epoch 801/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4051 - accuracy: 0.5419 - val_loss: 3.4009 - val_accuracy: 0.3607\n",
      "Epoch 802/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3988 - accuracy: 0.5377 - val_loss: 3.3935 - val_accuracy: 0.3564\n",
      "Epoch 803/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4000 - accuracy: 0.5348 - val_loss: 3.4559 - val_accuracy: 0.3650\n",
      "Epoch 804/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3545 - accuracy: 0.5461 - val_loss: 3.4625 - val_accuracy: 0.3571\n",
      "Epoch 805/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4091 - accuracy: 0.5392 - val_loss: 3.4631 - val_accuracy: 0.3558\n",
      "Epoch 806/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4108 - accuracy: 0.5436 - val_loss: 3.4641 - val_accuracy: 0.3583\n",
      "Epoch 807/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3929 - accuracy: 0.5471 - val_loss: 3.4298 - val_accuracy: 0.3577\n",
      "Epoch 808/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3966 - accuracy: 0.5313 - val_loss: 3.4486 - val_accuracy: 0.3522\n",
      "Epoch 809/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3961 - accuracy: 0.5434 - val_loss: 3.3963 - val_accuracy: 0.3552\n",
      "Epoch 810/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4075 - accuracy: 0.5349 - val_loss: 3.3735 - val_accuracy: 0.3619\n",
      "Epoch 811/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3909 - accuracy: 0.5430 - val_loss: 3.4192 - val_accuracy: 0.3522\n",
      "Epoch 812/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3928 - accuracy: 0.5439 - val_loss: 3.4255 - val_accuracy: 0.3583\n",
      "Epoch 813/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3923 - accuracy: 0.5432 - val_loss: 3.4538 - val_accuracy: 0.3601\n",
      "Epoch 814/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4013 - accuracy: 0.5439 - val_loss: 3.3723 - val_accuracy: 0.3546\n",
      "Epoch 815/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4145 - accuracy: 0.5332 - val_loss: 3.4537 - val_accuracy: 0.3595\n",
      "Epoch 816/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4157 - accuracy: 0.5307 - val_loss: 3.4143 - val_accuracy: 0.3619\n",
      "Epoch 817/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3978 - accuracy: 0.5387 - val_loss: 3.4409 - val_accuracy: 0.3425\n",
      "Epoch 818/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3967 - accuracy: 0.5415 - val_loss: 3.4703 - val_accuracy: 0.3400\n",
      "Epoch 819/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3878 - accuracy: 0.5412 - val_loss: 3.4084 - val_accuracy: 0.3577\n",
      "Epoch 820/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3985 - accuracy: 0.5405 - val_loss: 3.4287 - val_accuracy: 0.3583\n",
      "Epoch 821/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.4081 - accuracy: 0.5381 - val_loss: 3.5147 - val_accuracy: 0.3425\n",
      "Epoch 822/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3904 - accuracy: 0.5416 - val_loss: 3.4746 - val_accuracy: 0.3528\n",
      "Epoch 823/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3897 - accuracy: 0.5424 - val_loss: 3.4311 - val_accuracy: 0.3528\n",
      "Epoch 824/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3983 - accuracy: 0.5451 - val_loss: 3.5095 - val_accuracy: 0.3473\n",
      "Epoch 825/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3996 - accuracy: 0.5368 - val_loss: 3.4894 - val_accuracy: 0.3534\n",
      "Epoch 826/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4056 - accuracy: 0.5358 - val_loss: 3.4654 - val_accuracy: 0.3449\n",
      "Epoch 827/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3860 - accuracy: 0.5445 - val_loss: 3.4659 - val_accuracy: 0.3546\n",
      "Epoch 828/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3967 - accuracy: 0.5477 - val_loss: 3.4721 - val_accuracy: 0.3406\n",
      "Epoch 829/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4220 - accuracy: 0.5344 - val_loss: 3.5098 - val_accuracy: 0.3504\n",
      "Epoch 830/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4182 - accuracy: 0.5334 - val_loss: 3.4383 - val_accuracy: 0.3540\n",
      "Epoch 831/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4080 - accuracy: 0.5338 - val_loss: 3.4755 - val_accuracy: 0.3455\n",
      "Epoch 832/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4043 - accuracy: 0.5299 - val_loss: 3.4715 - val_accuracy: 0.3613\n",
      "Epoch 833/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3903 - accuracy: 0.5386 - val_loss: 3.4391 - val_accuracy: 0.3522\n",
      "Epoch 834/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3984 - accuracy: 0.5344 - val_loss: 3.4854 - val_accuracy: 0.3449\n",
      "Epoch 835/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4126 - accuracy: 0.5352 - val_loss: 3.4515 - val_accuracy: 0.3467\n",
      "Epoch 836/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4086 - accuracy: 0.5209 - val_loss: 3.4513 - val_accuracy: 0.3637\n",
      "Epoch 837/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3998 - accuracy: 0.5463 - val_loss: 3.4079 - val_accuracy: 0.3437\n",
      "Epoch 838/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4045 - accuracy: 0.5320 - val_loss: 3.4804 - val_accuracy: 0.3522\n",
      "Epoch 839/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4019 - accuracy: 0.5392 - val_loss: 3.4491 - val_accuracy: 0.3552\n",
      "Epoch 840/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3722 - accuracy: 0.5509 - val_loss: 3.4557 - val_accuracy: 0.3425\n",
      "Epoch 841/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3805 - accuracy: 0.5448 - val_loss: 3.4765 - val_accuracy: 0.3491\n",
      "Epoch 842/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3831 - accuracy: 0.5453 - val_loss: 3.4166 - val_accuracy: 0.3467\n",
      "Epoch 843/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4034 - accuracy: 0.5372 - val_loss: 3.4154 - val_accuracy: 0.3595\n",
      "Epoch 844/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3891 - accuracy: 0.5370 - val_loss: 3.4459 - val_accuracy: 0.3631\n",
      "Epoch 845/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4108 - accuracy: 0.5362 - val_loss: 3.4310 - val_accuracy: 0.3595\n",
      "Epoch 846/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3867 - accuracy: 0.5447 - val_loss: 3.4692 - val_accuracy: 0.3577\n",
      "Epoch 847/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4040 - accuracy: 0.5451 - val_loss: 3.4810 - val_accuracy: 0.3449\n",
      "Epoch 848/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3910 - accuracy: 0.5438 - val_loss: 3.4690 - val_accuracy: 0.3473\n",
      "Epoch 849/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4120 - accuracy: 0.5372 - val_loss: 3.4578 - val_accuracy: 0.3498\n",
      "Epoch 850/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4044 - accuracy: 0.5288 - val_loss: 3.4847 - val_accuracy: 0.3516\n",
      "Epoch 851/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3910 - accuracy: 0.5387 - val_loss: 3.4885 - val_accuracy: 0.3583\n",
      "Epoch 852/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4033 - accuracy: 0.5321 - val_loss: 3.5198 - val_accuracy: 0.3546\n",
      "Epoch 853/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4001 - accuracy: 0.5355 - val_loss: 3.4853 - val_accuracy: 0.3461\n",
      "Epoch 854/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4000 - accuracy: 0.5293 - val_loss: 3.4767 - val_accuracy: 0.3473\n",
      "Epoch 855/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3960 - accuracy: 0.5372 - val_loss: 3.4611 - val_accuracy: 0.3589\n",
      "Epoch 856/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3854 - accuracy: 0.5383 - val_loss: 3.4754 - val_accuracy: 0.3552\n",
      "Epoch 857/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4034 - accuracy: 0.5364 - val_loss: 3.4631 - val_accuracy: 0.3552\n",
      "Epoch 858/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4123 - accuracy: 0.5300 - val_loss: 3.4930 - val_accuracy: 0.3546\n",
      "Epoch 859/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4011 - accuracy: 0.5361 - val_loss: 3.4553 - val_accuracy: 0.3467\n",
      "Epoch 860/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3904 - accuracy: 0.5541 - val_loss: 3.4995 - val_accuracy: 0.3491\n",
      "Epoch 861/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3971 - accuracy: 0.5387 - val_loss: 3.5070 - val_accuracy: 0.3589\n",
      "Epoch 862/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4044 - accuracy: 0.5293 - val_loss: 3.5151 - val_accuracy: 0.3491\n",
      "Epoch 863/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3982 - accuracy: 0.5400 - val_loss: 3.4993 - val_accuracy: 0.3473\n",
      "Epoch 864/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3972 - accuracy: 0.5346 - val_loss: 3.4688 - val_accuracy: 0.3571\n",
      "Epoch 865/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4151 - accuracy: 0.5281 - val_loss: 3.4861 - val_accuracy: 0.3473\n",
      "Epoch 866/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3840 - accuracy: 0.5374 - val_loss: 3.4686 - val_accuracy: 0.3662\n",
      "Epoch 867/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3935 - accuracy: 0.5410 - val_loss: 3.4623 - val_accuracy: 0.3650\n",
      "Epoch 868/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4085 - accuracy: 0.5354 - val_loss: 3.4804 - val_accuracy: 0.3522\n",
      "Epoch 869/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3979 - accuracy: 0.5382 - val_loss: 3.5038 - val_accuracy: 0.3491\n",
      "Epoch 870/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3892 - accuracy: 0.5454 - val_loss: 3.4228 - val_accuracy: 0.3668\n",
      "Epoch 871/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4171 - accuracy: 0.5336 - val_loss: 3.4546 - val_accuracy: 0.3516\n",
      "Epoch 872/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3818 - accuracy: 0.5423 - val_loss: 3.5469 - val_accuracy: 0.3449\n",
      "Epoch 873/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3933 - accuracy: 0.5374 - val_loss: 3.4518 - val_accuracy: 0.3516\n",
      "Epoch 874/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4011 - accuracy: 0.5346 - val_loss: 3.4896 - val_accuracy: 0.3479\n",
      "Epoch 875/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4111 - accuracy: 0.5319 - val_loss: 3.4537 - val_accuracy: 0.3504\n",
      "Epoch 876/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4034 - accuracy: 0.5407 - val_loss: 3.5302 - val_accuracy: 0.3455\n",
      "Epoch 877/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3763 - accuracy: 0.5437 - val_loss: 3.5030 - val_accuracy: 0.3455\n",
      "Epoch 878/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3735 - accuracy: 0.5509 - val_loss: 3.4790 - val_accuracy: 0.3613\n",
      "Epoch 879/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4002 - accuracy: 0.5413 - val_loss: 3.5420 - val_accuracy: 0.3485\n",
      "Epoch 880/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3918 - accuracy: 0.5399 - val_loss: 3.5329 - val_accuracy: 0.3613\n",
      "Epoch 881/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3916 - accuracy: 0.5396 - val_loss: 3.4887 - val_accuracy: 0.3510\n",
      "Epoch 882/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3870 - accuracy: 0.5388 - val_loss: 3.4944 - val_accuracy: 0.3571\n",
      "Epoch 883/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4028 - accuracy: 0.5359 - val_loss: 3.4727 - val_accuracy: 0.3686\n",
      "Epoch 884/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3707 - accuracy: 0.5479 - val_loss: 3.4871 - val_accuracy: 0.3534\n",
      "Epoch 885/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3836 - accuracy: 0.5474 - val_loss: 3.4842 - val_accuracy: 0.3516\n",
      "Epoch 886/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3791 - accuracy: 0.5387 - val_loss: 3.4753 - val_accuracy: 0.3583\n",
      "Epoch 887/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3829 - accuracy: 0.5437 - val_loss: 3.4316 - val_accuracy: 0.3625\n",
      "Epoch 888/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3965 - accuracy: 0.5278 - val_loss: 3.4663 - val_accuracy: 0.3613\n",
      "Epoch 889/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3930 - accuracy: 0.5379 - val_loss: 3.5267 - val_accuracy: 0.3504\n",
      "Epoch 890/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3886 - accuracy: 0.5499 - val_loss: 3.5200 - val_accuracy: 0.3467\n",
      "Epoch 891/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.3928 - accuracy: 0.5373 - val_loss: 3.4705 - val_accuracy: 0.3631\n",
      "Epoch 892/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3757 - accuracy: 0.5549 - val_loss: 3.5079 - val_accuracy: 0.3449\n",
      "Epoch 893/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3959 - accuracy: 0.5419 - val_loss: 3.4506 - val_accuracy: 0.3510\n",
      "Epoch 894/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3877 - accuracy: 0.5348 - val_loss: 3.4669 - val_accuracy: 0.3637\n",
      "Epoch 895/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3741 - accuracy: 0.5403 - val_loss: 3.4625 - val_accuracy: 0.3631\n",
      "Epoch 896/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3901 - accuracy: 0.5440 - val_loss: 3.4886 - val_accuracy: 0.3656\n",
      "Epoch 897/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3975 - accuracy: 0.5430 - val_loss: 3.5055 - val_accuracy: 0.3479\n",
      "Epoch 898/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3740 - accuracy: 0.5458 - val_loss: 3.4348 - val_accuracy: 0.3583\n",
      "Epoch 899/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3967 - accuracy: 0.5351 - val_loss: 3.5378 - val_accuracy: 0.3431\n",
      "Epoch 900/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3838 - accuracy: 0.5385 - val_loss: 3.4620 - val_accuracy: 0.3564\n",
      "Epoch 901/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3850 - accuracy: 0.5390 - val_loss: 3.4415 - val_accuracy: 0.3546\n",
      "Epoch 902/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3994 - accuracy: 0.5392 - val_loss: 3.4487 - val_accuracy: 0.3601\n",
      "Epoch 903/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3841 - accuracy: 0.5414 - val_loss: 3.5086 - val_accuracy: 0.3485\n",
      "Epoch 904/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3984 - accuracy: 0.5472 - val_loss: 3.5563 - val_accuracy: 0.3540\n",
      "Epoch 905/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3887 - accuracy: 0.5409 - val_loss: 3.5023 - val_accuracy: 0.3522\n",
      "Epoch 906/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3945 - accuracy: 0.5364 - val_loss: 3.4904 - val_accuracy: 0.3637\n",
      "Epoch 907/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4144 - accuracy: 0.5386 - val_loss: 3.5247 - val_accuracy: 0.3412\n",
      "Epoch 908/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3767 - accuracy: 0.5390 - val_loss: 3.4585 - val_accuracy: 0.3583\n",
      "Epoch 909/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3790 - accuracy: 0.5452 - val_loss: 3.4565 - val_accuracy: 0.3637\n",
      "Epoch 910/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3997 - accuracy: 0.5316 - val_loss: 3.4794 - val_accuracy: 0.3625\n",
      "Epoch 911/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3968 - accuracy: 0.5369 - val_loss: 3.4906 - val_accuracy: 0.3601\n",
      "Epoch 912/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3864 - accuracy: 0.5338 - val_loss: 3.5403 - val_accuracy: 0.3431\n",
      "Epoch 913/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3929 - accuracy: 0.5366 - val_loss: 3.4318 - val_accuracy: 0.3613\n",
      "Epoch 914/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3839 - accuracy: 0.5414 - val_loss: 3.5322 - val_accuracy: 0.3412\n",
      "Epoch 915/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3788 - accuracy: 0.5450 - val_loss: 3.4860 - val_accuracy: 0.3455\n",
      "Epoch 916/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4130 - accuracy: 0.5340 - val_loss: 3.4837 - val_accuracy: 0.3522\n",
      "Epoch 917/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3986 - accuracy: 0.5461 - val_loss: 3.4854 - val_accuracy: 0.3528\n",
      "Epoch 918/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3944 - accuracy: 0.5356 - val_loss: 3.5032 - val_accuracy: 0.3577\n",
      "Epoch 919/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4142 - accuracy: 0.5295 - val_loss: 3.5261 - val_accuracy: 0.3504\n",
      "Epoch 920/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3977 - accuracy: 0.5387 - val_loss: 3.5052 - val_accuracy: 0.3461\n",
      "Epoch 921/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3765 - accuracy: 0.5466 - val_loss: 3.5271 - val_accuracy: 0.3564\n",
      "Epoch 922/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3834 - accuracy: 0.5435 - val_loss: 3.4961 - val_accuracy: 0.3485\n",
      "Epoch 923/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3950 - accuracy: 0.5408 - val_loss: 3.4684 - val_accuracy: 0.3552\n",
      "Epoch 924/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3713 - accuracy: 0.5552 - val_loss: 3.5117 - val_accuracy: 0.3577\n",
      "Epoch 925/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3774 - accuracy: 0.5480 - val_loss: 3.4871 - val_accuracy: 0.3595\n",
      "Epoch 926/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3949 - accuracy: 0.5400 - val_loss: 3.4685 - val_accuracy: 0.3637\n",
      "Epoch 927/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3835 - accuracy: 0.5445 - val_loss: 3.5260 - val_accuracy: 0.3443\n",
      "Epoch 928/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3877 - accuracy: 0.5487 - val_loss: 3.4886 - val_accuracy: 0.3485\n",
      "Epoch 929/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3868 - accuracy: 0.5455 - val_loss: 3.5535 - val_accuracy: 0.3425\n",
      "Epoch 930/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3886 - accuracy: 0.5383 - val_loss: 3.5176 - val_accuracy: 0.3504\n",
      "Epoch 931/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3964 - accuracy: 0.5328 - val_loss: 3.5698 - val_accuracy: 0.3485\n",
      "Epoch 932/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3900 - accuracy: 0.5356 - val_loss: 3.5836 - val_accuracy: 0.3400\n",
      "Epoch 933/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3827 - accuracy: 0.5413 - val_loss: 3.5638 - val_accuracy: 0.3425\n",
      "Epoch 934/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3667 - accuracy: 0.5516 - val_loss: 3.5345 - val_accuracy: 0.3498\n",
      "Epoch 935/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3949 - accuracy: 0.5449 - val_loss: 3.5579 - val_accuracy: 0.3583\n",
      "Epoch 936/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3956 - accuracy: 0.5372 - val_loss: 3.5270 - val_accuracy: 0.3607\n",
      "Epoch 937/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3906 - accuracy: 0.5399 - val_loss: 3.5611 - val_accuracy: 0.3498\n",
      "Epoch 938/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3703 - accuracy: 0.5469 - val_loss: 3.5696 - val_accuracy: 0.3473\n",
      "Epoch 939/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3811 - accuracy: 0.5339 - val_loss: 3.5756 - val_accuracy: 0.3522\n",
      "Epoch 940/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3641 - accuracy: 0.5470 - val_loss: 3.5691 - val_accuracy: 0.3449\n",
      "Epoch 941/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3908 - accuracy: 0.5452 - val_loss: 3.5414 - val_accuracy: 0.3662\n",
      "Epoch 942/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3882 - accuracy: 0.5461 - val_loss: 3.5562 - val_accuracy: 0.3589\n",
      "Epoch 943/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4074 - accuracy: 0.5304 - val_loss: 3.5504 - val_accuracy: 0.3601\n",
      "Epoch 944/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3961 - accuracy: 0.5457 - val_loss: 3.5599 - val_accuracy: 0.3583\n",
      "Epoch 945/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3923 - accuracy: 0.5395 - val_loss: 3.5870 - val_accuracy: 0.3558\n",
      "Epoch 946/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3816 - accuracy: 0.5410 - val_loss: 3.5641 - val_accuracy: 0.3510\n",
      "Epoch 947/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3801 - accuracy: 0.5538 - val_loss: 3.5772 - val_accuracy: 0.3546\n",
      "Epoch 948/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3592 - accuracy: 0.5455 - val_loss: 3.5452 - val_accuracy: 0.3589\n",
      "Epoch 949/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4117 - accuracy: 0.5273 - val_loss: 3.5009 - val_accuracy: 0.3522\n",
      "Epoch 950/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3838 - accuracy: 0.5398 - val_loss: 3.5179 - val_accuracy: 0.3558\n",
      "Epoch 951/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3705 - accuracy: 0.5474 - val_loss: 3.5885 - val_accuracy: 0.3473\n",
      "Epoch 952/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3940 - accuracy: 0.5407 - val_loss: 3.5937 - val_accuracy: 0.3461\n",
      "Epoch 953/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3857 - accuracy: 0.5377 - val_loss: 3.5285 - val_accuracy: 0.3510\n",
      "Epoch 954/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3823 - accuracy: 0.5408 - val_loss: 3.5032 - val_accuracy: 0.3522\n",
      "Epoch 955/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4007 - accuracy: 0.5392 - val_loss: 3.5591 - val_accuracy: 0.3589\n",
      "Epoch 956/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3995 - accuracy: 0.5530 - val_loss: 3.4739 - val_accuracy: 0.3656\n",
      "Epoch 957/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3849 - accuracy: 0.5368 - val_loss: 3.4968 - val_accuracy: 0.3692\n",
      "Epoch 958/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3636 - accuracy: 0.5423 - val_loss: 3.5206 - val_accuracy: 0.3412\n",
      "Epoch 959/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3840 - accuracy: 0.5415 - val_loss: 3.4880 - val_accuracy: 0.3668\n",
      "Epoch 960/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3946 - accuracy: 0.5464 - val_loss: 3.5953 - val_accuracy: 0.3552\n",
      "Epoch 961/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.3868 - accuracy: 0.5396 - val_loss: 3.5032 - val_accuracy: 0.3637\n",
      "Epoch 962/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3712 - accuracy: 0.5478 - val_loss: 3.5114 - val_accuracy: 0.3431\n",
      "Epoch 963/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3883 - accuracy: 0.5408 - val_loss: 3.5355 - val_accuracy: 0.3546\n",
      "Epoch 964/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3911 - accuracy: 0.5414 - val_loss: 3.6196 - val_accuracy: 0.3498\n",
      "Epoch 965/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3882 - accuracy: 0.5424 - val_loss: 3.5206 - val_accuracy: 0.3522\n",
      "Epoch 966/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3786 - accuracy: 0.5423 - val_loss: 3.5261 - val_accuracy: 0.3558\n",
      "Epoch 967/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3974 - accuracy: 0.5344 - val_loss: 3.5782 - val_accuracy: 0.3546\n",
      "Epoch 968/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3946 - accuracy: 0.5447 - val_loss: 3.5338 - val_accuracy: 0.3504\n",
      "Epoch 969/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3841 - accuracy: 0.5454 - val_loss: 3.5063 - val_accuracy: 0.3571\n",
      "Epoch 970/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3939 - accuracy: 0.5394 - val_loss: 3.5138 - val_accuracy: 0.3613\n",
      "Epoch 971/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3887 - accuracy: 0.5378 - val_loss: 3.5628 - val_accuracy: 0.3552\n",
      "Epoch 972/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3768 - accuracy: 0.5440 - val_loss: 3.5462 - val_accuracy: 0.3558\n",
      "Epoch 973/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3741 - accuracy: 0.5455 - val_loss: 3.5314 - val_accuracy: 0.3461\n",
      "Epoch 974/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3784 - accuracy: 0.5380 - val_loss: 3.4869 - val_accuracy: 0.3631\n",
      "Epoch 975/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4103 - accuracy: 0.5301 - val_loss: 3.5338 - val_accuracy: 0.3467\n",
      "Epoch 976/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3658 - accuracy: 0.5430 - val_loss: 3.5393 - val_accuracy: 0.3485\n",
      "Epoch 977/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3614 - accuracy: 0.5468 - val_loss: 3.5338 - val_accuracy: 0.3406\n",
      "Epoch 978/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3861 - accuracy: 0.5388 - val_loss: 3.5429 - val_accuracy: 0.3564\n",
      "Epoch 979/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3785 - accuracy: 0.5485 - val_loss: 3.5233 - val_accuracy: 0.3589\n",
      "Epoch 980/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3919 - accuracy: 0.5407 - val_loss: 3.5474 - val_accuracy: 0.3510\n",
      "Epoch 981/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3824 - accuracy: 0.5355 - val_loss: 3.5547 - val_accuracy: 0.3637\n",
      "Epoch 982/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3968 - accuracy: 0.5447 - val_loss: 3.5072 - val_accuracy: 0.3601\n",
      "Epoch 983/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3759 - accuracy: 0.5476 - val_loss: 3.5220 - val_accuracy: 0.3491\n",
      "Epoch 984/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3860 - accuracy: 0.5357 - val_loss: 3.5514 - val_accuracy: 0.3400\n",
      "Epoch 985/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4067 - accuracy: 0.5350 - val_loss: 3.4594 - val_accuracy: 0.3619\n",
      "Epoch 986/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3963 - accuracy: 0.5414 - val_loss: 3.5330 - val_accuracy: 0.3571\n",
      "Epoch 987/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4002 - accuracy: 0.5442 - val_loss: 3.5139 - val_accuracy: 0.3595\n",
      "Epoch 988/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3816 - accuracy: 0.5508 - val_loss: 3.4433 - val_accuracy: 0.3613\n",
      "Epoch 989/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3688 - accuracy: 0.5475 - val_loss: 3.5155 - val_accuracy: 0.3528\n",
      "Epoch 990/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3732 - accuracy: 0.5467 - val_loss: 3.4751 - val_accuracy: 0.3552\n",
      "Epoch 991/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3804 - accuracy: 0.5396 - val_loss: 3.5129 - val_accuracy: 0.3504\n",
      "Epoch 992/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3888 - accuracy: 0.5367 - val_loss: 3.5426 - val_accuracy: 0.3546\n",
      "Epoch 993/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3798 - accuracy: 0.5345 - val_loss: 3.5110 - val_accuracy: 0.3498\n",
      "Epoch 994/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3776 - accuracy: 0.5476 - val_loss: 3.4997 - val_accuracy: 0.3516\n",
      "Epoch 995/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3754 - accuracy: 0.5495 - val_loss: 3.5031 - val_accuracy: 0.3498\n",
      "Epoch 996/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3881 - accuracy: 0.5417 - val_loss: 3.5518 - val_accuracy: 0.3534\n",
      "Epoch 997/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3765 - accuracy: 0.5501 - val_loss: 3.5232 - val_accuracy: 0.3528\n",
      "Epoch 998/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.3886 - accuracy: 0.5350 - val_loss: 3.4718 - val_accuracy: 0.3577\n",
      "Epoch 999/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3880 - accuracy: 0.5351 - val_loss: 3.5219 - val_accuracy: 0.3510\n",
      "Epoch 1000/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3687 - accuracy: 0.5450 - val_loss: 3.5351 - val_accuracy: 0.3540\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 16)\n",
    "history_many_to_many_complex = many_to_many_model_complex.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  \n",
    "                                              batch_size=16, \n",
    "                                              validation_data=(xx_val, yy_val)  \n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file_complex = \"many_to_many_LSTM_complex_model.h5\"  \n",
    "many_to_many_model_complex.save(model_file_complex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_complex_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_complex.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 19 (Val Accuracy: 0.45072993636131287)\n",
      "Best Epoch for Training Accuracy: 997 (Train Accuracy: 0.5489659309387207)\n",
      "Best Epoch for Training Loss: 951 (Train Loss: 1.376098394393921)\n",
      "Best Epoch for Validation Loss: 5 (Val Loss: 2.182309627532959)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.45072993636131287\n",
      "Maximum Training Accuracy: 0.5489659309387207\n",
      "Minimum Training Loss: 1.376098394393921\n",
      "Minimum Validation Loss: 2.182309627532959\n"
     ]
    }
   ],
   "source": [
    "print_metrics_history(history_many_to_many_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     barrel_turn       0.00      0.00      0.00        36\n",
      "    basic_closed       0.58      0.44      0.50       143\n",
      "      basic_open       0.00      0.00      0.00        18\n",
      "           break       0.18      0.08      0.11       106\n",
      "       come_back       0.02      0.02      0.02        81\n",
      "        corridor       0.00      0.00      0.00        11\n",
      " frankie´s_sixes       0.17      0.05      0.08        41\n",
      "     groove_walk       0.00      0.00      0.00        10\n",
      "hallelujah_rocks       0.00      0.00      0.00         4\n",
      "    hand_to_hand       0.00      0.00      0.00         8\n",
      "     inside_spin       0.00      0.00      0.00         4\n",
      "     inside_turn       0.00      0.00      0.00        35\n",
      "    lindy_circle       0.00      0.00      0.00         4\n",
      "    outside_spin       0.04      0.03      0.03        40\n",
      "    outside_turn       0.12      0.04      0.06        24\n",
      "         pass_by       0.46      0.65      0.54       650\n",
      "        pop_turn       0.00      0.00      0.00         1\n",
      "       promenade       0.00      0.00      0.00        12\n",
      "          s_turn       0.00      0.00      0.00         4\n",
      "    sailor_kicks       0.00      0.00      0.00         4\n",
      "        send_out       0.05      0.06      0.06        16\n",
      "      sling_shot       0.00      0.00      0.00         8\n",
      "      sugar_push       0.13      0.06      0.08        64\n",
      "      sweetheart       0.08      0.02      0.03        54\n",
      "        swingout       0.19      0.17      0.18       163\n",
      "        switches       0.00      0.00      0.00         4\n",
      "          tandem       0.00      0.00      0.00         5\n",
      "       tuck_turn       0.37      0.50      0.42        94\n",
      "\n",
      "        accuracy                           0.35      1644\n",
      "       macro avg       0.09      0.08      0.08      1644\n",
      "    weighted avg       0.30      0.35      0.32      1644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict classes on the test set\n",
    "yy_pred = many_to_many_model_complex.predict(xx_val)\n",
    "\n",
    "# Convert predictions from one-hot encoded back to label indices\n",
    "yy_pred_classes = np.argmax(yy_pred, axis=-1)\n",
    "yy_true_classes = np.argmax(yy_val, axis=-1)\n",
    "\n",
    "# Convert numeric classes to actual labels\n",
    "yy_pred_labels = [class_labels[i] for i in yy_pred_classes.flatten()]\n",
    "yy_true_labels = [class_labels[i] for i in yy_true_classes.flatten()]\n",
    "\n",
    "# Generate a confusion matrix\n",
    "#conf_matrix = confusion_matrix(yy_true_classes.flatten(), yy_pred_classes.flatten())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "class_report = classification_report(yy_true_labels, yy_pred_labels, zero_division=0)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and axis to plot on\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # You can adjust the figure size as needed\n",
    "\n",
    "# Add the classification report text\n",
    "ax.text(0.5, 0.5, class_report, horizontalalignment='center', verticalalignment='center', \n",
    "        fontsize=12, family='monospace')\n",
    "\n",
    "# Remove the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure \n",
    "plt.savefig('classification_report_many_to_many_model_complex.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_complex, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3950 - accuracy: 0.5400 - val_loss: 3.5471 - val_accuracy: 0.3583\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3820 - accuracy: 0.5405 - val_loss: 3.5842 - val_accuracy: 0.3534\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3799 - accuracy: 0.5455 - val_loss: 3.5836 - val_accuracy: 0.3552\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3832 - accuracy: 0.5443 - val_loss: 3.5858 - val_accuracy: 0.3571\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3775 - accuracy: 0.5403 - val_loss: 3.5745 - val_accuracy: 0.3528\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3737 - accuracy: 0.5465 - val_loss: 3.6101 - val_accuracy: 0.3601\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3753 - accuracy: 0.5438 - val_loss: 3.5699 - val_accuracy: 0.3479\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3817 - accuracy: 0.5377 - val_loss: 3.6014 - val_accuracy: 0.3412\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3866 - accuracy: 0.5405 - val_loss: 3.5554 - val_accuracy: 0.3406\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3738 - accuracy: 0.5473 - val_loss: 3.5850 - val_accuracy: 0.3382\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3772 - accuracy: 0.5455 - val_loss: 3.6203 - val_accuracy: 0.3571\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3785 - accuracy: 0.5456 - val_loss: 3.6527 - val_accuracy: 0.3564\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3781 - accuracy: 0.5476 - val_loss: 3.6339 - val_accuracy: 0.3449\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3782 - accuracy: 0.5461 - val_loss: 3.6443 - val_accuracy: 0.3461\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3823 - accuracy: 0.5438 - val_loss: 3.5971 - val_accuracy: 0.3467\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3704 - accuracy: 0.5470 - val_loss: 3.5987 - val_accuracy: 0.3467\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3767 - accuracy: 0.5433 - val_loss: 3.6017 - val_accuracy: 0.3461\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3714 - accuracy: 0.5391 - val_loss: 3.5828 - val_accuracy: 0.3479\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3797 - accuracy: 0.5458 - val_loss: 3.5917 - val_accuracy: 0.3473\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3834 - accuracy: 0.5421 - val_loss: 3.6054 - val_accuracy: 0.3522\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3798 - accuracy: 0.5383 - val_loss: 3.6065 - val_accuracy: 0.3522\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3832 - accuracy: 0.5411 - val_loss: 3.5708 - val_accuracy: 0.3510\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3794 - accuracy: 0.5423 - val_loss: 3.6061 - val_accuracy: 0.3425\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3682 - accuracy: 0.5490 - val_loss: 3.6444 - val_accuracy: 0.3583\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3860 - accuracy: 0.5383 - val_loss: 3.6241 - val_accuracy: 0.3473\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3836 - accuracy: 0.5406 - val_loss: 3.6068 - val_accuracy: 0.3425\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3835 - accuracy: 0.5436 - val_loss: 3.6122 - val_accuracy: 0.3540\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3830 - accuracy: 0.5392 - val_loss: 3.6267 - val_accuracy: 0.3552\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3679 - accuracy: 0.5458 - val_loss: 3.6290 - val_accuracy: 0.3510\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3759 - accuracy: 0.5449 - val_loss: 3.6378 - val_accuracy: 0.3479\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3711 - accuracy: 0.5426 - val_loss: 3.6255 - val_accuracy: 0.3552\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3731 - accuracy: 0.5382 - val_loss: 3.6224 - val_accuracy: 0.3485\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3808 - accuracy: 0.5409 - val_loss: 3.6068 - val_accuracy: 0.3534\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3785 - accuracy: 0.5424 - val_loss: 3.5712 - val_accuracy: 0.3546\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3734 - accuracy: 0.5409 - val_loss: 3.6114 - val_accuracy: 0.3510\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3752 - accuracy: 0.5439 - val_loss: 3.5854 - val_accuracy: 0.3522\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3747 - accuracy: 0.5452 - val_loss: 3.6125 - val_accuracy: 0.3631\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3714 - accuracy: 0.5473 - val_loss: 3.6377 - val_accuracy: 0.3540\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3670 - accuracy: 0.5435 - val_loss: 3.6543 - val_accuracy: 0.3546\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3782 - accuracy: 0.5383 - val_loss: 3.5967 - val_accuracy: 0.3558\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3802 - accuracy: 0.5403 - val_loss: 3.6035 - val_accuracy: 0.3510\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3861 - accuracy: 0.5374 - val_loss: 3.6259 - val_accuracy: 0.3564\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3790 - accuracy: 0.5391 - val_loss: 3.6139 - val_accuracy: 0.3589\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3709 - accuracy: 0.5446 - val_loss: 3.6462 - val_accuracy: 0.3680\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3731 - accuracy: 0.5423 - val_loss: 3.5812 - val_accuracy: 0.3631\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3765 - accuracy: 0.5426 - val_loss: 3.6250 - val_accuracy: 0.3601\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3701 - accuracy: 0.5482 - val_loss: 3.6584 - val_accuracy: 0.3522\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3788 - accuracy: 0.5450 - val_loss: 3.6236 - val_accuracy: 0.3479\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3718 - accuracy: 0.5435 - val_loss: 3.6430 - val_accuracy: 0.3558\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3832 - accuracy: 0.5429 - val_loss: 3.6244 - val_accuracy: 0.3510\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3770 - accuracy: 0.5453 - val_loss: 3.6348 - val_accuracy: 0.3595\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3797 - accuracy: 0.5446 - val_loss: 3.6283 - val_accuracy: 0.3485\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3729 - accuracy: 0.5438 - val_loss: 3.6263 - val_accuracy: 0.3558\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3663 - accuracy: 0.5491 - val_loss: 3.6138 - val_accuracy: 0.3443\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3682 - accuracy: 0.5438 - val_loss: 3.6115 - val_accuracy: 0.3613\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3836 - accuracy: 0.5400 - val_loss: 3.6306 - val_accuracy: 0.3449\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3805 - accuracy: 0.5421 - val_loss: 3.6055 - val_accuracy: 0.3595\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3817 - accuracy: 0.5465 - val_loss: 3.6027 - val_accuracy: 0.3577\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3725 - accuracy: 0.5424 - val_loss: 3.5811 - val_accuracy: 0.3564\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3861 - accuracy: 0.5415 - val_loss: 3.5730 - val_accuracy: 0.3510\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3807 - accuracy: 0.5443 - val_loss: 3.6125 - val_accuracy: 0.3607\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3757 - accuracy: 0.5458 - val_loss: 3.6047 - val_accuracy: 0.3571\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3736 - accuracy: 0.5438 - val_loss: 3.6206 - val_accuracy: 0.3564\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3756 - accuracy: 0.5417 - val_loss: 3.5658 - val_accuracy: 0.3552\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3754 - accuracy: 0.5453 - val_loss: 3.6624 - val_accuracy: 0.3607\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3851 - accuracy: 0.5423 - val_loss: 3.6266 - val_accuracy: 0.3637\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3792 - accuracy: 0.5394 - val_loss: 3.6064 - val_accuracy: 0.3650\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3721 - accuracy: 0.5450 - val_loss: 3.6154 - val_accuracy: 0.3637\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3884 - accuracy: 0.5412 - val_loss: 3.5602 - val_accuracy: 0.3637\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3783 - accuracy: 0.5446 - val_loss: 3.6179 - val_accuracy: 0.3485\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3723 - accuracy: 0.5423 - val_loss: 3.5619 - val_accuracy: 0.3662\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3801 - accuracy: 0.5449 - val_loss: 3.5750 - val_accuracy: 0.3625\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3814 - accuracy: 0.5408 - val_loss: 3.6065 - val_accuracy: 0.3479\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3813 - accuracy: 0.5386 - val_loss: 3.6033 - val_accuracy: 0.3577\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3764 - accuracy: 0.5405 - val_loss: 3.6313 - val_accuracy: 0.3546\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3721 - accuracy: 0.5464 - val_loss: 3.6277 - val_accuracy: 0.3571\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3757 - accuracy: 0.5435 - val_loss: 3.5912 - val_accuracy: 0.3571\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3653 - accuracy: 0.5435 - val_loss: 3.6779 - val_accuracy: 0.3644\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3763 - accuracy: 0.5426 - val_loss: 3.5685 - val_accuracy: 0.3552\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3872 - accuracy: 0.5424 - val_loss: 3.5970 - val_accuracy: 0.3571\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3747 - accuracy: 0.5429 - val_loss: 3.6137 - val_accuracy: 0.3504\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3757 - accuracy: 0.5423 - val_loss: 3.5959 - val_accuracy: 0.3461\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3935 - accuracy: 0.5395 - val_loss: 3.5796 - val_accuracy: 0.3461\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3679 - accuracy: 0.5447 - val_loss: 3.6341 - val_accuracy: 0.3613\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3738 - accuracy: 0.5380 - val_loss: 3.6124 - val_accuracy: 0.3589\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3818 - accuracy: 0.5436 - val_loss: 3.5878 - val_accuracy: 0.3522\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3815 - accuracy: 0.5470 - val_loss: 3.6261 - val_accuracy: 0.3564\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3770 - accuracy: 0.5430 - val_loss: 3.5430 - val_accuracy: 0.3650\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3798 - accuracy: 0.5439 - val_loss: 3.5907 - val_accuracy: 0.3601\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3772 - accuracy: 0.5436 - val_loss: 3.6258 - val_accuracy: 0.3644\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3901 - accuracy: 0.5405 - val_loss: 3.5520 - val_accuracy: 0.3577\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3777 - accuracy: 0.5414 - val_loss: 3.5981 - val_accuracy: 0.3650\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3764 - accuracy: 0.5467 - val_loss: 3.5886 - val_accuracy: 0.3528\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3719 - accuracy: 0.5432 - val_loss: 3.5819 - val_accuracy: 0.3467\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3716 - accuracy: 0.5438 - val_loss: 3.5907 - val_accuracy: 0.3546\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3774 - accuracy: 0.5439 - val_loss: 3.6221 - val_accuracy: 0.3461\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3677 - accuracy: 0.5435 - val_loss: 3.6416 - val_accuracy: 0.3528\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3791 - accuracy: 0.5441 - val_loss: 3.6068 - val_accuracy: 0.3455\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3685 - accuracy: 0.5435 - val_loss: 3.5908 - val_accuracy: 0.3449\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3733 - accuracy: 0.5443 - val_loss: 3.5966 - val_accuracy: 0.3528\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3731 - accuracy: 0.5474 - val_loss: 3.6211 - val_accuracy: 0.3668\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3825 - accuracy: 0.5398 - val_loss: 3.6442 - val_accuracy: 0.3485\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3729 - accuracy: 0.5497 - val_loss: 3.6127 - val_accuracy: 0.3589\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3758 - accuracy: 0.5408 - val_loss: 3.6351 - val_accuracy: 0.3546\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3751 - accuracy: 0.5439 - val_loss: 3.6131 - val_accuracy: 0.3595\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3728 - accuracy: 0.5474 - val_loss: 3.6045 - val_accuracy: 0.3528\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3726 - accuracy: 0.5426 - val_loss: 3.6172 - val_accuracy: 0.3571\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3739 - accuracy: 0.5452 - val_loss: 3.6020 - val_accuracy: 0.3607\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3781 - accuracy: 0.5424 - val_loss: 3.5987 - val_accuracy: 0.3601\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3736 - accuracy: 0.5432 - val_loss: 3.6152 - val_accuracy: 0.3619\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3792 - accuracy: 0.5418 - val_loss: 3.6183 - val_accuracy: 0.3595\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3838 - accuracy: 0.5415 - val_loss: 3.6341 - val_accuracy: 0.3510\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3826 - accuracy: 0.5414 - val_loss: 3.5999 - val_accuracy: 0.3583\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3909 - accuracy: 0.5388 - val_loss: 3.5779 - val_accuracy: 0.3516\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3806 - accuracy: 0.5490 - val_loss: 3.6261 - val_accuracy: 0.3571\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3700 - accuracy: 0.5432 - val_loss: 3.6192 - val_accuracy: 0.3473\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3806 - accuracy: 0.5391 - val_loss: 3.6142 - val_accuracy: 0.3625\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3704 - accuracy: 0.5439 - val_loss: 3.6129 - val_accuracy: 0.3619\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3780 - accuracy: 0.5415 - val_loss: 3.5936 - val_accuracy: 0.3510\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3792 - accuracy: 0.5388 - val_loss: 3.6135 - val_accuracy: 0.3528\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3848 - accuracy: 0.5359 - val_loss: 3.6231 - val_accuracy: 0.3491\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3743 - accuracy: 0.5438 - val_loss: 3.6426 - val_accuracy: 0.3406\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3715 - accuracy: 0.5471 - val_loss: 3.6571 - val_accuracy: 0.3583\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3711 - accuracy: 0.5484 - val_loss: 3.6397 - val_accuracy: 0.3461\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3863 - accuracy: 0.5409 - val_loss: 3.6129 - val_accuracy: 0.3564\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3810 - accuracy: 0.5417 - val_loss: 3.6212 - val_accuracy: 0.3552\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3788 - accuracy: 0.5420 - val_loss: 3.6446 - val_accuracy: 0.3510\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3729 - accuracy: 0.5417 - val_loss: 3.6189 - val_accuracy: 0.3455\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3782 - accuracy: 0.5476 - val_loss: 3.6476 - val_accuracy: 0.3522\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3691 - accuracy: 0.5435 - val_loss: 3.6430 - val_accuracy: 0.3546\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3791 - accuracy: 0.5439 - val_loss: 3.6383 - val_accuracy: 0.3577\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3678 - accuracy: 0.5456 - val_loss: 3.6796 - val_accuracy: 0.3589\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3737 - accuracy: 0.5465 - val_loss: 3.6509 - val_accuracy: 0.3589\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3786 - accuracy: 0.5427 - val_loss: 3.6013 - val_accuracy: 0.3625\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3722 - accuracy: 0.5443 - val_loss: 3.6368 - val_accuracy: 0.3510\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3742 - accuracy: 0.5473 - val_loss: 3.6233 - val_accuracy: 0.3546\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3783 - accuracy: 0.5427 - val_loss: 3.6331 - val_accuracy: 0.3491\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3802 - accuracy: 0.5409 - val_loss: 3.6363 - val_accuracy: 0.3504\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3717 - accuracy: 0.5417 - val_loss: 3.6379 - val_accuracy: 0.3552\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3688 - accuracy: 0.5411 - val_loss: 3.6076 - val_accuracy: 0.3540\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3736 - accuracy: 0.5461 - val_loss: 3.6525 - val_accuracy: 0.3479\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3823 - accuracy: 0.5435 - val_loss: 3.6380 - val_accuracy: 0.3528\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3771 - accuracy: 0.5405 - val_loss: 3.5841 - val_accuracy: 0.3516\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3734 - accuracy: 0.5490 - val_loss: 3.6259 - val_accuracy: 0.3577\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3758 - accuracy: 0.5459 - val_loss: 3.6497 - val_accuracy: 0.3577\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3818 - accuracy: 0.5408 - val_loss: 3.6595 - val_accuracy: 0.3558\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3753 - accuracy: 0.5432 - val_loss: 3.6435 - val_accuracy: 0.3540\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3689 - accuracy: 0.5481 - val_loss: 3.6255 - val_accuracy: 0.3583\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3758 - accuracy: 0.5397 - val_loss: 3.6604 - val_accuracy: 0.3589\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3724 - accuracy: 0.5414 - val_loss: 3.6516 - val_accuracy: 0.3631\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3731 - accuracy: 0.5481 - val_loss: 3.6618 - val_accuracy: 0.3540\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3677 - accuracy: 0.5423 - val_loss: 3.6512 - val_accuracy: 0.3595\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3694 - accuracy: 0.5415 - val_loss: 3.6656 - val_accuracy: 0.3668\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3770 - accuracy: 0.5490 - val_loss: 3.6147 - val_accuracy: 0.3546\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3744 - accuracy: 0.5427 - val_loss: 3.6761 - val_accuracy: 0.3522\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3734 - accuracy: 0.5429 - val_loss: 3.6344 - val_accuracy: 0.3522\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3790 - accuracy: 0.5401 - val_loss: 3.6144 - val_accuracy: 0.3546\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3722 - accuracy: 0.5439 - val_loss: 3.6380 - val_accuracy: 0.3607\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3700 - accuracy: 0.5482 - val_loss: 3.6281 - val_accuracy: 0.3644\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3816 - accuracy: 0.5433 - val_loss: 3.6779 - val_accuracy: 0.3583\n",
      "Epoch 161/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3640 - accuracy: 0.5476 - val_loss: 3.6665 - val_accuracy: 0.3662\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3721 - accuracy: 0.5461 - val_loss: 3.6431 - val_accuracy: 0.3613\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3703 - accuracy: 0.5474 - val_loss: 3.6601 - val_accuracy: 0.3625\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3737 - accuracy: 0.5470 - val_loss: 3.6765 - val_accuracy: 0.3631\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3770 - accuracy: 0.5438 - val_loss: 3.6750 - val_accuracy: 0.3583\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3695 - accuracy: 0.5470 - val_loss: 3.6469 - val_accuracy: 0.3595\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3707 - accuracy: 0.5429 - val_loss: 3.6678 - val_accuracy: 0.3589\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3742 - accuracy: 0.5444 - val_loss: 3.6457 - val_accuracy: 0.3467\n",
      "Epoch 169/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3700 - accuracy: 0.5456 - val_loss: 3.6979 - val_accuracy: 0.3577\n",
      "Epoch 170/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3770 - accuracy: 0.5418 - val_loss: 3.6739 - val_accuracy: 0.3619\n",
      "Epoch 171/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3722 - accuracy: 0.5453 - val_loss: 3.6890 - val_accuracy: 0.3631\n",
      "Epoch 172/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3682 - accuracy: 0.5497 - val_loss: 3.6556 - val_accuracy: 0.3516\n",
      "Epoch 173/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3755 - accuracy: 0.5441 - val_loss: 3.6547 - val_accuracy: 0.3504\n",
      "Epoch 174/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3790 - accuracy: 0.5423 - val_loss: 3.6221 - val_accuracy: 0.3510\n",
      "Epoch 175/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3691 - accuracy: 0.5470 - val_loss: 3.6784 - val_accuracy: 0.3437\n",
      "Epoch 176/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3649 - accuracy: 0.5412 - val_loss: 3.6851 - val_accuracy: 0.3564\n",
      "Epoch 177/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3715 - accuracy: 0.5470 - val_loss: 3.6920 - val_accuracy: 0.3418\n",
      "Epoch 178/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3686 - accuracy: 0.5444 - val_loss: 3.6070 - val_accuracy: 0.3467\n",
      "Epoch 179/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3774 - accuracy: 0.5405 - val_loss: 3.6448 - val_accuracy: 0.3601\n",
      "Epoch 180/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3717 - accuracy: 0.5374 - val_loss: 3.6250 - val_accuracy: 0.3625\n",
      "Epoch 181/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3668 - accuracy: 0.5494 - val_loss: 3.6663 - val_accuracy: 0.3498\n",
      "Epoch 182/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3790 - accuracy: 0.5441 - val_loss: 3.6421 - val_accuracy: 0.3467\n",
      "Epoch 183/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3756 - accuracy: 0.5412 - val_loss: 3.6660 - val_accuracy: 0.3558\n",
      "Epoch 184/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3754 - accuracy: 0.5406 - val_loss: 3.6398 - val_accuracy: 0.3449\n",
      "Epoch 185/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3806 - accuracy: 0.5443 - val_loss: 3.6852 - val_accuracy: 0.3455\n",
      "Epoch 186/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3641 - accuracy: 0.5408 - val_loss: 3.6943 - val_accuracy: 0.3558\n",
      "Epoch 187/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3696 - accuracy: 0.5456 - val_loss: 3.6513 - val_accuracy: 0.3485\n",
      "Epoch 188/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3611 - accuracy: 0.5517 - val_loss: 3.6698 - val_accuracy: 0.3558\n",
      "Epoch 189/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3748 - accuracy: 0.5484 - val_loss: 3.6521 - val_accuracy: 0.3461\n",
      "Epoch 190/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3744 - accuracy: 0.5405 - val_loss: 3.7118 - val_accuracy: 0.3418\n",
      "Epoch 191/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3780 - accuracy: 0.5433 - val_loss: 3.6497 - val_accuracy: 0.3491\n",
      "Epoch 192/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3608 - accuracy: 0.5520 - val_loss: 3.6716 - val_accuracy: 0.3601\n",
      "Epoch 193/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3667 - accuracy: 0.5484 - val_loss: 3.6984 - val_accuracy: 0.3613\n",
      "Epoch 194/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3661 - accuracy: 0.5427 - val_loss: 3.6758 - val_accuracy: 0.3498\n",
      "Epoch 195/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3731 - accuracy: 0.5383 - val_loss: 3.6947 - val_accuracy: 0.3516\n",
      "Epoch 196/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3644 - accuracy: 0.5499 - val_loss: 3.7195 - val_accuracy: 0.3558\n",
      "Epoch 197/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3723 - accuracy: 0.5424 - val_loss: 3.6588 - val_accuracy: 0.3467\n",
      "Epoch 198/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3685 - accuracy: 0.5508 - val_loss: 3.6624 - val_accuracy: 0.3534\n",
      "Epoch 199/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3689 - accuracy: 0.5427 - val_loss: 3.6378 - val_accuracy: 0.3491\n",
      "Epoch 200/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3731 - accuracy: 0.5417 - val_loss: 3.6523 - val_accuracy: 0.3449\n",
      "Epoch 201/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3670 - accuracy: 0.5474 - val_loss: 3.6583 - val_accuracy: 0.3461\n",
      "Epoch 202/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3742 - accuracy: 0.5418 - val_loss: 3.6441 - val_accuracy: 0.3479\n",
      "Epoch 203/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3627 - accuracy: 0.5552 - val_loss: 3.6544 - val_accuracy: 0.3485\n",
      "Epoch 204/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3694 - accuracy: 0.5405 - val_loss: 3.6477 - val_accuracy: 0.3418\n",
      "Epoch 205/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3627 - accuracy: 0.5450 - val_loss: 3.6768 - val_accuracy: 0.3485\n",
      "Epoch 206/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3597 - accuracy: 0.5484 - val_loss: 3.6060 - val_accuracy: 0.3589\n",
      "Epoch 207/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3713 - accuracy: 0.5453 - val_loss: 3.6968 - val_accuracy: 0.3455\n",
      "Epoch 208/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3877 - accuracy: 0.5409 - val_loss: 3.6211 - val_accuracy: 0.3540\n",
      "Epoch 209/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3717 - accuracy: 0.5447 - val_loss: 3.6529 - val_accuracy: 0.3546\n",
      "Epoch 210/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3640 - accuracy: 0.5484 - val_loss: 3.6807 - val_accuracy: 0.3449\n",
      "Epoch 211/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3742 - accuracy: 0.5432 - val_loss: 3.6451 - val_accuracy: 0.3504\n",
      "Epoch 212/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3625 - accuracy: 0.5420 - val_loss: 3.6740 - val_accuracy: 0.3498\n",
      "Epoch 213/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3609 - accuracy: 0.5474 - val_loss: 3.6818 - val_accuracy: 0.3467\n",
      "Epoch 214/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3725 - accuracy: 0.5436 - val_loss: 3.6532 - val_accuracy: 0.3449\n",
      "Epoch 215/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3670 - accuracy: 0.5450 - val_loss: 3.6677 - val_accuracy: 0.3485\n",
      "Epoch 216/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3712 - accuracy: 0.5443 - val_loss: 3.6687 - val_accuracy: 0.3528\n",
      "Epoch 217/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3777 - accuracy: 0.5379 - val_loss: 3.6106 - val_accuracy: 0.3431\n",
      "Epoch 218/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3683 - accuracy: 0.5455 - val_loss: 3.6355 - val_accuracy: 0.3437\n",
      "Epoch 219/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3640 - accuracy: 0.5499 - val_loss: 3.6429 - val_accuracy: 0.3504\n",
      "Epoch 220/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3800 - accuracy: 0.5406 - val_loss: 3.6360 - val_accuracy: 0.3631\n",
      "Epoch 221/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3599 - accuracy: 0.5468 - val_loss: 3.6356 - val_accuracy: 0.3619\n",
      "Epoch 222/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3658 - accuracy: 0.5461 - val_loss: 3.6874 - val_accuracy: 0.3437\n",
      "Epoch 223/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3732 - accuracy: 0.5435 - val_loss: 3.7033 - val_accuracy: 0.3479\n",
      "Epoch 224/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3684 - accuracy: 0.5420 - val_loss: 3.6559 - val_accuracy: 0.3449\n",
      "Epoch 225/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3681 - accuracy: 0.5473 - val_loss: 3.6513 - val_accuracy: 0.3498\n",
      "Epoch 226/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3677 - accuracy: 0.5418 - val_loss: 3.6491 - val_accuracy: 0.3431\n",
      "Epoch 227/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3682 - accuracy: 0.5436 - val_loss: 3.6531 - val_accuracy: 0.3437\n",
      "Epoch 228/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3645 - accuracy: 0.5461 - val_loss: 3.6369 - val_accuracy: 0.3437\n",
      "Epoch 229/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3627 - accuracy: 0.5458 - val_loss: 3.6520 - val_accuracy: 0.3479\n",
      "Epoch 230/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3688 - accuracy: 0.5412 - val_loss: 3.6524 - val_accuracy: 0.3619\n",
      "Epoch 231/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3719 - accuracy: 0.5429 - val_loss: 3.6482 - val_accuracy: 0.3491\n",
      "Epoch 232/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3710 - accuracy: 0.5482 - val_loss: 3.6585 - val_accuracy: 0.3510\n",
      "Epoch 233/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3716 - accuracy: 0.5430 - val_loss: 3.6492 - val_accuracy: 0.3571\n",
      "Epoch 234/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3770 - accuracy: 0.5373 - val_loss: 3.6319 - val_accuracy: 0.3431\n",
      "Epoch 235/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3771 - accuracy: 0.5433 - val_loss: 3.6013 - val_accuracy: 0.3595\n",
      "Epoch 236/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3719 - accuracy: 0.5395 - val_loss: 3.6834 - val_accuracy: 0.3467\n",
      "Epoch 237/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3692 - accuracy: 0.5436 - val_loss: 3.6866 - val_accuracy: 0.3491\n",
      "Epoch 238/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3685 - accuracy: 0.5412 - val_loss: 3.6548 - val_accuracy: 0.3485\n",
      "Epoch 239/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3840 - accuracy: 0.5401 - val_loss: 3.6599 - val_accuracy: 0.3583\n",
      "Epoch 240/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3724 - accuracy: 0.5476 - val_loss: 3.6485 - val_accuracy: 0.3534\n",
      "Epoch 241/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3623 - accuracy: 0.5456 - val_loss: 3.6630 - val_accuracy: 0.3564\n",
      "Epoch 242/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3792 - accuracy: 0.5406 - val_loss: 3.6422 - val_accuracy: 0.3601\n",
      "Epoch 243/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3734 - accuracy: 0.5481 - val_loss: 3.6259 - val_accuracy: 0.3656\n",
      "Epoch 244/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3818 - accuracy: 0.5383 - val_loss: 3.6881 - val_accuracy: 0.3461\n",
      "Epoch 245/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3795 - accuracy: 0.5426 - val_loss: 3.6445 - val_accuracy: 0.3564\n",
      "Epoch 246/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3764 - accuracy: 0.5433 - val_loss: 3.6476 - val_accuracy: 0.3461\n",
      "Epoch 247/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3806 - accuracy: 0.5415 - val_loss: 3.6590 - val_accuracy: 0.3558\n",
      "Epoch 248/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3738 - accuracy: 0.5435 - val_loss: 3.6919 - val_accuracy: 0.3552\n",
      "Epoch 249/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3736 - accuracy: 0.5423 - val_loss: 3.6829 - val_accuracy: 0.3601\n",
      "Epoch 250/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3679 - accuracy: 0.5450 - val_loss: 3.6688 - val_accuracy: 0.3577\n",
      "Epoch 251/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3815 - accuracy: 0.5438 - val_loss: 3.6302 - val_accuracy: 0.3644\n",
      "Epoch 252/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3626 - accuracy: 0.5481 - val_loss: 3.6760 - val_accuracy: 0.3571\n",
      "Epoch 253/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3707 - accuracy: 0.5456 - val_loss: 3.6646 - val_accuracy: 0.3564\n",
      "Epoch 254/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3672 - accuracy: 0.5426 - val_loss: 3.6718 - val_accuracy: 0.3583\n",
      "Epoch 255/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3710 - accuracy: 0.5438 - val_loss: 3.6869 - val_accuracy: 0.3571\n",
      "Epoch 256/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3640 - accuracy: 0.5468 - val_loss: 3.6449 - val_accuracy: 0.3619\n",
      "Epoch 257/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3664 - accuracy: 0.5455 - val_loss: 3.6606 - val_accuracy: 0.3461\n",
      "Epoch 258/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3639 - accuracy: 0.5450 - val_loss: 3.6935 - val_accuracy: 0.3546\n",
      "Epoch 259/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3635 - accuracy: 0.5438 - val_loss: 3.6881 - val_accuracy: 0.3564\n",
      "Epoch 260/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3747 - accuracy: 0.5450 - val_loss: 3.7181 - val_accuracy: 0.3595\n",
      "Epoch 261/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3607 - accuracy: 0.5485 - val_loss: 3.6900 - val_accuracy: 0.3577\n",
      "Epoch 262/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3691 - accuracy: 0.5477 - val_loss: 3.6862 - val_accuracy: 0.3534\n",
      "Epoch 263/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3582 - accuracy: 0.5491 - val_loss: 3.6989 - val_accuracy: 0.3601\n",
      "Epoch 264/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3753 - accuracy: 0.5461 - val_loss: 3.6671 - val_accuracy: 0.3558\n",
      "Epoch 265/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3753 - accuracy: 0.5441 - val_loss: 3.6997 - val_accuracy: 0.3577\n",
      "Epoch 266/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3660 - accuracy: 0.5438 - val_loss: 3.6772 - val_accuracy: 0.3558\n",
      "Epoch 267/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3631 - accuracy: 0.5481 - val_loss: 3.7154 - val_accuracy: 0.3528\n",
      "Epoch 268/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3675 - accuracy: 0.5430 - val_loss: 3.6788 - val_accuracy: 0.3564\n",
      "Epoch 269/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3673 - accuracy: 0.5420 - val_loss: 3.6812 - val_accuracy: 0.3564\n",
      "Epoch 270/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3769 - accuracy: 0.5401 - val_loss: 3.6810 - val_accuracy: 0.3449\n",
      "Epoch 271/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3751 - accuracy: 0.5366 - val_loss: 3.6600 - val_accuracy: 0.3437\n",
      "Epoch 272/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3630 - accuracy: 0.5511 - val_loss: 3.6637 - val_accuracy: 0.3437\n",
      "Epoch 273/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3655 - accuracy: 0.5462 - val_loss: 3.6659 - val_accuracy: 0.3504\n",
      "Epoch 274/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3634 - accuracy: 0.5470 - val_loss: 3.6738 - val_accuracy: 0.3552\n",
      "Epoch 275/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3800 - accuracy: 0.5398 - val_loss: 3.6804 - val_accuracy: 0.3650\n",
      "Epoch 276/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3585 - accuracy: 0.5487 - val_loss: 3.7338 - val_accuracy: 0.3601\n",
      "Epoch 277/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3710 - accuracy: 0.5450 - val_loss: 3.7012 - val_accuracy: 0.3504\n",
      "Epoch 278/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3678 - accuracy: 0.5481 - val_loss: 3.7343 - val_accuracy: 0.3571\n",
      "Epoch 279/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3603 - accuracy: 0.5471 - val_loss: 3.7232 - val_accuracy: 0.3619\n",
      "Epoch 280/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3714 - accuracy: 0.5429 - val_loss: 3.7083 - val_accuracy: 0.3571\n",
      "Epoch 281/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3673 - accuracy: 0.5476 - val_loss: 3.6938 - val_accuracy: 0.3485\n",
      "Epoch 282/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3697 - accuracy: 0.5415 - val_loss: 3.6955 - val_accuracy: 0.3479\n",
      "Epoch 283/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3719 - accuracy: 0.5395 - val_loss: 3.6616 - val_accuracy: 0.3601\n",
      "Epoch 284/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3688 - accuracy: 0.5438 - val_loss: 3.7338 - val_accuracy: 0.3479\n",
      "Epoch 285/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3720 - accuracy: 0.5453 - val_loss: 3.7114 - val_accuracy: 0.3479\n",
      "Epoch 286/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3723 - accuracy: 0.5444 - val_loss: 3.6969 - val_accuracy: 0.3650\n",
      "Epoch 287/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3631 - accuracy: 0.5436 - val_loss: 3.7255 - val_accuracy: 0.3498\n",
      "Epoch 288/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3684 - accuracy: 0.5436 - val_loss: 3.6930 - val_accuracy: 0.3431\n",
      "Epoch 289/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3697 - accuracy: 0.5459 - val_loss: 3.7149 - val_accuracy: 0.3595\n",
      "Epoch 290/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3679 - accuracy: 0.5458 - val_loss: 3.7160 - val_accuracy: 0.3461\n",
      "Epoch 291/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3762 - accuracy: 0.5408 - val_loss: 3.6912 - val_accuracy: 0.3449\n",
      "Epoch 292/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3667 - accuracy: 0.5496 - val_loss: 3.6705 - val_accuracy: 0.3485\n",
      "Epoch 293/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3703 - accuracy: 0.5468 - val_loss: 3.7110 - val_accuracy: 0.3443\n",
      "Epoch 294/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3719 - accuracy: 0.5420 - val_loss: 3.6492 - val_accuracy: 0.3558\n",
      "Epoch 295/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3629 - accuracy: 0.5453 - val_loss: 3.7073 - val_accuracy: 0.3564\n",
      "Epoch 296/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3632 - accuracy: 0.5514 - val_loss: 3.6639 - val_accuracy: 0.3564\n",
      "Epoch 297/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3679 - accuracy: 0.5427 - val_loss: 3.6641 - val_accuracy: 0.3589\n",
      "Epoch 298/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3705 - accuracy: 0.5433 - val_loss: 3.6994 - val_accuracy: 0.3577\n",
      "Epoch 299/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3743 - accuracy: 0.5386 - val_loss: 3.6691 - val_accuracy: 0.3522\n",
      "Epoch 300/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3774 - accuracy: 0.5429 - val_loss: 3.6492 - val_accuracy: 0.3571\n",
      "Epoch 301/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3749 - accuracy: 0.5394 - val_loss: 3.6443 - val_accuracy: 0.3631\n",
      "Epoch 302/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3648 - accuracy: 0.5438 - val_loss: 3.7314 - val_accuracy: 0.3522\n",
      "Epoch 303/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3782 - accuracy: 0.5401 - val_loss: 3.6745 - val_accuracy: 0.3510\n",
      "Epoch 304/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3617 - accuracy: 0.5477 - val_loss: 3.7371 - val_accuracy: 0.3595\n",
      "Epoch 305/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3658 - accuracy: 0.5465 - val_loss: 3.7288 - val_accuracy: 0.3485\n",
      "Epoch 306/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3667 - accuracy: 0.5471 - val_loss: 3.7276 - val_accuracy: 0.3485\n",
      "Epoch 307/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3776 - accuracy: 0.5409 - val_loss: 3.6601 - val_accuracy: 0.3528\n",
      "Epoch 308/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3586 - accuracy: 0.5424 - val_loss: 3.6875 - val_accuracy: 0.3504\n",
      "Epoch 309/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3729 - accuracy: 0.5426 - val_loss: 3.6533 - val_accuracy: 0.3564\n",
      "Epoch 310/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3608 - accuracy: 0.5459 - val_loss: 3.7567 - val_accuracy: 0.3504\n",
      "Epoch 311/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3658 - accuracy: 0.5446 - val_loss: 3.6789 - val_accuracy: 0.3577\n",
      "Epoch 312/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3728 - accuracy: 0.5426 - val_loss: 3.7205 - val_accuracy: 0.3467\n",
      "Epoch 313/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3597 - accuracy: 0.5449 - val_loss: 3.7087 - val_accuracy: 0.3437\n",
      "Epoch 314/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3709 - accuracy: 0.5417 - val_loss: 3.7277 - val_accuracy: 0.3552\n",
      "Epoch 315/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3598 - accuracy: 0.5511 - val_loss: 3.7036 - val_accuracy: 0.3461\n",
      "Epoch 316/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3730 - accuracy: 0.5462 - val_loss: 3.7029 - val_accuracy: 0.3461\n",
      "Epoch 317/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3621 - accuracy: 0.5450 - val_loss: 3.6537 - val_accuracy: 0.3473\n",
      "Epoch 318/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3610 - accuracy: 0.5436 - val_loss: 3.7060 - val_accuracy: 0.3516\n",
      "Epoch 319/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3633 - accuracy: 0.5456 - val_loss: 3.6961 - val_accuracy: 0.3510\n",
      "Epoch 320/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3659 - accuracy: 0.5429 - val_loss: 3.7153 - val_accuracy: 0.3437\n",
      "Epoch 321/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3706 - accuracy: 0.5456 - val_loss: 3.6812 - val_accuracy: 0.3498\n",
      "Epoch 322/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3606 - accuracy: 0.5461 - val_loss: 3.7353 - val_accuracy: 0.3461\n",
      "Epoch 323/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3714 - accuracy: 0.5435 - val_loss: 3.6665 - val_accuracy: 0.3558\n",
      "Epoch 324/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3682 - accuracy: 0.5456 - val_loss: 3.7082 - val_accuracy: 0.3504\n",
      "Epoch 325/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3653 - accuracy: 0.5430 - val_loss: 3.7202 - val_accuracy: 0.3558\n",
      "Epoch 326/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3559 - accuracy: 0.5470 - val_loss: 3.7275 - val_accuracy: 0.3485\n",
      "Epoch 327/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3583 - accuracy: 0.5482 - val_loss: 3.7081 - val_accuracy: 0.3552\n",
      "Epoch 328/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3611 - accuracy: 0.5491 - val_loss: 3.7246 - val_accuracy: 0.3394\n",
      "Epoch 329/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3611 - accuracy: 0.5423 - val_loss: 3.7318 - val_accuracy: 0.3528\n",
      "Epoch 330/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3655 - accuracy: 0.5477 - val_loss: 3.7400 - val_accuracy: 0.3510\n",
      "Epoch 331/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3623 - accuracy: 0.5468 - val_loss: 3.7252 - val_accuracy: 0.3400\n",
      "Epoch 332/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3647 - accuracy: 0.5433 - val_loss: 3.7287 - val_accuracy: 0.3418\n",
      "Epoch 333/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3643 - accuracy: 0.5473 - val_loss: 3.7040 - val_accuracy: 0.3625\n",
      "Epoch 334/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3642 - accuracy: 0.5464 - val_loss: 3.7145 - val_accuracy: 0.3577\n",
      "Epoch 335/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3616 - accuracy: 0.5438 - val_loss: 3.7075 - val_accuracy: 0.3528\n",
      "Epoch 336/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3743 - accuracy: 0.5427 - val_loss: 3.6865 - val_accuracy: 0.3528\n",
      "Epoch 337/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3668 - accuracy: 0.5446 - val_loss: 3.6655 - val_accuracy: 0.3583\n",
      "Epoch 338/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3650 - accuracy: 0.5406 - val_loss: 3.6408 - val_accuracy: 0.3546\n",
      "Epoch 339/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3621 - accuracy: 0.5470 - val_loss: 3.7475 - val_accuracy: 0.3564\n",
      "Epoch 340/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3633 - accuracy: 0.5464 - val_loss: 3.7136 - val_accuracy: 0.3425\n",
      "Epoch 341/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3668 - accuracy: 0.5430 - val_loss: 3.6962 - val_accuracy: 0.3473\n",
      "Epoch 342/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3620 - accuracy: 0.5499 - val_loss: 3.7031 - val_accuracy: 0.3571\n",
      "Epoch 343/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3727 - accuracy: 0.5427 - val_loss: 3.7047 - val_accuracy: 0.3564\n",
      "Epoch 344/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3714 - accuracy: 0.5485 - val_loss: 3.7276 - val_accuracy: 0.3631\n",
      "Epoch 345/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3611 - accuracy: 0.5485 - val_loss: 3.7272 - val_accuracy: 0.3461\n",
      "Epoch 346/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3739 - accuracy: 0.5447 - val_loss: 3.6986 - val_accuracy: 0.3595\n",
      "Epoch 347/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3604 - accuracy: 0.5441 - val_loss: 3.7492 - val_accuracy: 0.3498\n",
      "Epoch 348/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3606 - accuracy: 0.5447 - val_loss: 3.7635 - val_accuracy: 0.3516\n",
      "Epoch 349/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3693 - accuracy: 0.5456 - val_loss: 3.7103 - val_accuracy: 0.3431\n",
      "Epoch 350/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3734 - accuracy: 0.5400 - val_loss: 3.7203 - val_accuracy: 0.3425\n",
      "Epoch 351/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3696 - accuracy: 0.5433 - val_loss: 3.6834 - val_accuracy: 0.3412\n",
      "Epoch 352/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3692 - accuracy: 0.5436 - val_loss: 3.6992 - val_accuracy: 0.3498\n",
      "Epoch 353/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3712 - accuracy: 0.5426 - val_loss: 3.6977 - val_accuracy: 0.3455\n",
      "Epoch 354/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3725 - accuracy: 0.5424 - val_loss: 3.6591 - val_accuracy: 0.3485\n",
      "Epoch 355/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3801 - accuracy: 0.5412 - val_loss: 3.6452 - val_accuracy: 0.3540\n",
      "Epoch 356/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3602 - accuracy: 0.5441 - val_loss: 3.7166 - val_accuracy: 0.3406\n",
      "Epoch 357/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3689 - accuracy: 0.5430 - val_loss: 3.7087 - val_accuracy: 0.3540\n",
      "Epoch 358/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3633 - accuracy: 0.5450 - val_loss: 3.7241 - val_accuracy: 0.3455\n",
      "Epoch 359/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3627 - accuracy: 0.5464 - val_loss: 3.7050 - val_accuracy: 0.3510\n",
      "Epoch 360/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3595 - accuracy: 0.5468 - val_loss: 3.7202 - val_accuracy: 0.3461\n",
      "Epoch 361/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3670 - accuracy: 0.5401 - val_loss: 3.6831 - val_accuracy: 0.3546\n",
      "Epoch 362/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3662 - accuracy: 0.5421 - val_loss: 3.6994 - val_accuracy: 0.3516\n",
      "Epoch 363/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3616 - accuracy: 0.5467 - val_loss: 3.7506 - val_accuracy: 0.3558\n",
      "Epoch 364/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3651 - accuracy: 0.5500 - val_loss: 3.7142 - val_accuracy: 0.3473\n",
      "Epoch 365/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3640 - accuracy: 0.5462 - val_loss: 3.7272 - val_accuracy: 0.3504\n",
      "Epoch 366/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3742 - accuracy: 0.5414 - val_loss: 3.6728 - val_accuracy: 0.3558\n",
      "Epoch 367/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3624 - accuracy: 0.5473 - val_loss: 3.6957 - val_accuracy: 0.3601\n",
      "Epoch 368/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3667 - accuracy: 0.5461 - val_loss: 3.6764 - val_accuracy: 0.3577\n",
      "Epoch 369/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3638 - accuracy: 0.5429 - val_loss: 3.6803 - val_accuracy: 0.3485\n",
      "Epoch 370/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3654 - accuracy: 0.5438 - val_loss: 3.7277 - val_accuracy: 0.3534\n",
      "Epoch 371/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3607 - accuracy: 0.5481 - val_loss: 3.7093 - val_accuracy: 0.3595\n",
      "Epoch 372/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3741 - accuracy: 0.5443 - val_loss: 3.7197 - val_accuracy: 0.3552\n",
      "Epoch 373/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3666 - accuracy: 0.5427 - val_loss: 3.7340 - val_accuracy: 0.3558\n",
      "Epoch 374/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3536 - accuracy: 0.5534 - val_loss: 3.7446 - val_accuracy: 0.3443\n",
      "Epoch 375/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3753 - accuracy: 0.5427 - val_loss: 3.7565 - val_accuracy: 0.3613\n",
      "Epoch 376/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3614 - accuracy: 0.5493 - val_loss: 3.6951 - val_accuracy: 0.3473\n",
      "Epoch 377/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3713 - accuracy: 0.5382 - val_loss: 3.7329 - val_accuracy: 0.3437\n",
      "Epoch 378/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3679 - accuracy: 0.5484 - val_loss: 3.7029 - val_accuracy: 0.3589\n",
      "Epoch 379/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3566 - accuracy: 0.5481 - val_loss: 3.7160 - val_accuracy: 0.3473\n",
      "Epoch 380/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3618 - accuracy: 0.5481 - val_loss: 3.7431 - val_accuracy: 0.3595\n",
      "Epoch 381/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3749 - accuracy: 0.5471 - val_loss: 3.7456 - val_accuracy: 0.3522\n",
      "Epoch 382/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3641 - accuracy: 0.5430 - val_loss: 3.6712 - val_accuracy: 0.3668\n",
      "Epoch 383/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3683 - accuracy: 0.5468 - val_loss: 3.7150 - val_accuracy: 0.3558\n",
      "Epoch 384/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3634 - accuracy: 0.5459 - val_loss: 3.7299 - val_accuracy: 0.3455\n",
      "Epoch 385/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3712 - accuracy: 0.5439 - val_loss: 3.7267 - val_accuracy: 0.3528\n",
      "Epoch 386/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3651 - accuracy: 0.5429 - val_loss: 3.7043 - val_accuracy: 0.3437\n",
      "Epoch 387/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3648 - accuracy: 0.5435 - val_loss: 3.7480 - val_accuracy: 0.3437\n",
      "Epoch 388/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3656 - accuracy: 0.5424 - val_loss: 3.7262 - val_accuracy: 0.3516\n",
      "Epoch 389/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3693 - accuracy: 0.5464 - val_loss: 3.7117 - val_accuracy: 0.3491\n",
      "Epoch 390/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3601 - accuracy: 0.5476 - val_loss: 3.7248 - val_accuracy: 0.3534\n",
      "Epoch 391/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3735 - accuracy: 0.5461 - val_loss: 3.6872 - val_accuracy: 0.3571\n",
      "Epoch 392/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3641 - accuracy: 0.5438 - val_loss: 3.7312 - val_accuracy: 0.3418\n",
      "Epoch 393/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3625 - accuracy: 0.5502 - val_loss: 3.7469 - val_accuracy: 0.3564\n",
      "Epoch 394/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3615 - accuracy: 0.5482 - val_loss: 3.7417 - val_accuracy: 0.3534\n",
      "Epoch 395/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3682 - accuracy: 0.5436 - val_loss: 3.7629 - val_accuracy: 0.3558\n",
      "Epoch 396/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3709 - accuracy: 0.5400 - val_loss: 3.6801 - val_accuracy: 0.3595\n",
      "Epoch 397/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3613 - accuracy: 0.5459 - val_loss: 3.7439 - val_accuracy: 0.3546\n",
      "Epoch 398/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3667 - accuracy: 0.5450 - val_loss: 3.7213 - val_accuracy: 0.3540\n",
      "Epoch 399/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3575 - accuracy: 0.5502 - val_loss: 3.7906 - val_accuracy: 0.3528\n",
      "Epoch 400/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3776 - accuracy: 0.5417 - val_loss: 3.7081 - val_accuracy: 0.3364\n",
      "Epoch 401/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3587 - accuracy: 0.5455 - val_loss: 3.7910 - val_accuracy: 0.3479\n",
      "Epoch 402/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3656 - accuracy: 0.5465 - val_loss: 3.7492 - val_accuracy: 0.3546\n",
      "Epoch 403/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3652 - accuracy: 0.5447 - val_loss: 3.7509 - val_accuracy: 0.3510\n",
      "Epoch 404/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3645 - accuracy: 0.5438 - val_loss: 3.7493 - val_accuracy: 0.3418\n",
      "Epoch 405/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3560 - accuracy: 0.5452 - val_loss: 3.7263 - val_accuracy: 0.3583\n",
      "Epoch 406/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3552 - accuracy: 0.5459 - val_loss: 3.7488 - val_accuracy: 0.3601\n",
      "Epoch 407/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3594 - accuracy: 0.5461 - val_loss: 3.7509 - val_accuracy: 0.3431\n",
      "Epoch 408/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3550 - accuracy: 0.5509 - val_loss: 3.7405 - val_accuracy: 0.3491\n",
      "Epoch 409/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3613 - accuracy: 0.5476 - val_loss: 3.7385 - val_accuracy: 0.3461\n",
      "Epoch 410/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3618 - accuracy: 0.5459 - val_loss: 3.7449 - val_accuracy: 0.3504\n",
      "Epoch 411/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3628 - accuracy: 0.5449 - val_loss: 3.7199 - val_accuracy: 0.3467\n",
      "Epoch 412/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3624 - accuracy: 0.5477 - val_loss: 3.7141 - val_accuracy: 0.3528\n",
      "Epoch 413/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3560 - accuracy: 0.5435 - val_loss: 3.7428 - val_accuracy: 0.3467\n",
      "Epoch 414/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.5481 - val_loss: 3.7559 - val_accuracy: 0.3485\n",
      "Epoch 415/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3603 - accuracy: 0.5470 - val_loss: 3.7738 - val_accuracy: 0.3534\n",
      "Epoch 416/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3631 - accuracy: 0.5436 - val_loss: 3.8056 - val_accuracy: 0.3431\n",
      "Epoch 417/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3628 - accuracy: 0.5479 - val_loss: 3.7713 - val_accuracy: 0.3558\n",
      "Epoch 418/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3642 - accuracy: 0.5476 - val_loss: 3.7514 - val_accuracy: 0.3583\n",
      "Epoch 419/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3651 - accuracy: 0.5464 - val_loss: 3.6987 - val_accuracy: 0.3583\n",
      "Epoch 420/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3659 - accuracy: 0.5470 - val_loss: 3.7035 - val_accuracy: 0.3540\n",
      "Epoch 421/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3659 - accuracy: 0.5447 - val_loss: 3.8046 - val_accuracy: 0.3571\n",
      "Epoch 422/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3772 - accuracy: 0.5426 - val_loss: 3.7161 - val_accuracy: 0.3571\n",
      "Epoch 423/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3655 - accuracy: 0.5449 - val_loss: 3.7829 - val_accuracy: 0.3589\n",
      "Epoch 424/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3551 - accuracy: 0.5465 - val_loss: 3.7653 - val_accuracy: 0.3589\n",
      "Epoch 425/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3815 - accuracy: 0.5432 - val_loss: 3.7331 - val_accuracy: 0.3455\n",
      "Epoch 426/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3605 - accuracy: 0.5512 - val_loss: 3.7586 - val_accuracy: 0.3522\n",
      "Epoch 427/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3636 - accuracy: 0.5465 - val_loss: 3.7928 - val_accuracy: 0.3528\n",
      "Epoch 428/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3568 - accuracy: 0.5465 - val_loss: 3.7350 - val_accuracy: 0.3534\n",
      "Epoch 429/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3633 - accuracy: 0.5412 - val_loss: 3.7546 - val_accuracy: 0.3534\n",
      "Epoch 430/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3639 - accuracy: 0.5496 - val_loss: 3.7846 - val_accuracy: 0.3534\n",
      "Epoch 431/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3625 - accuracy: 0.5462 - val_loss: 3.7605 - val_accuracy: 0.3540\n",
      "Epoch 432/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3610 - accuracy: 0.5497 - val_loss: 3.7381 - val_accuracy: 0.3595\n",
      "Epoch 433/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3613 - accuracy: 0.5479 - val_loss: 3.7568 - val_accuracy: 0.3540\n",
      "Epoch 434/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3657 - accuracy: 0.5517 - val_loss: 3.6993 - val_accuracy: 0.3498\n",
      "Epoch 435/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3633 - accuracy: 0.5485 - val_loss: 3.7265 - val_accuracy: 0.3571\n",
      "Epoch 436/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3557 - accuracy: 0.5477 - val_loss: 3.7325 - val_accuracy: 0.3607\n",
      "Epoch 437/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3626 - accuracy: 0.5433 - val_loss: 3.7458 - val_accuracy: 0.3589\n",
      "Epoch 438/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3618 - accuracy: 0.5459 - val_loss: 3.7344 - val_accuracy: 0.3583\n",
      "Epoch 439/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3600 - accuracy: 0.5471 - val_loss: 3.7642 - val_accuracy: 0.3583\n",
      "Epoch 440/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3608 - accuracy: 0.5453 - val_loss: 3.7920 - val_accuracy: 0.3552\n",
      "Epoch 441/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3662 - accuracy: 0.5461 - val_loss: 3.7091 - val_accuracy: 0.3516\n",
      "Epoch 442/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3630 - accuracy: 0.5479 - val_loss: 3.7515 - val_accuracy: 0.3516\n",
      "Epoch 443/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5508 - val_loss: 3.8304 - val_accuracy: 0.3583\n",
      "Epoch 444/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3699 - accuracy: 0.5443 - val_loss: 3.8127 - val_accuracy: 0.3577\n",
      "Epoch 445/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3558 - accuracy: 0.5471 - val_loss: 3.7830 - val_accuracy: 0.3498\n",
      "Epoch 446/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3644 - accuracy: 0.5456 - val_loss: 3.7948 - val_accuracy: 0.3564\n",
      "Epoch 447/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3558 - accuracy: 0.5470 - val_loss: 3.7999 - val_accuracy: 0.3498\n",
      "Epoch 448/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3639 - accuracy: 0.5447 - val_loss: 3.7797 - val_accuracy: 0.3498\n",
      "Epoch 449/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3637 - accuracy: 0.5485 - val_loss: 3.7809 - val_accuracy: 0.3601\n",
      "Epoch 450/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3559 - accuracy: 0.5468 - val_loss: 3.7822 - val_accuracy: 0.3571\n",
      "Epoch 451/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3601 - accuracy: 0.5473 - val_loss: 3.7962 - val_accuracy: 0.3504\n",
      "Epoch 452/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3594 - accuracy: 0.5497 - val_loss: 3.7900 - val_accuracy: 0.3552\n",
      "Epoch 453/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3665 - accuracy: 0.5446 - val_loss: 3.7629 - val_accuracy: 0.3552\n",
      "Epoch 454/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3696 - accuracy: 0.5438 - val_loss: 3.7706 - val_accuracy: 0.3552\n",
      "Epoch 455/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3569 - accuracy: 0.5474 - val_loss: 3.7452 - val_accuracy: 0.3595\n",
      "Epoch 456/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3555 - accuracy: 0.5517 - val_loss: 3.7770 - val_accuracy: 0.3601\n",
      "Epoch 457/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.5484 - val_loss: 3.7518 - val_accuracy: 0.3571\n",
      "Epoch 458/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3594 - accuracy: 0.5459 - val_loss: 3.7842 - val_accuracy: 0.3449\n",
      "Epoch 459/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3539 - accuracy: 0.5470 - val_loss: 3.7909 - val_accuracy: 0.3528\n",
      "Epoch 460/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3595 - accuracy: 0.5473 - val_loss: 3.7920 - val_accuracy: 0.3534\n",
      "Epoch 461/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3569 - accuracy: 0.5453 - val_loss: 3.7636 - val_accuracy: 0.3540\n",
      "Epoch 462/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3528 - accuracy: 0.5471 - val_loss: 3.7496 - val_accuracy: 0.3358\n",
      "Epoch 463/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3615 - accuracy: 0.5468 - val_loss: 3.7857 - val_accuracy: 0.3534\n",
      "Epoch 464/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3576 - accuracy: 0.5479 - val_loss: 3.7735 - val_accuracy: 0.3534\n",
      "Epoch 465/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3634 - accuracy: 0.5503 - val_loss: 3.8049 - val_accuracy: 0.3534\n",
      "Epoch 466/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3604 - accuracy: 0.5441 - val_loss: 3.8126 - val_accuracy: 0.3431\n",
      "Epoch 467/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3698 - accuracy: 0.5429 - val_loss: 3.7548 - val_accuracy: 0.3498\n",
      "Epoch 468/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3636 - accuracy: 0.5461 - val_loss: 3.7403 - val_accuracy: 0.3546\n",
      "Epoch 469/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3515 - accuracy: 0.5481 - val_loss: 3.7817 - val_accuracy: 0.3479\n",
      "Epoch 470/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3425 - accuracy: 0.5485 - val_loss: 3.7913 - val_accuracy: 0.3437\n",
      "Epoch 471/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3577 - accuracy: 0.5470 - val_loss: 3.7911 - val_accuracy: 0.3540\n",
      "Epoch 472/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3583 - accuracy: 0.5505 - val_loss: 3.7465 - val_accuracy: 0.3589\n",
      "Epoch 473/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3585 - accuracy: 0.5512 - val_loss: 3.7951 - val_accuracy: 0.3607\n",
      "Epoch 474/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3659 - accuracy: 0.5449 - val_loss: 3.7653 - val_accuracy: 0.3613\n",
      "Epoch 475/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3634 - accuracy: 0.5439 - val_loss: 3.7683 - val_accuracy: 0.3540\n",
      "Epoch 476/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3648 - accuracy: 0.5499 - val_loss: 3.7178 - val_accuracy: 0.3644\n",
      "Epoch 477/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3622 - accuracy: 0.5453 - val_loss: 3.7527 - val_accuracy: 0.3583\n",
      "Epoch 478/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3572 - accuracy: 0.5411 - val_loss: 3.7813 - val_accuracy: 0.3589\n",
      "Epoch 479/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3633 - accuracy: 0.5439 - val_loss: 3.7852 - val_accuracy: 0.3534\n",
      "Epoch 480/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3613 - accuracy: 0.5452 - val_loss: 3.7955 - val_accuracy: 0.3619\n",
      "Epoch 481/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3693 - accuracy: 0.5444 - val_loss: 3.7694 - val_accuracy: 0.3625\n",
      "Epoch 482/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3505 - accuracy: 0.5474 - val_loss: 3.7671 - val_accuracy: 0.3619\n",
      "Epoch 483/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3619 - accuracy: 0.5456 - val_loss: 3.7570 - val_accuracy: 0.3644\n",
      "Epoch 484/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3625 - accuracy: 0.5427 - val_loss: 3.7425 - val_accuracy: 0.3637\n",
      "Epoch 485/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3569 - accuracy: 0.5479 - val_loss: 3.8025 - val_accuracy: 0.3637\n",
      "Epoch 486/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3582 - accuracy: 0.5427 - val_loss: 3.7638 - val_accuracy: 0.3504\n",
      "Epoch 487/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3620 - accuracy: 0.5496 - val_loss: 3.7840 - val_accuracy: 0.3637\n",
      "Epoch 488/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3688 - accuracy: 0.5394 - val_loss: 3.7477 - val_accuracy: 0.3601\n",
      "Epoch 489/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3527 - accuracy: 0.5482 - val_loss: 3.7634 - val_accuracy: 0.3425\n",
      "Epoch 490/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3656 - accuracy: 0.5430 - val_loss: 3.7654 - val_accuracy: 0.3431\n",
      "Epoch 491/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3653 - accuracy: 0.5449 - val_loss: 3.7767 - val_accuracy: 0.3473\n",
      "Epoch 492/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3494 - accuracy: 0.5499 - val_loss: 3.7660 - val_accuracy: 0.3558\n",
      "Epoch 493/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3622 - accuracy: 0.5494 - val_loss: 3.7739 - val_accuracy: 0.3376\n",
      "Epoch 494/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3497 - accuracy: 0.5464 - val_loss: 3.8055 - val_accuracy: 0.3406\n",
      "Epoch 495/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3589 - accuracy: 0.5455 - val_loss: 3.7857 - val_accuracy: 0.3577\n",
      "Epoch 496/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3495 - accuracy: 0.5452 - val_loss: 3.8213 - val_accuracy: 0.3412\n",
      "Epoch 497/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3550 - accuracy: 0.5471 - val_loss: 3.8107 - val_accuracy: 0.3443\n",
      "Epoch 498/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3538 - accuracy: 0.5490 - val_loss: 3.7607 - val_accuracy: 0.3418\n",
      "Epoch 499/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3567 - accuracy: 0.5484 - val_loss: 3.7681 - val_accuracy: 0.3491\n",
      "Epoch 500/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3707 - accuracy: 0.5485 - val_loss: 3.7703 - val_accuracy: 0.3491\n",
      "Epoch 501/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3417 - accuracy: 0.5473 - val_loss: 3.7952 - val_accuracy: 0.3485\n",
      "Epoch 502/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3497 - accuracy: 0.5487 - val_loss: 3.7934 - val_accuracy: 0.3418\n",
      "Epoch 503/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3693 - accuracy: 0.5449 - val_loss: 3.7942 - val_accuracy: 0.3534\n",
      "Epoch 504/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3545 - accuracy: 0.5473 - val_loss: 3.8064 - val_accuracy: 0.3564\n",
      "Epoch 505/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5464 - val_loss: 3.8098 - val_accuracy: 0.3595\n",
      "Epoch 506/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3572 - accuracy: 0.5464 - val_loss: 3.7625 - val_accuracy: 0.3540\n",
      "Epoch 507/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3650 - accuracy: 0.5487 - val_loss: 3.7283 - val_accuracy: 0.3650\n",
      "Epoch 508/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3586 - accuracy: 0.5446 - val_loss: 3.7740 - val_accuracy: 0.3485\n",
      "Epoch 509/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5465 - val_loss: 3.7734 - val_accuracy: 0.3631\n",
      "Epoch 510/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3604 - accuracy: 0.5446 - val_loss: 3.7705 - val_accuracy: 0.3662\n",
      "Epoch 511/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3631 - accuracy: 0.5468 - val_loss: 3.7805 - val_accuracy: 0.3595\n",
      "Epoch 512/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3510 - accuracy: 0.5477 - val_loss: 3.7967 - val_accuracy: 0.3571\n",
      "Epoch 513/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3571 - accuracy: 0.5482 - val_loss: 3.7937 - val_accuracy: 0.3564\n",
      "Epoch 514/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3574 - accuracy: 0.5500 - val_loss: 3.7883 - val_accuracy: 0.3558\n",
      "Epoch 515/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3534 - accuracy: 0.5499 - val_loss: 3.8264 - val_accuracy: 0.3564\n",
      "Epoch 516/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3678 - accuracy: 0.5444 - val_loss: 3.6965 - val_accuracy: 0.3625\n",
      "Epoch 517/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3617 - accuracy: 0.5490 - val_loss: 3.7501 - val_accuracy: 0.3595\n",
      "Epoch 518/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3660 - accuracy: 0.5412 - val_loss: 3.7564 - val_accuracy: 0.3589\n",
      "Epoch 519/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3565 - accuracy: 0.5455 - val_loss: 3.7749 - val_accuracy: 0.3552\n",
      "Epoch 520/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3574 - accuracy: 0.5473 - val_loss: 3.7372 - val_accuracy: 0.3510\n",
      "Epoch 521/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3668 - accuracy: 0.5412 - val_loss: 3.7777 - val_accuracy: 0.3455\n",
      "Epoch 522/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3677 - accuracy: 0.5414 - val_loss: 3.7390 - val_accuracy: 0.3418\n",
      "Epoch 523/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3615 - accuracy: 0.5420 - val_loss: 3.7548 - val_accuracy: 0.3546\n",
      "Epoch 524/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3636 - accuracy: 0.5405 - val_loss: 3.8067 - val_accuracy: 0.3467\n",
      "Epoch 525/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3609 - accuracy: 0.5462 - val_loss: 3.7288 - val_accuracy: 0.3491\n",
      "Epoch 526/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3633 - accuracy: 0.5449 - val_loss: 3.7984 - val_accuracy: 0.3449\n",
      "Epoch 527/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3588 - accuracy: 0.5453 - val_loss: 3.7511 - val_accuracy: 0.3510\n",
      "Epoch 528/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3669 - accuracy: 0.5430 - val_loss: 3.7713 - val_accuracy: 0.3589\n",
      "Epoch 529/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3514 - accuracy: 0.5496 - val_loss: 3.8237 - val_accuracy: 0.3510\n",
      "Epoch 530/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3565 - accuracy: 0.5488 - val_loss: 3.7864 - val_accuracy: 0.3625\n",
      "Epoch 531/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3597 - accuracy: 0.5491 - val_loss: 3.7792 - val_accuracy: 0.3552\n",
      "Epoch 532/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3522 - accuracy: 0.5468 - val_loss: 3.8295 - val_accuracy: 0.3583\n",
      "Epoch 533/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3636 - accuracy: 0.5450 - val_loss: 3.8201 - val_accuracy: 0.3564\n",
      "Epoch 534/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.5468 - val_loss: 3.7339 - val_accuracy: 0.3656\n",
      "Epoch 535/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3578 - accuracy: 0.5482 - val_loss: 3.7374 - val_accuracy: 0.3564\n",
      "Epoch 536/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3634 - accuracy: 0.5435 - val_loss: 3.7630 - val_accuracy: 0.3461\n",
      "Epoch 537/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3665 - accuracy: 0.5421 - val_loss: 3.7344 - val_accuracy: 0.3601\n",
      "Epoch 538/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3599 - accuracy: 0.5473 - val_loss: 3.7618 - val_accuracy: 0.3473\n",
      "Epoch 539/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3657 - accuracy: 0.5443 - val_loss: 3.8644 - val_accuracy: 0.3522\n",
      "Epoch 540/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3648 - accuracy: 0.5365 - val_loss: 3.7383 - val_accuracy: 0.3461\n",
      "Epoch 541/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3477 - accuracy: 0.5506 - val_loss: 3.8396 - val_accuracy: 0.3418\n",
      "Epoch 542/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5452 - val_loss: 3.8164 - val_accuracy: 0.3564\n",
      "Epoch 543/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3601 - accuracy: 0.5408 - val_loss: 3.8027 - val_accuracy: 0.3522\n",
      "Epoch 544/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3624 - accuracy: 0.5458 - val_loss: 3.7753 - val_accuracy: 0.3540\n",
      "Epoch 545/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3616 - accuracy: 0.5417 - val_loss: 3.8212 - val_accuracy: 0.3564\n",
      "Epoch 546/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3614 - accuracy: 0.5453 - val_loss: 3.7538 - val_accuracy: 0.3619\n",
      "Epoch 547/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3556 - accuracy: 0.5500 - val_loss: 3.8313 - val_accuracy: 0.3528\n",
      "Epoch 548/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5467 - val_loss: 3.8059 - val_accuracy: 0.3552\n",
      "Epoch 549/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3497 - accuracy: 0.5459 - val_loss: 3.8359 - val_accuracy: 0.3504\n",
      "Epoch 550/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3560 - accuracy: 0.5471 - val_loss: 3.8028 - val_accuracy: 0.3625\n",
      "Epoch 551/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5474 - val_loss: 3.7759 - val_accuracy: 0.3491\n",
      "Epoch 552/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3552 - accuracy: 0.5439 - val_loss: 3.7864 - val_accuracy: 0.3522\n",
      "Epoch 553/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3504 - accuracy: 0.5519 - val_loss: 3.8136 - val_accuracy: 0.3528\n",
      "Epoch 554/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3645 - accuracy: 0.5433 - val_loss: 3.8116 - val_accuracy: 0.3564\n",
      "Epoch 555/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3661 - accuracy: 0.5438 - val_loss: 3.7720 - val_accuracy: 0.3631\n",
      "Epoch 556/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3592 - accuracy: 0.5487 - val_loss: 3.7844 - val_accuracy: 0.3601\n",
      "Epoch 557/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3566 - accuracy: 0.5508 - val_loss: 3.8657 - val_accuracy: 0.3491\n",
      "Epoch 558/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3581 - accuracy: 0.5461 - val_loss: 3.7701 - val_accuracy: 0.3577\n",
      "Epoch 559/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3646 - accuracy: 0.5429 - val_loss: 3.7874 - val_accuracy: 0.3546\n",
      "Epoch 560/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5471 - val_loss: 3.8428 - val_accuracy: 0.3479\n",
      "Epoch 561/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3556 - accuracy: 0.5446 - val_loss: 3.8120 - val_accuracy: 0.3583\n",
      "Epoch 562/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3591 - accuracy: 0.5496 - val_loss: 3.8301 - val_accuracy: 0.3564\n",
      "Epoch 563/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5496 - val_loss: 3.8383 - val_accuracy: 0.3546\n",
      "Epoch 564/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3536 - accuracy: 0.5493 - val_loss: 3.8101 - val_accuracy: 0.3546\n",
      "Epoch 565/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.5458 - val_loss: 3.8241 - val_accuracy: 0.3425\n",
      "Epoch 566/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3664 - accuracy: 0.5430 - val_loss: 3.7265 - val_accuracy: 0.3467\n",
      "Epoch 567/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3516 - accuracy: 0.5423 - val_loss: 3.8085 - val_accuracy: 0.3437\n",
      "Epoch 568/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3532 - accuracy: 0.5514 - val_loss: 3.8132 - val_accuracy: 0.3546\n",
      "Epoch 569/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3622 - accuracy: 0.5423 - val_loss: 3.7831 - val_accuracy: 0.3437\n",
      "Epoch 570/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3599 - accuracy: 0.5458 - val_loss: 3.7824 - val_accuracy: 0.3510\n",
      "Epoch 571/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3586 - accuracy: 0.5496 - val_loss: 3.7608 - val_accuracy: 0.3534\n",
      "Epoch 572/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3562 - accuracy: 0.5509 - val_loss: 3.7570 - val_accuracy: 0.3595\n",
      "Epoch 573/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3618 - accuracy: 0.5453 - val_loss: 3.7950 - val_accuracy: 0.3534\n",
      "Epoch 574/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3568 - accuracy: 0.5485 - val_loss: 3.7801 - val_accuracy: 0.3449\n",
      "Epoch 575/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3476 - accuracy: 0.5508 - val_loss: 3.8296 - val_accuracy: 0.3431\n",
      "Epoch 576/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3546 - accuracy: 0.5491 - val_loss: 3.7887 - val_accuracy: 0.3595\n",
      "Epoch 577/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3560 - accuracy: 0.5488 - val_loss: 3.7496 - val_accuracy: 0.3583\n",
      "Epoch 578/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3573 - accuracy: 0.5519 - val_loss: 3.8191 - val_accuracy: 0.3571\n",
      "Epoch 579/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3598 - accuracy: 0.5494 - val_loss: 3.7745 - val_accuracy: 0.3528\n",
      "Epoch 580/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3553 - accuracy: 0.5488 - val_loss: 3.7485 - val_accuracy: 0.3577\n",
      "Epoch 581/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3614 - accuracy: 0.5405 - val_loss: 3.7831 - val_accuracy: 0.3589\n",
      "Epoch 582/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5444 - val_loss: 3.7635 - val_accuracy: 0.3613\n",
      "Epoch 583/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3612 - accuracy: 0.5444 - val_loss: 3.7428 - val_accuracy: 0.3583\n",
      "Epoch 584/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3591 - accuracy: 0.5477 - val_loss: 3.8189 - val_accuracy: 0.3607\n",
      "Epoch 585/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3580 - accuracy: 0.5453 - val_loss: 3.7127 - val_accuracy: 0.3491\n",
      "Epoch 586/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3586 - accuracy: 0.5435 - val_loss: 3.7521 - val_accuracy: 0.3625\n",
      "Epoch 587/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3563 - accuracy: 0.5459 - val_loss: 3.7786 - val_accuracy: 0.3552\n",
      "Epoch 588/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5449 - val_loss: 3.7553 - val_accuracy: 0.3625\n",
      "Epoch 589/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3595 - accuracy: 0.5481 - val_loss: 3.7648 - val_accuracy: 0.3564\n",
      "Epoch 590/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3619 - accuracy: 0.5477 - val_loss: 3.7895 - val_accuracy: 0.3558\n",
      "Epoch 591/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3581 - accuracy: 0.5494 - val_loss: 3.7284 - val_accuracy: 0.3564\n",
      "Epoch 592/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3519 - accuracy: 0.5465 - val_loss: 3.7462 - val_accuracy: 0.3589\n",
      "Epoch 593/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3612 - accuracy: 0.5455 - val_loss: 3.7706 - val_accuracy: 0.3552\n",
      "Epoch 594/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3508 - accuracy: 0.5477 - val_loss: 3.7957 - val_accuracy: 0.3607\n",
      "Epoch 595/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3605 - accuracy: 0.5443 - val_loss: 3.7683 - val_accuracy: 0.3577\n",
      "Epoch 596/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3596 - accuracy: 0.5459 - val_loss: 3.7489 - val_accuracy: 0.3558\n",
      "Epoch 597/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3553 - accuracy: 0.5471 - val_loss: 3.7831 - val_accuracy: 0.3516\n",
      "Epoch 598/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3622 - accuracy: 0.5465 - val_loss: 3.7729 - val_accuracy: 0.3564\n",
      "Epoch 599/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3614 - accuracy: 0.5467 - val_loss: 3.8186 - val_accuracy: 0.3522\n",
      "Epoch 600/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3722 - accuracy: 0.5409 - val_loss: 3.7613 - val_accuracy: 0.3528\n",
      "Epoch 601/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3542 - accuracy: 0.5446 - val_loss: 3.8013 - val_accuracy: 0.3552\n",
      "Epoch 602/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3542 - accuracy: 0.5443 - val_loss: 3.8024 - val_accuracy: 0.3564\n",
      "Epoch 603/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.5462 - val_loss: 3.8476 - val_accuracy: 0.3546\n",
      "Epoch 604/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3584 - accuracy: 0.5493 - val_loss: 3.8215 - val_accuracy: 0.3613\n",
      "Epoch 605/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3530 - accuracy: 0.5424 - val_loss: 3.8129 - val_accuracy: 0.3601\n",
      "Epoch 606/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3623 - accuracy: 0.5459 - val_loss: 3.7957 - val_accuracy: 0.3595\n",
      "Epoch 607/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3610 - accuracy: 0.5450 - val_loss: 3.8063 - val_accuracy: 0.3534\n",
      "Epoch 608/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3537 - accuracy: 0.5421 - val_loss: 3.8413 - val_accuracy: 0.3601\n",
      "Epoch 609/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3563 - accuracy: 0.5461 - val_loss: 3.7660 - val_accuracy: 0.3528\n",
      "Epoch 610/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.5441 - val_loss: 3.8276 - val_accuracy: 0.3558\n",
      "Epoch 611/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3436 - accuracy: 0.5554 - val_loss: 3.7906 - val_accuracy: 0.3406\n",
      "Epoch 612/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3569 - accuracy: 0.5429 - val_loss: 3.8000 - val_accuracy: 0.3491\n",
      "Epoch 613/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3618 - accuracy: 0.5477 - val_loss: 3.7283 - val_accuracy: 0.3589\n",
      "Epoch 614/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3555 - accuracy: 0.5444 - val_loss: 3.8503 - val_accuracy: 0.3467\n",
      "Epoch 615/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3599 - accuracy: 0.5430 - val_loss: 3.7400 - val_accuracy: 0.3613\n",
      "Epoch 616/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5488 - val_loss: 3.7905 - val_accuracy: 0.3546\n",
      "Epoch 617/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3539 - accuracy: 0.5476 - val_loss: 3.8094 - val_accuracy: 0.3595\n",
      "Epoch 618/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3539 - accuracy: 0.5468 - val_loss: 3.8338 - val_accuracy: 0.3467\n",
      "Epoch 619/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3406 - accuracy: 0.5534 - val_loss: 3.8499 - val_accuracy: 0.3607\n",
      "Epoch 620/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3514 - accuracy: 0.5491 - val_loss: 3.8255 - val_accuracy: 0.3534\n",
      "Epoch 621/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3532 - accuracy: 0.5477 - val_loss: 3.7911 - val_accuracy: 0.3552\n",
      "Epoch 622/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3512 - accuracy: 0.5443 - val_loss: 3.8552 - val_accuracy: 0.3522\n",
      "Epoch 623/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.5502 - val_loss: 3.7752 - val_accuracy: 0.3577\n",
      "Epoch 624/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3607 - accuracy: 0.5474 - val_loss: 3.8219 - val_accuracy: 0.3552\n",
      "Epoch 625/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3574 - accuracy: 0.5476 - val_loss: 3.8062 - val_accuracy: 0.3552\n",
      "Epoch 626/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3615 - accuracy: 0.5500 - val_loss: 3.8075 - val_accuracy: 0.3558\n",
      "Epoch 627/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3455 - accuracy: 0.5459 - val_loss: 3.8985 - val_accuracy: 0.3540\n",
      "Epoch 628/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3614 - accuracy: 0.5452 - val_loss: 3.8337 - val_accuracy: 0.3412\n",
      "Epoch 629/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3555 - accuracy: 0.5459 - val_loss: 3.8575 - val_accuracy: 0.3406\n",
      "Epoch 630/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3553 - accuracy: 0.5500 - val_loss: 3.8236 - val_accuracy: 0.3504\n",
      "Epoch 631/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3628 - accuracy: 0.5500 - val_loss: 3.8573 - val_accuracy: 0.3431\n",
      "Epoch 632/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3512 - accuracy: 0.5485 - val_loss: 3.8383 - val_accuracy: 0.3564\n",
      "Epoch 633/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3518 - accuracy: 0.5461 - val_loss: 3.8012 - val_accuracy: 0.3595\n",
      "Epoch 634/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3574 - accuracy: 0.5447 - val_loss: 3.8175 - val_accuracy: 0.3461\n",
      "Epoch 635/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3506 - accuracy: 0.5493 - val_loss: 3.8289 - val_accuracy: 0.3473\n",
      "Epoch 636/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3662 - accuracy: 0.5452 - val_loss: 3.7878 - val_accuracy: 0.3571\n",
      "Epoch 637/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3545 - accuracy: 0.5512 - val_loss: 3.8310 - val_accuracy: 0.3431\n",
      "Epoch 638/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3588 - accuracy: 0.5471 - val_loss: 3.8121 - val_accuracy: 0.3522\n",
      "Epoch 639/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3638 - accuracy: 0.5432 - val_loss: 3.8232 - val_accuracy: 0.3552\n",
      "Epoch 640/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3491 - accuracy: 0.5500 - val_loss: 3.8265 - val_accuracy: 0.3510\n",
      "Epoch 641/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3528 - accuracy: 0.5511 - val_loss: 3.7982 - val_accuracy: 0.3528\n",
      "Epoch 642/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3600 - accuracy: 0.5436 - val_loss: 3.8289 - val_accuracy: 0.3461\n",
      "Epoch 643/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3537 - accuracy: 0.5453 - val_loss: 3.8161 - val_accuracy: 0.3449\n",
      "Epoch 644/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3628 - accuracy: 0.5462 - val_loss: 3.8135 - val_accuracy: 0.3315\n",
      "Epoch 645/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5470 - val_loss: 3.8408 - val_accuracy: 0.3370\n",
      "Epoch 646/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3558 - accuracy: 0.5464 - val_loss: 3.7997 - val_accuracy: 0.3534\n",
      "Epoch 647/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3553 - accuracy: 0.5450 - val_loss: 3.7900 - val_accuracy: 0.3546\n",
      "Epoch 648/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.5439 - val_loss: 3.8122 - val_accuracy: 0.3510\n",
      "Epoch 649/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3494 - accuracy: 0.5517 - val_loss: 3.8546 - val_accuracy: 0.3461\n",
      "Epoch 650/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.5420 - val_loss: 3.8056 - val_accuracy: 0.3491\n",
      "Epoch 651/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3555 - accuracy: 0.5516 - val_loss: 3.8105 - val_accuracy: 0.3552\n",
      "Epoch 652/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3577 - accuracy: 0.5496 - val_loss: 3.7674 - val_accuracy: 0.3540\n",
      "Epoch 653/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3600 - accuracy: 0.5458 - val_loss: 3.7797 - val_accuracy: 0.3571\n",
      "Epoch 654/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3492 - accuracy: 0.5464 - val_loss: 3.8022 - val_accuracy: 0.3491\n",
      "Epoch 655/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3592 - accuracy: 0.5395 - val_loss: 3.7915 - val_accuracy: 0.3516\n",
      "Epoch 656/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3596 - accuracy: 0.5496 - val_loss: 3.8289 - val_accuracy: 0.3461\n",
      "Epoch 657/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3590 - accuracy: 0.5479 - val_loss: 3.8318 - val_accuracy: 0.3522\n",
      "Epoch 658/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.5453 - val_loss: 3.8444 - val_accuracy: 0.3467\n",
      "Epoch 659/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3527 - accuracy: 0.5494 - val_loss: 3.8845 - val_accuracy: 0.3498\n",
      "Epoch 660/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3584 - accuracy: 0.5432 - val_loss: 3.8273 - val_accuracy: 0.3516\n",
      "Epoch 661/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3607 - accuracy: 0.5405 - val_loss: 3.8380 - val_accuracy: 0.3473\n",
      "Epoch 662/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3575 - accuracy: 0.5506 - val_loss: 3.7998 - val_accuracy: 0.3461\n",
      "Epoch 663/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3567 - accuracy: 0.5456 - val_loss: 3.8164 - val_accuracy: 0.3516\n",
      "Epoch 664/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3617 - accuracy: 0.5400 - val_loss: 3.8168 - val_accuracy: 0.3485\n",
      "Epoch 665/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3576 - accuracy: 0.5438 - val_loss: 3.8863 - val_accuracy: 0.3479\n",
      "Epoch 666/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3506 - accuracy: 0.5444 - val_loss: 3.7698 - val_accuracy: 0.3528\n",
      "Epoch 667/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3653 - accuracy: 0.5420 - val_loss: 3.7972 - val_accuracy: 0.3461\n",
      "Epoch 668/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3572 - accuracy: 0.5453 - val_loss: 3.7833 - val_accuracy: 0.3449\n",
      "Epoch 669/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3578 - accuracy: 0.5484 - val_loss: 3.7644 - val_accuracy: 0.3479\n",
      "Epoch 670/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3476 - accuracy: 0.5474 - val_loss: 3.8086 - val_accuracy: 0.3473\n",
      "Epoch 671/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3580 - accuracy: 0.5503 - val_loss: 3.8344 - val_accuracy: 0.3528\n",
      "Epoch 672/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3558 - accuracy: 0.5438 - val_loss: 3.7811 - val_accuracy: 0.3418\n",
      "Epoch 673/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5420 - val_loss: 3.7689 - val_accuracy: 0.3558\n",
      "Epoch 674/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3594 - accuracy: 0.5406 - val_loss: 3.7759 - val_accuracy: 0.3540\n",
      "Epoch 675/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.5477 - val_loss: 3.8597 - val_accuracy: 0.3443\n",
      "Epoch 676/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3475 - accuracy: 0.5477 - val_loss: 3.8157 - val_accuracy: 0.3516\n",
      "Epoch 677/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3612 - accuracy: 0.5444 - val_loss: 3.7823 - val_accuracy: 0.3516\n",
      "Epoch 678/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3652 - accuracy: 0.5429 - val_loss: 3.7832 - val_accuracy: 0.3552\n",
      "Epoch 679/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3469 - accuracy: 0.5452 - val_loss: 3.8433 - val_accuracy: 0.3583\n",
      "Epoch 680/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3588 - accuracy: 0.5400 - val_loss: 3.8077 - val_accuracy: 0.3564\n",
      "Epoch 681/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3589 - accuracy: 0.5470 - val_loss: 3.8365 - val_accuracy: 0.3540\n",
      "Epoch 682/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3531 - accuracy: 0.5446 - val_loss: 3.7671 - val_accuracy: 0.3607\n",
      "Epoch 683/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3557 - accuracy: 0.5471 - val_loss: 3.8328 - val_accuracy: 0.3577\n",
      "Epoch 684/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5476 - val_loss: 3.7962 - val_accuracy: 0.3571\n",
      "Epoch 685/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3513 - accuracy: 0.5459 - val_loss: 3.7729 - val_accuracy: 0.3534\n",
      "Epoch 686/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3604 - accuracy: 0.5449 - val_loss: 3.8008 - val_accuracy: 0.3522\n",
      "Epoch 687/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3632 - accuracy: 0.5394 - val_loss: 3.7759 - val_accuracy: 0.3589\n",
      "Epoch 688/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3557 - accuracy: 0.5482 - val_loss: 3.8155 - val_accuracy: 0.3516\n",
      "Epoch 689/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3583 - accuracy: 0.5481 - val_loss: 3.7958 - val_accuracy: 0.3504\n",
      "Epoch 690/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3600 - accuracy: 0.5446 - val_loss: 3.7648 - val_accuracy: 0.3589\n",
      "Epoch 691/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3485 - accuracy: 0.5494 - val_loss: 3.8172 - val_accuracy: 0.3558\n",
      "Epoch 692/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3580 - accuracy: 0.5444 - val_loss: 3.8381 - val_accuracy: 0.3510\n",
      "Epoch 693/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 1.3597 - accuracy: 0.5485 - val_loss: 3.7800 - val_accuracy: 0.3516\n",
      "Epoch 694/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3616 - accuracy: 0.5473 - val_loss: 3.7564 - val_accuracy: 0.3485\n",
      "Epoch 695/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3610 - accuracy: 0.5467 - val_loss: 3.8367 - val_accuracy: 0.3552\n",
      "Epoch 696/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.5514 - val_loss: 3.8362 - val_accuracy: 0.3540\n",
      "Epoch 697/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3526 - accuracy: 0.5426 - val_loss: 3.8502 - val_accuracy: 0.3504\n",
      "Epoch 698/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3441 - accuracy: 0.5499 - val_loss: 3.8545 - val_accuracy: 0.3552\n",
      "Epoch 699/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3549 - accuracy: 0.5481 - val_loss: 3.8221 - val_accuracy: 0.3583\n",
      "Epoch 700/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3608 - accuracy: 0.5453 - val_loss: 3.8247 - val_accuracy: 0.3546\n",
      "Epoch 701/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3563 - accuracy: 0.5408 - val_loss: 3.8491 - val_accuracy: 0.3571\n",
      "Epoch 702/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3616 - accuracy: 0.5424 - val_loss: 3.8186 - val_accuracy: 0.3564\n",
      "Epoch 703/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3492 - accuracy: 0.5458 - val_loss: 3.8330 - val_accuracy: 0.3558\n",
      "Epoch 704/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3568 - accuracy: 0.5449 - val_loss: 3.8129 - val_accuracy: 0.3534\n",
      "Epoch 705/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3625 - accuracy: 0.5471 - val_loss: 3.8213 - val_accuracy: 0.3607\n",
      "Epoch 706/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3640 - accuracy: 0.5443 - val_loss: 3.7902 - val_accuracy: 0.3546\n",
      "Epoch 707/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.5455 - val_loss: 3.8318 - val_accuracy: 0.3540\n",
      "Epoch 708/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3478 - accuracy: 0.5450 - val_loss: 3.8397 - val_accuracy: 0.3504\n",
      "Epoch 709/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3555 - accuracy: 0.5470 - val_loss: 3.7710 - val_accuracy: 0.3467\n",
      "Epoch 710/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3520 - accuracy: 0.5462 - val_loss: 3.8187 - val_accuracy: 0.3552\n",
      "Epoch 711/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3625 - accuracy: 0.5433 - val_loss: 3.8139 - val_accuracy: 0.3601\n",
      "Epoch 712/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3522 - accuracy: 0.5423 - val_loss: 3.8278 - val_accuracy: 0.3406\n",
      "Epoch 713/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3514 - accuracy: 0.5435 - val_loss: 3.8417 - val_accuracy: 0.3564\n",
      "Epoch 714/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3571 - accuracy: 0.5494 - val_loss: 3.8246 - val_accuracy: 0.3504\n",
      "Epoch 715/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3587 - accuracy: 0.5418 - val_loss: 3.8240 - val_accuracy: 0.3516\n",
      "Epoch 716/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3573 - accuracy: 0.5467 - val_loss: 3.8560 - val_accuracy: 0.3400\n",
      "Epoch 717/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3508 - accuracy: 0.5490 - val_loss: 3.8690 - val_accuracy: 0.3418\n",
      "Epoch 718/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3596 - accuracy: 0.5474 - val_loss: 3.7964 - val_accuracy: 0.3552\n",
      "Epoch 719/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3521 - accuracy: 0.5493 - val_loss: 3.8386 - val_accuracy: 0.3577\n",
      "Epoch 720/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3485 - accuracy: 0.5491 - val_loss: 3.8072 - val_accuracy: 0.3601\n",
      "Epoch 721/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3500 - accuracy: 0.5481 - val_loss: 3.8100 - val_accuracy: 0.3510\n",
      "Epoch 722/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3500 - accuracy: 0.5470 - val_loss: 3.8610 - val_accuracy: 0.3449\n",
      "Epoch 723/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3586 - accuracy: 0.5444 - val_loss: 3.8765 - val_accuracy: 0.3443\n",
      "Epoch 724/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3463 - accuracy: 0.5500 - val_loss: 3.8857 - val_accuracy: 0.3534\n",
      "Epoch 725/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3468 - accuracy: 0.5482 - val_loss: 3.8624 - val_accuracy: 0.3467\n",
      "Epoch 726/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3640 - accuracy: 0.5427 - val_loss: 3.8223 - val_accuracy: 0.3443\n",
      "Epoch 727/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3510 - accuracy: 0.5467 - val_loss: 3.9024 - val_accuracy: 0.3418\n",
      "Epoch 728/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3418 - accuracy: 0.5534 - val_loss: 3.9224 - val_accuracy: 0.3534\n",
      "Epoch 729/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3553 - accuracy: 0.5449 - val_loss: 3.8348 - val_accuracy: 0.3601\n",
      "Epoch 730/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3547 - accuracy: 0.5429 - val_loss: 3.7710 - val_accuracy: 0.3583\n",
      "Epoch 731/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3548 - accuracy: 0.5467 - val_loss: 3.8403 - val_accuracy: 0.3564\n",
      "Epoch 732/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3498 - accuracy: 0.5450 - val_loss: 3.8580 - val_accuracy: 0.3455\n",
      "Epoch 733/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3508 - accuracy: 0.5505 - val_loss: 3.8409 - val_accuracy: 0.3485\n",
      "Epoch 734/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3368 - accuracy: 0.5532 - val_loss: 3.8673 - val_accuracy: 0.3449\n",
      "Epoch 735/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3564 - accuracy: 0.5479 - val_loss: 3.8777 - val_accuracy: 0.3418\n",
      "Epoch 736/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.5523 - val_loss: 3.8400 - val_accuracy: 0.3558\n",
      "Epoch 737/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3446 - accuracy: 0.5494 - val_loss: 3.8912 - val_accuracy: 0.3498\n",
      "Epoch 738/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3484 - accuracy: 0.5491 - val_loss: 3.8345 - val_accuracy: 0.3498\n",
      "Epoch 739/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3581 - accuracy: 0.5484 - val_loss: 3.8324 - val_accuracy: 0.3406\n",
      "Epoch 740/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3458 - accuracy: 0.5471 - val_loss: 3.8570 - val_accuracy: 0.3534\n",
      "Epoch 741/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3574 - accuracy: 0.5432 - val_loss: 3.8034 - val_accuracy: 0.3577\n",
      "Epoch 742/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3659 - accuracy: 0.5418 - val_loss: 3.8402 - val_accuracy: 0.3504\n",
      "Epoch 743/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3457 - accuracy: 0.5477 - val_loss: 3.8209 - val_accuracy: 0.3522\n",
      "Epoch 744/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3511 - accuracy: 0.5464 - val_loss: 3.8668 - val_accuracy: 0.3528\n",
      "Epoch 745/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3505 - accuracy: 0.5525 - val_loss: 3.8494 - val_accuracy: 0.3583\n",
      "Epoch 746/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3486 - accuracy: 0.5505 - val_loss: 3.8813 - val_accuracy: 0.3412\n",
      "Epoch 747/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3618 - accuracy: 0.5427 - val_loss: 3.8558 - val_accuracy: 0.3589\n",
      "Epoch 748/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3571 - accuracy: 0.5453 - val_loss: 3.8359 - val_accuracy: 0.3540\n",
      "Epoch 749/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3524 - accuracy: 0.5471 - val_loss: 3.8140 - val_accuracy: 0.3528\n",
      "Epoch 750/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3422 - accuracy: 0.5482 - val_loss: 3.8140 - val_accuracy: 0.3485\n",
      "Epoch 751/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3497 - accuracy: 0.5462 - val_loss: 3.8628 - val_accuracy: 0.3558\n",
      "Epoch 752/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3631 - accuracy: 0.5481 - val_loss: 3.8351 - val_accuracy: 0.3601\n",
      "Epoch 753/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3611 - accuracy: 0.5455 - val_loss: 3.8807 - val_accuracy: 0.3528\n",
      "Epoch 754/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3385 - accuracy: 0.5500 - val_loss: 3.8597 - val_accuracy: 0.3577\n",
      "Epoch 755/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3503 - accuracy: 0.5477 - val_loss: 3.8492 - val_accuracy: 0.3504\n",
      "Epoch 756/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3564 - accuracy: 0.5465 - val_loss: 3.8109 - val_accuracy: 0.3571\n",
      "Epoch 757/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.5503 - val_loss: 3.8574 - val_accuracy: 0.3473\n",
      "Epoch 758/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3478 - accuracy: 0.5473 - val_loss: 3.8726 - val_accuracy: 0.3473\n",
      "Epoch 759/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3528 - accuracy: 0.5514 - val_loss: 3.8644 - val_accuracy: 0.3473\n",
      "Epoch 760/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3484 - accuracy: 0.5516 - val_loss: 3.8914 - val_accuracy: 0.3485\n",
      "Epoch 761/1000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 1.3587 - accuracy: 0.5465 - val_loss: 3.8288 - val_accuracy: 0.3479\n",
      "Epoch 762/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5471 - val_loss: 3.8061 - val_accuracy: 0.3491\n",
      "Epoch 763/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.5509 - val_loss: 3.8278 - val_accuracy: 0.3571\n",
      "Epoch 764/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3490 - accuracy: 0.5444 - val_loss: 3.8060 - val_accuracy: 0.3571\n",
      "Epoch 765/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3447 - accuracy: 0.5516 - val_loss: 3.8584 - val_accuracy: 0.3491\n",
      "Epoch 766/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3538 - accuracy: 0.5503 - val_loss: 3.8549 - val_accuracy: 0.3589\n",
      "Epoch 767/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3485 - accuracy: 0.5491 - val_loss: 3.8783 - val_accuracy: 0.3491\n",
      "Epoch 768/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3385 - accuracy: 0.5520 - val_loss: 3.9571 - val_accuracy: 0.3504\n",
      "Epoch 769/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3593 - accuracy: 0.5426 - val_loss: 3.8363 - val_accuracy: 0.3564\n",
      "Epoch 770/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3594 - accuracy: 0.5449 - val_loss: 3.8908 - val_accuracy: 0.3577\n",
      "Epoch 771/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3556 - accuracy: 0.5426 - val_loss: 3.8547 - val_accuracy: 0.3595\n",
      "Epoch 772/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.5446 - val_loss: 3.8355 - val_accuracy: 0.3601\n",
      "Epoch 773/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3613 - accuracy: 0.5423 - val_loss: 3.8372 - val_accuracy: 0.3528\n",
      "Epoch 774/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3462 - accuracy: 0.5439 - val_loss: 3.8543 - val_accuracy: 0.3631\n",
      "Epoch 775/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.5465 - val_loss: 3.8522 - val_accuracy: 0.3558\n",
      "Epoch 776/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3529 - accuracy: 0.5482 - val_loss: 3.8694 - val_accuracy: 0.3540\n",
      "Epoch 777/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3449 - accuracy: 0.5477 - val_loss: 3.9200 - val_accuracy: 0.3491\n",
      "Epoch 778/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3508 - accuracy: 0.5424 - val_loss: 3.8974 - val_accuracy: 0.3473\n",
      "Epoch 779/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3553 - accuracy: 0.5435 - val_loss: 3.8243 - val_accuracy: 0.3601\n",
      "Epoch 780/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5497 - val_loss: 3.8906 - val_accuracy: 0.3461\n",
      "Epoch 781/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3475 - accuracy: 0.5456 - val_loss: 3.8926 - val_accuracy: 0.3449\n",
      "Epoch 782/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3570 - accuracy: 0.5444 - val_loss: 3.8712 - val_accuracy: 0.3522\n",
      "Epoch 783/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3530 - accuracy: 0.5467 - val_loss: 3.8534 - val_accuracy: 0.3522\n",
      "Epoch 784/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3490 - accuracy: 0.5555 - val_loss: 3.8238 - val_accuracy: 0.3516\n",
      "Epoch 785/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.5493 - val_loss: 3.8623 - val_accuracy: 0.3498\n",
      "Epoch 786/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3537 - accuracy: 0.5471 - val_loss: 3.8190 - val_accuracy: 0.3473\n",
      "Epoch 787/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.5479 - val_loss: 3.8398 - val_accuracy: 0.3443\n",
      "Epoch 788/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3474 - accuracy: 0.5430 - val_loss: 3.8471 - val_accuracy: 0.3431\n",
      "Epoch 789/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3607 - accuracy: 0.5426 - val_loss: 3.8377 - val_accuracy: 0.3406\n",
      "Epoch 790/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3494 - accuracy: 0.5493 - val_loss: 3.8327 - val_accuracy: 0.3437\n",
      "Epoch 791/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3527 - accuracy: 0.5450 - val_loss: 3.8672 - val_accuracy: 0.3425\n",
      "Epoch 792/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3486 - accuracy: 0.5493 - val_loss: 3.8490 - val_accuracy: 0.3522\n",
      "Epoch 793/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5473 - val_loss: 3.8393 - val_accuracy: 0.3577\n",
      "Epoch 794/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3520 - accuracy: 0.5444 - val_loss: 3.8404 - val_accuracy: 0.3461\n",
      "Epoch 795/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3556 - accuracy: 0.5453 - val_loss: 3.8271 - val_accuracy: 0.3522\n",
      "Epoch 796/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3465 - accuracy: 0.5503 - val_loss: 3.7750 - val_accuracy: 0.3546\n",
      "Epoch 797/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.3521 - accuracy: 0.5493 - val_loss: 3.8359 - val_accuracy: 0.3528\n",
      "Epoch 798/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3520 - accuracy: 0.5506 - val_loss: 3.8432 - val_accuracy: 0.3455\n",
      "Epoch 799/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3543 - accuracy: 0.5433 - val_loss: 3.8293 - val_accuracy: 0.3479\n",
      "Epoch 800/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3632 - accuracy: 0.5461 - val_loss: 3.8654 - val_accuracy: 0.3479\n",
      "Epoch 801/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3544 - accuracy: 0.5485 - val_loss: 3.8450 - val_accuracy: 0.3546\n",
      "Epoch 802/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3544 - accuracy: 0.5485 - val_loss: 3.8386 - val_accuracy: 0.3461\n",
      "Epoch 803/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3486 - accuracy: 0.5449 - val_loss: 3.9047 - val_accuracy: 0.3564\n",
      "Epoch 804/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.5511 - val_loss: 3.8793 - val_accuracy: 0.3485\n",
      "Epoch 805/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3400 - accuracy: 0.5476 - val_loss: 3.8603 - val_accuracy: 0.3522\n",
      "Epoch 806/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5465 - val_loss: 3.8590 - val_accuracy: 0.3546\n",
      "Epoch 807/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3514 - accuracy: 0.5449 - val_loss: 3.8746 - val_accuracy: 0.3491\n",
      "Epoch 808/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3557 - accuracy: 0.5490 - val_loss: 3.8580 - val_accuracy: 0.3504\n",
      "Epoch 809/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3462 - accuracy: 0.5503 - val_loss: 3.9098 - val_accuracy: 0.3504\n",
      "Epoch 810/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3532 - accuracy: 0.5488 - val_loss: 3.8454 - val_accuracy: 0.3583\n",
      "Epoch 811/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3523 - accuracy: 0.5491 - val_loss: 3.8118 - val_accuracy: 0.3516\n",
      "Epoch 812/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3513 - accuracy: 0.5433 - val_loss: 3.8705 - val_accuracy: 0.3467\n",
      "Epoch 813/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3652 - accuracy: 0.5456 - val_loss: 3.7829 - val_accuracy: 0.3601\n",
      "Epoch 814/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3483 - accuracy: 0.5523 - val_loss: 3.8383 - val_accuracy: 0.3595\n",
      "Epoch 815/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3465 - accuracy: 0.5525 - val_loss: 3.9028 - val_accuracy: 0.3558\n",
      "Epoch 816/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3568 - accuracy: 0.5447 - val_loss: 3.8289 - val_accuracy: 0.3571\n",
      "Epoch 817/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3502 - accuracy: 0.5449 - val_loss: 3.8440 - val_accuracy: 0.3461\n",
      "Epoch 818/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3500 - accuracy: 0.5477 - val_loss: 3.8504 - val_accuracy: 0.3498\n",
      "Epoch 819/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3513 - accuracy: 0.5519 - val_loss: 3.7894 - val_accuracy: 0.3528\n",
      "Epoch 820/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3548 - accuracy: 0.5502 - val_loss: 3.8430 - val_accuracy: 0.3613\n",
      "Epoch 821/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3540 - accuracy: 0.5406 - val_loss: 3.8174 - val_accuracy: 0.3607\n",
      "Epoch 822/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3510 - accuracy: 0.5519 - val_loss: 3.7994 - val_accuracy: 0.3637\n",
      "Epoch 823/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3484 - accuracy: 0.5528 - val_loss: 3.8216 - val_accuracy: 0.3534\n",
      "Epoch 824/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3458 - accuracy: 0.5458 - val_loss: 3.8735 - val_accuracy: 0.3601\n",
      "Epoch 825/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.5471 - val_loss: 3.8298 - val_accuracy: 0.3589\n",
      "Epoch 826/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3545 - accuracy: 0.5497 - val_loss: 3.8526 - val_accuracy: 0.3558\n",
      "Epoch 827/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3577 - accuracy: 0.5467 - val_loss: 3.8570 - val_accuracy: 0.3564\n",
      "Epoch 828/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5471 - val_loss: 3.8823 - val_accuracy: 0.3583\n",
      "Epoch 829/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3498 - accuracy: 0.5433 - val_loss: 3.8561 - val_accuracy: 0.3589\n",
      "Epoch 830/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3489 - accuracy: 0.5509 - val_loss: 3.8766 - val_accuracy: 0.3558\n",
      "Epoch 831/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3560 - accuracy: 0.5429 - val_loss: 3.8576 - val_accuracy: 0.3631\n",
      "Epoch 832/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3538 - accuracy: 0.5468 - val_loss: 3.8589 - val_accuracy: 0.3650\n",
      "Epoch 833/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3444 - accuracy: 0.5477 - val_loss: 3.8533 - val_accuracy: 0.3485\n",
      "Epoch 834/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3587 - accuracy: 0.5447 - val_loss: 3.8194 - val_accuracy: 0.3498\n",
      "Epoch 835/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3532 - accuracy: 0.5497 - val_loss: 3.8793 - val_accuracy: 0.3528\n",
      "Epoch 836/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5497 - val_loss: 3.8072 - val_accuracy: 0.3692\n",
      "Epoch 837/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3507 - accuracy: 0.5523 - val_loss: 3.8348 - val_accuracy: 0.3656\n",
      "Epoch 838/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3498 - accuracy: 0.5514 - val_loss: 3.8501 - val_accuracy: 0.3583\n",
      "Epoch 839/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3483 - accuracy: 0.5446 - val_loss: 3.8295 - val_accuracy: 0.3686\n",
      "Epoch 840/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3504 - accuracy: 0.5477 - val_loss: 3.8631 - val_accuracy: 0.3583\n",
      "Epoch 841/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3415 - accuracy: 0.5493 - val_loss: 3.8880 - val_accuracy: 0.3504\n",
      "Epoch 842/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3547 - accuracy: 0.5433 - val_loss: 3.8295 - val_accuracy: 0.3625\n",
      "Epoch 843/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3452 - accuracy: 0.5502 - val_loss: 3.8918 - val_accuracy: 0.3631\n",
      "Epoch 844/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3538 - accuracy: 0.5456 - val_loss: 3.8627 - val_accuracy: 0.3662\n",
      "Epoch 845/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3465 - accuracy: 0.5482 - val_loss: 3.8791 - val_accuracy: 0.3577\n",
      "Epoch 846/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3620 - accuracy: 0.5471 - val_loss: 3.8806 - val_accuracy: 0.3552\n",
      "Epoch 847/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3501 - accuracy: 0.5505 - val_loss: 3.8818 - val_accuracy: 0.3601\n",
      "Epoch 848/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3509 - accuracy: 0.5525 - val_loss: 3.8819 - val_accuracy: 0.3522\n",
      "Epoch 849/1000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.3505 - accuracy: 0.5481 - val_loss: 3.8832 - val_accuracy: 0.3455\n",
      "Epoch 850/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3488 - accuracy: 0.5477 - val_loss: 3.8689 - val_accuracy: 0.3558\n",
      "Epoch 851/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.5421 - val_loss: 3.8708 - val_accuracy: 0.3601\n",
      "Epoch 852/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3516 - accuracy: 0.5464 - val_loss: 3.8721 - val_accuracy: 0.3613\n",
      "Epoch 853/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3549 - accuracy: 0.5467 - val_loss: 3.8948 - val_accuracy: 0.3455\n",
      "Epoch 854/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3605 - accuracy: 0.5511 - val_loss: 3.8674 - val_accuracy: 0.3637\n",
      "Epoch 855/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3499 - accuracy: 0.5505 - val_loss: 3.9138 - val_accuracy: 0.3589\n",
      "Epoch 856/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3480 - accuracy: 0.5514 - val_loss: 3.9088 - val_accuracy: 0.3613\n",
      "Epoch 857/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3410 - accuracy: 0.5511 - val_loss: 3.8719 - val_accuracy: 0.3613\n",
      "Epoch 858/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3549 - accuracy: 0.5481 - val_loss: 3.8512 - val_accuracy: 0.3522\n",
      "Epoch 859/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3537 - accuracy: 0.5450 - val_loss: 3.8271 - val_accuracy: 0.3516\n",
      "Epoch 860/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3518 - accuracy: 0.5484 - val_loss: 3.8925 - val_accuracy: 0.3577\n",
      "Epoch 861/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3483 - accuracy: 0.5484 - val_loss: 3.8962 - val_accuracy: 0.3516\n",
      "Epoch 862/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3470 - accuracy: 0.5474 - val_loss: 3.8727 - val_accuracy: 0.3637\n",
      "Epoch 863/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3544 - accuracy: 0.5473 - val_loss: 3.9267 - val_accuracy: 0.3516\n",
      "Epoch 864/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3531 - accuracy: 0.5481 - val_loss: 3.8993 - val_accuracy: 0.3583\n",
      "Epoch 865/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3605 - accuracy: 0.5456 - val_loss: 3.8206 - val_accuracy: 0.3644\n",
      "Epoch 866/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3524 - accuracy: 0.5473 - val_loss: 3.8385 - val_accuracy: 0.3637\n",
      "Epoch 867/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3534 - accuracy: 0.5462 - val_loss: 3.8903 - val_accuracy: 0.3467\n",
      "Epoch 868/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3548 - accuracy: 0.5477 - val_loss: 3.8632 - val_accuracy: 0.3437\n",
      "Epoch 869/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3505 - accuracy: 0.5465 - val_loss: 3.8816 - val_accuracy: 0.3455\n",
      "Epoch 870/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3547 - accuracy: 0.5508 - val_loss: 3.8464 - val_accuracy: 0.3485\n",
      "Epoch 871/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3485 - accuracy: 0.5464 - val_loss: 3.8876 - val_accuracy: 0.3504\n",
      "Epoch 872/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3449 - accuracy: 0.5467 - val_loss: 3.8642 - val_accuracy: 0.3437\n",
      "Epoch 873/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.5485 - val_loss: 3.8733 - val_accuracy: 0.3504\n",
      "Epoch 874/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3506 - accuracy: 0.5471 - val_loss: 3.8643 - val_accuracy: 0.3546\n",
      "Epoch 875/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.5482 - val_loss: 3.9042 - val_accuracy: 0.3516\n",
      "Epoch 876/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3485 - accuracy: 0.5464 - val_loss: 3.8749 - val_accuracy: 0.3522\n",
      "Epoch 877/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3436 - accuracy: 0.5517 - val_loss: 3.9390 - val_accuracy: 0.3473\n",
      "Epoch 878/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3501 - accuracy: 0.5446 - val_loss: 3.9266 - val_accuracy: 0.3625\n",
      "Epoch 879/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5506 - val_loss: 3.8785 - val_accuracy: 0.3613\n",
      "Epoch 880/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.5499 - val_loss: 3.8907 - val_accuracy: 0.3589\n",
      "Epoch 881/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3528 - accuracy: 0.5477 - val_loss: 3.8711 - val_accuracy: 0.3510\n",
      "Epoch 882/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3515 - accuracy: 0.5461 - val_loss: 3.8752 - val_accuracy: 0.3571\n",
      "Epoch 883/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3515 - accuracy: 0.5432 - val_loss: 3.8425 - val_accuracy: 0.3644\n",
      "Epoch 884/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3514 - accuracy: 0.5488 - val_loss: 3.8808 - val_accuracy: 0.3577\n",
      "Epoch 885/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3481 - accuracy: 0.5516 - val_loss: 3.9049 - val_accuracy: 0.3619\n",
      "Epoch 886/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3489 - accuracy: 0.5573 - val_loss: 3.8833 - val_accuracy: 0.3613\n",
      "Epoch 887/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3470 - accuracy: 0.5512 - val_loss: 3.8044 - val_accuracy: 0.3631\n",
      "Epoch 888/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.5467 - val_loss: 3.8685 - val_accuracy: 0.3583\n",
      "Epoch 889/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3518 - accuracy: 0.5474 - val_loss: 3.8760 - val_accuracy: 0.3577\n",
      "Epoch 890/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3508 - accuracy: 0.5500 - val_loss: 3.8475 - val_accuracy: 0.3498\n",
      "Epoch 891/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3470 - accuracy: 0.5514 - val_loss: 3.8887 - val_accuracy: 0.3479\n",
      "Epoch 892/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3432 - accuracy: 0.5506 - val_loss: 3.8496 - val_accuracy: 0.3491\n",
      "Epoch 893/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3569 - accuracy: 0.5444 - val_loss: 3.8145 - val_accuracy: 0.3571\n",
      "Epoch 894/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3522 - accuracy: 0.5474 - val_loss: 3.8568 - val_accuracy: 0.3668\n",
      "Epoch 895/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3449 - accuracy: 0.5481 - val_loss: 3.8483 - val_accuracy: 0.3613\n",
      "Epoch 896/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3513 - accuracy: 0.5474 - val_loss: 3.8900 - val_accuracy: 0.3443\n",
      "Epoch 897/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3528 - accuracy: 0.5482 - val_loss: 3.8618 - val_accuracy: 0.3449\n",
      "Epoch 898/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3407 - accuracy: 0.5496 - val_loss: 3.8933 - val_accuracy: 0.3528\n",
      "Epoch 899/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3548 - accuracy: 0.5474 - val_loss: 3.8543 - val_accuracy: 0.3485\n",
      "Epoch 900/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3459 - accuracy: 0.5522 - val_loss: 3.8609 - val_accuracy: 0.3631\n",
      "Epoch 901/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3599 - accuracy: 0.5421 - val_loss: 3.8517 - val_accuracy: 0.3595\n",
      "Epoch 902/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.5482 - val_loss: 3.8361 - val_accuracy: 0.3558\n",
      "Epoch 903/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3418 - accuracy: 0.5467 - val_loss: 3.9113 - val_accuracy: 0.3485\n",
      "Epoch 904/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3549 - accuracy: 0.5461 - val_loss: 3.9252 - val_accuracy: 0.3491\n",
      "Epoch 905/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3461 - accuracy: 0.5511 - val_loss: 3.9362 - val_accuracy: 0.3491\n",
      "Epoch 906/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3507 - accuracy: 0.5420 - val_loss: 3.8924 - val_accuracy: 0.3485\n",
      "Epoch 907/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3472 - accuracy: 0.5476 - val_loss: 3.8823 - val_accuracy: 0.3546\n",
      "Epoch 908/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3461 - accuracy: 0.5474 - val_loss: 3.8692 - val_accuracy: 0.3546\n",
      "Epoch 909/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3556 - accuracy: 0.5484 - val_loss: 3.9108 - val_accuracy: 0.3522\n",
      "Epoch 910/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5473 - val_loss: 3.8479 - val_accuracy: 0.3564\n",
      "Epoch 911/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3524 - accuracy: 0.5482 - val_loss: 3.8116 - val_accuracy: 0.3516\n",
      "Epoch 912/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3462 - accuracy: 0.5461 - val_loss: 3.8503 - val_accuracy: 0.3461\n",
      "Epoch 913/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5477 - val_loss: 3.8486 - val_accuracy: 0.3637\n",
      "Epoch 914/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3599 - accuracy: 0.5484 - val_loss: 3.8243 - val_accuracy: 0.3607\n",
      "Epoch 915/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3492 - accuracy: 0.5474 - val_loss: 3.8558 - val_accuracy: 0.3595\n",
      "Epoch 916/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3521 - accuracy: 0.5491 - val_loss: 3.8605 - val_accuracy: 0.3601\n",
      "Epoch 917/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3466 - accuracy: 0.5514 - val_loss: 3.9012 - val_accuracy: 0.3479\n",
      "Epoch 918/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3463 - accuracy: 0.5514 - val_loss: 3.8724 - val_accuracy: 0.3571\n",
      "Epoch 919/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3460 - accuracy: 0.5505 - val_loss: 3.8787 - val_accuracy: 0.3455\n",
      "Epoch 920/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3529 - accuracy: 0.5452 - val_loss: 3.8876 - val_accuracy: 0.3498\n",
      "Epoch 921/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3418 - accuracy: 0.5508 - val_loss: 3.9047 - val_accuracy: 0.3613\n",
      "Epoch 922/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.5467 - val_loss: 3.8424 - val_accuracy: 0.3479\n",
      "Epoch 923/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3505 - accuracy: 0.5477 - val_loss: 3.8902 - val_accuracy: 0.3595\n",
      "Epoch 924/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3450 - accuracy: 0.5516 - val_loss: 3.9143 - val_accuracy: 0.3528\n",
      "Epoch 925/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3436 - accuracy: 0.5529 - val_loss: 3.9076 - val_accuracy: 0.3607\n",
      "Epoch 926/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3635 - accuracy: 0.5471 - val_loss: 3.8304 - val_accuracy: 0.3631\n",
      "Epoch 927/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3463 - accuracy: 0.5473 - val_loss: 3.8649 - val_accuracy: 0.3552\n",
      "Epoch 928/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3521 - accuracy: 0.5502 - val_loss: 3.8456 - val_accuracy: 0.3516\n",
      "Epoch 929/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3559 - accuracy: 0.5528 - val_loss: 3.8569 - val_accuracy: 0.3552\n",
      "Epoch 930/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3477 - accuracy: 0.5443 - val_loss: 3.8673 - val_accuracy: 0.3491\n",
      "Epoch 931/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.5477 - val_loss: 3.8565 - val_accuracy: 0.3613\n",
      "Epoch 932/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3457 - accuracy: 0.5476 - val_loss: 3.8592 - val_accuracy: 0.3370\n",
      "Epoch 933/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3433 - accuracy: 0.5503 - val_loss: 3.8929 - val_accuracy: 0.3473\n",
      "Epoch 934/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3569 - accuracy: 0.5435 - val_loss: 3.8589 - val_accuracy: 0.3510\n",
      "Epoch 935/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3526 - accuracy: 0.5458 - val_loss: 3.9006 - val_accuracy: 0.3540\n",
      "Epoch 936/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3472 - accuracy: 0.5502 - val_loss: 3.8657 - val_accuracy: 0.3619\n",
      "Epoch 937/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3404 - accuracy: 0.5535 - val_loss: 3.9432 - val_accuracy: 0.3619\n",
      "Epoch 938/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3433 - accuracy: 0.5493 - val_loss: 3.8998 - val_accuracy: 0.3589\n",
      "Epoch 939/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3489 - accuracy: 0.5441 - val_loss: 3.9435 - val_accuracy: 0.3491\n",
      "Epoch 940/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3535 - accuracy: 0.5450 - val_loss: 3.8683 - val_accuracy: 0.3601\n",
      "Epoch 941/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3476 - accuracy: 0.5476 - val_loss: 3.9019 - val_accuracy: 0.3625\n",
      "Epoch 942/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3529 - accuracy: 0.5450 - val_loss: 3.8651 - val_accuracy: 0.3540\n",
      "Epoch 943/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3447 - accuracy: 0.5453 - val_loss: 3.8814 - val_accuracy: 0.3644\n",
      "Epoch 944/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3383 - accuracy: 0.5520 - val_loss: 3.8843 - val_accuracy: 0.3540\n",
      "Epoch 945/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3484 - accuracy: 0.5496 - val_loss: 3.8957 - val_accuracy: 0.3546\n",
      "Epoch 946/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3448 - accuracy: 0.5455 - val_loss: 3.9174 - val_accuracy: 0.3516\n",
      "Epoch 947/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3442 - accuracy: 0.5462 - val_loss: 3.9261 - val_accuracy: 0.3546\n",
      "Epoch 948/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3446 - accuracy: 0.5496 - val_loss: 3.8824 - val_accuracy: 0.3528\n",
      "Epoch 949/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3410 - accuracy: 0.5473 - val_loss: 3.9399 - val_accuracy: 0.3558\n",
      "Epoch 950/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3492 - accuracy: 0.5453 - val_loss: 3.8689 - val_accuracy: 0.3577\n",
      "Epoch 951/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3486 - accuracy: 0.5496 - val_loss: 3.8768 - val_accuracy: 0.3455\n",
      "Epoch 952/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3488 - accuracy: 0.5500 - val_loss: 3.9611 - val_accuracy: 0.3577\n",
      "Epoch 953/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3588 - accuracy: 0.5493 - val_loss: 3.8710 - val_accuracy: 0.3637\n",
      "Epoch 954/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3429 - accuracy: 0.5493 - val_loss: 3.8986 - val_accuracy: 0.3607\n",
      "Epoch 955/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3430 - accuracy: 0.5514 - val_loss: 3.8719 - val_accuracy: 0.3637\n",
      "Epoch 956/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3534 - accuracy: 0.5438 - val_loss: 3.8896 - val_accuracy: 0.3534\n",
      "Epoch 957/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3446 - accuracy: 0.5503 - val_loss: 3.8649 - val_accuracy: 0.3607\n",
      "Epoch 958/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5453 - val_loss: 3.9256 - val_accuracy: 0.3467\n",
      "Epoch 959/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3472 - accuracy: 0.5465 - val_loss: 3.8985 - val_accuracy: 0.3455\n",
      "Epoch 960/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3516 - accuracy: 0.5456 - val_loss: 3.9042 - val_accuracy: 0.3425\n",
      "Epoch 961/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3479 - accuracy: 0.5537 - val_loss: 3.9045 - val_accuracy: 0.3467\n",
      "Epoch 962/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3496 - accuracy: 0.5441 - val_loss: 3.9399 - val_accuracy: 0.3473\n",
      "Epoch 963/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3481 - accuracy: 0.5458 - val_loss: 3.9014 - val_accuracy: 0.3449\n",
      "Epoch 964/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3474 - accuracy: 0.5529 - val_loss: 3.8983 - val_accuracy: 0.3504\n",
      "Epoch 965/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3380 - accuracy: 0.5523 - val_loss: 3.8968 - val_accuracy: 0.3491\n",
      "Epoch 966/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3458 - accuracy: 0.5484 - val_loss: 3.9019 - val_accuracy: 0.3595\n",
      "Epoch 967/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3475 - accuracy: 0.5420 - val_loss: 3.8646 - val_accuracy: 0.3467\n",
      "Epoch 968/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3461 - accuracy: 0.5479 - val_loss: 3.9563 - val_accuracy: 0.3437\n",
      "Epoch 969/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3478 - accuracy: 0.5526 - val_loss: 3.8930 - val_accuracy: 0.3589\n",
      "Epoch 970/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3473 - accuracy: 0.5438 - val_loss: 3.8470 - val_accuracy: 0.3558\n",
      "Epoch 971/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3448 - accuracy: 0.5503 - val_loss: 3.9361 - val_accuracy: 0.3491\n",
      "Epoch 972/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3480 - accuracy: 0.5476 - val_loss: 3.8962 - val_accuracy: 0.3467\n",
      "Epoch 973/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3475 - accuracy: 0.5496 - val_loss: 3.9336 - val_accuracy: 0.3516\n",
      "Epoch 974/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3522 - accuracy: 0.5462 - val_loss: 3.8424 - val_accuracy: 0.3607\n",
      "Epoch 975/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3385 - accuracy: 0.5503 - val_loss: 3.9358 - val_accuracy: 0.3449\n",
      "Epoch 976/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3518 - accuracy: 0.5493 - val_loss: 3.8897 - val_accuracy: 0.3595\n",
      "Epoch 977/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3473 - accuracy: 0.5479 - val_loss: 3.9204 - val_accuracy: 0.3449\n",
      "Epoch 978/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3433 - accuracy: 0.5491 - val_loss: 3.9353 - val_accuracy: 0.3564\n",
      "Epoch 979/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3489 - accuracy: 0.5505 - val_loss: 3.9267 - val_accuracy: 0.3619\n",
      "Epoch 980/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.5512 - val_loss: 3.9032 - val_accuracy: 0.3589\n",
      "Epoch 981/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3457 - accuracy: 0.5499 - val_loss: 3.9230 - val_accuracy: 0.3473\n",
      "Epoch 982/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3440 - accuracy: 0.5508 - val_loss: 3.9149 - val_accuracy: 0.3583\n",
      "Epoch 983/1000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.5490 - val_loss: 3.9044 - val_accuracy: 0.3479\n",
      "Epoch 984/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3603 - accuracy: 0.5471 - val_loss: 3.9021 - val_accuracy: 0.3455\n",
      "Epoch 985/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.5436 - val_loss: 3.8673 - val_accuracy: 0.3595\n",
      "Epoch 986/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3404 - accuracy: 0.5474 - val_loss: 3.9088 - val_accuracy: 0.3595\n",
      "Epoch 987/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3479 - accuracy: 0.5471 - val_loss: 3.8742 - val_accuracy: 0.3601\n",
      "Epoch 988/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3545 - accuracy: 0.5470 - val_loss: 3.9085 - val_accuracy: 0.3595\n",
      "Epoch 989/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3472 - accuracy: 0.5424 - val_loss: 3.9131 - val_accuracy: 0.3522\n",
      "Epoch 990/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3581 - accuracy: 0.5424 - val_loss: 3.9045 - val_accuracy: 0.3558\n",
      "Epoch 991/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3422 - accuracy: 0.5493 - val_loss: 3.9235 - val_accuracy: 0.3564\n",
      "Epoch 992/1000\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.3456 - accuracy: 0.5468 - val_loss: 3.8990 - val_accuracy: 0.3577\n",
      "Epoch 993/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3451 - accuracy: 0.5477 - val_loss: 3.8873 - val_accuracy: 0.3571\n",
      "Epoch 994/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3489 - accuracy: 0.5499 - val_loss: 3.8937 - val_accuracy: 0.3528\n",
      "Epoch 995/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3488 - accuracy: 0.5497 - val_loss: 3.9271 - val_accuracy: 0.3516\n",
      "Epoch 996/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3517 - accuracy: 0.5488 - val_loss: 3.9093 - val_accuracy: 0.3516\n",
      "Epoch 997/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3550 - accuracy: 0.5471 - val_loss: 3.8186 - val_accuracy: 0.3735\n",
      "Epoch 998/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3513 - accuracy: 0.5508 - val_loss: 3.8847 - val_accuracy: 0.3631\n",
      "Epoch 999/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3515 - accuracy: 0.5461 - val_loss: 3.8932 - val_accuracy: 0.3631\n",
      "Epoch 1000/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3547 - accuracy: 0.5435 - val_loss: 3.8832 - val_accuracy: 0.3686\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 32)\n",
    "history_many_to_many_complex_32 = many_to_many_model_complex.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=32,  # Batch size\n",
    "                                              validation_data=(xx_test, yy_test)  # Validation data\n",
    "                                               ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_complex_model_history_bs32.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_complex_32.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_history(history_many_to_many_complex_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_complex_32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3393 - accuracy: 0.5482 - val_loss: 3.8855 - val_accuracy: 0.3656\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3407 - accuracy: 0.5506 - val_loss: 3.9187 - val_accuracy: 0.3540\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3487 - accuracy: 0.5490 - val_loss: 3.9276 - val_accuracy: 0.3534\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3437 - accuracy: 0.5473 - val_loss: 3.9328 - val_accuracy: 0.3504\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3467 - accuracy: 0.5487 - val_loss: 3.9139 - val_accuracy: 0.3571\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3454 - accuracy: 0.5467 - val_loss: 3.8962 - val_accuracy: 0.3510\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3354 - accuracy: 0.5557 - val_loss: 3.9391 - val_accuracy: 0.3467\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3358 - accuracy: 0.5561 - val_loss: 3.9479 - val_accuracy: 0.3504\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3423 - accuracy: 0.5508 - val_loss: 3.9153 - val_accuracy: 0.3522\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3385 - accuracy: 0.5554 - val_loss: 3.9214 - val_accuracy: 0.3498\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3340 - accuracy: 0.5522 - val_loss: 3.9367 - val_accuracy: 0.3485\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5496 - val_loss: 3.9399 - val_accuracy: 0.3516\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3345 - accuracy: 0.5484 - val_loss: 3.9066 - val_accuracy: 0.3510\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3419 - accuracy: 0.5487 - val_loss: 3.9652 - val_accuracy: 0.3498\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3338 - accuracy: 0.5550 - val_loss: 3.9616 - val_accuracy: 0.3534\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3450 - accuracy: 0.5505 - val_loss: 3.9299 - val_accuracy: 0.3534\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.5465 - val_loss: 3.9679 - val_accuracy: 0.3504\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3412 - accuracy: 0.5523 - val_loss: 3.9387 - val_accuracy: 0.3479\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3374 - accuracy: 0.5505 - val_loss: 3.9559 - val_accuracy: 0.3491\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3307 - accuracy: 0.5525 - val_loss: 3.9330 - val_accuracy: 0.3467\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3394 - accuracy: 0.5493 - val_loss: 3.9361 - val_accuracy: 0.3516\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3379 - accuracy: 0.5470 - val_loss: 3.9700 - val_accuracy: 0.3540\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3413 - accuracy: 0.5446 - val_loss: 3.9404 - val_accuracy: 0.3625\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3424 - accuracy: 0.5511 - val_loss: 3.9555 - val_accuracy: 0.3491\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3358 - accuracy: 0.5503 - val_loss: 3.9349 - val_accuracy: 0.3473\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3422 - accuracy: 0.5493 - val_loss: 3.9291 - val_accuracy: 0.3546\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.5481 - val_loss: 3.9548 - val_accuracy: 0.3552\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3428 - accuracy: 0.5474 - val_loss: 3.9457 - val_accuracy: 0.3534\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3320 - accuracy: 0.5506 - val_loss: 3.9678 - val_accuracy: 0.3491\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3411 - accuracy: 0.5496 - val_loss: 3.9384 - val_accuracy: 0.3540\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3392 - accuracy: 0.5470 - val_loss: 3.9473 - val_accuracy: 0.3558\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3405 - accuracy: 0.5494 - val_loss: 3.9295 - val_accuracy: 0.3540\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3256 - accuracy: 0.5550 - val_loss: 3.9656 - val_accuracy: 0.3510\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3318 - accuracy: 0.5516 - val_loss: 3.9575 - val_accuracy: 0.3485\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3453 - accuracy: 0.5484 - val_loss: 3.9307 - val_accuracy: 0.3437\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3421 - accuracy: 0.5485 - val_loss: 3.9266 - val_accuracy: 0.3510\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3322 - accuracy: 0.5526 - val_loss: 3.9718 - val_accuracy: 0.3437\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.5499 - val_loss: 3.9472 - val_accuracy: 0.3510\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3394 - accuracy: 0.5461 - val_loss: 3.9449 - val_accuracy: 0.3473\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3509 - accuracy: 0.5514 - val_loss: 3.9560 - val_accuracy: 0.3418\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.5540 - val_loss: 3.9431 - val_accuracy: 0.3425\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3411 - accuracy: 0.5482 - val_loss: 3.9683 - val_accuracy: 0.3437\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3414 - accuracy: 0.5490 - val_loss: 3.9303 - val_accuracy: 0.3461\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3367 - accuracy: 0.5516 - val_loss: 3.9194 - val_accuracy: 0.3522\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3370 - accuracy: 0.5477 - val_loss: 3.9520 - val_accuracy: 0.3443\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3250 - accuracy: 0.5516 - val_loss: 3.9716 - val_accuracy: 0.3400\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3418 - accuracy: 0.5477 - val_loss: 3.9696 - val_accuracy: 0.3485\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3455 - accuracy: 0.5517 - val_loss: 3.9408 - val_accuracy: 0.3510\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3398 - accuracy: 0.5502 - val_loss: 3.9283 - val_accuracy: 0.3498\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.5493 - val_loss: 3.9146 - val_accuracy: 0.3443\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3467 - accuracy: 0.5449 - val_loss: 3.9365 - val_accuracy: 0.3455\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3400 - accuracy: 0.5500 - val_loss: 3.9106 - val_accuracy: 0.3485\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3299 - accuracy: 0.5525 - val_loss: 3.9481 - val_accuracy: 0.3461\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3455 - accuracy: 0.5477 - val_loss: 3.9030 - val_accuracy: 0.3510\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3430 - accuracy: 0.5458 - val_loss: 3.8880 - val_accuracy: 0.3449\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3459 - accuracy: 0.5494 - val_loss: 3.9019 - val_accuracy: 0.3485\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5488 - val_loss: 3.9571 - val_accuracy: 0.3406\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3364 - accuracy: 0.5509 - val_loss: 3.9190 - val_accuracy: 0.3431\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3354 - accuracy: 0.5541 - val_loss: 3.9569 - val_accuracy: 0.3412\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3434 - accuracy: 0.5496 - val_loss: 3.9457 - val_accuracy: 0.3473\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3396 - accuracy: 0.5523 - val_loss: 3.9101 - val_accuracy: 0.3479\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3383 - accuracy: 0.5522 - val_loss: 3.9679 - val_accuracy: 0.3498\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3429 - accuracy: 0.5464 - val_loss: 3.9885 - val_accuracy: 0.3540\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.5514 - val_loss: 3.9875 - val_accuracy: 0.3516\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3364 - accuracy: 0.5528 - val_loss: 4.0009 - val_accuracy: 0.3485\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3341 - accuracy: 0.5493 - val_loss: 3.9795 - val_accuracy: 0.3516\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3475 - accuracy: 0.5496 - val_loss: 3.9335 - val_accuracy: 0.3479\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3419 - accuracy: 0.5544 - val_loss: 3.8834 - val_accuracy: 0.3467\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3455 - accuracy: 0.5531 - val_loss: 3.9275 - val_accuracy: 0.3467\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3357 - accuracy: 0.5517 - val_loss: 3.9538 - val_accuracy: 0.3412\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3440 - accuracy: 0.5473 - val_loss: 3.9302 - val_accuracy: 0.3449\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3427 - accuracy: 0.5511 - val_loss: 3.9036 - val_accuracy: 0.3528\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3471 - accuracy: 0.5509 - val_loss: 3.9238 - val_accuracy: 0.3479\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3422 - accuracy: 0.5487 - val_loss: 3.8947 - val_accuracy: 0.3504\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3339 - accuracy: 0.5502 - val_loss: 3.9366 - val_accuracy: 0.3485\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3376 - accuracy: 0.5509 - val_loss: 3.9561 - val_accuracy: 0.3516\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3345 - accuracy: 0.5547 - val_loss: 3.9563 - val_accuracy: 0.3479\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5511 - val_loss: 3.9376 - val_accuracy: 0.3583\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3471 - accuracy: 0.5455 - val_loss: 3.9137 - val_accuracy: 0.3577\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3432 - accuracy: 0.5499 - val_loss: 3.9295 - val_accuracy: 0.3516\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.5465 - val_loss: 3.9668 - val_accuracy: 0.3558\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3469 - accuracy: 0.5449 - val_loss: 3.9765 - val_accuracy: 0.3546\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5482 - val_loss: 3.9427 - val_accuracy: 0.3491\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3363 - accuracy: 0.5488 - val_loss: 3.9691 - val_accuracy: 0.3467\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3304 - accuracy: 0.5517 - val_loss: 3.9593 - val_accuracy: 0.3455\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3354 - accuracy: 0.5496 - val_loss: 3.9601 - val_accuracy: 0.3425\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3430 - accuracy: 0.5505 - val_loss: 3.9419 - val_accuracy: 0.3425\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3466 - accuracy: 0.5503 - val_loss: 3.9573 - val_accuracy: 0.3485\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3352 - accuracy: 0.5477 - val_loss: 3.9465 - val_accuracy: 0.3571\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3442 - accuracy: 0.5496 - val_loss: 3.9542 - val_accuracy: 0.3455\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3419 - accuracy: 0.5514 - val_loss: 3.9168 - val_accuracy: 0.3479\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3354 - accuracy: 0.5534 - val_loss: 3.9507 - val_accuracy: 0.3467\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3391 - accuracy: 0.5511 - val_loss: 3.9419 - val_accuracy: 0.3558\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3460 - accuracy: 0.5505 - val_loss: 3.9143 - val_accuracy: 0.3467\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3322 - accuracy: 0.5519 - val_loss: 3.9270 - val_accuracy: 0.3571\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3400 - accuracy: 0.5502 - val_loss: 3.9461 - val_accuracy: 0.3516\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3359 - accuracy: 0.5546 - val_loss: 3.9406 - val_accuracy: 0.3467\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3395 - accuracy: 0.5496 - val_loss: 3.9802 - val_accuracy: 0.3546\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3414 - accuracy: 0.5506 - val_loss: 3.9462 - val_accuracy: 0.3589\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3459 - accuracy: 0.5476 - val_loss: 3.9396 - val_accuracy: 0.3589\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3391 - accuracy: 0.5505 - val_loss: 3.9848 - val_accuracy: 0.3528\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3348 - accuracy: 0.5497 - val_loss: 3.9634 - val_accuracy: 0.3534\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3281 - accuracy: 0.5546 - val_loss: 3.9399 - val_accuracy: 0.3552\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5564 - val_loss: 3.9490 - val_accuracy: 0.3583\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3413 - accuracy: 0.5499 - val_loss: 3.9555 - val_accuracy: 0.3485\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3382 - accuracy: 0.5479 - val_loss: 3.9257 - val_accuracy: 0.3528\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3321 - accuracy: 0.5543 - val_loss: 3.8986 - val_accuracy: 0.3552\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3414 - accuracy: 0.5519 - val_loss: 3.9463 - val_accuracy: 0.3455\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3452 - accuracy: 0.5482 - val_loss: 3.9532 - val_accuracy: 0.3552\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3375 - accuracy: 0.5479 - val_loss: 3.9817 - val_accuracy: 0.3540\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3381 - accuracy: 0.5535 - val_loss: 3.9653 - val_accuracy: 0.3534\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3401 - accuracy: 0.5520 - val_loss: 3.9625 - val_accuracy: 0.3516\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3441 - accuracy: 0.5525 - val_loss: 3.9303 - val_accuracy: 0.3516\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3442 - accuracy: 0.5485 - val_loss: 3.9261 - val_accuracy: 0.3467\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3453 - accuracy: 0.5520 - val_loss: 3.9215 - val_accuracy: 0.3425\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3386 - accuracy: 0.5505 - val_loss: 3.9565 - val_accuracy: 0.3418\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3305 - accuracy: 0.5540 - val_loss: 3.9514 - val_accuracy: 0.3364\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3456 - accuracy: 0.5484 - val_loss: 3.9104 - val_accuracy: 0.3461\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3332 - accuracy: 0.5493 - val_loss: 3.9689 - val_accuracy: 0.3406\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3386 - accuracy: 0.5491 - val_loss: 3.9540 - val_accuracy: 0.3498\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3387 - accuracy: 0.5488 - val_loss: 3.9231 - val_accuracy: 0.3455\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3326 - accuracy: 0.5575 - val_loss: 3.9422 - val_accuracy: 0.3443\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3481 - accuracy: 0.5473 - val_loss: 3.8771 - val_accuracy: 0.3558\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3385 - accuracy: 0.5511 - val_loss: 3.9640 - val_accuracy: 0.3443\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3400 - accuracy: 0.5468 - val_loss: 3.9132 - val_accuracy: 0.3504\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3437 - accuracy: 0.5487 - val_loss: 3.8861 - val_accuracy: 0.3510\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3269 - accuracy: 0.5554 - val_loss: 3.9232 - val_accuracy: 0.3510\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.5535 - val_loss: 3.9452 - val_accuracy: 0.3455\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3422 - accuracy: 0.5496 - val_loss: 3.8631 - val_accuracy: 0.3546\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3377 - accuracy: 0.5505 - val_loss: 3.8715 - val_accuracy: 0.3558\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3386 - accuracy: 0.5526 - val_loss: 3.9208 - val_accuracy: 0.3510\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3372 - accuracy: 0.5519 - val_loss: 3.9115 - val_accuracy: 0.3552\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.5540 - val_loss: 3.9646 - val_accuracy: 0.3504\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.5494 - val_loss: 3.9269 - val_accuracy: 0.3504\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3418 - accuracy: 0.5511 - val_loss: 3.9449 - val_accuracy: 0.3558\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3420 - accuracy: 0.5493 - val_loss: 3.9224 - val_accuracy: 0.3522\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5514 - val_loss: 3.9443 - val_accuracy: 0.3461\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3387 - accuracy: 0.5512 - val_loss: 3.9439 - val_accuracy: 0.3577\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3336 - accuracy: 0.5532 - val_loss: 3.9168 - val_accuracy: 0.3394\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3377 - accuracy: 0.5444 - val_loss: 3.9418 - val_accuracy: 0.3504\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3430 - accuracy: 0.5470 - val_loss: 3.9541 - val_accuracy: 0.3431\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3412 - accuracy: 0.5496 - val_loss: 3.9028 - val_accuracy: 0.3382\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3324 - accuracy: 0.5512 - val_loss: 3.9435 - val_accuracy: 0.3534\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3473 - accuracy: 0.5497 - val_loss: 3.9346 - val_accuracy: 0.3522\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.5522 - val_loss: 3.9384 - val_accuracy: 0.3583\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3413 - accuracy: 0.5493 - val_loss: 3.8983 - val_accuracy: 0.3473\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3410 - accuracy: 0.5541 - val_loss: 3.9210 - val_accuracy: 0.3467\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.5453 - val_loss: 3.9219 - val_accuracy: 0.3522\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3395 - accuracy: 0.5497 - val_loss: 3.9822 - val_accuracy: 0.3540\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3442 - accuracy: 0.5529 - val_loss: 3.9662 - val_accuracy: 0.3558\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3426 - accuracy: 0.5482 - val_loss: 3.9303 - val_accuracy: 0.3534\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3438 - accuracy: 0.5508 - val_loss: 3.9691 - val_accuracy: 0.3534\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3365 - accuracy: 0.5529 - val_loss: 3.9687 - val_accuracy: 0.3522\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3470 - accuracy: 0.5516 - val_loss: 3.9585 - val_accuracy: 0.3491\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3394 - accuracy: 0.5520 - val_loss: 3.9401 - val_accuracy: 0.3601\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3263 - accuracy: 0.5508 - val_loss: 3.9779 - val_accuracy: 0.3516\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3421 - accuracy: 0.5500 - val_loss: 3.9444 - val_accuracy: 0.3589\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3440 - accuracy: 0.5491 - val_loss: 3.9257 - val_accuracy: 0.3625\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3370 - accuracy: 0.5499 - val_loss: 3.9434 - val_accuracy: 0.3583\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.5503 - val_loss: 3.9286 - val_accuracy: 0.3522\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3408 - accuracy: 0.5523 - val_loss: 3.9766 - val_accuracy: 0.3467\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3411 - accuracy: 0.5543 - val_loss: 3.9644 - val_accuracy: 0.3571\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3402 - accuracy: 0.5468 - val_loss: 3.9338 - val_accuracy: 0.3595\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3452 - accuracy: 0.5481 - val_loss: 3.9279 - val_accuracy: 0.3540\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5500 - val_loss: 3.9296 - val_accuracy: 0.3498\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3412 - accuracy: 0.5502 - val_loss: 3.9020 - val_accuracy: 0.3619\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3359 - accuracy: 0.5522 - val_loss: 3.9820 - val_accuracy: 0.3564\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3336 - accuracy: 0.5471 - val_loss: 3.9731 - val_accuracy: 0.3461\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3476 - accuracy: 0.5517 - val_loss: 3.9338 - val_accuracy: 0.3467\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3457 - accuracy: 0.5479 - val_loss: 3.9482 - val_accuracy: 0.3558\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5508 - val_loss: 3.9538 - val_accuracy: 0.3449\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3328 - accuracy: 0.5547 - val_loss: 3.9589 - val_accuracy: 0.3552\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3403 - accuracy: 0.5477 - val_loss: 3.9260 - val_accuracy: 0.3552\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3467 - accuracy: 0.5488 - val_loss: 3.9331 - val_accuracy: 0.3552\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3426 - accuracy: 0.5473 - val_loss: 3.9688 - val_accuracy: 0.3534\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5496 - val_loss: 3.9441 - val_accuracy: 0.3479\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3481 - accuracy: 0.5443 - val_loss: 3.9789 - val_accuracy: 0.3504\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3373 - accuracy: 0.5477 - val_loss: 3.9627 - val_accuracy: 0.3534\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.5531 - val_loss: 3.9599 - val_accuracy: 0.3485\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3445 - accuracy: 0.5505 - val_loss: 3.9519 - val_accuracy: 0.3540\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3391 - accuracy: 0.5467 - val_loss: 3.9675 - val_accuracy: 0.3498\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3468 - accuracy: 0.5398 - val_loss: 3.9552 - val_accuracy: 0.3449\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5538 - val_loss: 3.9706 - val_accuracy: 0.3540\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3425 - accuracy: 0.5511 - val_loss: 3.9354 - val_accuracy: 0.3443\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3389 - accuracy: 0.5523 - val_loss: 4.0124 - val_accuracy: 0.3485\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5502 - val_loss: 3.9956 - val_accuracy: 0.3455\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3399 - accuracy: 0.5525 - val_loss: 3.9744 - val_accuracy: 0.3455\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5511 - val_loss: 3.9345 - val_accuracy: 0.3431\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3349 - accuracy: 0.5525 - val_loss: 4.0020 - val_accuracy: 0.3485\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3387 - accuracy: 0.5550 - val_loss: 3.9476 - val_accuracy: 0.3461\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3404 - accuracy: 0.5503 - val_loss: 3.9399 - val_accuracy: 0.3504\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3383 - accuracy: 0.5543 - val_loss: 3.9515 - val_accuracy: 0.3516\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3339 - accuracy: 0.5517 - val_loss: 3.9424 - val_accuracy: 0.3382\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3412 - accuracy: 0.5555 - val_loss: 3.9601 - val_accuracy: 0.3425\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3445 - accuracy: 0.5462 - val_loss: 3.9816 - val_accuracy: 0.3534\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3271 - accuracy: 0.5564 - val_loss: 3.9530 - val_accuracy: 0.3546\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5485 - val_loss: 3.9228 - val_accuracy: 0.3564\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5494 - val_loss: 3.9878 - val_accuracy: 0.3571\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3402 - accuracy: 0.5487 - val_loss: 3.9785 - val_accuracy: 0.3564\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3374 - accuracy: 0.5526 - val_loss: 3.9843 - val_accuracy: 0.3558\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3393 - accuracy: 0.5485 - val_loss: 3.9807 - val_accuracy: 0.3437\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3445 - accuracy: 0.5470 - val_loss: 3.9568 - val_accuracy: 0.3467\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3423 - accuracy: 0.5493 - val_loss: 3.9481 - val_accuracy: 0.3498\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3478 - accuracy: 0.5461 - val_loss: 3.9459 - val_accuracy: 0.3510\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3429 - accuracy: 0.5508 - val_loss: 3.9283 - val_accuracy: 0.3455\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3342 - accuracy: 0.5516 - val_loss: 3.9462 - val_accuracy: 0.3577\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3446 - accuracy: 0.5450 - val_loss: 3.9440 - val_accuracy: 0.3455\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3357 - accuracy: 0.5499 - val_loss: 3.9407 - val_accuracy: 0.3443\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3343 - accuracy: 0.5531 - val_loss: 3.9792 - val_accuracy: 0.3449\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3378 - accuracy: 0.5506 - val_loss: 3.9802 - val_accuracy: 0.3467\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3391 - accuracy: 0.5535 - val_loss: 3.9526 - val_accuracy: 0.3455\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3409 - accuracy: 0.5529 - val_loss: 3.9692 - val_accuracy: 0.3425\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3416 - accuracy: 0.5497 - val_loss: 3.9404 - val_accuracy: 0.3431\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3415 - accuracy: 0.5505 - val_loss: 3.9320 - val_accuracy: 0.3467\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.5499 - val_loss: 3.9638 - val_accuracy: 0.3437\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3283 - accuracy: 0.5511 - val_loss: 3.9479 - val_accuracy: 0.3528\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3344 - accuracy: 0.5532 - val_loss: 3.9662 - val_accuracy: 0.3485\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3366 - accuracy: 0.5549 - val_loss: 3.9709 - val_accuracy: 0.3449\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3387 - accuracy: 0.5490 - val_loss: 3.9414 - val_accuracy: 0.3418\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3364 - accuracy: 0.5470 - val_loss: 3.9592 - val_accuracy: 0.3473\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3406 - accuracy: 0.5477 - val_loss: 3.9521 - val_accuracy: 0.3510\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.5499 - val_loss: 3.9966 - val_accuracy: 0.3546\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3370 - accuracy: 0.5488 - val_loss: 3.9699 - val_accuracy: 0.3479\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3397 - accuracy: 0.5509 - val_loss: 3.9519 - val_accuracy: 0.3540\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5436 - val_loss: 3.9782 - val_accuracy: 0.3558\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3318 - accuracy: 0.5487 - val_loss: 3.9492 - val_accuracy: 0.3564\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3416 - accuracy: 0.5449 - val_loss: 3.9285 - val_accuracy: 0.3522\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3471 - accuracy: 0.5467 - val_loss: 3.9515 - val_accuracy: 0.3461\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3358 - accuracy: 0.5537 - val_loss: 3.9236 - val_accuracy: 0.3552\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3323 - accuracy: 0.5528 - val_loss: 3.9613 - val_accuracy: 0.3516\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3429 - accuracy: 0.5519 - val_loss: 3.9197 - val_accuracy: 0.3583\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.5467 - val_loss: 3.9300 - val_accuracy: 0.3558\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3402 - accuracy: 0.5509 - val_loss: 3.9617 - val_accuracy: 0.3558\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3398 - accuracy: 0.5481 - val_loss: 3.9728 - val_accuracy: 0.3504\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3447 - accuracy: 0.5465 - val_loss: 3.9211 - val_accuracy: 0.3540\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3487 - accuracy: 0.5452 - val_loss: 3.9528 - val_accuracy: 0.3583\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.3405 - accuracy: 0.5456 - val_loss: 3.9441 - val_accuracy: 0.3601\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5494 - val_loss: 3.9688 - val_accuracy: 0.3564\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3454 - accuracy: 0.5514 - val_loss: 3.9548 - val_accuracy: 0.3577\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3295 - accuracy: 0.5488 - val_loss: 3.9214 - val_accuracy: 0.3516\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3389 - accuracy: 0.5511 - val_loss: 3.9233 - val_accuracy: 0.3546\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3243 - accuracy: 0.5547 - val_loss: 3.9515 - val_accuracy: 0.3540\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3367 - accuracy: 0.5502 - val_loss: 3.9590 - val_accuracy: 0.3491\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3363 - accuracy: 0.5531 - val_loss: 3.9711 - val_accuracy: 0.3516\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3358 - accuracy: 0.5505 - val_loss: 3.9301 - val_accuracy: 0.3522\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3291 - accuracy: 0.5529 - val_loss: 3.9598 - val_accuracy: 0.3558\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3451 - accuracy: 0.5468 - val_loss: 3.9594 - val_accuracy: 0.3479\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3405 - accuracy: 0.5484 - val_loss: 3.9523 - val_accuracy: 0.3552\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3301 - accuracy: 0.5519 - val_loss: 3.9585 - val_accuracy: 0.3510\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3425 - accuracy: 0.5479 - val_loss: 3.9616 - val_accuracy: 0.3449\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3338 - accuracy: 0.5517 - val_loss: 3.9804 - val_accuracy: 0.3504\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3432 - accuracy: 0.5467 - val_loss: 3.9805 - val_accuracy: 0.3498\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3294 - accuracy: 0.5496 - val_loss: 4.0233 - val_accuracy: 0.3485\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3398 - accuracy: 0.5508 - val_loss: 3.9823 - val_accuracy: 0.3564\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3396 - accuracy: 0.5496 - val_loss: 4.0242 - val_accuracy: 0.3504\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3396 - accuracy: 0.5494 - val_loss: 3.9637 - val_accuracy: 0.3498\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3303 - accuracy: 0.5511 - val_loss: 3.9825 - val_accuracy: 0.3583\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.5508 - val_loss: 3.9818 - val_accuracy: 0.3564\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3300 - accuracy: 0.5485 - val_loss: 4.0192 - val_accuracy: 0.3510\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3331 - accuracy: 0.5488 - val_loss: 3.9577 - val_accuracy: 0.3583\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3314 - accuracy: 0.5509 - val_loss: 3.9587 - val_accuracy: 0.3528\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3317 - accuracy: 0.5566 - val_loss: 3.9486 - val_accuracy: 0.3431\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3342 - accuracy: 0.5534 - val_loss: 4.0036 - val_accuracy: 0.3425\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3388 - accuracy: 0.5464 - val_loss: 4.0175 - val_accuracy: 0.3437\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3322 - accuracy: 0.5502 - val_loss: 4.0522 - val_accuracy: 0.3455\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3399 - accuracy: 0.5487 - val_loss: 3.9905 - val_accuracy: 0.3431\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5531 - val_loss: 4.0277 - val_accuracy: 0.3583\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3476 - accuracy: 0.5476 - val_loss: 4.0255 - val_accuracy: 0.3431\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3374 - accuracy: 0.5514 - val_loss: 4.0135 - val_accuracy: 0.3607\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5535 - val_loss: 4.0253 - val_accuracy: 0.3491\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5500 - val_loss: 3.9851 - val_accuracy: 0.3528\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3334 - accuracy: 0.5497 - val_loss: 4.0299 - val_accuracy: 0.3455\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3389 - accuracy: 0.5522 - val_loss: 3.9778 - val_accuracy: 0.3546\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3384 - accuracy: 0.5487 - val_loss: 3.9608 - val_accuracy: 0.3571\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3371 - accuracy: 0.5505 - val_loss: 4.0243 - val_accuracy: 0.3558\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3438 - accuracy: 0.5474 - val_loss: 3.9819 - val_accuracy: 0.3552\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3376 - accuracy: 0.5535 - val_loss: 3.9542 - val_accuracy: 0.3528\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3367 - accuracy: 0.5493 - val_loss: 3.9602 - val_accuracy: 0.3467\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.5516 - val_loss: 3.9713 - val_accuracy: 0.3540\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.5455 - val_loss: 3.9980 - val_accuracy: 0.3510\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3464 - accuracy: 0.5436 - val_loss: 3.9653 - val_accuracy: 0.3564\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3309 - accuracy: 0.5529 - val_loss: 3.9852 - val_accuracy: 0.3589\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3326 - accuracy: 0.5519 - val_loss: 3.9875 - val_accuracy: 0.3564\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3322 - accuracy: 0.5525 - val_loss: 4.0468 - val_accuracy: 0.3546\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3365 - accuracy: 0.5506 - val_loss: 4.0001 - val_accuracy: 0.3571\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5511 - val_loss: 4.0260 - val_accuracy: 0.3571\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3352 - accuracy: 0.5540 - val_loss: 4.0380 - val_accuracy: 0.3522\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3450 - accuracy: 0.5438 - val_loss: 3.9970 - val_accuracy: 0.3589\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5531 - val_loss: 4.0215 - val_accuracy: 0.3552\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5491 - val_loss: 4.0066 - val_accuracy: 0.3607\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3341 - accuracy: 0.5543 - val_loss: 4.0363 - val_accuracy: 0.3637\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3442 - accuracy: 0.5549 - val_loss: 3.9610 - val_accuracy: 0.3583\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3366 - accuracy: 0.5526 - val_loss: 4.0319 - val_accuracy: 0.3534\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3415 - accuracy: 0.5468 - val_loss: 4.0022 - val_accuracy: 0.3516\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3376 - accuracy: 0.5499 - val_loss: 3.9966 - val_accuracy: 0.3485\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3346 - accuracy: 0.5546 - val_loss: 4.0130 - val_accuracy: 0.3583\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3330 - accuracy: 0.5523 - val_loss: 3.9883 - val_accuracy: 0.3613\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3283 - accuracy: 0.5502 - val_loss: 4.0350 - val_accuracy: 0.3528\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3361 - accuracy: 0.5503 - val_loss: 3.9786 - val_accuracy: 0.3473\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3390 - accuracy: 0.5500 - val_loss: 4.0052 - val_accuracy: 0.3449\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3380 - accuracy: 0.5519 - val_loss: 3.9866 - val_accuracy: 0.3552\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3415 - accuracy: 0.5476 - val_loss: 4.0008 - val_accuracy: 0.3485\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3204 - accuracy: 0.5581 - val_loss: 4.0364 - val_accuracy: 0.3455\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3450 - accuracy: 0.5456 - val_loss: 4.0095 - val_accuracy: 0.3412\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3355 - accuracy: 0.5532 - val_loss: 4.0367 - val_accuracy: 0.3394\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3343 - accuracy: 0.5525 - val_loss: 3.9956 - val_accuracy: 0.3394\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3344 - accuracy: 0.5449 - val_loss: 4.0147 - val_accuracy: 0.3540\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3358 - accuracy: 0.5494 - val_loss: 4.0314 - val_accuracy: 0.3546\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3299 - accuracy: 0.5503 - val_loss: 3.9876 - val_accuracy: 0.3552\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5528 - val_loss: 4.0253 - val_accuracy: 0.3528\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3362 - accuracy: 0.5529 - val_loss: 4.0298 - val_accuracy: 0.3528\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3448 - accuracy: 0.5502 - val_loss: 3.9979 - val_accuracy: 0.3595\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3412 - accuracy: 0.5496 - val_loss: 3.9977 - val_accuracy: 0.3552\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3357 - accuracy: 0.5511 - val_loss: 4.0133 - val_accuracy: 0.3534\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3287 - accuracy: 0.5579 - val_loss: 3.9947 - val_accuracy: 0.3540\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3253 - accuracy: 0.5525 - val_loss: 4.0199 - val_accuracy: 0.3571\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3328 - accuracy: 0.5516 - val_loss: 4.0039 - val_accuracy: 0.3583\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.5500 - val_loss: 3.9893 - val_accuracy: 0.3558\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3459 - accuracy: 0.5427 - val_loss: 3.9923 - val_accuracy: 0.3558\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3343 - accuracy: 0.5484 - val_loss: 4.0270 - val_accuracy: 0.3540\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3321 - accuracy: 0.5526 - val_loss: 4.0566 - val_accuracy: 0.3528\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5514 - val_loss: 3.9834 - val_accuracy: 0.3571\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3359 - accuracy: 0.5522 - val_loss: 3.9950 - val_accuracy: 0.3577\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3468 - accuracy: 0.5511 - val_loss: 3.9942 - val_accuracy: 0.3571\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3295 - accuracy: 0.5555 - val_loss: 3.9731 - val_accuracy: 0.3577\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3229 - accuracy: 0.5522 - val_loss: 4.0070 - val_accuracy: 0.3589\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3371 - accuracy: 0.5508 - val_loss: 3.9852 - val_accuracy: 0.3595\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.5500 - val_loss: 3.9947 - val_accuracy: 0.3485\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3361 - accuracy: 0.5470 - val_loss: 4.0075 - val_accuracy: 0.3552\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5519 - val_loss: 3.9869 - val_accuracy: 0.3564\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5481 - val_loss: 4.0108 - val_accuracy: 0.3510\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3399 - accuracy: 0.5479 - val_loss: 3.9613 - val_accuracy: 0.3449\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5497 - val_loss: 3.9804 - val_accuracy: 0.3479\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3397 - accuracy: 0.5534 - val_loss: 3.9630 - val_accuracy: 0.3498\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3420 - accuracy: 0.5458 - val_loss: 3.9565 - val_accuracy: 0.3425\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3400 - accuracy: 0.5505 - val_loss: 3.9675 - val_accuracy: 0.3406\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3415 - accuracy: 0.5471 - val_loss: 3.9683 - val_accuracy: 0.3504\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3357 - accuracy: 0.5494 - val_loss: 3.9709 - val_accuracy: 0.3504\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3340 - accuracy: 0.5493 - val_loss: 3.9826 - val_accuracy: 0.3558\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5550 - val_loss: 4.0315 - val_accuracy: 0.3504\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5509 - val_loss: 3.9901 - val_accuracy: 0.3467\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3343 - accuracy: 0.5519 - val_loss: 3.9771 - val_accuracy: 0.3467\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3422 - accuracy: 0.5458 - val_loss: 3.9849 - val_accuracy: 0.3558\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3407 - accuracy: 0.5534 - val_loss: 4.0142 - val_accuracy: 0.3564\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3319 - accuracy: 0.5519 - val_loss: 3.9899 - val_accuracy: 0.3510\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3411 - accuracy: 0.5485 - val_loss: 3.9987 - val_accuracy: 0.3552\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5512 - val_loss: 3.9925 - val_accuracy: 0.3564\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3332 - accuracy: 0.5512 - val_loss: 3.9980 - val_accuracy: 0.3546\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3264 - accuracy: 0.5534 - val_loss: 4.0473 - val_accuracy: 0.3552\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3435 - accuracy: 0.5499 - val_loss: 4.0153 - val_accuracy: 0.3510\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3326 - accuracy: 0.5525 - val_loss: 4.0397 - val_accuracy: 0.3510\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3367 - accuracy: 0.5496 - val_loss: 4.0249 - val_accuracy: 0.3491\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.5497 - val_loss: 4.0597 - val_accuracy: 0.3552\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3278 - accuracy: 0.5546 - val_loss: 4.0757 - val_accuracy: 0.3552\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3420 - accuracy: 0.5444 - val_loss: 4.0239 - val_accuracy: 0.3491\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3409 - accuracy: 0.5516 - val_loss: 4.0096 - val_accuracy: 0.3552\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3424 - accuracy: 0.5493 - val_loss: 4.0412 - val_accuracy: 0.3400\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3405 - accuracy: 0.5496 - val_loss: 4.0016 - val_accuracy: 0.3449\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.5497 - val_loss: 3.9730 - val_accuracy: 0.3546\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3395 - accuracy: 0.5479 - val_loss: 4.0156 - val_accuracy: 0.3540\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3404 - accuracy: 0.5520 - val_loss: 3.9716 - val_accuracy: 0.3571\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3405 - accuracy: 0.5506 - val_loss: 4.0075 - val_accuracy: 0.3449\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.5557 - val_loss: 4.0058 - val_accuracy: 0.3412\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3373 - accuracy: 0.5477 - val_loss: 3.9613 - val_accuracy: 0.3571\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3390 - accuracy: 0.5519 - val_loss: 3.9968 - val_accuracy: 0.3437\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3277 - accuracy: 0.5523 - val_loss: 3.9693 - val_accuracy: 0.3449\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3390 - accuracy: 0.5490 - val_loss: 3.9813 - val_accuracy: 0.3522\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3300 - accuracy: 0.5519 - val_loss: 4.0030 - val_accuracy: 0.3601\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3393 - accuracy: 0.5537 - val_loss: 4.0212 - val_accuracy: 0.3528\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3262 - accuracy: 0.5508 - val_loss: 3.9967 - val_accuracy: 0.3571\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3447 - accuracy: 0.5446 - val_loss: 3.9917 - val_accuracy: 0.3552\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3386 - accuracy: 0.5508 - val_loss: 3.9536 - val_accuracy: 0.3564\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3410 - accuracy: 0.5458 - val_loss: 3.9794 - val_accuracy: 0.3619\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3393 - accuracy: 0.5481 - val_loss: 3.9355 - val_accuracy: 0.3607\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3404 - accuracy: 0.5467 - val_loss: 3.9808 - val_accuracy: 0.3571\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5485 - val_loss: 4.0023 - val_accuracy: 0.3564\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3345 - accuracy: 0.5528 - val_loss: 3.9638 - val_accuracy: 0.3552\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3347 - accuracy: 0.5499 - val_loss: 3.9659 - val_accuracy: 0.3552\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5474 - val_loss: 4.0288 - val_accuracy: 0.3522\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3388 - accuracy: 0.5496 - val_loss: 3.9563 - val_accuracy: 0.3534\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3514 - accuracy: 0.5441 - val_loss: 3.9342 - val_accuracy: 0.3637\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3245 - accuracy: 0.5544 - val_loss: 3.9968 - val_accuracy: 0.3595\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3371 - accuracy: 0.5499 - val_loss: 4.0382 - val_accuracy: 0.3522\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3276 - accuracy: 0.5550 - val_loss: 4.0386 - val_accuracy: 0.3552\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3310 - accuracy: 0.5493 - val_loss: 4.0101 - val_accuracy: 0.3522\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5494 - val_loss: 4.0269 - val_accuracy: 0.3461\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3508 - accuracy: 0.5499 - val_loss: 4.0152 - val_accuracy: 0.3516\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3288 - accuracy: 0.5488 - val_loss: 4.0306 - val_accuracy: 0.3425\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3371 - accuracy: 0.5477 - val_loss: 4.0349 - val_accuracy: 0.3425\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3301 - accuracy: 0.5547 - val_loss: 4.0274 - val_accuracy: 0.3540\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3401 - accuracy: 0.5516 - val_loss: 4.0261 - val_accuracy: 0.3571\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5514 - val_loss: 4.0252 - val_accuracy: 0.3431\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5514 - val_loss: 4.0427 - val_accuracy: 0.3558\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3362 - accuracy: 0.5458 - val_loss: 4.0014 - val_accuracy: 0.3583\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3306 - accuracy: 0.5493 - val_loss: 4.0095 - val_accuracy: 0.3583\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3316 - accuracy: 0.5512 - val_loss: 4.0267 - val_accuracy: 0.3431\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3427 - accuracy: 0.5470 - val_loss: 3.9682 - val_accuracy: 0.3595\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3333 - accuracy: 0.5503 - val_loss: 3.9871 - val_accuracy: 0.3571\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3423 - accuracy: 0.5484 - val_loss: 3.9276 - val_accuracy: 0.3607\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3321 - accuracy: 0.5500 - val_loss: 4.0029 - val_accuracy: 0.3558\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3332 - accuracy: 0.5531 - val_loss: 3.9844 - val_accuracy: 0.3491\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3346 - accuracy: 0.5493 - val_loss: 3.9751 - val_accuracy: 0.3558\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3381 - accuracy: 0.5462 - val_loss: 4.0229 - val_accuracy: 0.3546\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3334 - accuracy: 0.5528 - val_loss: 4.0138 - val_accuracy: 0.3564\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3326 - accuracy: 0.5503 - val_loss: 4.0130 - val_accuracy: 0.3540\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3417 - accuracy: 0.5477 - val_loss: 4.0179 - val_accuracy: 0.3534\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3255 - accuracy: 0.5532 - val_loss: 4.0431 - val_accuracy: 0.3522\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5540 - val_loss: 4.0323 - val_accuracy: 0.3498\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3303 - accuracy: 0.5508 - val_loss: 3.9917 - val_accuracy: 0.3522\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3299 - accuracy: 0.5519 - val_loss: 4.0284 - val_accuracy: 0.3473\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3392 - accuracy: 0.5506 - val_loss: 3.9849 - val_accuracy: 0.3504\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.5488 - val_loss: 3.9840 - val_accuracy: 0.3431\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3322 - accuracy: 0.5503 - val_loss: 3.9875 - val_accuracy: 0.3406\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3354 - accuracy: 0.5458 - val_loss: 3.9861 - val_accuracy: 0.3412\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3269 - accuracy: 0.5528 - val_loss: 3.9987 - val_accuracy: 0.3394\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.5537 - val_loss: 4.0237 - val_accuracy: 0.3406\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3330 - accuracy: 0.5500 - val_loss: 4.0258 - val_accuracy: 0.3504\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3320 - accuracy: 0.5511 - val_loss: 4.0218 - val_accuracy: 0.3455\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3386 - accuracy: 0.5473 - val_loss: 4.0396 - val_accuracy: 0.3461\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3388 - accuracy: 0.5502 - val_loss: 4.0288 - val_accuracy: 0.3571\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3364 - accuracy: 0.5509 - val_loss: 4.0353 - val_accuracy: 0.3498\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3306 - accuracy: 0.5532 - val_loss: 4.0838 - val_accuracy: 0.3418\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3369 - accuracy: 0.5487 - val_loss: 4.0049 - val_accuracy: 0.3431\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3322 - accuracy: 0.5493 - val_loss: 4.0048 - val_accuracy: 0.3382\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3298 - accuracy: 0.5528 - val_loss: 4.0376 - val_accuracy: 0.3583\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3408 - accuracy: 0.5509 - val_loss: 4.0367 - val_accuracy: 0.3418\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.5525 - val_loss: 3.9998 - val_accuracy: 0.3540\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5514 - val_loss: 4.0217 - val_accuracy: 0.3425\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3405 - accuracy: 0.5484 - val_loss: 3.9993 - val_accuracy: 0.3364\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3392 - accuracy: 0.5531 - val_loss: 4.0052 - val_accuracy: 0.3461\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3396 - accuracy: 0.5474 - val_loss: 4.0382 - val_accuracy: 0.3479\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3334 - accuracy: 0.5502 - val_loss: 3.9965 - val_accuracy: 0.3473\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3285 - accuracy: 0.5520 - val_loss: 4.0202 - val_accuracy: 0.3418\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3386 - accuracy: 0.5505 - val_loss: 3.9989 - val_accuracy: 0.3443\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5508 - val_loss: 4.0059 - val_accuracy: 0.3491\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3314 - accuracy: 0.5561 - val_loss: 4.0035 - val_accuracy: 0.3619\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3303 - accuracy: 0.5516 - val_loss: 3.9918 - val_accuracy: 0.3583\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3450 - accuracy: 0.5499 - val_loss: 3.9804 - val_accuracy: 0.3382\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3402 - accuracy: 0.5488 - val_loss: 4.0128 - val_accuracy: 0.3455\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3420 - accuracy: 0.5511 - val_loss: 3.9871 - val_accuracy: 0.3449\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3391 - accuracy: 0.5516 - val_loss: 4.0047 - val_accuracy: 0.3491\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3425 - accuracy: 0.5528 - val_loss: 3.9748 - val_accuracy: 0.3498\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3374 - accuracy: 0.5488 - val_loss: 3.9868 - val_accuracy: 0.3552\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3272 - accuracy: 0.5508 - val_loss: 4.0282 - val_accuracy: 0.3455\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3152 - accuracy: 0.5522 - val_loss: 4.0851 - val_accuracy: 0.3510\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5534 - val_loss: 4.0058 - val_accuracy: 0.3534\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3337 - accuracy: 0.5511 - val_loss: 4.0130 - val_accuracy: 0.3601\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3296 - accuracy: 0.5474 - val_loss: 3.9953 - val_accuracy: 0.3461\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3268 - accuracy: 0.5557 - val_loss: 4.0090 - val_accuracy: 0.3485\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3300 - accuracy: 0.5487 - val_loss: 4.0267 - val_accuracy: 0.3498\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3430 - accuracy: 0.5414 - val_loss: 3.9878 - val_accuracy: 0.3498\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3258 - accuracy: 0.5494 - val_loss: 4.0391 - val_accuracy: 0.3534\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3399 - accuracy: 0.5479 - val_loss: 4.0364 - val_accuracy: 0.3467\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3468 - accuracy: 0.5446 - val_loss: 4.0413 - val_accuracy: 0.3546\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3291 - accuracy: 0.5508 - val_loss: 4.0266 - val_accuracy: 0.3516\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3409 - accuracy: 0.5512 - val_loss: 4.0328 - val_accuracy: 0.3437\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3349 - accuracy: 0.5547 - val_loss: 4.0082 - val_accuracy: 0.3546\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3339 - accuracy: 0.5520 - val_loss: 4.0255 - val_accuracy: 0.3467\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3315 - accuracy: 0.5503 - val_loss: 4.0134 - val_accuracy: 0.3485\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3372 - accuracy: 0.5516 - val_loss: 4.0326 - val_accuracy: 0.3510\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3401 - accuracy: 0.5496 - val_loss: 3.9731 - val_accuracy: 0.3644\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5482 - val_loss: 3.9949 - val_accuracy: 0.3473\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3310 - accuracy: 0.5503 - val_loss: 4.0029 - val_accuracy: 0.3571\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3336 - accuracy: 0.5520 - val_loss: 4.0517 - val_accuracy: 0.3498\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3421 - accuracy: 0.5456 - val_loss: 4.0144 - val_accuracy: 0.3498\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3397 - accuracy: 0.5473 - val_loss: 4.0309 - val_accuracy: 0.3564\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5522 - val_loss: 4.0009 - val_accuracy: 0.3498\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3280 - accuracy: 0.5534 - val_loss: 4.0013 - val_accuracy: 0.3449\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3300 - accuracy: 0.5546 - val_loss: 3.9733 - val_accuracy: 0.3461\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3246 - accuracy: 0.5534 - val_loss: 4.0214 - val_accuracy: 0.3467\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3365 - accuracy: 0.5526 - val_loss: 4.0237 - val_accuracy: 0.3577\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3307 - accuracy: 0.5506 - val_loss: 4.0127 - val_accuracy: 0.3528\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3301 - accuracy: 0.5512 - val_loss: 4.0233 - val_accuracy: 0.3370\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3383 - accuracy: 0.5509 - val_loss: 4.0063 - val_accuracy: 0.3455\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3322 - accuracy: 0.5452 - val_loss: 4.0314 - val_accuracy: 0.3376\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3373 - accuracy: 0.5496 - val_loss: 4.0447 - val_accuracy: 0.3443\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3335 - accuracy: 0.5506 - val_loss: 4.0666 - val_accuracy: 0.3431\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3406 - accuracy: 0.5493 - val_loss: 4.0467 - val_accuracy: 0.3504\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3273 - accuracy: 0.5531 - val_loss: 4.0057 - val_accuracy: 0.3644\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.5476 - val_loss: 4.0374 - val_accuracy: 0.3589\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3467 - accuracy: 0.5456 - val_loss: 3.9814 - val_accuracy: 0.3467\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3363 - accuracy: 0.5547 - val_loss: 4.0336 - val_accuracy: 0.3540\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3381 - accuracy: 0.5497 - val_loss: 4.0271 - val_accuracy: 0.3461\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3323 - accuracy: 0.5503 - val_loss: 4.0235 - val_accuracy: 0.3479\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3378 - accuracy: 0.5563 - val_loss: 4.0426 - val_accuracy: 0.3485\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3338 - accuracy: 0.5528 - val_loss: 4.0823 - val_accuracy: 0.3479\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3272 - accuracy: 0.5543 - val_loss: 4.1146 - val_accuracy: 0.3467\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3443 - accuracy: 0.5499 - val_loss: 3.9992 - val_accuracy: 0.3491\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3473 - accuracy: 0.5471 - val_loss: 4.0305 - val_accuracy: 0.3418\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3346 - accuracy: 0.5575 - val_loss: 4.0423 - val_accuracy: 0.3425\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5532 - val_loss: 4.0306 - val_accuracy: 0.3431\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3231 - accuracy: 0.5519 - val_loss: 4.0730 - val_accuracy: 0.3461\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3313 - accuracy: 0.5531 - val_loss: 4.0582 - val_accuracy: 0.3400\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.5464 - val_loss: 4.0648 - val_accuracy: 0.3382\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3286 - accuracy: 0.5554 - val_loss: 4.0544 - val_accuracy: 0.3400\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3307 - accuracy: 0.5509 - val_loss: 4.0729 - val_accuracy: 0.3540\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3318 - accuracy: 0.5525 - val_loss: 4.0675 - val_accuracy: 0.3491\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5473 - val_loss: 4.0505 - val_accuracy: 0.3449\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3376 - accuracy: 0.5534 - val_loss: 4.0490 - val_accuracy: 0.3552\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3315 - accuracy: 0.5474 - val_loss: 4.0604 - val_accuracy: 0.3485\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3300 - accuracy: 0.5503 - val_loss: 4.0403 - val_accuracy: 0.3431\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3325 - accuracy: 0.5512 - val_loss: 4.0229 - val_accuracy: 0.3558\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3246 - accuracy: 0.5526 - val_loss: 4.0902 - val_accuracy: 0.3400\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3354 - accuracy: 0.5473 - val_loss: 4.0325 - val_accuracy: 0.3510\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3380 - accuracy: 0.5490 - val_loss: 4.0415 - val_accuracy: 0.3473\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3262 - accuracy: 0.5523 - val_loss: 4.0684 - val_accuracy: 0.3498\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5572 - val_loss: 4.0609 - val_accuracy: 0.3583\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3373 - accuracy: 0.5535 - val_loss: 4.0296 - val_accuracy: 0.3534\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3284 - accuracy: 0.5555 - val_loss: 4.0495 - val_accuracy: 0.3546\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3278 - accuracy: 0.5537 - val_loss: 4.0845 - val_accuracy: 0.3558\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3414 - accuracy: 0.5414 - val_loss: 4.0295 - val_accuracy: 0.3504\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.5474 - val_loss: 4.0852 - val_accuracy: 0.3540\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3271 - accuracy: 0.5537 - val_loss: 4.0527 - val_accuracy: 0.3522\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3329 - accuracy: 0.5526 - val_loss: 4.0248 - val_accuracy: 0.3504\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3375 - accuracy: 0.5470 - val_loss: 4.0136 - val_accuracy: 0.3418\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5575 - val_loss: 4.0352 - val_accuracy: 0.3418\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3234 - accuracy: 0.5528 - val_loss: 4.0024 - val_accuracy: 0.3455\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3315 - accuracy: 0.5532 - val_loss: 4.0532 - val_accuracy: 0.3443\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3272 - accuracy: 0.5522 - val_loss: 4.0423 - val_accuracy: 0.3522\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3303 - accuracy: 0.5503 - val_loss: 4.0314 - val_accuracy: 0.3534\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3303 - accuracy: 0.5482 - val_loss: 4.0653 - val_accuracy: 0.3394\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5470 - val_loss: 4.1132 - val_accuracy: 0.3418\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3330 - accuracy: 0.5497 - val_loss: 4.0645 - val_accuracy: 0.3431\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3288 - accuracy: 0.5538 - val_loss: 4.0304 - val_accuracy: 0.3461\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5500 - val_loss: 4.0867 - val_accuracy: 0.3491\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3351 - accuracy: 0.5540 - val_loss: 4.0337 - val_accuracy: 0.3589\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3319 - accuracy: 0.5506 - val_loss: 4.0702 - val_accuracy: 0.3455\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3315 - accuracy: 0.5497 - val_loss: 4.1044 - val_accuracy: 0.3552\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3303 - accuracy: 0.5497 - val_loss: 4.1089 - val_accuracy: 0.3485\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3316 - accuracy: 0.5579 - val_loss: 4.0951 - val_accuracy: 0.3558\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5471 - val_loss: 4.0381 - val_accuracy: 0.3583\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3437 - accuracy: 0.5452 - val_loss: 4.0359 - val_accuracy: 0.3583\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5523 - val_loss: 4.0816 - val_accuracy: 0.3431\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.5482 - val_loss: 4.0795 - val_accuracy: 0.3522\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3296 - accuracy: 0.5525 - val_loss: 4.0159 - val_accuracy: 0.3510\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3376 - accuracy: 0.5514 - val_loss: 4.0452 - val_accuracy: 0.3564\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.5506 - val_loss: 4.0280 - val_accuracy: 0.3613\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3320 - accuracy: 0.5532 - val_loss: 4.0816 - val_accuracy: 0.3546\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3287 - accuracy: 0.5523 - val_loss: 4.0763 - val_accuracy: 0.3449\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3304 - accuracy: 0.5471 - val_loss: 4.0809 - val_accuracy: 0.3522\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.5476 - val_loss: 4.0561 - val_accuracy: 0.3577\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5482 - val_loss: 4.0607 - val_accuracy: 0.3522\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3303 - accuracy: 0.5502 - val_loss: 4.0719 - val_accuracy: 0.3510\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3346 - accuracy: 0.5491 - val_loss: 4.0685 - val_accuracy: 0.3485\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3310 - accuracy: 0.5499 - val_loss: 4.0370 - val_accuracy: 0.3498\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3366 - accuracy: 0.5506 - val_loss: 4.0255 - val_accuracy: 0.3534\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3426 - accuracy: 0.5473 - val_loss: 4.0492 - val_accuracy: 0.3473\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3254 - accuracy: 0.5497 - val_loss: 4.0746 - val_accuracy: 0.3558\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3340 - accuracy: 0.5532 - val_loss: 4.1259 - val_accuracy: 0.3491\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3365 - accuracy: 0.5505 - val_loss: 4.0695 - val_accuracy: 0.3546\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.5496 - val_loss: 4.0654 - val_accuracy: 0.3577\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3295 - accuracy: 0.5525 - val_loss: 4.0756 - val_accuracy: 0.3571\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3282 - accuracy: 0.5552 - val_loss: 4.0487 - val_accuracy: 0.3467\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3359 - accuracy: 0.5549 - val_loss: 4.0700 - val_accuracy: 0.3540\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3330 - accuracy: 0.5487 - val_loss: 4.0985 - val_accuracy: 0.3528\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3357 - accuracy: 0.5496 - val_loss: 4.0629 - val_accuracy: 0.3449\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5519 - val_loss: 4.0536 - val_accuracy: 0.3425\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3397 - accuracy: 0.5511 - val_loss: 4.0526 - val_accuracy: 0.3491\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5508 - val_loss: 4.0581 - val_accuracy: 0.3589\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3427 - accuracy: 0.5430 - val_loss: 4.0235 - val_accuracy: 0.3504\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.5537 - val_loss: 4.0934 - val_accuracy: 0.3552\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3371 - accuracy: 0.5506 - val_loss: 4.1128 - val_accuracy: 0.3473\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3296 - accuracy: 0.5566 - val_loss: 4.0659 - val_accuracy: 0.3558\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3345 - accuracy: 0.5496 - val_loss: 4.0560 - val_accuracy: 0.3485\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3480 - accuracy: 0.5497 - val_loss: 4.0038 - val_accuracy: 0.3619\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3301 - accuracy: 0.5519 - val_loss: 4.0335 - val_accuracy: 0.3504\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.5491 - val_loss: 4.0704 - val_accuracy: 0.3479\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3343 - accuracy: 0.5522 - val_loss: 4.0582 - val_accuracy: 0.3479\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3341 - accuracy: 0.5529 - val_loss: 4.0721 - val_accuracy: 0.3491\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3325 - accuracy: 0.5535 - val_loss: 4.0503 - val_accuracy: 0.3449\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3385 - accuracy: 0.5470 - val_loss: 4.0204 - val_accuracy: 0.3546\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5477 - val_loss: 4.0385 - val_accuracy: 0.3522\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3309 - accuracy: 0.5474 - val_loss: 4.0952 - val_accuracy: 0.3552\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3278 - accuracy: 0.5566 - val_loss: 4.0987 - val_accuracy: 0.3461\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3456 - accuracy: 0.5531 - val_loss: 4.0414 - val_accuracy: 0.3485\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3257 - accuracy: 0.5538 - val_loss: 4.0713 - val_accuracy: 0.3491\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3293 - accuracy: 0.5519 - val_loss: 4.0774 - val_accuracy: 0.3564\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3269 - accuracy: 0.5505 - val_loss: 4.0162 - val_accuracy: 0.3601\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3324 - accuracy: 0.5502 - val_loss: 4.0705 - val_accuracy: 0.3443\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3369 - accuracy: 0.5535 - val_loss: 4.0118 - val_accuracy: 0.3577\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5512 - val_loss: 4.0427 - val_accuracy: 0.3607\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.5502 - val_loss: 4.0231 - val_accuracy: 0.3571\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3250 - accuracy: 0.5531 - val_loss: 4.0292 - val_accuracy: 0.3631\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3336 - accuracy: 0.5488 - val_loss: 4.0479 - val_accuracy: 0.3595\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3339 - accuracy: 0.5520 - val_loss: 4.0728 - val_accuracy: 0.3564\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3299 - accuracy: 0.5560 - val_loss: 4.0773 - val_accuracy: 0.3558\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3281 - accuracy: 0.5476 - val_loss: 4.0487 - val_accuracy: 0.3595\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3397 - accuracy: 0.5481 - val_loss: 4.0636 - val_accuracy: 0.3540\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3261 - accuracy: 0.5502 - val_loss: 4.0390 - val_accuracy: 0.3577\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3376 - accuracy: 0.5526 - val_loss: 4.0392 - val_accuracy: 0.3558\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3389 - accuracy: 0.5493 - val_loss: 4.0195 - val_accuracy: 0.3498\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3336 - accuracy: 0.5547 - val_loss: 4.0831 - val_accuracy: 0.3540\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3354 - accuracy: 0.5459 - val_loss: 4.0548 - val_accuracy: 0.3528\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3260 - accuracy: 0.5528 - val_loss: 4.0641 - val_accuracy: 0.3552\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3382 - accuracy: 0.5497 - val_loss: 4.0432 - val_accuracy: 0.3498\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.3261 - accuracy: 0.5517 - val_loss: 4.0834 - val_accuracy: 0.3485\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3413 - accuracy: 0.5484 - val_loss: 4.0405 - val_accuracy: 0.3583\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3370 - accuracy: 0.5467 - val_loss: 4.0583 - val_accuracy: 0.3595\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3386 - accuracy: 0.5522 - val_loss: 4.0645 - val_accuracy: 0.3571\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.5506 - val_loss: 4.1181 - val_accuracy: 0.3552\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3261 - accuracy: 0.5546 - val_loss: 4.1126 - val_accuracy: 0.3607\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3411 - accuracy: 0.5441 - val_loss: 4.1008 - val_accuracy: 0.3589\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3312 - accuracy: 0.5443 - val_loss: 4.0868 - val_accuracy: 0.3564\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3283 - accuracy: 0.5511 - val_loss: 4.0675 - val_accuracy: 0.3491\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3307 - accuracy: 0.5519 - val_loss: 4.0809 - val_accuracy: 0.3473\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3306 - accuracy: 0.5525 - val_loss: 4.0798 - val_accuracy: 0.3479\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3374 - accuracy: 0.5471 - val_loss: 4.0713 - val_accuracy: 0.3564\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3332 - accuracy: 0.5531 - val_loss: 4.1064 - val_accuracy: 0.3504\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3298 - accuracy: 0.5506 - val_loss: 4.0482 - val_accuracy: 0.3437\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3297 - accuracy: 0.5496 - val_loss: 4.0992 - val_accuracy: 0.3571\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3292 - accuracy: 0.5490 - val_loss: 4.0658 - val_accuracy: 0.3534\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3446 - accuracy: 0.5481 - val_loss: 4.0356 - val_accuracy: 0.3546\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5490 - val_loss: 4.0584 - val_accuracy: 0.3552\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3328 - accuracy: 0.5477 - val_loss: 4.0554 - val_accuracy: 0.3552\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3354 - accuracy: 0.5474 - val_loss: 4.0406 - val_accuracy: 0.3564\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3357 - accuracy: 0.5487 - val_loss: 4.0916 - val_accuracy: 0.3516\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3285 - accuracy: 0.5546 - val_loss: 4.1012 - val_accuracy: 0.3546\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3376 - accuracy: 0.5541 - val_loss: 4.0465 - val_accuracy: 0.3522\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3365 - accuracy: 0.5488 - val_loss: 4.0754 - val_accuracy: 0.3534\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3244 - accuracy: 0.5549 - val_loss: 4.0359 - val_accuracy: 0.3631\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3387 - accuracy: 0.5493 - val_loss: 4.0755 - val_accuracy: 0.3540\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3357 - accuracy: 0.5444 - val_loss: 4.0270 - val_accuracy: 0.3528\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3287 - accuracy: 0.5519 - val_loss: 4.0676 - val_accuracy: 0.3607\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3357 - accuracy: 0.5476 - val_loss: 4.0781 - val_accuracy: 0.3558\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3408 - accuracy: 0.5443 - val_loss: 4.0060 - val_accuracy: 0.3577\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5490 - val_loss: 4.0696 - val_accuracy: 0.3558\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3379 - accuracy: 0.5461 - val_loss: 4.0575 - val_accuracy: 0.3583\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3235 - accuracy: 0.5534 - val_loss: 4.0801 - val_accuracy: 0.3613\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3386 - accuracy: 0.5502 - val_loss: 4.0499 - val_accuracy: 0.3455\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3328 - accuracy: 0.5579 - val_loss: 4.0572 - val_accuracy: 0.3479\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3366 - accuracy: 0.5520 - val_loss: 4.0469 - val_accuracy: 0.3461\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3324 - accuracy: 0.5509 - val_loss: 4.0697 - val_accuracy: 0.3485\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5519 - val_loss: 4.0570 - val_accuracy: 0.3479\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3336 - accuracy: 0.5499 - val_loss: 4.0442 - val_accuracy: 0.3577\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3289 - accuracy: 0.5535 - val_loss: 4.0888 - val_accuracy: 0.3516\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5526 - val_loss: 4.0754 - val_accuracy: 0.3589\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3390 - accuracy: 0.5487 - val_loss: 4.0491 - val_accuracy: 0.3504\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3352 - accuracy: 0.5485 - val_loss: 4.0277 - val_accuracy: 0.3504\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3398 - accuracy: 0.5512 - val_loss: 4.0429 - val_accuracy: 0.3473\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3459 - accuracy: 0.5468 - val_loss: 4.0454 - val_accuracy: 0.3534\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3330 - accuracy: 0.5508 - val_loss: 4.0411 - val_accuracy: 0.3558\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3334 - accuracy: 0.5517 - val_loss: 4.0632 - val_accuracy: 0.3461\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.5493 - val_loss: 4.0876 - val_accuracy: 0.3534\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3407 - accuracy: 0.5511 - val_loss: 4.0734 - val_accuracy: 0.3504\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3321 - accuracy: 0.5503 - val_loss: 4.0408 - val_accuracy: 0.3510\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5497 - val_loss: 4.0692 - val_accuracy: 0.3498\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3306 - accuracy: 0.5485 - val_loss: 4.0632 - val_accuracy: 0.3516\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3301 - accuracy: 0.5512 - val_loss: 4.0626 - val_accuracy: 0.3534\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3305 - accuracy: 0.5503 - val_loss: 4.0951 - val_accuracy: 0.3455\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3281 - accuracy: 0.5526 - val_loss: 4.0713 - val_accuracy: 0.3443\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3291 - accuracy: 0.5488 - val_loss: 4.0472 - val_accuracy: 0.3425\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.5519 - val_loss: 4.0654 - val_accuracy: 0.3498\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3288 - accuracy: 0.5540 - val_loss: 4.0532 - val_accuracy: 0.3595\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3329 - accuracy: 0.5528 - val_loss: 4.0465 - val_accuracy: 0.3504\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3327 - accuracy: 0.5522 - val_loss: 4.0472 - val_accuracy: 0.3491\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3276 - accuracy: 0.5487 - val_loss: 4.0568 - val_accuracy: 0.3516\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3240 - accuracy: 0.5550 - val_loss: 4.1039 - val_accuracy: 0.3479\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3392 - accuracy: 0.5579 - val_loss: 4.0726 - val_accuracy: 0.3491\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3346 - accuracy: 0.5481 - val_loss: 4.0555 - val_accuracy: 0.3546\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3291 - accuracy: 0.5540 - val_loss: 4.0736 - val_accuracy: 0.3449\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3348 - accuracy: 0.5512 - val_loss: 4.0286 - val_accuracy: 0.3552\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3351 - accuracy: 0.5497 - val_loss: 4.0836 - val_accuracy: 0.3479\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3367 - accuracy: 0.5479 - val_loss: 4.0236 - val_accuracy: 0.3455\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3383 - accuracy: 0.5514 - val_loss: 4.0278 - val_accuracy: 0.3571\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3401 - accuracy: 0.5417 - val_loss: 4.0524 - val_accuracy: 0.3504\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3347 - accuracy: 0.5529 - val_loss: 4.0586 - val_accuracy: 0.3498\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3316 - accuracy: 0.5512 - val_loss: 4.0303 - val_accuracy: 0.3516\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3420 - accuracy: 0.5474 - val_loss: 4.0415 - val_accuracy: 0.3516\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3247 - accuracy: 0.5552 - val_loss: 4.0788 - val_accuracy: 0.3461\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3210 - accuracy: 0.5547 - val_loss: 4.0912 - val_accuracy: 0.3558\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3320 - accuracy: 0.5509 - val_loss: 4.0776 - val_accuracy: 0.3516\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.5499 - val_loss: 4.0510 - val_accuracy: 0.3510\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3316 - accuracy: 0.5526 - val_loss: 4.0261 - val_accuracy: 0.3583\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3340 - accuracy: 0.5540 - val_loss: 4.0240 - val_accuracy: 0.3589\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3265 - accuracy: 0.5512 - val_loss: 4.0906 - val_accuracy: 0.3485\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.5517 - val_loss: 4.0875 - val_accuracy: 0.3467\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5503 - val_loss: 4.0467 - val_accuracy: 0.3504\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3273 - accuracy: 0.5509 - val_loss: 4.0966 - val_accuracy: 0.3491\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3312 - accuracy: 0.5532 - val_loss: 4.0454 - val_accuracy: 0.3650\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3258 - accuracy: 0.5503 - val_loss: 4.0913 - val_accuracy: 0.3510\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3356 - accuracy: 0.5511 - val_loss: 4.1100 - val_accuracy: 0.3522\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3253 - accuracy: 0.5509 - val_loss: 4.0831 - val_accuracy: 0.3558\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3367 - accuracy: 0.5500 - val_loss: 4.0589 - val_accuracy: 0.3498\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3259 - accuracy: 0.5578 - val_loss: 4.1193 - val_accuracy: 0.3583\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3243 - accuracy: 0.5493 - val_loss: 4.1006 - val_accuracy: 0.3491\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3275 - accuracy: 0.5543 - val_loss: 4.0968 - val_accuracy: 0.3467\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3338 - accuracy: 0.5511 - val_loss: 4.0594 - val_accuracy: 0.3504\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3267 - accuracy: 0.5552 - val_loss: 4.0995 - val_accuracy: 0.3449\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3328 - accuracy: 0.5471 - val_loss: 4.0668 - val_accuracy: 0.3601\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3248 - accuracy: 0.5528 - val_loss: 4.0956 - val_accuracy: 0.3437\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3247 - accuracy: 0.5517 - val_loss: 4.0996 - val_accuracy: 0.3564\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3293 - accuracy: 0.5506 - val_loss: 4.0908 - val_accuracy: 0.3510\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3397 - accuracy: 0.5477 - val_loss: 4.0821 - val_accuracy: 0.3479\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3297 - accuracy: 0.5485 - val_loss: 4.0550 - val_accuracy: 0.3571\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3257 - accuracy: 0.5512 - val_loss: 4.0813 - val_accuracy: 0.3467\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5481 - val_loss: 4.0874 - val_accuracy: 0.3528\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3341 - accuracy: 0.5541 - val_loss: 4.0802 - val_accuracy: 0.3510\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3305 - accuracy: 0.5541 - val_loss: 4.0937 - val_accuracy: 0.3461\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3368 - accuracy: 0.5481 - val_loss: 4.0692 - val_accuracy: 0.3485\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3225 - accuracy: 0.5482 - val_loss: 4.1178 - val_accuracy: 0.3504\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3389 - accuracy: 0.5487 - val_loss: 4.0325 - val_accuracy: 0.3473\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5479 - val_loss: 4.0675 - val_accuracy: 0.3601\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3368 - accuracy: 0.5481 - val_loss: 4.0919 - val_accuracy: 0.3546\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3231 - accuracy: 0.5538 - val_loss: 4.0935 - val_accuracy: 0.3516\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3305 - accuracy: 0.5488 - val_loss: 4.0640 - val_accuracy: 0.3534\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3273 - accuracy: 0.5529 - val_loss: 4.0645 - val_accuracy: 0.3510\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3294 - accuracy: 0.5506 - val_loss: 4.0563 - val_accuracy: 0.3510\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3327 - accuracy: 0.5538 - val_loss: 4.0594 - val_accuracy: 0.3583\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3286 - accuracy: 0.5496 - val_loss: 4.0774 - val_accuracy: 0.3516\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5471 - val_loss: 4.0937 - val_accuracy: 0.3498\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3282 - accuracy: 0.5514 - val_loss: 4.1351 - val_accuracy: 0.3534\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3279 - accuracy: 0.5549 - val_loss: 4.1191 - val_accuracy: 0.3461\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3327 - accuracy: 0.5493 - val_loss: 4.0739 - val_accuracy: 0.3522\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5528 - val_loss: 4.1177 - val_accuracy: 0.3571\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3359 - accuracy: 0.5493 - val_loss: 4.1022 - val_accuracy: 0.3504\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3356 - accuracy: 0.5503 - val_loss: 4.0616 - val_accuracy: 0.3455\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3260 - accuracy: 0.5535 - val_loss: 4.0901 - val_accuracy: 0.3473\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3353 - accuracy: 0.5481 - val_loss: 4.0609 - val_accuracy: 0.3589\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3393 - accuracy: 0.5490 - val_loss: 4.0704 - val_accuracy: 0.3564\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3326 - accuracy: 0.5459 - val_loss: 4.0940 - val_accuracy: 0.3516\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3326 - accuracy: 0.5534 - val_loss: 4.1264 - val_accuracy: 0.3564\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3323 - accuracy: 0.5468 - val_loss: 4.0579 - val_accuracy: 0.3491\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3287 - accuracy: 0.5558 - val_loss: 4.0877 - val_accuracy: 0.3485\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3340 - accuracy: 0.5447 - val_loss: 4.1154 - val_accuracy: 0.3491\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5487 - val_loss: 4.0776 - val_accuracy: 0.3491\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3271 - accuracy: 0.5516 - val_loss: 4.0931 - val_accuracy: 0.3449\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3249 - accuracy: 0.5517 - val_loss: 4.0972 - val_accuracy: 0.3455\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3332 - accuracy: 0.5519 - val_loss: 4.0670 - val_accuracy: 0.3431\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3223 - accuracy: 0.5525 - val_loss: 4.1406 - val_accuracy: 0.3498\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5511 - val_loss: 4.1167 - val_accuracy: 0.3546\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3229 - accuracy: 0.5537 - val_loss: 4.0980 - val_accuracy: 0.3498\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.5512 - val_loss: 4.0717 - val_accuracy: 0.3589\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3281 - accuracy: 0.5547 - val_loss: 4.1171 - val_accuracy: 0.3540\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3262 - accuracy: 0.5523 - val_loss: 4.1267 - val_accuracy: 0.3461\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3345 - accuracy: 0.5517 - val_loss: 4.0773 - val_accuracy: 0.3491\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3417 - accuracy: 0.5508 - val_loss: 4.0794 - val_accuracy: 0.3510\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.5444 - val_loss: 4.0619 - val_accuracy: 0.3558\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3425 - accuracy: 0.5465 - val_loss: 4.0806 - val_accuracy: 0.3546\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3347 - accuracy: 0.5499 - val_loss: 4.0594 - val_accuracy: 0.3528\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3385 - accuracy: 0.5465 - val_loss: 4.0577 - val_accuracy: 0.3583\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3294 - accuracy: 0.5502 - val_loss: 4.0658 - val_accuracy: 0.3577\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3179 - accuracy: 0.5550 - val_loss: 4.1088 - val_accuracy: 0.3528\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3338 - accuracy: 0.5503 - val_loss: 4.1036 - val_accuracy: 0.3491\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3363 - accuracy: 0.5476 - val_loss: 4.0555 - val_accuracy: 0.3510\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3319 - accuracy: 0.5532 - val_loss: 4.1002 - val_accuracy: 0.3491\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3290 - accuracy: 0.5552 - val_loss: 4.0775 - val_accuracy: 0.3479\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3424 - accuracy: 0.5461 - val_loss: 4.0507 - val_accuracy: 0.3516\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3235 - accuracy: 0.5531 - val_loss: 4.1038 - val_accuracy: 0.3443\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3281 - accuracy: 0.5490 - val_loss: 4.0925 - val_accuracy: 0.3504\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5511 - val_loss: 4.0823 - val_accuracy: 0.3455\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3246 - accuracy: 0.5503 - val_loss: 4.1137 - val_accuracy: 0.3418\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3324 - accuracy: 0.5528 - val_loss: 4.0929 - val_accuracy: 0.3516\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3154 - accuracy: 0.5549 - val_loss: 4.1155 - val_accuracy: 0.3370\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3378 - accuracy: 0.5520 - val_loss: 4.1168 - val_accuracy: 0.3437\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.5500 - val_loss: 4.0884 - val_accuracy: 0.3485\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3340 - accuracy: 0.5493 - val_loss: 4.1065 - val_accuracy: 0.3498\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3423 - accuracy: 0.5412 - val_loss: 4.0507 - val_accuracy: 0.3449\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.5506 - val_loss: 4.0725 - val_accuracy: 0.3534\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3260 - accuracy: 0.5517 - val_loss: 4.0831 - val_accuracy: 0.3528\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3254 - accuracy: 0.5525 - val_loss: 4.1007 - val_accuracy: 0.3443\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3327 - accuracy: 0.5537 - val_loss: 4.1337 - val_accuracy: 0.3504\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3315 - accuracy: 0.5512 - val_loss: 4.1027 - val_accuracy: 0.3491\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3382 - accuracy: 0.5519 - val_loss: 4.0628 - val_accuracy: 0.3571\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3274 - accuracy: 0.5462 - val_loss: 4.0747 - val_accuracy: 0.3571\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3310 - accuracy: 0.5537 - val_loss: 4.0627 - val_accuracy: 0.3528\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3327 - accuracy: 0.5479 - val_loss: 4.0944 - val_accuracy: 0.3479\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3325 - accuracy: 0.5508 - val_loss: 4.0608 - val_accuracy: 0.3498\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3261 - accuracy: 0.5528 - val_loss: 4.0843 - val_accuracy: 0.3467\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3254 - accuracy: 0.5525 - val_loss: 4.0931 - val_accuracy: 0.3540\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5484 - val_loss: 4.0701 - val_accuracy: 0.3485\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3271 - accuracy: 0.5552 - val_loss: 4.0834 - val_accuracy: 0.3425\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3329 - accuracy: 0.5534 - val_loss: 4.1139 - val_accuracy: 0.3534\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.5508 - val_loss: 4.1190 - val_accuracy: 0.3479\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3263 - accuracy: 0.5485 - val_loss: 4.0774 - val_accuracy: 0.3504\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3329 - accuracy: 0.5534 - val_loss: 4.0727 - val_accuracy: 0.3418\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3395 - accuracy: 0.5473 - val_loss: 4.0737 - val_accuracy: 0.3485\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3320 - accuracy: 0.5490 - val_loss: 4.0757 - val_accuracy: 0.3467\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3237 - accuracy: 0.5560 - val_loss: 4.1185 - val_accuracy: 0.3510\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3238 - accuracy: 0.5500 - val_loss: 4.0808 - val_accuracy: 0.3516\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3237 - accuracy: 0.5544 - val_loss: 4.0809 - val_accuracy: 0.3473\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3371 - accuracy: 0.5509 - val_loss: 4.0552 - val_accuracy: 0.3455\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3324 - accuracy: 0.5514 - val_loss: 4.0661 - val_accuracy: 0.3443\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3389 - accuracy: 0.5503 - val_loss: 4.0995 - val_accuracy: 0.3425\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3285 - accuracy: 0.5529 - val_loss: 4.0989 - val_accuracy: 0.3431\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3263 - accuracy: 0.5508 - val_loss: 4.1196 - val_accuracy: 0.3534\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3283 - accuracy: 0.5473 - val_loss: 4.1363 - val_accuracy: 0.3558\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3369 - accuracy: 0.5500 - val_loss: 4.0966 - val_accuracy: 0.3558\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5541 - val_loss: 4.0518 - val_accuracy: 0.3571\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3323 - accuracy: 0.5512 - val_loss: 4.0877 - val_accuracy: 0.3571\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3309 - accuracy: 0.5525 - val_loss: 4.0556 - val_accuracy: 0.3479\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3279 - accuracy: 0.5484 - val_loss: 4.0712 - val_accuracy: 0.3516\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5500 - val_loss: 4.1230 - val_accuracy: 0.3498\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3268 - accuracy: 0.5479 - val_loss: 4.1172 - val_accuracy: 0.3504\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3325 - accuracy: 0.5538 - val_loss: 4.0637 - val_accuracy: 0.3577\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3251 - accuracy: 0.5479 - val_loss: 4.0826 - val_accuracy: 0.3510\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.5532 - val_loss: 4.0823 - val_accuracy: 0.3394\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3338 - accuracy: 0.5474 - val_loss: 4.0628 - val_accuracy: 0.3437\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3294 - accuracy: 0.5506 - val_loss: 4.0592 - val_accuracy: 0.3473\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3317 - accuracy: 0.5508 - val_loss: 4.0849 - val_accuracy: 0.3510\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3334 - accuracy: 0.5497 - val_loss: 4.0758 - val_accuracy: 0.3498\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3392 - accuracy: 0.5490 - val_loss: 4.0893 - val_accuracy: 0.3498\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.5485 - val_loss: 4.0687 - val_accuracy: 0.3498\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3400 - accuracy: 0.5514 - val_loss: 4.0770 - val_accuracy: 0.3443\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3267 - accuracy: 0.5499 - val_loss: 4.0835 - val_accuracy: 0.3491\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.5490 - val_loss: 4.0317 - val_accuracy: 0.3571\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5511 - val_loss: 4.0692 - val_accuracy: 0.3412\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3233 - accuracy: 0.5550 - val_loss: 4.0938 - val_accuracy: 0.3412\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3338 - accuracy: 0.5516 - val_loss: 4.0841 - val_accuracy: 0.3418\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3398 - accuracy: 0.5476 - val_loss: 4.0726 - val_accuracy: 0.3443\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.5506 - val_loss: 4.0694 - val_accuracy: 0.3558\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3298 - accuracy: 0.5528 - val_loss: 4.0855 - val_accuracy: 0.3455\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3280 - accuracy: 0.5512 - val_loss: 4.0709 - val_accuracy: 0.3431\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3415 - accuracy: 0.5497 - val_loss: 4.0625 - val_accuracy: 0.3528\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3296 - accuracy: 0.5529 - val_loss: 4.1129 - val_accuracy: 0.3522\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3366 - accuracy: 0.5446 - val_loss: 4.0662 - val_accuracy: 0.3449\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3256 - accuracy: 0.5500 - val_loss: 4.0873 - val_accuracy: 0.3388\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3256 - accuracy: 0.5552 - val_loss: 4.0896 - val_accuracy: 0.3437\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3270 - accuracy: 0.5496 - val_loss: 4.1122 - val_accuracy: 0.3498\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3303 - accuracy: 0.5496 - val_loss: 4.0822 - val_accuracy: 0.3491\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3332 - accuracy: 0.5519 - val_loss: 4.0740 - val_accuracy: 0.3552\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3453 - accuracy: 0.5441 - val_loss: 4.0758 - val_accuracy: 0.3485\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3278 - accuracy: 0.5531 - val_loss: 4.0931 - val_accuracy: 0.3467\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3331 - accuracy: 0.5494 - val_loss: 4.0806 - val_accuracy: 0.3528\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.5523 - val_loss: 4.0770 - val_accuracy: 0.3534\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3372 - accuracy: 0.5473 - val_loss: 4.0601 - val_accuracy: 0.3546\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3243 - accuracy: 0.5546 - val_loss: 4.0995 - val_accuracy: 0.3516\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3262 - accuracy: 0.5519 - val_loss: 4.1082 - val_accuracy: 0.3504\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3282 - accuracy: 0.5557 - val_loss: 4.0783 - val_accuracy: 0.3504\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3368 - accuracy: 0.5444 - val_loss: 4.1159 - val_accuracy: 0.3431\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3322 - accuracy: 0.5479 - val_loss: 4.0812 - val_accuracy: 0.3425\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3302 - accuracy: 0.5508 - val_loss: 4.0769 - val_accuracy: 0.3461\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3302 - accuracy: 0.5566 - val_loss: 4.1033 - val_accuracy: 0.3412\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3260 - accuracy: 0.5541 - val_loss: 4.1141 - val_accuracy: 0.3491\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3293 - accuracy: 0.5535 - val_loss: 4.1169 - val_accuracy: 0.3510\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3216 - accuracy: 0.5525 - val_loss: 4.0938 - val_accuracy: 0.3564\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.5487 - val_loss: 4.0833 - val_accuracy: 0.3595\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3261 - accuracy: 0.5532 - val_loss: 4.0948 - val_accuracy: 0.3467\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3243 - accuracy: 0.5535 - val_loss: 4.0997 - val_accuracy: 0.3461\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3277 - accuracy: 0.5549 - val_loss: 4.1170 - val_accuracy: 0.3473\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3318 - accuracy: 0.5540 - val_loss: 4.0883 - val_accuracy: 0.3516\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3224 - accuracy: 0.5552 - val_loss: 4.1149 - val_accuracy: 0.3443\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3335 - accuracy: 0.5484 - val_loss: 4.1020 - val_accuracy: 0.3485\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3307 - accuracy: 0.5549 - val_loss: 4.1281 - val_accuracy: 0.3455\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3349 - accuracy: 0.5476 - val_loss: 4.1343 - val_accuracy: 0.3516\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3227 - accuracy: 0.5549 - val_loss: 4.1686 - val_accuracy: 0.3485\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3286 - accuracy: 0.5494 - val_loss: 4.1185 - val_accuracy: 0.3540\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3320 - accuracy: 0.5499 - val_loss: 4.0942 - val_accuracy: 0.3516\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3208 - accuracy: 0.5516 - val_loss: 4.1101 - val_accuracy: 0.3479\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5488 - val_loss: 4.1114 - val_accuracy: 0.3485\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3250 - accuracy: 0.5550 - val_loss: 4.1855 - val_accuracy: 0.3467\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3256 - accuracy: 0.5485 - val_loss: 4.1134 - val_accuracy: 0.3644\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3338 - accuracy: 0.5508 - val_loss: 4.0972 - val_accuracy: 0.3522\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3223 - accuracy: 0.5558 - val_loss: 4.1703 - val_accuracy: 0.3504\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3355 - accuracy: 0.5484 - val_loss: 4.1220 - val_accuracy: 0.3504\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3256 - accuracy: 0.5477 - val_loss: 4.0984 - val_accuracy: 0.3558\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3221 - accuracy: 0.5512 - val_loss: 4.1297 - val_accuracy: 0.3449\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3221 - accuracy: 0.5537 - val_loss: 4.1285 - val_accuracy: 0.3449\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3272 - accuracy: 0.5557 - val_loss: 4.1080 - val_accuracy: 0.3473\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3233 - accuracy: 0.5526 - val_loss: 4.1442 - val_accuracy: 0.3473\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3299 - accuracy: 0.5560 - val_loss: 4.1347 - val_accuracy: 0.3437\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3385 - accuracy: 0.5517 - val_loss: 4.1048 - val_accuracy: 0.3425\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3242 - accuracy: 0.5493 - val_loss: 4.1228 - val_accuracy: 0.3418\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3291 - accuracy: 0.5477 - val_loss: 4.1294 - val_accuracy: 0.3412\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3218 - accuracy: 0.5547 - val_loss: 4.1355 - val_accuracy: 0.3425\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3290 - accuracy: 0.5462 - val_loss: 4.1134 - val_accuracy: 0.3425\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3312 - accuracy: 0.5508 - val_loss: 4.1274 - val_accuracy: 0.3504\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3295 - accuracy: 0.5484 - val_loss: 4.1248 - val_accuracy: 0.3510\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3271 - accuracy: 0.5522 - val_loss: 4.1325 - val_accuracy: 0.3522\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3293 - accuracy: 0.5497 - val_loss: 4.1416 - val_accuracy: 0.3400\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3246 - accuracy: 0.5529 - val_loss: 4.1868 - val_accuracy: 0.3431\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3305 - accuracy: 0.5522 - val_loss: 4.1369 - val_accuracy: 0.3546\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3307 - accuracy: 0.5517 - val_loss: 4.0964 - val_accuracy: 0.3388\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3327 - accuracy: 0.5514 - val_loss: 4.1359 - val_accuracy: 0.3406\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3277 - accuracy: 0.5541 - val_loss: 4.1164 - val_accuracy: 0.3449\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3250 - accuracy: 0.5526 - val_loss: 4.1005 - val_accuracy: 0.3412\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3197 - accuracy: 0.5549 - val_loss: 4.1171 - val_accuracy: 0.3418\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3399 - accuracy: 0.5467 - val_loss: 4.1399 - val_accuracy: 0.3498\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3267 - accuracy: 0.5540 - val_loss: 4.1143 - val_accuracy: 0.3467\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3324 - accuracy: 0.5514 - val_loss: 4.1500 - val_accuracy: 0.3418\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3311 - accuracy: 0.5506 - val_loss: 4.1621 - val_accuracy: 0.3431\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3266 - accuracy: 0.5505 - val_loss: 4.1072 - val_accuracy: 0.3479\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3245 - accuracy: 0.5516 - val_loss: 4.1389 - val_accuracy: 0.3418\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3330 - accuracy: 0.5499 - val_loss: 4.1094 - val_accuracy: 0.3601\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3364 - accuracy: 0.5470 - val_loss: 4.0795 - val_accuracy: 0.3546\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3276 - accuracy: 0.5516 - val_loss: 4.0727 - val_accuracy: 0.3504\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5534 - val_loss: 4.1006 - val_accuracy: 0.3534\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3284 - accuracy: 0.5520 - val_loss: 4.1163 - val_accuracy: 0.3595\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3231 - accuracy: 0.5526 - val_loss: 4.1072 - val_accuracy: 0.3577\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3246 - accuracy: 0.5550 - val_loss: 4.1267 - val_accuracy: 0.3510\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3250 - accuracy: 0.5529 - val_loss: 4.0992 - val_accuracy: 0.3589\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3296 - accuracy: 0.5505 - val_loss: 4.1166 - val_accuracy: 0.3546\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3282 - accuracy: 0.5520 - val_loss: 4.1400 - val_accuracy: 0.3473\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3259 - accuracy: 0.5544 - val_loss: 4.1511 - val_accuracy: 0.3552\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3323 - accuracy: 0.5493 - val_loss: 4.1060 - val_accuracy: 0.3491\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3337 - accuracy: 0.5532 - val_loss: 4.1148 - val_accuracy: 0.3564\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3249 - accuracy: 0.5512 - val_loss: 4.1225 - val_accuracy: 0.3601\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3336 - accuracy: 0.5461 - val_loss: 4.0984 - val_accuracy: 0.3522\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3250 - accuracy: 0.5550 - val_loss: 4.1358 - val_accuracy: 0.3498\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3184 - accuracy: 0.5561 - val_loss: 4.1432 - val_accuracy: 0.3577\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3275 - accuracy: 0.5537 - val_loss: 4.1676 - val_accuracy: 0.3577\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3293 - accuracy: 0.5557 - val_loss: 4.1487 - val_accuracy: 0.3607\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3268 - accuracy: 0.5522 - val_loss: 4.1328 - val_accuracy: 0.3479\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3458 - accuracy: 0.5520 - val_loss: 4.1267 - val_accuracy: 0.3461\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3258 - accuracy: 0.5522 - val_loss: 4.1186 - val_accuracy: 0.3504\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3256 - accuracy: 0.5558 - val_loss: 4.1376 - val_accuracy: 0.3473\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3290 - accuracy: 0.5493 - val_loss: 4.1223 - val_accuracy: 0.3473\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3249 - accuracy: 0.5540 - val_loss: 4.1749 - val_accuracy: 0.3431\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3357 - accuracy: 0.5436 - val_loss: 4.1389 - val_accuracy: 0.3455\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3261 - accuracy: 0.5567 - val_loss: 4.1256 - val_accuracy: 0.3455\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3302 - accuracy: 0.5487 - val_loss: 4.0857 - val_accuracy: 0.3479\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3272 - accuracy: 0.5491 - val_loss: 4.0675 - val_accuracy: 0.3589\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3304 - accuracy: 0.5511 - val_loss: 4.1221 - val_accuracy: 0.3631\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3225 - accuracy: 0.5497 - val_loss: 4.1116 - val_accuracy: 0.3583\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3392 - accuracy: 0.5467 - val_loss: 4.0992 - val_accuracy: 0.3589\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3255 - accuracy: 0.5522 - val_loss: 4.1060 - val_accuracy: 0.3571\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3274 - accuracy: 0.5496 - val_loss: 4.1060 - val_accuracy: 0.3491\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3174 - accuracy: 0.5573 - val_loss: 4.1436 - val_accuracy: 0.3534\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3273 - accuracy: 0.5550 - val_loss: 4.0983 - val_accuracy: 0.3625\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3271 - accuracy: 0.5520 - val_loss: 4.1362 - val_accuracy: 0.3601\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.5465 - val_loss: 4.1039 - val_accuracy: 0.3607\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3285 - accuracy: 0.5488 - val_loss: 4.0913 - val_accuracy: 0.3577\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5535 - val_loss: 4.1083 - val_accuracy: 0.3571\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5528 - val_loss: 4.0846 - val_accuracy: 0.3558\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3233 - accuracy: 0.5528 - val_loss: 4.0834 - val_accuracy: 0.3552\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3254 - accuracy: 0.5529 - val_loss: 4.1020 - val_accuracy: 0.3601\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3193 - accuracy: 0.5526 - val_loss: 4.0618 - val_accuracy: 0.3613\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3265 - accuracy: 0.5468 - val_loss: 4.0930 - val_accuracy: 0.3595\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3309 - accuracy: 0.5487 - val_loss: 4.1077 - val_accuracy: 0.3461\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3252 - accuracy: 0.5522 - val_loss: 4.0826 - val_accuracy: 0.3625\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3314 - accuracy: 0.5506 - val_loss: 4.1115 - val_accuracy: 0.3595\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3209 - accuracy: 0.5552 - val_loss: 4.1082 - val_accuracy: 0.3637\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3202 - accuracy: 0.5570 - val_loss: 4.1243 - val_accuracy: 0.3510\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3328 - accuracy: 0.5446 - val_loss: 4.1612 - val_accuracy: 0.3534\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3313 - accuracy: 0.5514 - val_loss: 4.1035 - val_accuracy: 0.3577\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3309 - accuracy: 0.5543 - val_loss: 4.0863 - val_accuracy: 0.3504\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3225 - accuracy: 0.5554 - val_loss: 4.0808 - val_accuracy: 0.3516\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3210 - accuracy: 0.5570 - val_loss: 4.1183 - val_accuracy: 0.3601\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3296 - accuracy: 0.5523 - val_loss: 4.1075 - val_accuracy: 0.3601\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3342 - accuracy: 0.5520 - val_loss: 4.0984 - val_accuracy: 0.3546\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3249 - accuracy: 0.5525 - val_loss: 4.1216 - val_accuracy: 0.3625\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3304 - accuracy: 0.5496 - val_loss: 4.1466 - val_accuracy: 0.3479\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3371 - accuracy: 0.5500 - val_loss: 4.0972 - val_accuracy: 0.3528\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3389 - accuracy: 0.5490 - val_loss: 4.0513 - val_accuracy: 0.3552\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3289 - accuracy: 0.5471 - val_loss: 4.1265 - val_accuracy: 0.3540\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3302 - accuracy: 0.5487 - val_loss: 4.1655 - val_accuracy: 0.3522\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3242 - accuracy: 0.5544 - val_loss: 4.1379 - val_accuracy: 0.3534\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3305 - accuracy: 0.5503 - val_loss: 4.1200 - val_accuracy: 0.3461\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3310 - accuracy: 0.5555 - val_loss: 4.1366 - val_accuracy: 0.3510\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3336 - accuracy: 0.5497 - val_loss: 4.1267 - val_accuracy: 0.3461\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3311 - accuracy: 0.5526 - val_loss: 4.1191 - val_accuracy: 0.3455\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3337 - accuracy: 0.5532 - val_loss: 4.1119 - val_accuracy: 0.3498\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3180 - accuracy: 0.5608 - val_loss: 4.1293 - val_accuracy: 0.3473\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3358 - accuracy: 0.5467 - val_loss: 4.1023 - val_accuracy: 0.3558\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3301 - accuracy: 0.5547 - val_loss: 4.1220 - val_accuracy: 0.3400\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3221 - accuracy: 0.5543 - val_loss: 4.1191 - val_accuracy: 0.3540\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3176 - accuracy: 0.5550 - val_loss: 4.1368 - val_accuracy: 0.3412\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3291 - accuracy: 0.5468 - val_loss: 4.1544 - val_accuracy: 0.3449\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3307 - accuracy: 0.5520 - val_loss: 4.1184 - val_accuracy: 0.3437\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3249 - accuracy: 0.5490 - val_loss: 4.1607 - val_accuracy: 0.3485\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3300 - accuracy: 0.5523 - val_loss: 4.1037 - val_accuracy: 0.3577\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3260 - accuracy: 0.5534 - val_loss: 4.1260 - val_accuracy: 0.3510\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3232 - accuracy: 0.5554 - val_loss: 4.1598 - val_accuracy: 0.3455\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3210 - accuracy: 0.5488 - val_loss: 4.1160 - val_accuracy: 0.3461\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3251 - accuracy: 0.5537 - val_loss: 4.1232 - val_accuracy: 0.3443\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3284 - accuracy: 0.5566 - val_loss: 4.1077 - val_accuracy: 0.3510\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3255 - accuracy: 0.5544 - val_loss: 4.1207 - val_accuracy: 0.3491\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3293 - accuracy: 0.5471 - val_loss: 4.0843 - val_accuracy: 0.3552\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3361 - accuracy: 0.5529 - val_loss: 4.0821 - val_accuracy: 0.3546\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3258 - accuracy: 0.5522 - val_loss: 4.1214 - val_accuracy: 0.3485\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3347 - accuracy: 0.5502 - val_loss: 4.0800 - val_accuracy: 0.3558\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3290 - accuracy: 0.5509 - val_loss: 4.1161 - val_accuracy: 0.3461\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3293 - accuracy: 0.5509 - val_loss: 4.1246 - val_accuracy: 0.3571\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3294 - accuracy: 0.5481 - val_loss: 4.1450 - val_accuracy: 0.3540\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3416 - accuracy: 0.5465 - val_loss: 4.0935 - val_accuracy: 0.3516\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3413 - accuracy: 0.5464 - val_loss: 4.1001 - val_accuracy: 0.3564\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3247 - accuracy: 0.5535 - val_loss: 4.1106 - val_accuracy: 0.3467\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3248 - accuracy: 0.5505 - val_loss: 4.1259 - val_accuracy: 0.3491\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3276 - accuracy: 0.5517 - val_loss: 4.1414 - val_accuracy: 0.3449\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3306 - accuracy: 0.5452 - val_loss: 4.1334 - val_accuracy: 0.3425\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3232 - accuracy: 0.5534 - val_loss: 4.1569 - val_accuracy: 0.3498\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3220 - accuracy: 0.5523 - val_loss: 4.1532 - val_accuracy: 0.3473\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3339 - accuracy: 0.5520 - val_loss: 4.1001 - val_accuracy: 0.3504\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3278 - accuracy: 0.5506 - val_loss: 4.1298 - val_accuracy: 0.3449\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.3389 - accuracy: 0.5487 - val_loss: 4.0744 - val_accuracy: 0.3418\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3251 - accuracy: 0.5520 - val_loss: 4.1165 - val_accuracy: 0.3418\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3267 - accuracy: 0.5540 - val_loss: 4.0982 - val_accuracy: 0.3425\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3219 - accuracy: 0.5517 - val_loss: 4.1121 - val_accuracy: 0.3510\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3290 - accuracy: 0.5502 - val_loss: 4.1593 - val_accuracy: 0.3443\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3311 - accuracy: 0.5487 - val_loss: 4.1058 - val_accuracy: 0.3449\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3275 - accuracy: 0.5566 - val_loss: 4.1270 - val_accuracy: 0.3491\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3275 - accuracy: 0.5532 - val_loss: 4.1278 - val_accuracy: 0.3455\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3290 - accuracy: 0.5499 - val_loss: 4.1319 - val_accuracy: 0.3510\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3282 - accuracy: 0.5487 - val_loss: 4.1232 - val_accuracy: 0.3546\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3215 - accuracy: 0.5552 - val_loss: 4.1468 - val_accuracy: 0.3473\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3281 - accuracy: 0.5499 - val_loss: 4.1592 - val_accuracy: 0.3473\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3324 - accuracy: 0.5517 - val_loss: 4.1192 - val_accuracy: 0.3418\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3255 - accuracy: 0.5522 - val_loss: 4.1535 - val_accuracy: 0.3461\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.5525 - val_loss: 4.1236 - val_accuracy: 0.3516\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3293 - accuracy: 0.5564 - val_loss: 4.1457 - val_accuracy: 0.3467\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.3321 - accuracy: 0.5509 - val_loss: 4.1382 - val_accuracy: 0.3467\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (batch size 64)\n",
    "history_many_to_many_complex_64 = many_to_many_model_complex.fit(xx_train, yy_train, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=64,  # Batch size\n",
    "                                              validation_data=(xx_test, yy_test)  # Validation data\n",
    "                                               ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_complex_model_history_bs64.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_complex_64.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_history(history_many_to_many_complex_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_complex_64, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.3467153284671533\n",
      "Accuracy for Label barrel_turn: 0.0\n",
      "Accuracy for Label basic_charleston: nan\n",
      "Accuracy for Label basic_closed: 0.42657342657342656\n",
      "Accuracy for Label basic_open: 0.0\n",
      "Accuracy for Label break: 0.08490566037735849\n",
      "Accuracy for Label come_back: 0.024691358024691357\n",
      "Accuracy for Label corridor: 0.0\n",
      "Accuracy for Label frankie´s_points: nan\n",
      "Accuracy for Label frankie´s_sixes: 0.04878048780487805\n",
      "Accuracy for Label groove_walk: 0.0\n",
      "Accuracy for Label hallelujah_rocks: 0.0\n",
      "Accuracy for Label hand_to_hand: 0.0\n",
      "Accuracy for Label hand_to_hand_charleston: nan\n",
      "Accuracy for Label inside_spin: 0.0\n",
      "Accuracy for Label inside_turn: 0.0\n",
      "Accuracy for Label lindy_circle: 0.0\n",
      "Accuracy for Label mini_dip: nan\n",
      "Accuracy for Label outside_spin: 0.025\n",
      "Accuracy for Label outside_turn: 0.041666666666666664\n",
      "Accuracy for Label pass_by: 0.6523076923076923\n",
      "Accuracy for Label pop_turn: 0.0\n",
      "Accuracy for Label promenade: 0.0\n",
      "Accuracy for Label s_turn: 0.0\n",
      "Accuracy for Label sailor_kicks: 0.0\n",
      "Accuracy for Label send_out: 0.0625\n",
      "Accuracy for Label sling_shot: 0.0\n",
      "Accuracy for Label sugar_push: 0.0625\n",
      "Accuracy for Label sweetheart: 0.018518518518518517\n",
      "Accuracy for Label swingout: 0.2147239263803681\n",
      "Accuracy for Label switches: 0.0\n",
      "Accuracy for Label tandem: 0.0\n",
      "Accuracy for Label tuck_turn: 0.30851063829787234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Predict labels on the test data\n",
    "predictions = many_to_many_model_complex.predict(xx_test)\n",
    "\n",
    "# Convert one-hot encoded predictions to single labels using TensorFlow's argmax\n",
    "predicted_labels_encoded = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Flatten the arrays for label-wise accuracy calculation\n",
    "predicted_labels_encoded = predicted_labels_encoded.flatten()\n",
    "\n",
    "# Convert one-hot encoded true labels to single labels using TensorFlow's argmax\n",
    "true_labels_encoded = tf.argmax(yy_test, axis=-1).numpy().flatten()\n",
    "\n",
    "# Map predicted labels to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "# Map true labels to original labels\n",
    "true_labels = label_encoder.inverse_transform(true_labels_encoded)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Display label-wise accuracy\n",
    "unique_labels = label_encoder.classes_\n",
    "for label in unique_labels:\n",
    "    label_indices = true_labels == label\n",
    "    label_accuracy = accuracy_score(true_labels[label_indices], predicted_labels[label_indices])\n",
    "    print(f'Accuracy for Label {label}: {label_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a word2vec model for the dance move sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'frankie´s_sixes',\n",
       "  'hallelujah_rocks',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'frankie´s_points',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'inside_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sling_shot',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'inside_spin'],\n",
       " ['groove_walk',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'come_back'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'switches',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back'],\n",
       " ['come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'corridor',\n",
       "  'inside_spin',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back'],\n",
       " ['pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_charleston',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'corridor',\n",
       "  'hand_to_hand_charleston',\n",
       "  'frankie´s_sixes'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'pop_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'mini_dip',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle'],\n",
       " ['groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'outside_spin',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'groove_walk',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin'],\n",
       " ['groove_walk',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sling_shot',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade'],\n",
       " ['groove_walk',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout'],\n",
       " ['swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'swingout'],\n",
       " ['groove_walk',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'corridor'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'sweetheart'],\n",
       " ['basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'barrel_turn',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'mini_dip',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'outside_spin',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'inside_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'pop_turn'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'lindy_circle',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'tuck_turn',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'hallelujah_rocks',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'barrel_turn',\n",
       "  'outside_spin',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'pass_by'],\n",
       " ['groove_walk',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes'],\n",
       " ['groove_walk',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'hand_to_hand',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sling_shot',\n",
       "  'sling_shot',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'basic_closed',\n",
       "  'tuck_turn'],\n",
       " ['groove_walk',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by']]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model\n",
    "word2vec_model = Word2Vec(lists_extracted, vector_size=100, window=3, min_count=1, workers=4)\n",
    "\n",
    "# Save the model for later use\n",
    "word2vec_model.save(\"lindyhop_moves_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f4f1089f358>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04565154  0.09230679  0.08688464  0.13637583 -0.01513857 -0.06920461\n",
      "  0.14715016  0.19098045 -0.15600672 -0.13825713  0.09050777 -0.09743053\n",
      "  0.00868952  0.07922212  0.02120247 -0.04458927  0.16966315  0.05521603\n",
      " -0.12658231 -0.2715543   0.05603347  0.00378757  0.24885255 -0.01874815\n",
      " -0.0306618   0.06091048 -0.08870434  0.05766023 -0.07050441  0.04014183\n",
      "  0.11143244 -0.07308721  0.05842291 -0.12233337 -0.04683715  0.08301029\n",
      "  0.07930008 -0.02897829 -0.0821113  -0.05149851  0.09115343 -0.06452671\n",
      " -0.09981759  0.04327979  0.04943946 -0.01031253 -0.10547889 -0.0618293\n",
      "  0.02623595  0.03843953  0.0053837  -0.12939256 -0.07783518 -0.03112757\n",
      " -0.09670492 -0.03992368  0.0512801  -0.08999103 -0.03384485 -0.00890474\n",
      " -0.04040616 -0.06004788  0.1674135  -0.02685238 -0.09943943  0.17649834\n",
      " -0.00323685  0.12997423 -0.15348533 -0.0127951   0.02286167  0.15707497\n",
      "  0.06567636  0.09023935  0.08001017  0.00049106  0.06410327  0.08265287\n",
      " -0.05962176 -0.0765774  -0.137158   -0.04845566  0.04518832  0.07698253\n",
      " -0.08197682 -0.09552969  0.16477704 -0.0762771  -0.02788014  0.01718981\n",
      "  0.0504312   0.02702937  0.00872295 -0.02662026  0.18875301  0.04293555\n",
      "  0.09073133 -0.09349893  0.01790545  0.06981567]\n"
     ]
    }
   ],
   "source": [
    "# Get an embedding for a specific move\n",
    "move_vector = word2vec_model.wv['lindy_circle'] \n",
    "print(move_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass_by: 0.9978436231613159\n",
      "come_back: 0.9974063038825989\n",
      "basic_closed: 0.9973371028900146\n",
      "tuck_turn: 0.9970701932907104\n",
      "break: 0.9968063831329346\n"
     ]
    }
   ],
   "source": [
    "# Finding moves similar to a given move (it can be interpreted that those moves co-occured more often in the dataset)\n",
    "similar_moves = word2vec_model.wv.most_similar('lindy_circle', topn=5) \n",
    "for move, similarity in similar_moves:\n",
    "    print(f\"{move}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass_by\n",
      "swingout\n",
      "come_back\n",
      "tuck_turn\n",
      "basic_closed\n",
      "break\n",
      "lindy_circle\n",
      "sugar_push\n",
      "outside_spin\n",
      "sweetheart\n",
      "send_out\n",
      "groove_walk\n",
      "frankie´s_sixes\n",
      "barrel_turn\n",
      "inside_turn\n",
      "promenade\n",
      "outside_turn\n",
      "corridor\n",
      "basic_open\n",
      "switches\n",
      "inside_spin\n",
      "hand_to_hand\n",
      "sailor_kicks\n",
      "sling_shot\n",
      "pop_turn\n",
      "mini_dip\n",
      "hallelujah_rocks\n",
      "tandem\n",
      "hand_to_hand_charleston\n",
      "basic_charleston\n",
      "frankie´s_points\n",
      "s_turn\n"
     ]
    }
   ],
   "source": [
    "# Check vocabulary of Word2Vec model\n",
    "for move in word2vec_model.wv.key_to_index:\n",
    "    print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=32, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve all vectors from the model\n",
    "vectors = word2vec_model.wv.vectors\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "vectors_2d = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, move in enumerate(word2vec_model.wv.key_to_index):\n",
    "    plt.scatter(vectors_2d[i, 0], vectors_2d[i, 1])\n",
    "    plt.text(vectors_2d[i, 0]+0.03, vectors_2d[i, 1]+0.03, move, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an embedding matrix for use in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 9, 28, 28, 28, 15,  2, 31, 19,  5,  2, 28, 28, 28, 28, 19, 19, 26,\n",
       "        19,  5, 28, 28, 28, 28,  5, 31, 19, 19, 17, 19,  5, 31, 19, 19, 26,\n",
       "        19, 17,  5, 28, 15, 31, 19, 28, 28, 28, 28, 15,  2, 31, 19, 19, 26,\n",
       "         5, 31, 19, 26, 19, 17,  5,  2, 28, 28, 28]),\n",
       " array([ 9, 28, 28, 28, 15,  2, 31, 19, 15, 24, 19, 17,  5, 28, 28, 28, 28,\n",
       "        15,  2, 31, 19, 19, 19, 19, 19,  3, 28, 28, 28, 28, 28, 15,  2, 31,\n",
       "        19, 19, 19, 17,  6, 28, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 19,\n",
       "        28, 28, 28,  5,  2, 24, 28, 28, 28]),\n",
       " array([ 9, 28, 19, 19,  5, 31,  2, 31, 19, 28, 28,  5, 31, 19, 19, 28, 28,\n",
       "        28, 15, 31, 19, 17, 19, 19, 19, 27, 19, 26, 19,  5, 31, 19, 19, 28,\n",
       "        28, 28, 15,  2, 31, 19, 17,  5,  2,  2, 31, 19, 26, 19]),\n",
       " array([28, 28, 28, 28, 15, 31, 19,  5, 28, 28, 28, 15, 31, 19, 17,  5,  2,\n",
       "        31, 19, 26, 27, 19, 19, 26,  3, 28, 28, 28, 28, 15, 31, 19, 17, 26,\n",
       "        27, 19, 26, 19, 19,  5, 31, 19, 28, 28, 15, 31, 19, 19, 26, 27, 19,\n",
       "        28, 28, 15]),\n",
       " array([28, 28, 28, 15, 31, 19, 19, 13, 15, 28, 28, 28, 15, 31, 19, 13, 15,\n",
       "        31, 19, 19, 19, 15, 28, 28, 28,  5,  2, 31, 19, 26, 19, 27, 19, 17,\n",
       "        15, 28, 28, 28, 28, 15, 31, 19, 19, 19, 19, 26, 19, 17,  5, 28, 28,\n",
       "        15,  2, 28, 28]),\n",
       " array([28, 28, 28, 19, 19, 19,  5, 31, 19, 19, 26, 27, 19, 19, 19, 15,  2,\n",
       "        31, 19, 28, 19,  5]),\n",
       " array([ 5,  2, 24, 19, 17,  5,  2, 31, 17, 19,  5,  2, 21, 31, 19, 27, 19,\n",
       "        28, 28, 15, 31, 31, 26, 26, 26, 31,  5,  2,  9,  2, 31, 19, 19,  5,\n",
       "        24, 19, 19, 19, 27,  8,  5,  2, 21, 31, 19, 27, 19,  5,  2, 31, 27,\n",
       "        19, 26, 27,  5,  2,  2,  2]),\n",
       " array([ 9,  2,  2, 24, 19, 19,  5,  2,  9,  2, 31, 19, 17, 19,  5,  2, 28,\n",
       "        28, 15, 31, 19, 19, 19,  8, 19, 26, 26, 31, 19,  5,  2, 31, 17, 19,\n",
       "         5,  2,  2, 31, 27, 27, 19, 19,  5,  2,  2, 31, 19, 19, 19,  5,  2,\n",
       "        24, 19, 28,  5, 24, 26, 27,  5,  2, 21]),\n",
       " array([ 5,  2, 24, 19, 19,  5,  2, 28, 28, 29,  5,  2, 31, 19,  5,  2, 24,\n",
       "        19, 11, 19,  5, 24,  8, 10,  5,  2, 28,  5,  2, 24, 26, 26, 31, 19,\n",
       "         4,  5,  2, 31, 19, 19, 19,  4, 19,  5, 28, 28,  7,  5,  2, 31, 17,\n",
       "        19, 13,  5,  2, 24,  4,  5,  2,  2, 21, 31, 19]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19, 19,  5,  2,  2, 31, 17, 19, 17, 19,  5,\n",
       "         2,  2, 31, 19,  8, 19, 27, 19,  5,  2,  2, 24,  4,  5,  2, 28, 28,\n",
       "        28, 28,  5,  2,  2, 21, 31, 19, 26, 26, 19,  5,  4,  2,  2, 24, 26,\n",
       "        26, 27, 19,  5,  2,  2, 24, 28, 28,  5]),\n",
       " array([ 9,  5,  2,  2, 24, 19, 19,  5,  2,  4,  2, 31, 19,  4,  5,  2, 28,\n",
       "        28, 28, 15,  2,  2, 31, 17, 19,  5,  2,  2, 21, 31, 19, 17,  5,  2,\n",
       "         2, 24, 17, 19, 19,  5,  2, 24, 28, 26, 26,  5,  2, 17,  4,  2, 21,\n",
       "        31, 17, 19, 27, 19,  4, 19, 26, 26, 14, 19]),\n",
       " array([ 9,  2, 31,  5, 28, 15, 14, 26, 19, 15, 28, 31, 26, 19, 15, 19, 26,\n",
       "        19, 17, 26, 19, 27, 18, 15,  9, 15, 31, 26, 19, 15, 31,  4, 18, 15,\n",
       "        31,  8,  5,  9, 28, 28, 18, 19, 26, 31, 19,  5,  2,  4, 27, 19, 26,\n",
       "        19, 25, 15, 14, 19,  5,  2,  4, 27, 13]),\n",
       " array([ 9,  4, 15, 28, 19, 19, 15, 24, 26, 19,  0, 15, 31, 26, 19,  2,  2,\n",
       "         2, 28, 15, 14, 11, 14, 15, 31, 19, 26, 19, 15, 13, 18, 27,  0, 15,\n",
       "        31, 17,  4, 19, 26, 28, 15, 14,  8, 26, 19, 15, 31, 19, 26,  5,  2,\n",
       "         4,  0, 18,  2, 15, 14, 26, 28, 15, 31,  2, 28, 11, 14,  5]),\n",
       " array([ 9, 28, 15, 31, 26, 19, 28, 17, 19, 26, 19,  5, 28, 29, 19, 19, 26,\n",
       "        28, 28, 19,  5,  2, 31,  2,  9, 31, 15, 31,  8,  2, 31, 26, 19,  4,\n",
       "        28, 18, 26, 19,  5,  9, 19, 15, 31, 29, 28, 19,  8,  3,  3, 15, 31,\n",
       "        26, 19,  4,  5]),\n",
       " array([ 5,  2, 31, 19, 19,  5, 31, 19, 26,  5,  2, 31, 19, 19,  5,  4, 31,\n",
       "        19, 26, 19,  5, 31, 19,  5, 21, 31, 19, 27,  5,  4, 31, 19, 27, 19,\n",
       "        17,  5,  9, 13,  5, 24, 19, 19,  5, 28, 28, 28,  5,  9, 31, 19, 26,\n",
       "        19,  5, 31, 19,  8,  5]),\n",
       " array([ 5, 31, 19, 19,  5, 28, 19, 17,  5,  9,  6, 13,  5, 31, 19, 19,  5,\n",
       "        21, 31, 14, 19,  5, 28, 28, 15, 21,  9, 31, 19,  8,  5, 21,  9, 31,\n",
       "        19, 26, 19,  5, 28, 28,  5, 18, 19,  5,  9,  4, 31, 19, 26, 19,  4,\n",
       "         5, 31, 19, 19,  5]),\n",
       " array([19, 19,  5, 31, 19, 19,  5, 31, 19, 19, 19,  5, 28, 28,  5, 31, 19,\n",
       "        19,  9, 27, 19, 17, 19,  5, 28, 19, 19,  4, 19,  5, 21,  9, 31, 19,\n",
       "         5, 18, 19,  5,  1, 31, 19, 26, 19, 19,  5, 31, 19, 26, 19, 28, 28,\n",
       "        15,  6, 12,  8]),\n",
       " array([ 9, 28, 28, 15,  4, 28,  4, 15, 28, 28, 15,  4, 31, 19, 19, 19, 15,\n",
       "        31, 19, 19, 19,  5, 31,  5, 31, 17,  5, 28, 28, 28,  4, 15,  4, 24,\n",
       "         4, 28, 28, 15, 20,  8, 19,  4, 15, 28, 15, 31,  4,  5, 28, 28, 28,\n",
       "        28]),\n",
       " array([ 9, 15, 28, 28,  4, 15, 31, 17, 19, 19, 28, 19, 16, 19, 17, 19,  0,\n",
       "         4, 15,  9, 31,  8, 15, 28, 28, 28, 29, 15, 21, 21, 31, 17,  4, 19,\n",
       "        19,  4, 19, 19, 15, 31,  4,  5, 24, 19,  5, 24,  4, 15, 31, 19, 15,\n",
       "        24,  4, 15, 31,  4]),\n",
       " array([ 9,  4, 15, 31, 17,  4, 19, 19, 19, 11, 19, 19, 15,  4, 31, 28, 29,\n",
       "        15, 28, 24,  4, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19,  4, 19, 19,\n",
       "        15, 31, 19,  0, 28, 28, 15,  4, 24, 19, 19, 15, 31, 19, 11, 19, 19,\n",
       "        28, 29, 15, 28, 28, 15]),\n",
       " array([ 9, 31, 19, 27, 19, 17, 19, 19, 19, 19, 17, 19, 19, 19,  5,  9,  2,\n",
       "        21, 21, 24, 19, 19, 19, 28, 28,  4, 19, 27, 19,  4, 19, 27, 19,  4,\n",
       "        18, 19, 28, 15, 28, 19, 19, 19,  5,  4, 24, 19, 19, 18, 17, 17,  0,\n",
       "         4, 19,  9,  5, 24,  4, 19, 31, 19, 17]),\n",
       " array([ 9, 24, 19, 26, 26, 26, 19, 19,  4, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        27, 17,  8, 19,  4, 19, 19, 14, 19, 19, 19, 25, 19, 15,  9, 28, 28,\n",
       "        28, 28, 15, 31,  0,  4, 19, 19, 19,  0,  4, 19, 19, 19,  5,  4, 24,\n",
       "         5,  2, 21]),\n",
       " array([ 9,  5,  2, 31,  5,  2, 24, 19,  4, 19,  5, 31,  4, 19,  4, 19, 28,\n",
       "        28,  4,  5, 28,  5, 31, 27, 19,  5,  4, 19,  4, 19, 28]),\n",
       " array([28, 19, 19,  5, 24,  4, 19, 27,  8, 28,  2, 31, 17, 19, 15,  2,  6,\n",
       "         2, 24, 19, 19, 27, 19, 28, 19, 19,  5, 28,  4,  5, 28, 19, 19, 27,\n",
       "         5, 31, 19, 19, 19, 19, 15,  2, 31, 19,  5, 24, 19,  5,  4,  2,  6,\n",
       "        28]),\n",
       " array([ 9, 28, 28,  6, 19, 19, 19, 19,  5,  4, 19, 19, 19, 27,  5, 28, 28,\n",
       "        19, 19,  3, 19,  4, 19, 19,  5,  2, 15, 28, 19,  4, 19, 19,  5, 24,\n",
       "         4, 19, 19, 27, 19,  5,  2,  2, 28, 24, 19, 19, 17, 19, 19,  5, 28,\n",
       "        19,  5, 28,  4, 19,  5, 24, 19, 19]),\n",
       " array([28, 19,  5, 31, 17, 19,  3, 19,  4, 19, 19, 19, 15, 31, 19,  5, 24,\n",
       "         4, 19, 17, 19,  5, 28, 19, 26, 26, 19,  5,  4, 24, 19, 19, 19,  5,\n",
       "        24, 19, 15, 31,  4, 19, 27, 19,  5, 28, 19,  4, 19,  4, 19,  5,  6,\n",
       "        28,  4, 19, 19,  4, 29, 19,  5,  6]),\n",
       " array([ 2, 31, 19, 19, 27, 19, 17, 19, 28, 19, 19, 19, 26, 19, 19, 28, 19,\n",
       "        19,  8, 19, 28, 19, 19, 27, 19, 19, 19, 19, 15, 31, 19, 19, 23, 19,\n",
       "         8, 19, 19,  8,  4, 19, 28, 19, 19,  8, 19, 28, 19, 19, 19, 19, 28]),\n",
       " array([ 2, 31, 19, 19, 28, 19,  4, 17, 19,  5,  2,  2,  2, 31, 19, 19,  8,\n",
       "        19, 28, 19, 15, 31, 19,  5, 31, 19, 19, 19, 19,  8, 19, 17, 19, 28,\n",
       "        19, 15, 31,  4, 14,  5, 31, 19,  8, 19, 28, 19, 17, 19, 28, 19, 19,\n",
       "        28, 19, 19, 19, 23, 19, 27]),\n",
       " array([ 2, 31, 19, 27, 19, 19, 19, 28, 19, 23, 19,  8,  0, 28, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19,  8, 19, 28, 19, 15, 31, 17, 19, 19, 28, 19,\n",
       "        19, 19, 19, 28, 19, 19,  4, 19, 28, 19, 19, 19, 27, 19, 28, 19, 19,\n",
       "        27, 19]),\n",
       " array([ 9,  2,  2,  2, 24,  4, 19, 26, 19, 15, 24, 19, 19, 28, 28, 28,  4,\n",
       "         0, 27, 17, 19,  4, 28,  4, 19, 15, 24, 19, 17, 19, 26, 19, 15, 31,\n",
       "        17, 19,  4, 19,  0,  4, 19, 15, 31, 19, 29, 19, 15, 31, 19, 28, 19,\n",
       "         4, 19, 17, 19, 15,  2, 31, 19, 19, 15, 31]),\n",
       " array([ 9, 19, 15, 28, 26, 19, 28, 19, 19,  0, 19,  4, 15,  2, 31, 19,  4,\n",
       "        15, 21, 28, 28, 28,  4,  5,  2, 31, 17,  0,  4, 19, 26, 19, 15,  2,\n",
       "        15, 31, 19, 15, 24, 26, 23, 19, 28, 15, 31, 19, 15, 24, 19, 17, 19,\n",
       "        15, 31,  4, 15, 28, 28,  4, 15]),\n",
       " array([ 9, 19, 19, 19, 15, 28, 15, 24, 26, 19, 28,  5, 31, 19]),\n",
       " array([ 9,  2, 31, 19, 16,  5,  2, 31, 17, 19, 28, 15,  4, 31, 19, 19, 18,\n",
       "        19, 28, 19, 28, 19, 19,  0, 18, 26, 26, 27, 19, 28, 14, 28, 17, 18,\n",
       "        19, 19,  4,  5,  9,  2, 19, 27,  4,  0, 27,  0, 27, 14,  2, 28, 28,\n",
       "         2, 20]),\n",
       " array([ 9,  2, 31, 19, 19, 27,  4, 19, 19,  5,  9, 31, 19,  5,  4,  2, 24,\n",
       "        17, 19,  4, 19, 28, 28, 18, 19,  0,  4, 19, 27,  0,  5,  2,  4, 31,\n",
       "        19,  4, 19,  4, 21, 31, 19,  0, 19, 27, 19, 19,  0,  4, 31, 19, 26,\n",
       "        26, 22, 30, 30,  4]),\n",
       " array([ 9, 31, 19, 19,  0, 19, 19, 31, 19, 19, 27, 15,  4, 24, 19, 19, 28,\n",
       "        19, 27,  9, 19, 19, 19, 28,  4, 19, 28,  4, 19, 19,  4, 14, 28, 19,\n",
       "         4, 14, 31, 18, 19,  4, 17, 19, 10,  4, 18, 19, 19, 19, 27, 19, 19,\n",
       "        18, 19,  4, 28, 28, 19, 19, 19]),\n",
       " array([ 9,  2,  2,  2,  2, 31, 19, 19, 14, 14, 14,  0, 17, 27, 19, 19, 28,\n",
       "         5,  2,  2, 31, 19, 19, 19, 28, 28, 28, 19, 19, 19, 19,  5,  2, 24,\n",
       "        23,  0, 27, 19, 19,  5,  2,  2,  2, 31, 19, 19,  5,  2,  2, 31, 28,\n",
       "        28, 14, 14, 19, 19]),\n",
       " array([ 9, 19, 28, 19, 28,  5,  2,  2, 31, 19, 19,  5,  2,  2, 31, 19,  5,\n",
       "         2,  2,  2,  6, 31, 17, 19, 19,  5, 31, 19, 19,  5,  2,  2, 31, 19,\n",
       "        19,  3, 19, 19, 28, 28, 28, 19, 19, 19, 28,  5,  2, 21, 24, 28, 19,\n",
       "         5, 21,  2,  2, 31, 17, 19, 19, 19,  3, 19]),\n",
       " array([ 9,  2, 31, 19,  4, 19, 19,  4, 19, 19, 19,  4, 19,  5,  2,  2, 31,\n",
       "        19, 19,  3,  4, 19, 19, 19, 29, 19, 19, 19,  3,  4, 19,  5,  2,  2,\n",
       "         4,  2, 31, 19,  4, 19,  5,  2, 31,  4, 19, 19,  3, 28,  5, 31, 19,\n",
       "         4, 19, 19,  4]),\n",
       " array([ 9, 19, 27, 19, 26, 27, 19,  8, 19, 19, 19, 28, 19,  8, 19, 19, 11,\n",
       "        19,  5, 31, 19, 28, 28, 19, 28, 18, 19, 28, 14, 19, 19,  8, 19, 26,\n",
       "        19, 19, 26, 17, 19, 26, 28, 28, 19, 19, 19, 19, 19, 26, 28,  6, 19,\n",
       "         8]),\n",
       " array([ 9, 19, 19, 28, 19, 28, 19, 11, 19, 26, 19, 17, 19, 19, 26, 27, 19,\n",
       "        13, 19, 19, 28, 28, 18, 19, 26, 25, 25, 19, 26, 19, 26, 28, 19,  8,\n",
       "         6, 19,  8, 19, 19, 19,  8,  5,  2, 31,  2, 28,  2, 31]),\n",
       " array([ 9, 26, 19, 19, 19, 26,  8, 19, 19, 17, 19,  8, 19, 19,  8, 19, 28,\n",
       "        19, 19, 26, 19, 28, 19, 19, 17, 19, 17,  8, 19, 19, 19, 19, 19, 26,\n",
       "        19, 19, 28, 28, 19, 26, 19, 19])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten all sequences into a single list to find unique moves\n",
    "all_moves = [move for sequence in lists_extracted for move in sequence]\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_moves)\n",
    "\n",
    "# Number of unique classes (moves)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Function to convert moves to integers\n",
    "def encode_sequence(sequence):\n",
    "    # Encode the sequence\n",
    "    return label_encoder.transform(sequence)\n",
    "\n",
    "# Apply encoding to each sequence\n",
    "encoded_sequences = [encode_sequence(sequence) for sequence in lists_extracted]\n",
    "encoded_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barrel_turn': 0, 'basic_charleston': 1, 'basic_closed': 2, 'basic_open': 3, 'break': 4, 'come_back': 5, 'corridor': 6, 'frankie´s_points': 7, 'frankie´s_sixes': 8, 'groove_walk': 9, 'hallelujah_rocks': 10, 'hand_to_hand': 11, 'hand_to_hand_charleston': 12, 'inside_spin': 13, 'inside_turn': 14, 'lindy_circle': 15, 'mini_dip': 16, 'outside_spin': 17, 'outside_turn': 18, 'pass_by': 19, 'pop_turn': 20, 'promenade': 21, 's_turn': 22, 'sailor_kicks': 23, 'send_out': 24, 'sling_shot': 25, 'sugar_push': 26, 'sweetheart': 27, 'swingout': 28, 'switches': 29, 'tandem': 30, 'tuck_turn': 31}\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from moves to indices using the LabelEncoder\n",
    "move_to_index = {move: index for index, move in enumerate(label_encoder.classes_)}\n",
    "\n",
    "# Print the mapping\n",
    "print(move_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create embedding matrix\n",
    "\n",
    "# Assuming 'move_to_index' is your mapping from move names to indices\n",
    "embedding_matrix = np.zeros((len(move_to_index), 100))  # 100 is the vector_size\n",
    "\n",
    "for move, i in move_to_index.items():\n",
    "    if move in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[move]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04542539,  0.07414072,  0.05057511, ..., -0.06139921,\n",
       "         0.00665566,  0.05288935],\n",
       "       [-0.0075555 , -0.00329107,  0.00354963, ..., -0.01305514,\n",
       "        -0.00455797,  0.00511153],\n",
       "       [-0.08580953,  0.1426644 ,  0.12035948, ..., -0.1230483 ,\n",
       "         0.02897234,  0.09621964],\n",
       "       ...,\n",
       "       [-0.01748785,  0.04731126,  0.03965464, ..., -0.0301785 ,\n",
       "         0.01392032,  0.03688603],\n",
       "       [-0.00843198,  0.02499254,  0.01546631, ..., -0.01299354,\n",
       "        -0.00415079,  0.00867285],\n",
       "       [-0.07613422,  0.13139595,  0.11004833, ..., -0.11785343,\n",
       "         0.02172278,  0.07516012]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding_matrix\n",
    "np.save('embedding_matrix_word2vec_100.npy', embedding_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding_matrix\n",
    "loaded_embedding_matrix = np.load('embedding_matrix_word2vec_100.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input-output pairs for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb, y_emb = create_input_output_pairs_mtm(encoded_sequences, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an input to Numpy Array\n",
    "x_emb = np.array(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an output to a one-hot-encoded vector\n",
    "y_emb_one_hot = to_categorical(y_emb, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_emb_train: (1644, 4)\n",
      "Shape of y_emb_train: (1644, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets (80-20 split)\n",
    "split_index_2 = int(0.8 * len(x_emb))\n",
    "x_emb_train, x_emb_test = x_emb[:split_index_2], x_emb[split_index_2:]\n",
    "y_emb_train, y_emb_test = y_emb_one_hot[:split_index_2], y_emb_one_hot[split_index_2:]\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of x_emb_train:\", x_emb_train.shape)\n",
    "print(\"Shape of y_emb_train:\", y_emb_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline LSTM with trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding matrix\n",
    "embedding_matrix = np.load('embedding_matrix_word2vec_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 100)            3200      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 4, 64)             42240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 47,520\n",
      "Trainable params: 44,320\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, TimeDistributed, Dense, Embedding\n",
    "import random\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Parameters\n",
    "input_length = 4  # Length of input sequences\n",
    "num_moves = len(embedding_matrix)  # Number of unique moves\n",
    "embedding_dim = len(embedding_matrix[0])  # Dimension of Word2Vec embeddings\n",
    "\n",
    "# Define the LSTM model with the Embedding layer\n",
    "Emb_model_simple = Sequential([\n",
    "    # Embedding layer with pre-trained Word2Vec weights\n",
    "    Embedding(input_dim=num_moves, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False, \n",
    "              input_length=input_length),\n",
    "    \n",
    "    # LSTM layer\n",
    "    LSTM(64, return_sequences=True),\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # TimeDistributed Dense layer for output at each time step\n",
    "    TimeDistributed(Dense(num_moves, activation='softmax'))  # Assuming output size equals the number of moves\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "Emb_model_simple.compile(optimizer='adam', \n",
    "                           loss='categorical_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "Emb_model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(Emb_model_simple, to_file='Emb_model_simple_architecture.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "103/103 [==============================] - 2s 8ms/step - loss: 3.0502 - accuracy: 0.2559 - val_loss: 2.5324 - val_accuracy: 0.3954\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 2.5052 - accuracy: 0.3097 - val_loss: 2.4899 - val_accuracy: 0.3954\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.4765 - accuracy: 0.3033 - val_loss: 2.4349 - val_accuracy: 0.3954\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.4280 - accuracy: 0.3097 - val_loss: 2.4332 - val_accuracy: 0.3954\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.4244 - accuracy: 0.3049 - val_loss: 2.4313 - val_accuracy: 0.3954\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 2.4052 - accuracy: 0.3111 - val_loss: 2.4312 - val_accuracy: 0.3954\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3894 - accuracy: 0.3190 - val_loss: 2.4265 - val_accuracy: 0.3954\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3913 - accuracy: 0.3079 - val_loss: 2.4054 - val_accuracy: 0.3954\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3932 - accuracy: 0.3019 - val_loss: 2.4141 - val_accuracy: 0.3954\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3818 - accuracy: 0.3097 - val_loss: 2.4061 - val_accuracy: 0.3954\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3598 - accuracy: 0.3114 - val_loss: 2.3954 - val_accuracy: 0.3954\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3718 - accuracy: 0.3115 - val_loss: 2.4018 - val_accuracy: 0.3954\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3670 - accuracy: 0.3031 - val_loss: 2.3912 - val_accuracy: 0.3954\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3307 - accuracy: 0.3085 - val_loss: 2.3772 - val_accuracy: 0.3954\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3116 - accuracy: 0.3134 - val_loss: 2.3651 - val_accuracy: 0.3954\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2998 - accuracy: 0.3061 - val_loss: 2.3382 - val_accuracy: 0.3954\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2768 - accuracy: 0.3181 - val_loss: 2.3356 - val_accuracy: 0.3942\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2737 - accuracy: 0.3172 - val_loss: 2.3234 - val_accuracy: 0.3942\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2587 - accuracy: 0.3157 - val_loss: 2.3195 - val_accuracy: 0.4185\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2743 - accuracy: 0.3173 - val_loss: 2.3040 - val_accuracy: 0.4118\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.2549 - accuracy: 0.3140 - val_loss: 2.2819 - val_accuracy: 0.4039\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 2.2161 - accuracy: 0.3272 - val_loss: 2.2650 - val_accuracy: 0.4416\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1854 - accuracy: 0.3501 - val_loss: 2.2618 - val_accuracy: 0.4234\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1704 - accuracy: 0.3478 - val_loss: 2.2682 - val_accuracy: 0.4264\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1674 - accuracy: 0.3448 - val_loss: 2.2595 - val_accuracy: 0.4161\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1851 - accuracy: 0.3466 - val_loss: 2.2356 - val_accuracy: 0.4307\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1491 - accuracy: 0.3626 - val_loss: 2.2577 - val_accuracy: 0.4288\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1543 - accuracy: 0.3583 - val_loss: 2.2188 - val_accuracy: 0.4343\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1317 - accuracy: 0.3548 - val_loss: 2.2243 - val_accuracy: 0.4282\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1168 - accuracy: 0.3683 - val_loss: 2.2109 - val_accuracy: 0.4392\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1142 - accuracy: 0.3693 - val_loss: 2.2239 - val_accuracy: 0.4349\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1044 - accuracy: 0.3705 - val_loss: 2.2334 - val_accuracy: 0.4252\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1390 - accuracy: 0.3668 - val_loss: 2.2080 - val_accuracy: 0.4331\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0767 - accuracy: 0.3714 - val_loss: 2.2079 - val_accuracy: 0.4446\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0477 - accuracy: 0.3938 - val_loss: 2.2376 - val_accuracy: 0.4282\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0723 - accuracy: 0.3768 - val_loss: 2.2103 - val_accuracy: 0.4392\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0262 - accuracy: 0.3957 - val_loss: 2.2077 - val_accuracy: 0.4428\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0453 - accuracy: 0.3861 - val_loss: 2.2056 - val_accuracy: 0.4349\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0413 - accuracy: 0.3878 - val_loss: 2.2199 - val_accuracy: 0.4252\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0113 - accuracy: 0.3992 - val_loss: 2.2108 - val_accuracy: 0.4410\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0512 - accuracy: 0.3940 - val_loss: 2.2185 - val_accuracy: 0.4373\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9994 - accuracy: 0.4075 - val_loss: 2.2389 - val_accuracy: 0.4313\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9983 - accuracy: 0.4018 - val_loss: 2.2084 - val_accuracy: 0.4416\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0016 - accuracy: 0.3997 - val_loss: 2.2114 - val_accuracy: 0.4459\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9776 - accuracy: 0.4073 - val_loss: 2.2078 - val_accuracy: 0.4240\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9886 - accuracy: 0.4078 - val_loss: 2.2370 - val_accuracy: 0.4361\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9821 - accuracy: 0.4113 - val_loss: 2.2173 - val_accuracy: 0.4367\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9771 - accuracy: 0.4190 - val_loss: 2.2164 - val_accuracy: 0.4264\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.0064 - accuracy: 0.4085 - val_loss: 2.2110 - val_accuracy: 0.4319\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9798 - accuracy: 0.4098 - val_loss: 2.2173 - val_accuracy: 0.4465\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9615 - accuracy: 0.4179 - val_loss: 2.2264 - val_accuracy: 0.4185\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9764 - accuracy: 0.4104 - val_loss: 2.2165 - val_accuracy: 0.4361\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9800 - accuracy: 0.4131 - val_loss: 2.2201 - val_accuracy: 0.4300\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9778 - accuracy: 0.4053 - val_loss: 2.2373 - val_accuracy: 0.4392\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9370 - accuracy: 0.4150 - val_loss: 2.2261 - val_accuracy: 0.4300\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9822 - accuracy: 0.4106 - val_loss: 2.2161 - val_accuracy: 0.4264\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9746 - accuracy: 0.4162 - val_loss: 2.2129 - val_accuracy: 0.4373\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9860 - accuracy: 0.4118 - val_loss: 2.2205 - val_accuracy: 0.4179\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.9477 - accuracy: 0.4230 - val_loss: 2.2329 - val_accuracy: 0.4422\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9507 - accuracy: 0.4241 - val_loss: 2.2048 - val_accuracy: 0.4440\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9825 - accuracy: 0.4100 - val_loss: 2.2182 - val_accuracy: 0.4471\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9397 - accuracy: 0.4206 - val_loss: 2.2276 - val_accuracy: 0.4288\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9318 - accuracy: 0.4291 - val_loss: 2.2158 - val_accuracy: 0.4373\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9568 - accuracy: 0.4120 - val_loss: 2.2576 - val_accuracy: 0.4331\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9515 - accuracy: 0.4163 - val_loss: 2.2545 - val_accuracy: 0.4191\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9291 - accuracy: 0.4273 - val_loss: 2.2217 - val_accuracy: 0.4428\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9164 - accuracy: 0.4289 - val_loss: 2.2350 - val_accuracy: 0.4392\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9028 - accuracy: 0.4229 - val_loss: 2.2446 - val_accuracy: 0.4422\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9064 - accuracy: 0.4235 - val_loss: 2.2288 - val_accuracy: 0.4373\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9145 - accuracy: 0.4291 - val_loss: 2.2335 - val_accuracy: 0.4440\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9340 - accuracy: 0.4159 - val_loss: 2.2381 - val_accuracy: 0.4459\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9396 - accuracy: 0.4168 - val_loss: 2.2369 - val_accuracy: 0.4355\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8996 - accuracy: 0.4311 - val_loss: 2.2618 - val_accuracy: 0.4404\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8837 - accuracy: 0.4337 - val_loss: 2.2389 - val_accuracy: 0.4294\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9194 - accuracy: 0.4143 - val_loss: 2.2529 - val_accuracy: 0.4392\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8803 - accuracy: 0.4355 - val_loss: 2.2407 - val_accuracy: 0.4392\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8832 - accuracy: 0.4351 - val_loss: 2.2519 - val_accuracy: 0.4446\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8981 - accuracy: 0.4198 - val_loss: 2.2644 - val_accuracy: 0.4440\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.8986 - accuracy: 0.4248 - val_loss: 2.2518 - val_accuracy: 0.4416\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8938 - accuracy: 0.4258 - val_loss: 2.2251 - val_accuracy: 0.4446\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8955 - accuracy: 0.4181 - val_loss: 2.2465 - val_accuracy: 0.4380\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9305 - accuracy: 0.4262 - val_loss: 2.2437 - val_accuracy: 0.4428\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8865 - accuracy: 0.4285 - val_loss: 2.2530 - val_accuracy: 0.4483\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8774 - accuracy: 0.4321 - val_loss: 2.2381 - val_accuracy: 0.4440\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9207 - accuracy: 0.4161 - val_loss: 2.2492 - val_accuracy: 0.4422\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8876 - accuracy: 0.4256 - val_loss: 2.2441 - val_accuracy: 0.4471\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8639 - accuracy: 0.4376 - val_loss: 2.2371 - val_accuracy: 0.4434\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8759 - accuracy: 0.4312 - val_loss: 2.2473 - val_accuracy: 0.4331\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8905 - accuracy: 0.4348 - val_loss: 2.2715 - val_accuracy: 0.4349\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8769 - accuracy: 0.4320 - val_loss: 2.2481 - val_accuracy: 0.4361\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8705 - accuracy: 0.4245 - val_loss: 2.2569 - val_accuracy: 0.4270\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8625 - accuracy: 0.4330 - val_loss: 2.2535 - val_accuracy: 0.4422\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8706 - accuracy: 0.4242 - val_loss: 2.2807 - val_accuracy: 0.4440\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8997 - accuracy: 0.4163 - val_loss: 2.2568 - val_accuracy: 0.4234\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8876 - accuracy: 0.4202 - val_loss: 2.2760 - val_accuracy: 0.4331\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8943 - accuracy: 0.4291 - val_loss: 2.2733 - val_accuracy: 0.4209\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8915 - accuracy: 0.4292 - val_loss: 2.2511 - val_accuracy: 0.4398\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8481 - accuracy: 0.4275 - val_loss: 2.2668 - val_accuracy: 0.4367\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8793 - accuracy: 0.4276 - val_loss: 2.2944 - val_accuracy: 0.4422\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8386 - accuracy: 0.4381 - val_loss: 2.2669 - val_accuracy: 0.4410\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8526 - accuracy: 0.4290 - val_loss: 2.2778 - val_accuracy: 0.4355\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8618 - accuracy: 0.4321 - val_loss: 2.2553 - val_accuracy: 0.4453\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8531 - accuracy: 0.4322 - val_loss: 2.2655 - val_accuracy: 0.4440\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8439 - accuracy: 0.4379 - val_loss: 2.2877 - val_accuracy: 0.4434\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8461 - accuracy: 0.4357 - val_loss: 2.2743 - val_accuracy: 0.4465\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8478 - accuracy: 0.4383 - val_loss: 2.2811 - val_accuracy: 0.4434\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8342 - accuracy: 0.4289 - val_loss: 2.2755 - val_accuracy: 0.4483\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.8454 - accuracy: 0.4363 - val_loss: 2.2815 - val_accuracy: 0.4422\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8427 - accuracy: 0.4390 - val_loss: 2.3085 - val_accuracy: 0.4155\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8422 - accuracy: 0.4377 - val_loss: 2.2704 - val_accuracy: 0.4282\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8620 - accuracy: 0.4268 - val_loss: 2.2619 - val_accuracy: 0.4404\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8415 - accuracy: 0.4406 - val_loss: 2.2554 - val_accuracy: 0.4513\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8251 - accuracy: 0.4354 - val_loss: 2.2854 - val_accuracy: 0.4380\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8554 - accuracy: 0.4332 - val_loss: 2.2695 - val_accuracy: 0.4373\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8535 - accuracy: 0.4336 - val_loss: 2.2864 - val_accuracy: 0.4404\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.8181 - accuracy: 0.4359 - val_loss: 2.3050 - val_accuracy: 0.4386\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8494 - accuracy: 0.4339 - val_loss: 2.2932 - val_accuracy: 0.4428\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8245 - accuracy: 0.4502 - val_loss: 2.2998 - val_accuracy: 0.4246\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8014 - accuracy: 0.4525 - val_loss: 2.2921 - val_accuracy: 0.4361\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8451 - accuracy: 0.4372 - val_loss: 2.3023 - val_accuracy: 0.4313\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8273 - accuracy: 0.4409 - val_loss: 2.2946 - val_accuracy: 0.4380\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8537 - accuracy: 0.4327 - val_loss: 2.2813 - val_accuracy: 0.4434\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8287 - accuracy: 0.4376 - val_loss: 2.2884 - val_accuracy: 0.4380\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8197 - accuracy: 0.4437 - val_loss: 2.3015 - val_accuracy: 0.4361\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8041 - accuracy: 0.4440 - val_loss: 2.2931 - val_accuracy: 0.4453\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8254 - accuracy: 0.4446 - val_loss: 2.3181 - val_accuracy: 0.4337\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8088 - accuracy: 0.4447 - val_loss: 2.2788 - val_accuracy: 0.4386\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8260 - accuracy: 0.4341 - val_loss: 2.3033 - val_accuracy: 0.4373\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8104 - accuracy: 0.4305 - val_loss: 2.2869 - val_accuracy: 0.4380\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7980 - accuracy: 0.4420 - val_loss: 2.3071 - val_accuracy: 0.4294\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8033 - accuracy: 0.4408 - val_loss: 2.2913 - val_accuracy: 0.4355\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8150 - accuracy: 0.4390 - val_loss: 2.3147 - val_accuracy: 0.4276\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8095 - accuracy: 0.4441 - val_loss: 2.2914 - val_accuracy: 0.4373\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7716 - accuracy: 0.4493 - val_loss: 2.3377 - val_accuracy: 0.4258\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7958 - accuracy: 0.4396 - val_loss: 2.2953 - val_accuracy: 0.4367\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8091 - accuracy: 0.4364 - val_loss: 2.3080 - val_accuracy: 0.4300\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7944 - accuracy: 0.4510 - val_loss: 2.3095 - val_accuracy: 0.4313\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8183 - accuracy: 0.4390 - val_loss: 2.3285 - val_accuracy: 0.4343\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8027 - accuracy: 0.4443 - val_loss: 2.3170 - val_accuracy: 0.4446\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7933 - accuracy: 0.4461 - val_loss: 2.3399 - val_accuracy: 0.4343\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7671 - accuracy: 0.4537 - val_loss: 2.3282 - val_accuracy: 0.4264\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8104 - accuracy: 0.4515 - val_loss: 2.3355 - val_accuracy: 0.4367\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7965 - accuracy: 0.4441 - val_loss: 2.3184 - val_accuracy: 0.4294\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.8106 - accuracy: 0.4300 - val_loss: 2.3298 - val_accuracy: 0.4264\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7784 - accuracy: 0.4502 - val_loss: 2.3297 - val_accuracy: 0.4343\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7763 - accuracy: 0.4476 - val_loss: 2.3213 - val_accuracy: 0.4392\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.4444 - val_loss: 2.3194 - val_accuracy: 0.4300\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7910 - accuracy: 0.4500 - val_loss: 2.3176 - val_accuracy: 0.4331\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7696 - accuracy: 0.4480 - val_loss: 2.3302 - val_accuracy: 0.4343\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7734 - accuracy: 0.4526 - val_loss: 2.3230 - val_accuracy: 0.4313\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7918 - accuracy: 0.4538 - val_loss: 2.3477 - val_accuracy: 0.4124\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.4463 - val_loss: 2.3604 - val_accuracy: 0.4221\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7787 - accuracy: 0.4439 - val_loss: 2.3277 - val_accuracy: 0.4179\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7809 - accuracy: 0.4531 - val_loss: 2.3445 - val_accuracy: 0.4148\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7886 - accuracy: 0.4338 - val_loss: 2.3263 - val_accuracy: 0.4325\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7641 - accuracy: 0.4501 - val_loss: 2.3252 - val_accuracy: 0.4337\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7829 - accuracy: 0.4363 - val_loss: 2.3455 - val_accuracy: 0.4112\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7470 - accuracy: 0.4573 - val_loss: 2.3302 - val_accuracy: 0.4179\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7807 - accuracy: 0.4445 - val_loss: 2.3491 - val_accuracy: 0.4191\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7690 - accuracy: 0.4523 - val_loss: 2.3160 - val_accuracy: 0.4337\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7378 - accuracy: 0.4520 - val_loss: 2.3803 - val_accuracy: 0.4185\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7452 - accuracy: 0.4563 - val_loss: 2.3310 - val_accuracy: 0.4234\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7701 - accuracy: 0.4476 - val_loss: 2.3441 - val_accuracy: 0.4270\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7452 - accuracy: 0.4382 - val_loss: 2.3424 - val_accuracy: 0.4258\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7430 - accuracy: 0.4599 - val_loss: 2.3544 - val_accuracy: 0.4227\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7620 - accuracy: 0.4432 - val_loss: 2.3638 - val_accuracy: 0.4142\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7480 - accuracy: 0.4489 - val_loss: 2.3413 - val_accuracy: 0.4398\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7329 - accuracy: 0.4553 - val_loss: 2.3586 - val_accuracy: 0.4227\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7614 - accuracy: 0.4378 - val_loss: 2.3485 - val_accuracy: 0.4276\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7443 - accuracy: 0.4439 - val_loss: 2.3475 - val_accuracy: 0.4373\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.7347 - accuracy: 0.4582 - val_loss: 2.3378 - val_accuracy: 0.4307\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7432 - accuracy: 0.4586 - val_loss: 2.3676 - val_accuracy: 0.4155\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7486 - accuracy: 0.4481 - val_loss: 2.3429 - val_accuracy: 0.4270\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7448 - accuracy: 0.4544 - val_loss: 2.3499 - val_accuracy: 0.4203\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7396 - accuracy: 0.4596 - val_loss: 2.3559 - val_accuracy: 0.4161\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7630 - accuracy: 0.4475 - val_loss: 2.3609 - val_accuracy: 0.4155\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7276 - accuracy: 0.4567 - val_loss: 2.4018 - val_accuracy: 0.3990\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7413 - accuracy: 0.4450 - val_loss: 2.3361 - val_accuracy: 0.4331\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.7326 - accuracy: 0.4442 - val_loss: 2.3798 - val_accuracy: 0.4185\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7462 - accuracy: 0.4497 - val_loss: 2.3691 - val_accuracy: 0.4185\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.7517 - accuracy: 0.4488 - val_loss: 2.3785 - val_accuracy: 0.4240\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7435 - accuracy: 0.4481 - val_loss: 2.3779 - val_accuracy: 0.4179\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7310 - accuracy: 0.4589 - val_loss: 2.3658 - val_accuracy: 0.4221\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7225 - accuracy: 0.4593 - val_loss: 2.3693 - val_accuracy: 0.4039\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7242 - accuracy: 0.4506 - val_loss: 2.3578 - val_accuracy: 0.4234\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7255 - accuracy: 0.4487 - val_loss: 2.3703 - val_accuracy: 0.4185\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7175 - accuracy: 0.4670 - val_loss: 2.3504 - val_accuracy: 0.4331\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7155 - accuracy: 0.4663 - val_loss: 2.3664 - val_accuracy: 0.4215\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7250 - accuracy: 0.4551 - val_loss: 2.4002 - val_accuracy: 0.4130\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7171 - accuracy: 0.4594 - val_loss: 2.3938 - val_accuracy: 0.4027\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7189 - accuracy: 0.4540 - val_loss: 2.3749 - val_accuracy: 0.4197\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.7321 - accuracy: 0.4600 - val_loss: 2.3700 - val_accuracy: 0.4319\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7113 - accuracy: 0.4540 - val_loss: 2.3962 - val_accuracy: 0.3954\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7227 - accuracy: 0.4522 - val_loss: 2.3984 - val_accuracy: 0.4136\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7142 - accuracy: 0.4716 - val_loss: 2.3913 - val_accuracy: 0.4063\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7105 - accuracy: 0.4585 - val_loss: 2.3758 - val_accuracy: 0.4118\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6945 - accuracy: 0.4601 - val_loss: 2.3804 - val_accuracy: 0.4167\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7093 - accuracy: 0.4651 - val_loss: 2.3988 - val_accuracy: 0.4051\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6956 - accuracy: 0.4713 - val_loss: 2.3983 - val_accuracy: 0.3936\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7094 - accuracy: 0.4590 - val_loss: 2.3950 - val_accuracy: 0.4130\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6817 - accuracy: 0.4728 - val_loss: 2.3710 - val_accuracy: 0.4082\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7098 - accuracy: 0.4617 - val_loss: 2.4340 - val_accuracy: 0.3911\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7240 - accuracy: 0.4480 - val_loss: 2.3873 - val_accuracy: 0.4112\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6971 - accuracy: 0.4618 - val_loss: 2.4055 - val_accuracy: 0.4148\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6844 - accuracy: 0.4661 - val_loss: 2.3542 - val_accuracy: 0.4240\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7056 - accuracy: 0.4641 - val_loss: 2.3920 - val_accuracy: 0.4148\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7109 - accuracy: 0.4658 - val_loss: 2.3895 - val_accuracy: 0.4136\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7012 - accuracy: 0.4566 - val_loss: 2.3858 - val_accuracy: 0.4197\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7051 - accuracy: 0.4638 - val_loss: 2.3755 - val_accuracy: 0.4221\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7150 - accuracy: 0.4574 - val_loss: 2.3646 - val_accuracy: 0.4240\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7106 - accuracy: 0.4581 - val_loss: 2.4157 - val_accuracy: 0.4039\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7053 - accuracy: 0.4538 - val_loss: 2.3809 - val_accuracy: 0.4167\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6841 - accuracy: 0.4678 - val_loss: 2.3853 - val_accuracy: 0.4148\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7041 - accuracy: 0.4678 - val_loss: 2.4030 - val_accuracy: 0.4094\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6656 - accuracy: 0.4657 - val_loss: 2.4052 - val_accuracy: 0.4088\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.7002 - accuracy: 0.4687 - val_loss: 2.4187 - val_accuracy: 0.4148\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6845 - accuracy: 0.4676 - val_loss: 2.4192 - val_accuracy: 0.4088\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6983 - accuracy: 0.4569 - val_loss: 2.4078 - val_accuracy: 0.4191\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6859 - accuracy: 0.4733 - val_loss: 2.3796 - val_accuracy: 0.4258\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6754 - accuracy: 0.4738 - val_loss: 2.4270 - val_accuracy: 0.4033\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6947 - accuracy: 0.4643 - val_loss: 2.4170 - val_accuracy: 0.4112\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6862 - accuracy: 0.4688 - val_loss: 2.4066 - val_accuracy: 0.4191\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6728 - accuracy: 0.4586 - val_loss: 2.4094 - val_accuracy: 0.4033\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6660 - accuracy: 0.4726 - val_loss: 2.4140 - val_accuracy: 0.3978\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6773 - accuracy: 0.4604 - val_loss: 2.4047 - val_accuracy: 0.4082\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6607 - accuracy: 0.4716 - val_loss: 2.4100 - val_accuracy: 0.4057\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6639 - accuracy: 0.4720 - val_loss: 2.4146 - val_accuracy: 0.4045\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6388 - accuracy: 0.4819 - val_loss: 2.4182 - val_accuracy: 0.4009\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6694 - accuracy: 0.4687 - val_loss: 2.4162 - val_accuracy: 0.4057\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6903 - accuracy: 0.4681 - val_loss: 2.3938 - val_accuracy: 0.4142\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6953 - accuracy: 0.4666 - val_loss: 2.4194 - val_accuracy: 0.4118\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6556 - accuracy: 0.4762 - val_loss: 2.4322 - val_accuracy: 0.3996\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6605 - accuracy: 0.4719 - val_loss: 2.4029 - val_accuracy: 0.4130\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6812 - accuracy: 0.4719 - val_loss: 2.4282 - val_accuracy: 0.3905\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6913 - accuracy: 0.4667 - val_loss: 2.4199 - val_accuracy: 0.4088\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6866 - accuracy: 0.4619 - val_loss: 2.4141 - val_accuracy: 0.4161\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6802 - accuracy: 0.4695 - val_loss: 2.4285 - val_accuracy: 0.4045\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6820 - accuracy: 0.4692 - val_loss: 2.4430 - val_accuracy: 0.4100\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.4694 - val_loss: 2.4150 - val_accuracy: 0.4075\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6615 - accuracy: 0.4729 - val_loss: 2.4088 - val_accuracy: 0.4039\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6637 - accuracy: 0.4740 - val_loss: 2.4169 - val_accuracy: 0.4118\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6616 - accuracy: 0.4726 - val_loss: 2.4398 - val_accuracy: 0.4002\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6673 - accuracy: 0.4601 - val_loss: 2.4693 - val_accuracy: 0.3875\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6432 - accuracy: 0.4760 - val_loss: 2.4578 - val_accuracy: 0.3942\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6580 - accuracy: 0.4685 - val_loss: 2.4080 - val_accuracy: 0.4100\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6591 - accuracy: 0.4828 - val_loss: 2.4401 - val_accuracy: 0.3960\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6603 - accuracy: 0.4746 - val_loss: 2.4383 - val_accuracy: 0.4002\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6589 - accuracy: 0.4721 - val_loss: 2.4126 - val_accuracy: 0.4045\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6548 - accuracy: 0.4780 - val_loss: 2.4183 - val_accuracy: 0.4057\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6345 - accuracy: 0.4815 - val_loss: 2.4410 - val_accuracy: 0.4045\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6500 - accuracy: 0.4766 - val_loss: 2.4338 - val_accuracy: 0.4027\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6416 - accuracy: 0.4695 - val_loss: 2.4628 - val_accuracy: 0.3948\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6785 - accuracy: 0.4718 - val_loss: 2.4378 - val_accuracy: 0.4082\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6601 - accuracy: 0.4715 - val_loss: 2.4407 - val_accuracy: 0.4063\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6516 - accuracy: 0.4784 - val_loss: 2.4221 - val_accuracy: 0.4173\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6302 - accuracy: 0.4801 - val_loss: 2.4312 - val_accuracy: 0.4112\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6553 - accuracy: 0.4722 - val_loss: 2.4390 - val_accuracy: 0.4075\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6560 - accuracy: 0.4715 - val_loss: 2.4597 - val_accuracy: 0.3911\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6472 - accuracy: 0.4736 - val_loss: 2.4316 - val_accuracy: 0.4124\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6385 - accuracy: 0.4770 - val_loss: 2.4144 - val_accuracy: 0.4094\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6358 - accuracy: 0.4862 - val_loss: 2.4190 - val_accuracy: 0.4142\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6585 - accuracy: 0.4867 - val_loss: 2.4847 - val_accuracy: 0.3869\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6536 - accuracy: 0.4712 - val_loss: 2.4329 - val_accuracy: 0.4100\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6474 - accuracy: 0.4785 - val_loss: 2.4557 - val_accuracy: 0.4027\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6392 - accuracy: 0.4751 - val_loss: 2.4475 - val_accuracy: 0.4015\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6680 - accuracy: 0.4689 - val_loss: 2.4344 - val_accuracy: 0.4118\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6274 - accuracy: 0.4845 - val_loss: 2.4359 - val_accuracy: 0.3960\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6223 - accuracy: 0.4715 - val_loss: 2.4244 - val_accuracy: 0.4027\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6446 - accuracy: 0.4761 - val_loss: 2.4391 - val_accuracy: 0.4033\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6614 - accuracy: 0.4632 - val_loss: 2.4525 - val_accuracy: 0.4088\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6194 - accuracy: 0.4862 - val_loss: 2.4743 - val_accuracy: 0.3948\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6371 - accuracy: 0.4733 - val_loss: 2.4779 - val_accuracy: 0.4094\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6300 - accuracy: 0.4823 - val_loss: 2.4463 - val_accuracy: 0.3887\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6436 - accuracy: 0.4848 - val_loss: 2.4638 - val_accuracy: 0.3960\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6419 - accuracy: 0.4688 - val_loss: 2.4247 - val_accuracy: 0.4088\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6178 - accuracy: 0.4880 - val_loss: 2.4778 - val_accuracy: 0.4033\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6316 - accuracy: 0.4729 - val_loss: 2.4480 - val_accuracy: 0.4118\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6208 - accuracy: 0.4879 - val_loss: 2.4666 - val_accuracy: 0.3905\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6099 - accuracy: 0.4823 - val_loss: 2.5044 - val_accuracy: 0.3863\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6287 - accuracy: 0.4817 - val_loss: 2.4745 - val_accuracy: 0.4002\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6113 - accuracy: 0.4930 - val_loss: 2.4496 - val_accuracy: 0.3929\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6080 - accuracy: 0.4885 - val_loss: 2.4531 - val_accuracy: 0.4069\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6167 - accuracy: 0.4847 - val_loss: 2.4568 - val_accuracy: 0.4057\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6376 - accuracy: 0.4723 - val_loss: 2.4239 - val_accuracy: 0.4136\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6185 - accuracy: 0.4880 - val_loss: 2.4837 - val_accuracy: 0.4033\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.6289 - accuracy: 0.4893 - val_loss: 2.4931 - val_accuracy: 0.3905\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6208 - accuracy: 0.4864 - val_loss: 2.4454 - val_accuracy: 0.4088\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6250 - accuracy: 0.4841 - val_loss: 2.4788 - val_accuracy: 0.3911\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6248 - accuracy: 0.4793 - val_loss: 2.4576 - val_accuracy: 0.4100\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6200 - accuracy: 0.4859 - val_loss: 2.4802 - val_accuracy: 0.3960\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.6044 - accuracy: 0.4908 - val_loss: 2.4722 - val_accuracy: 0.3887\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6194 - accuracy: 0.4838 - val_loss: 2.4675 - val_accuracy: 0.3929\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6030 - accuracy: 0.4845 - val_loss: 2.4707 - val_accuracy: 0.3844\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6243 - accuracy: 0.4730 - val_loss: 2.4693 - val_accuracy: 0.4057\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6259 - accuracy: 0.4823 - val_loss: 2.4926 - val_accuracy: 0.3942\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5990 - accuracy: 0.4832 - val_loss: 2.4979 - val_accuracy: 0.3942\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6080 - accuracy: 0.4830 - val_loss: 2.4836 - val_accuracy: 0.3996\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6165 - accuracy: 0.4903 - val_loss: 2.4822 - val_accuracy: 0.3905\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6306 - accuracy: 0.4868 - val_loss: 2.4894 - val_accuracy: 0.4057\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6073 - accuracy: 0.4880 - val_loss: 2.4791 - val_accuracy: 0.3984\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6076 - accuracy: 0.4854 - val_loss: 2.4761 - val_accuracy: 0.3936\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6084 - accuracy: 0.4760 - val_loss: 2.4721 - val_accuracy: 0.4063\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6139 - accuracy: 0.4834 - val_loss: 2.4988 - val_accuracy: 0.3923\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6039 - accuracy: 0.4798 - val_loss: 2.4700 - val_accuracy: 0.3923\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6006 - accuracy: 0.4883 - val_loss: 2.4783 - val_accuracy: 0.3948\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6005 - accuracy: 0.4951 - val_loss: 2.4899 - val_accuracy: 0.3972\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6058 - accuracy: 0.4865 - val_loss: 2.4885 - val_accuracy: 0.3850\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6150 - accuracy: 0.4872 - val_loss: 2.4870 - val_accuracy: 0.3990\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6052 - accuracy: 0.4868 - val_loss: 2.5083 - val_accuracy: 0.3899\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6175 - accuracy: 0.4794 - val_loss: 2.4806 - val_accuracy: 0.3905\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6254 - accuracy: 0.4795 - val_loss: 2.5011 - val_accuracy: 0.3887\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5885 - accuracy: 0.4880 - val_loss: 2.4948 - val_accuracy: 0.3881\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6185 - accuracy: 0.4821 - val_loss: 2.5083 - val_accuracy: 0.3796\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6163 - accuracy: 0.4840 - val_loss: 2.5070 - val_accuracy: 0.3844\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6116 - accuracy: 0.4869 - val_loss: 2.5281 - val_accuracy: 0.3869\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6128 - accuracy: 0.4874 - val_loss: 2.4861 - val_accuracy: 0.3954\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5898 - accuracy: 0.4872 - val_loss: 2.5026 - val_accuracy: 0.3954\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5958 - accuracy: 0.4842 - val_loss: 2.5062 - val_accuracy: 0.3978\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6030 - accuracy: 0.4817 - val_loss: 2.5162 - val_accuracy: 0.3881\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5896 - accuracy: 0.4931 - val_loss: 2.5176 - val_accuracy: 0.3856\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5920 - accuracy: 0.4910 - val_loss: 2.5153 - val_accuracy: 0.3875\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5947 - accuracy: 0.4961 - val_loss: 2.4900 - val_accuracy: 0.3905\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5768 - accuracy: 0.4999 - val_loss: 2.5019 - val_accuracy: 0.3808\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5857 - accuracy: 0.4891 - val_loss: 2.5180 - val_accuracy: 0.3917\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6017 - accuracy: 0.4835 - val_loss: 2.5136 - val_accuracy: 0.4002\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5812 - accuracy: 0.4850 - val_loss: 2.5260 - val_accuracy: 0.3753\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5845 - accuracy: 0.4895 - val_loss: 2.5181 - val_accuracy: 0.3765\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5882 - accuracy: 0.4906 - val_loss: 2.5353 - val_accuracy: 0.3814\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5911 - accuracy: 0.4863 - val_loss: 2.5291 - val_accuracy: 0.3674\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5791 - accuracy: 0.4969 - val_loss: 2.5201 - val_accuracy: 0.3777\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5619 - accuracy: 0.4940 - val_loss: 2.5348 - val_accuracy: 0.3759\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5669 - accuracy: 0.4975 - val_loss: 2.5374 - val_accuracy: 0.3832\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5541 - accuracy: 0.4956 - val_loss: 2.5072 - val_accuracy: 0.3899\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5916 - accuracy: 0.4948 - val_loss: 2.5048 - val_accuracy: 0.3954\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5830 - accuracy: 0.4973 - val_loss: 2.5140 - val_accuracy: 0.3960\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5902 - accuracy: 0.4877 - val_loss: 2.5228 - val_accuracy: 0.3917\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5845 - accuracy: 0.4950 - val_loss: 2.4797 - val_accuracy: 0.4100\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5907 - accuracy: 0.4929 - val_loss: 2.5307 - val_accuracy: 0.3814\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5753 - accuracy: 0.4982 - val_loss: 2.5311 - val_accuracy: 0.3747\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.5701 - accuracy: 0.5012 - val_loss: 2.4991 - val_accuracy: 0.3948\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5727 - accuracy: 0.4986 - val_loss: 2.5152 - val_accuracy: 0.3936\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5694 - accuracy: 0.4959 - val_loss: 2.5249 - val_accuracy: 0.3960\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.5826 - accuracy: 0.4870 - val_loss: 2.5164 - val_accuracy: 0.3826\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5729 - accuracy: 0.4939 - val_loss: 2.5219 - val_accuracy: 0.3808\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5804 - accuracy: 0.4973 - val_loss: 2.5113 - val_accuracy: 0.3905\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5731 - accuracy: 0.4988 - val_loss: 2.5161 - val_accuracy: 0.3960\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5786 - accuracy: 0.4879 - val_loss: 2.5173 - val_accuracy: 0.3869\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5666 - accuracy: 0.4925 - val_loss: 2.5584 - val_accuracy: 0.3741\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5792 - accuracy: 0.4969 - val_loss: 2.5258 - val_accuracy: 0.3832\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5742 - accuracy: 0.4969 - val_loss: 2.5194 - val_accuracy: 0.3899\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5826 - accuracy: 0.4983 - val_loss: 2.5305 - val_accuracy: 0.3759\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5645 - accuracy: 0.5109 - val_loss: 2.5119 - val_accuracy: 0.3826\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5516 - accuracy: 0.5031 - val_loss: 2.5581 - val_accuracy: 0.3668\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5807 - accuracy: 0.4958 - val_loss: 2.5087 - val_accuracy: 0.3929\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 0.5010 - val_loss: 2.5623 - val_accuracy: 0.3826\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5715 - accuracy: 0.4977 - val_loss: 2.5352 - val_accuracy: 0.3856\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5940 - accuracy: 0.4837 - val_loss: 2.5220 - val_accuracy: 0.3850\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.6004 - accuracy: 0.4855 - val_loss: 2.5432 - val_accuracy: 0.3729\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5655 - accuracy: 0.5012 - val_loss: 2.5357 - val_accuracy: 0.3747\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5790 - accuracy: 0.4911 - val_loss: 2.5325 - val_accuracy: 0.3838\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5490 - accuracy: 0.5049 - val_loss: 2.5482 - val_accuracy: 0.3741\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5641 - accuracy: 0.4919 - val_loss: 2.5257 - val_accuracy: 0.3856\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5635 - accuracy: 0.4976 - val_loss: 2.5534 - val_accuracy: 0.3796\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5552 - accuracy: 0.4906 - val_loss: 2.5278 - val_accuracy: 0.3996\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5825 - accuracy: 0.4941 - val_loss: 2.5280 - val_accuracy: 0.3844\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.5658 - accuracy: 0.4967 - val_loss: 2.5201 - val_accuracy: 0.3808\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5717 - accuracy: 0.4948 - val_loss: 2.5426 - val_accuracy: 0.3911\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5913 - accuracy: 0.4849 - val_loss: 2.5550 - val_accuracy: 0.3765\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5538 - accuracy: 0.5087 - val_loss: 2.5175 - val_accuracy: 0.3802\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5687 - accuracy: 0.4933 - val_loss: 2.5272 - val_accuracy: 0.3869\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5577 - accuracy: 0.4965 - val_loss: 2.5370 - val_accuracy: 0.3850\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5532 - accuracy: 0.5059 - val_loss: 2.5698 - val_accuracy: 0.3832\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5568 - accuracy: 0.5053 - val_loss: 2.5320 - val_accuracy: 0.3881\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5521 - accuracy: 0.4957 - val_loss: 2.5176 - val_accuracy: 0.4045\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5736 - accuracy: 0.4994 - val_loss: 2.5599 - val_accuracy: 0.3826\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5315 - accuracy: 0.5108 - val_loss: 2.5392 - val_accuracy: 0.3899\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5567 - accuracy: 0.5017 - val_loss: 2.5524 - val_accuracy: 0.3838\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5520 - accuracy: 0.4954 - val_loss: 2.5418 - val_accuracy: 0.3796\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5634 - accuracy: 0.4953 - val_loss: 2.5688 - val_accuracy: 0.3717\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5383 - accuracy: 0.5042 - val_loss: 2.5641 - val_accuracy: 0.3796\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5371 - accuracy: 0.5151 - val_loss: 2.5318 - val_accuracy: 0.3960\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 0.4939 - val_loss: 2.5478 - val_accuracy: 0.3826\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5350 - accuracy: 0.5165 - val_loss: 2.5631 - val_accuracy: 0.3820\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5655 - accuracy: 0.5003 - val_loss: 2.5277 - val_accuracy: 0.4015\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5473 - accuracy: 0.5032 - val_loss: 2.5540 - val_accuracy: 0.3899\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5586 - accuracy: 0.4970 - val_loss: 2.5553 - val_accuracy: 0.3765\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5560 - accuracy: 0.4994 - val_loss: 2.5665 - val_accuracy: 0.3759\n",
      "Epoch 388/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5429 - accuracy: 0.5024 - val_loss: 2.5434 - val_accuracy: 0.3863\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5632 - accuracy: 0.4947 - val_loss: 2.5694 - val_accuracy: 0.3783\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5327 - accuracy: 0.5102 - val_loss: 2.5914 - val_accuracy: 0.3698\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5269 - accuracy: 0.4990 - val_loss: 2.5750 - val_accuracy: 0.3656\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5509 - accuracy: 0.5035 - val_loss: 2.5394 - val_accuracy: 0.3875\n",
      "Epoch 393/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5443 - accuracy: 0.5039 - val_loss: 2.5391 - val_accuracy: 0.3875\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5584 - accuracy: 0.4990 - val_loss: 2.5461 - val_accuracy: 0.3765\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5431 - accuracy: 0.5016 - val_loss: 2.5875 - val_accuracy: 0.3759\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5500 - accuracy: 0.4983 - val_loss: 2.5581 - val_accuracy: 0.3783\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5388 - accuracy: 0.5024 - val_loss: 2.5775 - val_accuracy: 0.3717\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5511 - accuracy: 0.4945 - val_loss: 2.5540 - val_accuracy: 0.3838\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5553 - accuracy: 0.4996 - val_loss: 2.5868 - val_accuracy: 0.3771\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5486 - accuracy: 0.5065 - val_loss: 2.5645 - val_accuracy: 0.3796\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5573 - accuracy: 0.4980 - val_loss: 2.5667 - val_accuracy: 0.3771\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5440 - accuracy: 0.5131 - val_loss: 2.5661 - val_accuracy: 0.3777\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5626 - accuracy: 0.4917 - val_loss: 2.5605 - val_accuracy: 0.3893\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5301 - accuracy: 0.5037 - val_loss: 2.5964 - val_accuracy: 0.3893\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5522 - accuracy: 0.5030 - val_loss: 2.5642 - val_accuracy: 0.3838\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5450 - accuracy: 0.5086 - val_loss: 2.5859 - val_accuracy: 0.3759\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5633 - accuracy: 0.4913 - val_loss: 2.5580 - val_accuracy: 0.3814\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.5027 - val_loss: 2.5383 - val_accuracy: 0.3887\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5319 - accuracy: 0.5105 - val_loss: 2.5864 - val_accuracy: 0.3607\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5343 - accuracy: 0.5144 - val_loss: 2.5486 - val_accuracy: 0.3893\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5600 - accuracy: 0.5015 - val_loss: 2.5525 - val_accuracy: 0.3838\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5426 - accuracy: 0.5008 - val_loss: 2.5967 - val_accuracy: 0.3808\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5458 - accuracy: 0.4980 - val_loss: 2.5708 - val_accuracy: 0.3790\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5381 - accuracy: 0.4998 - val_loss: 2.5731 - val_accuracy: 0.3966\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5286 - accuracy: 0.5127 - val_loss: 2.6067 - val_accuracy: 0.3796\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5393 - accuracy: 0.5036 - val_loss: 2.5910 - val_accuracy: 0.3735\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5319 - accuracy: 0.5063 - val_loss: 2.5751 - val_accuracy: 0.3686\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5276 - accuracy: 0.4974 - val_loss: 2.5622 - val_accuracy: 0.3850\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5240 - accuracy: 0.4988 - val_loss: 2.5713 - val_accuracy: 0.3832\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5446 - accuracy: 0.4983 - val_loss: 2.5949 - val_accuracy: 0.3790\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5440 - accuracy: 0.4917 - val_loss: 2.5511 - val_accuracy: 0.3972\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5219 - accuracy: 0.5102 - val_loss: 2.5748 - val_accuracy: 0.3777\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5374 - accuracy: 0.5050 - val_loss: 2.6163 - val_accuracy: 0.3650\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5328 - accuracy: 0.5023 - val_loss: 2.5968 - val_accuracy: 0.3698\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5234 - accuracy: 0.5166 - val_loss: 2.5599 - val_accuracy: 0.3844\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5197 - accuracy: 0.5131 - val_loss: 2.5757 - val_accuracy: 0.3832\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5708 - accuracy: 0.4952 - val_loss: 2.5835 - val_accuracy: 0.3832\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5348 - accuracy: 0.5093 - val_loss: 2.5743 - val_accuracy: 0.3759\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5206 - accuracy: 0.5002 - val_loss: 2.5846 - val_accuracy: 0.3814\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5060 - accuracy: 0.5124 - val_loss: 2.5960 - val_accuracy: 0.3717\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5197 - accuracy: 0.5174 - val_loss: 2.5938 - val_accuracy: 0.3777\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5602 - accuracy: 0.5004 - val_loss: 2.5738 - val_accuracy: 0.3790\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5236 - accuracy: 0.5058 - val_loss: 2.5805 - val_accuracy: 0.3917\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5128 - accuracy: 0.5104 - val_loss: 2.6029 - val_accuracy: 0.3832\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5390 - accuracy: 0.5067 - val_loss: 2.5795 - val_accuracy: 0.3765\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5302 - accuracy: 0.5053 - val_loss: 2.5903 - val_accuracy: 0.3735\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5313 - accuracy: 0.5045 - val_loss: 2.5766 - val_accuracy: 0.3802\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5144 - accuracy: 0.5153 - val_loss: 2.6047 - val_accuracy: 0.3704\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5339 - accuracy: 0.5125 - val_loss: 2.5919 - val_accuracy: 0.3668\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5033 - accuracy: 0.5124 - val_loss: 2.6021 - val_accuracy: 0.3680\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5344 - accuracy: 0.5061 - val_loss: 2.5868 - val_accuracy: 0.3796\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5092 - accuracy: 0.5106 - val_loss: 2.5626 - val_accuracy: 0.3783\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5219 - accuracy: 0.5058 - val_loss: 2.5846 - val_accuracy: 0.3826\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5110 - accuracy: 0.5107 - val_loss: 2.6090 - val_accuracy: 0.3717\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5171 - accuracy: 0.5103 - val_loss: 2.5956 - val_accuracy: 0.3844\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5355 - accuracy: 0.4943 - val_loss: 2.5904 - val_accuracy: 0.3790\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 0.5174 - val_loss: 2.6092 - val_accuracy: 0.3783\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5172 - accuracy: 0.5033 - val_loss: 2.5725 - val_accuracy: 0.3753\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.5083 - accuracy: 0.5166 - val_loss: 2.6252 - val_accuracy: 0.3802\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5265 - accuracy: 0.5079 - val_loss: 2.5814 - val_accuracy: 0.3783\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5224 - accuracy: 0.5093 - val_loss: 2.5979 - val_accuracy: 0.3771\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5083 - accuracy: 0.5056 - val_loss: 2.6246 - val_accuracy: 0.3644\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5039 - accuracy: 0.5126 - val_loss: 2.6176 - val_accuracy: 0.3704\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4995 - accuracy: 0.5224 - val_loss: 2.5828 - val_accuracy: 0.3802\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5178 - accuracy: 0.5170 - val_loss: 2.6181 - val_accuracy: 0.3790\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5270 - accuracy: 0.5048 - val_loss: 2.5917 - val_accuracy: 0.3802\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5242 - accuracy: 0.5051 - val_loss: 2.6385 - val_accuracy: 0.3747\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5213 - accuracy: 0.5149 - val_loss: 2.6044 - val_accuracy: 0.3625\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5349 - accuracy: 0.5014 - val_loss: 2.6043 - val_accuracy: 0.3777\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4992 - accuracy: 0.5142 - val_loss: 2.6186 - val_accuracy: 0.3777\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5253 - accuracy: 0.5032 - val_loss: 2.6062 - val_accuracy: 0.3771\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5183 - accuracy: 0.5147 - val_loss: 2.6087 - val_accuracy: 0.3783\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5049 - accuracy: 0.5155 - val_loss: 2.5795 - val_accuracy: 0.3808\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5036 - accuracy: 0.5146 - val_loss: 2.6116 - val_accuracy: 0.3729\n",
      "Epoch 465/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5436 - accuracy: 0.5039 - val_loss: 2.5914 - val_accuracy: 0.3856\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5050 - accuracy: 0.5110 - val_loss: 2.6550 - val_accuracy: 0.3698\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5356 - accuracy: 0.5011 - val_loss: 2.5996 - val_accuracy: 0.3826\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4979 - accuracy: 0.5163 - val_loss: 2.5914 - val_accuracy: 0.3790\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5222 - accuracy: 0.5037 - val_loss: 2.6155 - val_accuracy: 0.3735\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 0.5127 - val_loss: 2.6032 - val_accuracy: 0.3808\n",
      "Epoch 471/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5149 - accuracy: 0.5073 - val_loss: 2.6203 - val_accuracy: 0.3710\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5136 - accuracy: 0.5042 - val_loss: 2.6158 - val_accuracy: 0.3771\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5080 - accuracy: 0.5171 - val_loss: 2.6217 - val_accuracy: 0.3662\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4997 - accuracy: 0.5147 - val_loss: 2.6191 - val_accuracy: 0.3662\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5062 - accuracy: 0.5116 - val_loss: 2.6225 - val_accuracy: 0.3759\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5036 - accuracy: 0.5107 - val_loss: 2.5998 - val_accuracy: 0.3747\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5111 - accuracy: 0.5023 - val_loss: 2.5943 - val_accuracy: 0.3826\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5117 - accuracy: 0.5144 - val_loss: 2.5980 - val_accuracy: 0.3692\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5283 - accuracy: 0.5061 - val_loss: 2.6263 - val_accuracy: 0.3723\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4951 - accuracy: 0.5134 - val_loss: 2.6353 - val_accuracy: 0.3625\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5044 - accuracy: 0.5111 - val_loss: 2.6116 - val_accuracy: 0.3790\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4990 - accuracy: 0.5212 - val_loss: 2.5978 - val_accuracy: 0.3863\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5074 - accuracy: 0.5069 - val_loss: 2.6086 - val_accuracy: 0.3796\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5126 - accuracy: 0.5153 - val_loss: 2.6486 - val_accuracy: 0.3656\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4977 - accuracy: 0.5118 - val_loss: 2.6322 - val_accuracy: 0.3644\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4941 - accuracy: 0.5091 - val_loss: 2.6296 - val_accuracy: 0.3674\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5077 - accuracy: 0.5080 - val_loss: 2.6239 - val_accuracy: 0.3662\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4962 - accuracy: 0.5050 - val_loss: 2.6232 - val_accuracy: 0.3692\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5311 - accuracy: 0.5075 - val_loss: 2.6254 - val_accuracy: 0.3741\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5180 - accuracy: 0.5140 - val_loss: 2.6390 - val_accuracy: 0.3650\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4843 - accuracy: 0.5168 - val_loss: 2.6127 - val_accuracy: 0.3814\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5146 - accuracy: 0.5022 - val_loss: 2.6401 - val_accuracy: 0.3759\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4709 - accuracy: 0.5206 - val_loss: 2.6097 - val_accuracy: 0.3741\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.5005 - accuracy: 0.5183 - val_loss: 2.6312 - val_accuracy: 0.3759\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4977 - accuracy: 0.5176 - val_loss: 2.6383 - val_accuracy: 0.3710\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5113 - accuracy: 0.5122 - val_loss: 2.6194 - val_accuracy: 0.3814\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5297 - accuracy: 0.5081 - val_loss: 2.6346 - val_accuracy: 0.3735\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5025 - accuracy: 0.5185 - val_loss: 2.6275 - val_accuracy: 0.3765\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4965 - accuracy: 0.5180 - val_loss: 2.6541 - val_accuracy: 0.3656\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4918 - accuracy: 0.5187 - val_loss: 2.6099 - val_accuracy: 0.3856\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4959 - accuracy: 0.5217 - val_loss: 2.6413 - val_accuracy: 0.3656\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.5193 - accuracy: 0.5210 - val_loss: 2.6638 - val_accuracy: 0.3741\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4811 - accuracy: 0.5195 - val_loss: 2.6482 - val_accuracy: 0.3759\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4991 - accuracy: 0.5133 - val_loss: 2.6689 - val_accuracy: 0.3704\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5046 - accuracy: 0.5114 - val_loss: 2.6433 - val_accuracy: 0.3759\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4829 - accuracy: 0.5107 - val_loss: 2.6490 - val_accuracy: 0.3796\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4975 - accuracy: 0.5138 - val_loss: 2.6493 - val_accuracy: 0.3771\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5109 - accuracy: 0.5164 - val_loss: 2.6542 - val_accuracy: 0.3692\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4759 - accuracy: 0.5147 - val_loss: 2.6267 - val_accuracy: 0.3783\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4799 - accuracy: 0.5190 - val_loss: 2.6245 - val_accuracy: 0.3729\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5051 - accuracy: 0.5110 - val_loss: 2.6361 - val_accuracy: 0.3765\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4991 - accuracy: 0.5131 - val_loss: 2.6250 - val_accuracy: 0.3820\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4943 - accuracy: 0.5173 - val_loss: 2.6594 - val_accuracy: 0.3692\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4957 - accuracy: 0.5090 - val_loss: 2.6563 - val_accuracy: 0.3698\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5184 - accuracy: 0.5051 - val_loss: 2.6819 - val_accuracy: 0.3723\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5090 - accuracy: 0.5078 - val_loss: 2.6381 - val_accuracy: 0.3674\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5310 - accuracy: 0.4973 - val_loss: 2.6238 - val_accuracy: 0.3808\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4792 - accuracy: 0.5165 - val_loss: 2.6379 - val_accuracy: 0.3759\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4818 - accuracy: 0.5190 - val_loss: 2.6450 - val_accuracy: 0.3577\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5164 - accuracy: 0.5112 - val_loss: 2.6298 - val_accuracy: 0.3796\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4952 - accuracy: 0.5152 - val_loss: 2.6461 - val_accuracy: 0.3741\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5114 - accuracy: 0.5074 - val_loss: 2.6645 - val_accuracy: 0.3662\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4815 - accuracy: 0.5189 - val_loss: 2.6438 - val_accuracy: 0.3783\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4938 - accuracy: 0.5124 - val_loss: 2.6257 - val_accuracy: 0.3771\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4912 - accuracy: 0.5206 - val_loss: 2.6366 - val_accuracy: 0.3741\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4976 - accuracy: 0.5243 - val_loss: 2.6520 - val_accuracy: 0.3583\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4815 - accuracy: 0.5225 - val_loss: 2.6398 - val_accuracy: 0.3832\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5012 - accuracy: 0.5091 - val_loss: 2.6572 - val_accuracy: 0.3753\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4827 - accuracy: 0.5209 - val_loss: 2.6587 - val_accuracy: 0.3759\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4826 - accuracy: 0.5184 - val_loss: 2.6709 - val_accuracy: 0.3644\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4962 - accuracy: 0.5094 - val_loss: 2.6593 - val_accuracy: 0.3656\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5069 - accuracy: 0.5063 - val_loss: 2.6679 - val_accuracy: 0.3735\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5033 - accuracy: 0.5151 - val_loss: 2.6269 - val_accuracy: 0.3753\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4936 - accuracy: 0.5221 - val_loss: 2.6561 - val_accuracy: 0.3717\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4831 - accuracy: 0.5226 - val_loss: 2.6457 - val_accuracy: 0.3802\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4910 - accuracy: 0.5142 - val_loss: 2.6513 - val_accuracy: 0.3808\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4755 - accuracy: 0.5103 - val_loss: 2.6714 - val_accuracy: 0.3729\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5013 - accuracy: 0.5110 - val_loss: 2.6578 - val_accuracy: 0.3698\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4834 - accuracy: 0.5229 - val_loss: 2.6666 - val_accuracy: 0.3692\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4926 - accuracy: 0.5133 - val_loss: 2.6385 - val_accuracy: 0.3747\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5057 - accuracy: 0.5210 - val_loss: 2.6744 - val_accuracy: 0.3717\n",
      "Epoch 542/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4919 - accuracy: 0.5114 - val_loss: 2.6964 - val_accuracy: 0.3692\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4936 - accuracy: 0.5109 - val_loss: 2.6442 - val_accuracy: 0.3771\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4775 - accuracy: 0.5185 - val_loss: 2.6585 - val_accuracy: 0.3717\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4875 - accuracy: 0.5205 - val_loss: 2.6644 - val_accuracy: 0.3735\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4847 - accuracy: 0.5136 - val_loss: 2.6676 - val_accuracy: 0.3686\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4899 - accuracy: 0.5149 - val_loss: 2.6751 - val_accuracy: 0.3704\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4939 - accuracy: 0.5114 - val_loss: 2.6734 - val_accuracy: 0.3625\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4968 - accuracy: 0.5236 - val_loss: 2.6471 - val_accuracy: 0.3771\n",
      "Epoch 550/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4884 - accuracy: 0.5126 - val_loss: 2.6508 - val_accuracy: 0.3777\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4925 - accuracy: 0.5164 - val_loss: 2.6760 - val_accuracy: 0.3668\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4798 - accuracy: 0.5112 - val_loss: 2.6689 - val_accuracy: 0.3759\n",
      "Epoch 553/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4937 - accuracy: 0.5077 - val_loss: 2.6509 - val_accuracy: 0.3790\n",
      "Epoch 554/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4873 - accuracy: 0.5180 - val_loss: 2.6441 - val_accuracy: 0.3723\n",
      "Epoch 555/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5043 - accuracy: 0.5183 - val_loss: 2.7033 - val_accuracy: 0.3625\n",
      "Epoch 556/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5037 - accuracy: 0.5027 - val_loss: 2.6636 - val_accuracy: 0.3637\n",
      "Epoch 557/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4595 - accuracy: 0.5219 - val_loss: 2.6670 - val_accuracy: 0.3680\n",
      "Epoch 558/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4892 - accuracy: 0.5103 - val_loss: 2.6807 - val_accuracy: 0.3698\n",
      "Epoch 559/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4892 - accuracy: 0.5206 - val_loss: 2.6647 - val_accuracy: 0.3710\n",
      "Epoch 560/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4831 - accuracy: 0.5141 - val_loss: 2.6629 - val_accuracy: 0.3826\n",
      "Epoch 561/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4959 - accuracy: 0.5165 - val_loss: 2.6942 - val_accuracy: 0.3765\n",
      "Epoch 562/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4804 - accuracy: 0.5221 - val_loss: 2.6888 - val_accuracy: 0.3723\n",
      "Epoch 563/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4846 - accuracy: 0.5123 - val_loss: 2.6917 - val_accuracy: 0.3601\n",
      "Epoch 564/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4821 - accuracy: 0.5269 - val_loss: 2.6730 - val_accuracy: 0.3735\n",
      "Epoch 565/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5064 - accuracy: 0.5081 - val_loss: 2.6522 - val_accuracy: 0.3765\n",
      "Epoch 566/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4637 - accuracy: 0.5331 - val_loss: 2.6836 - val_accuracy: 0.3692\n",
      "Epoch 567/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4683 - accuracy: 0.5238 - val_loss: 2.6956 - val_accuracy: 0.3625\n",
      "Epoch 568/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4889 - accuracy: 0.5228 - val_loss: 2.6674 - val_accuracy: 0.3601\n",
      "Epoch 569/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4859 - accuracy: 0.5212 - val_loss: 2.6872 - val_accuracy: 0.3668\n",
      "Epoch 570/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4821 - accuracy: 0.5149 - val_loss: 2.6695 - val_accuracy: 0.3717\n",
      "Epoch 571/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4842 - accuracy: 0.5223 - val_loss: 2.6749 - val_accuracy: 0.3735\n",
      "Epoch 572/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4756 - accuracy: 0.5329 - val_loss: 2.6605 - val_accuracy: 0.3698\n",
      "Epoch 573/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4783 - accuracy: 0.5207 - val_loss: 2.6867 - val_accuracy: 0.3777\n",
      "Epoch 574/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4912 - accuracy: 0.5240 - val_loss: 2.7055 - val_accuracy: 0.3589\n",
      "Epoch 575/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4697 - accuracy: 0.5195 - val_loss: 2.7040 - val_accuracy: 0.3662\n",
      "Epoch 576/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4771 - accuracy: 0.5155 - val_loss: 2.6974 - val_accuracy: 0.3637\n",
      "Epoch 577/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4811 - accuracy: 0.5100 - val_loss: 2.6749 - val_accuracy: 0.3686\n",
      "Epoch 578/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4730 - accuracy: 0.5190 - val_loss: 2.6882 - val_accuracy: 0.3644\n",
      "Epoch 579/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4732 - accuracy: 0.5245 - val_loss: 2.6832 - val_accuracy: 0.3704\n",
      "Epoch 580/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4952 - accuracy: 0.5106 - val_loss: 2.6775 - val_accuracy: 0.3704\n",
      "Epoch 581/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4884 - accuracy: 0.5055 - val_loss: 2.6677 - val_accuracy: 0.3717\n",
      "Epoch 582/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4729 - accuracy: 0.5180 - val_loss: 2.6664 - val_accuracy: 0.3765\n",
      "Epoch 583/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4847 - accuracy: 0.5235 - val_loss: 2.6720 - val_accuracy: 0.3747\n",
      "Epoch 584/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4870 - accuracy: 0.5247 - val_loss: 2.7103 - val_accuracy: 0.3680\n",
      "Epoch 585/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4735 - accuracy: 0.5165 - val_loss: 2.6639 - val_accuracy: 0.3790\n",
      "Epoch 586/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4851 - accuracy: 0.5105 - val_loss: 2.6603 - val_accuracy: 0.3723\n",
      "Epoch 587/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4793 - accuracy: 0.5098 - val_loss: 2.6903 - val_accuracy: 0.3692\n",
      "Epoch 588/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4709 - accuracy: 0.5220 - val_loss: 2.6988 - val_accuracy: 0.3686\n",
      "Epoch 589/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.5007 - accuracy: 0.5097 - val_loss: 2.6862 - val_accuracy: 0.3656\n",
      "Epoch 590/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4951 - accuracy: 0.5152 - val_loss: 2.6866 - val_accuracy: 0.3717\n",
      "Epoch 591/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4793 - accuracy: 0.5162 - val_loss: 2.6998 - val_accuracy: 0.3729\n",
      "Epoch 592/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4647 - accuracy: 0.5304 - val_loss: 2.6853 - val_accuracy: 0.3759\n",
      "Epoch 593/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4838 - accuracy: 0.5185 - val_loss: 2.6581 - val_accuracy: 0.3790\n",
      "Epoch 594/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4733 - accuracy: 0.5221 - val_loss: 2.7139 - val_accuracy: 0.3680\n",
      "Epoch 595/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4710 - accuracy: 0.5178 - val_loss: 2.7005 - val_accuracy: 0.3729\n",
      "Epoch 596/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4608 - accuracy: 0.5268 - val_loss: 2.6961 - val_accuracy: 0.3680\n",
      "Epoch 597/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4618 - accuracy: 0.5227 - val_loss: 2.7163 - val_accuracy: 0.3662\n",
      "Epoch 598/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4728 - accuracy: 0.5184 - val_loss: 2.6595 - val_accuracy: 0.3723\n",
      "Epoch 599/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4725 - accuracy: 0.5146 - val_loss: 2.6722 - val_accuracy: 0.3802\n",
      "Epoch 600/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4641 - accuracy: 0.5265 - val_loss: 2.6809 - val_accuracy: 0.3540\n",
      "Epoch 601/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4701 - accuracy: 0.5188 - val_loss: 2.7263 - val_accuracy: 0.3668\n",
      "Epoch 602/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4558 - accuracy: 0.5221 - val_loss: 2.6809 - val_accuracy: 0.3747\n",
      "Epoch 603/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4769 - accuracy: 0.5156 - val_loss: 2.6942 - val_accuracy: 0.3814\n",
      "Epoch 604/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4809 - accuracy: 0.5090 - val_loss: 2.7157 - val_accuracy: 0.3595\n",
      "Epoch 605/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4816 - accuracy: 0.5048 - val_loss: 2.6932 - val_accuracy: 0.3796\n",
      "Epoch 606/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4617 - accuracy: 0.5135 - val_loss: 2.6922 - val_accuracy: 0.3741\n",
      "Epoch 607/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4916 - accuracy: 0.5138 - val_loss: 2.6828 - val_accuracy: 0.3741\n",
      "Epoch 608/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4790 - accuracy: 0.5171 - val_loss: 2.7056 - val_accuracy: 0.3613\n",
      "Epoch 609/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4735 - accuracy: 0.5191 - val_loss: 2.6930 - val_accuracy: 0.3723\n",
      "Epoch 610/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4739 - accuracy: 0.5200 - val_loss: 2.6897 - val_accuracy: 0.3771\n",
      "Epoch 611/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4629 - accuracy: 0.5328 - val_loss: 2.7117 - val_accuracy: 0.3710\n",
      "Epoch 612/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4606 - accuracy: 0.5139 - val_loss: 2.7147 - val_accuracy: 0.3680\n",
      "Epoch 613/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4592 - accuracy: 0.5272 - val_loss: 2.7047 - val_accuracy: 0.3753\n",
      "Epoch 614/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4666 - accuracy: 0.5234 - val_loss: 2.7074 - val_accuracy: 0.3771\n",
      "Epoch 615/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4513 - accuracy: 0.5300 - val_loss: 2.7177 - val_accuracy: 0.3656\n",
      "Epoch 616/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4758 - accuracy: 0.5267 - val_loss: 2.6968 - val_accuracy: 0.3717\n",
      "Epoch 617/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4715 - accuracy: 0.5162 - val_loss: 2.7051 - val_accuracy: 0.3601\n",
      "Epoch 618/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4511 - accuracy: 0.5203 - val_loss: 2.7374 - val_accuracy: 0.3571\n",
      "Epoch 619/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4931 - accuracy: 0.5202 - val_loss: 2.7463 - val_accuracy: 0.3613\n",
      "Epoch 620/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4625 - accuracy: 0.5285 - val_loss: 2.7072 - val_accuracy: 0.3631\n",
      "Epoch 621/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4660 - accuracy: 0.5174 - val_loss: 2.7003 - val_accuracy: 0.3741\n",
      "Epoch 622/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4899 - accuracy: 0.5120 - val_loss: 2.7596 - val_accuracy: 0.3619\n",
      "Epoch 623/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4832 - accuracy: 0.5152 - val_loss: 2.7137 - val_accuracy: 0.3686\n",
      "Epoch 624/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4710 - accuracy: 0.5050 - val_loss: 2.7003 - val_accuracy: 0.3741\n",
      "Epoch 625/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4843 - accuracy: 0.5115 - val_loss: 2.6904 - val_accuracy: 0.3710\n",
      "Epoch 626/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4611 - accuracy: 0.5332 - val_loss: 2.7057 - val_accuracy: 0.3613\n",
      "Epoch 627/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4551 - accuracy: 0.5313 - val_loss: 2.7156 - val_accuracy: 0.3692\n",
      "Epoch 628/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4817 - accuracy: 0.5241 - val_loss: 2.7063 - val_accuracy: 0.3723\n",
      "Epoch 629/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4592 - accuracy: 0.5296 - val_loss: 2.6962 - val_accuracy: 0.3741\n",
      "Epoch 630/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4699 - accuracy: 0.5165 - val_loss: 2.7573 - val_accuracy: 0.3552\n",
      "Epoch 631/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4726 - accuracy: 0.5264 - val_loss: 2.7234 - val_accuracy: 0.3644\n",
      "Epoch 632/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4446 - accuracy: 0.5199 - val_loss: 2.7153 - val_accuracy: 0.3747\n",
      "Epoch 633/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4610 - accuracy: 0.5198 - val_loss: 2.6881 - val_accuracy: 0.3735\n",
      "Epoch 634/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4983 - accuracy: 0.5151 - val_loss: 2.7346 - val_accuracy: 0.3680\n",
      "Epoch 635/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4677 - accuracy: 0.5243 - val_loss: 2.6855 - val_accuracy: 0.3723\n",
      "Epoch 636/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4619 - accuracy: 0.5207 - val_loss: 2.7191 - val_accuracy: 0.3631\n",
      "Epoch 637/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4423 - accuracy: 0.5304 - val_loss: 2.7300 - val_accuracy: 0.3601\n",
      "Epoch 638/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4624 - accuracy: 0.5283 - val_loss: 2.7445 - val_accuracy: 0.3613\n",
      "Epoch 639/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4779 - accuracy: 0.5214 - val_loss: 2.6858 - val_accuracy: 0.3747\n",
      "Epoch 640/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4522 - accuracy: 0.5237 - val_loss: 2.7219 - val_accuracy: 0.3680\n",
      "Epoch 641/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4588 - accuracy: 0.5287 - val_loss: 2.7215 - val_accuracy: 0.3741\n",
      "Epoch 642/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4970 - accuracy: 0.5049 - val_loss: 2.7397 - val_accuracy: 0.3710\n",
      "Epoch 643/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4686 - accuracy: 0.5217 - val_loss: 2.7438 - val_accuracy: 0.3668\n",
      "Epoch 644/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4453 - accuracy: 0.5339 - val_loss: 2.6798 - val_accuracy: 0.3790\n",
      "Epoch 645/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4752 - accuracy: 0.5266 - val_loss: 2.7022 - val_accuracy: 0.3625\n",
      "Epoch 646/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4770 - accuracy: 0.5190 - val_loss: 2.7286 - val_accuracy: 0.3662\n",
      "Epoch 647/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4856 - accuracy: 0.5048 - val_loss: 2.7161 - val_accuracy: 0.3644\n",
      "Epoch 648/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4535 - accuracy: 0.5243 - val_loss: 2.7127 - val_accuracy: 0.3668\n",
      "Epoch 649/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4408 - accuracy: 0.5273 - val_loss: 2.7216 - val_accuracy: 0.3607\n",
      "Epoch 650/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4860 - accuracy: 0.5144 - val_loss: 2.7043 - val_accuracy: 0.3735\n",
      "Epoch 651/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4752 - accuracy: 0.5231 - val_loss: 2.6925 - val_accuracy: 0.3729\n",
      "Epoch 652/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4682 - accuracy: 0.5259 - val_loss: 2.7072 - val_accuracy: 0.3717\n",
      "Epoch 653/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4447 - accuracy: 0.5310 - val_loss: 2.7115 - val_accuracy: 0.3631\n",
      "Epoch 654/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4637 - accuracy: 0.5233 - val_loss: 2.7407 - val_accuracy: 0.3516\n",
      "Epoch 655/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4522 - accuracy: 0.5258 - val_loss: 2.7364 - val_accuracy: 0.3589\n",
      "Epoch 656/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4505 - accuracy: 0.5281 - val_loss: 2.7330 - val_accuracy: 0.3583\n",
      "Epoch 657/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4563 - accuracy: 0.5184 - val_loss: 2.7431 - val_accuracy: 0.3583\n",
      "Epoch 658/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4478 - accuracy: 0.5232 - val_loss: 2.7239 - val_accuracy: 0.3625\n",
      "Epoch 659/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4701 - accuracy: 0.5187 - val_loss: 2.7232 - val_accuracy: 0.3753\n",
      "Epoch 660/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4658 - accuracy: 0.5196 - val_loss: 2.6993 - val_accuracy: 0.3717\n",
      "Epoch 661/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4644 - accuracy: 0.5352 - val_loss: 2.7378 - val_accuracy: 0.3637\n",
      "Epoch 662/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4681 - accuracy: 0.5204 - val_loss: 2.7335 - val_accuracy: 0.3619\n",
      "Epoch 663/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4531 - accuracy: 0.5325 - val_loss: 2.7081 - val_accuracy: 0.3717\n",
      "Epoch 664/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4636 - accuracy: 0.5141 - val_loss: 2.6964 - val_accuracy: 0.3668\n",
      "Epoch 665/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4489 - accuracy: 0.5205 - val_loss: 2.7169 - val_accuracy: 0.3717\n",
      "Epoch 666/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4595 - accuracy: 0.5155 - val_loss: 2.7206 - val_accuracy: 0.3704\n",
      "Epoch 667/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4561 - accuracy: 0.5151 - val_loss: 2.7130 - val_accuracy: 0.3668\n",
      "Epoch 668/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4604 - accuracy: 0.5256 - val_loss: 2.7250 - val_accuracy: 0.3710\n",
      "Epoch 669/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4501 - accuracy: 0.5330 - val_loss: 2.7150 - val_accuracy: 0.3717\n",
      "Epoch 670/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4494 - accuracy: 0.5202 - val_loss: 2.7097 - val_accuracy: 0.3741\n",
      "Epoch 671/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4546 - accuracy: 0.5277 - val_loss: 2.7033 - val_accuracy: 0.3753\n",
      "Epoch 672/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4518 - accuracy: 0.5284 - val_loss: 2.7254 - val_accuracy: 0.3717\n",
      "Epoch 673/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4379 - accuracy: 0.5259 - val_loss: 2.7107 - val_accuracy: 0.3704\n",
      "Epoch 674/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4512 - accuracy: 0.5253 - val_loss: 2.7136 - val_accuracy: 0.3729\n",
      "Epoch 675/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4424 - accuracy: 0.5338 - val_loss: 2.7076 - val_accuracy: 0.3759\n",
      "Epoch 676/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4574 - accuracy: 0.5214 - val_loss: 2.7414 - val_accuracy: 0.3644\n",
      "Epoch 677/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4672 - accuracy: 0.5192 - val_loss: 2.7166 - val_accuracy: 0.3637\n",
      "Epoch 678/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4596 - accuracy: 0.5193 - val_loss: 2.7348 - val_accuracy: 0.3625\n",
      "Epoch 679/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4662 - accuracy: 0.5167 - val_loss: 2.7663 - val_accuracy: 0.3571\n",
      "Epoch 680/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4462 - accuracy: 0.5347 - val_loss: 2.7124 - val_accuracy: 0.3692\n",
      "Epoch 681/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4469 - accuracy: 0.5252 - val_loss: 2.7390 - val_accuracy: 0.3583\n",
      "Epoch 682/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4638 - accuracy: 0.5171 - val_loss: 2.7527 - val_accuracy: 0.3741\n",
      "Epoch 683/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4695 - accuracy: 0.5256 - val_loss: 2.7407 - val_accuracy: 0.3698\n",
      "Epoch 684/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4487 - accuracy: 0.5289 - val_loss: 2.7532 - val_accuracy: 0.3680\n",
      "Epoch 685/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4570 - accuracy: 0.5185 - val_loss: 2.7321 - val_accuracy: 0.3692\n",
      "Epoch 686/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4629 - accuracy: 0.5283 - val_loss: 2.7358 - val_accuracy: 0.3650\n",
      "Epoch 687/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4483 - accuracy: 0.5316 - val_loss: 2.7595 - val_accuracy: 0.3528\n",
      "Epoch 688/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4447 - accuracy: 0.5226 - val_loss: 2.7544 - val_accuracy: 0.3650\n",
      "Epoch 689/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4427 - accuracy: 0.5316 - val_loss: 2.7064 - val_accuracy: 0.3747\n",
      "Epoch 690/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4488 - accuracy: 0.5257 - val_loss: 2.7197 - val_accuracy: 0.3710\n",
      "Epoch 691/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4747 - accuracy: 0.5183 - val_loss: 2.7395 - val_accuracy: 0.3729\n",
      "Epoch 692/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4593 - accuracy: 0.5265 - val_loss: 2.7535 - val_accuracy: 0.3674\n",
      "Epoch 693/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4369 - accuracy: 0.5300 - val_loss: 2.7270 - val_accuracy: 0.3710\n",
      "Epoch 694/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4496 - accuracy: 0.5240 - val_loss: 2.7323 - val_accuracy: 0.3698\n",
      "Epoch 695/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4461 - accuracy: 0.5334 - val_loss: 2.7389 - val_accuracy: 0.3668\n",
      "Epoch 696/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4426 - accuracy: 0.5301 - val_loss: 2.7235 - val_accuracy: 0.3698\n",
      "Epoch 697/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4427 - accuracy: 0.5317 - val_loss: 2.7640 - val_accuracy: 0.3552\n",
      "Epoch 698/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4506 - accuracy: 0.5196 - val_loss: 2.7071 - val_accuracy: 0.3759\n",
      "Epoch 699/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4469 - accuracy: 0.5254 - val_loss: 2.8022 - val_accuracy: 0.3625\n",
      "Epoch 700/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4483 - accuracy: 0.5286 - val_loss: 2.7457 - val_accuracy: 0.3674\n",
      "Epoch 701/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4431 - accuracy: 0.5256 - val_loss: 2.7260 - val_accuracy: 0.3662\n",
      "Epoch 702/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4288 - accuracy: 0.5334 - val_loss: 2.7396 - val_accuracy: 0.3759\n",
      "Epoch 703/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4509 - accuracy: 0.5215 - val_loss: 2.7281 - val_accuracy: 0.3710\n",
      "Epoch 704/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4365 - accuracy: 0.5349 - val_loss: 2.7479 - val_accuracy: 0.3686\n",
      "Epoch 705/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4416 - accuracy: 0.5341 - val_loss: 2.7834 - val_accuracy: 0.3613\n",
      "Epoch 706/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4628 - accuracy: 0.5222 - val_loss: 2.7502 - val_accuracy: 0.3674\n",
      "Epoch 707/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4344 - accuracy: 0.5328 - val_loss: 2.7534 - val_accuracy: 0.3631\n",
      "Epoch 708/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4384 - accuracy: 0.5277 - val_loss: 2.7954 - val_accuracy: 0.3607\n",
      "Epoch 709/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4445 - accuracy: 0.5263 - val_loss: 2.7580 - val_accuracy: 0.3759\n",
      "Epoch 710/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4248 - accuracy: 0.5305 - val_loss: 2.7814 - val_accuracy: 0.3577\n",
      "Epoch 711/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4367 - accuracy: 0.5271 - val_loss: 2.7385 - val_accuracy: 0.3680\n",
      "Epoch 712/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4541 - accuracy: 0.5267 - val_loss: 2.7802 - val_accuracy: 0.3558\n",
      "Epoch 713/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4358 - accuracy: 0.5275 - val_loss: 2.7341 - val_accuracy: 0.3656\n",
      "Epoch 714/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4306 - accuracy: 0.5288 - val_loss: 2.7551 - val_accuracy: 0.3680\n",
      "Epoch 715/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4394 - accuracy: 0.5333 - val_loss: 2.7437 - val_accuracy: 0.3747\n",
      "Epoch 716/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4385 - accuracy: 0.5257 - val_loss: 2.7646 - val_accuracy: 0.3613\n",
      "Epoch 717/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.5262 - val_loss: 2.7343 - val_accuracy: 0.3668\n",
      "Epoch 718/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4346 - accuracy: 0.5241 - val_loss: 2.7241 - val_accuracy: 0.3741\n",
      "Epoch 719/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.5354 - val_loss: 2.7357 - val_accuracy: 0.3686\n",
      "Epoch 720/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4450 - accuracy: 0.5275 - val_loss: 2.7445 - val_accuracy: 0.3692\n",
      "Epoch 721/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4452 - accuracy: 0.5249 - val_loss: 2.7663 - val_accuracy: 0.3485\n",
      "Epoch 722/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4373 - accuracy: 0.5299 - val_loss: 2.7797 - val_accuracy: 0.3595\n",
      "Epoch 723/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4519 - accuracy: 0.5221 - val_loss: 2.7482 - val_accuracy: 0.3680\n",
      "Epoch 724/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4472 - accuracy: 0.5345 - val_loss: 2.7785 - val_accuracy: 0.3504\n",
      "Epoch 725/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4356 - accuracy: 0.5225 - val_loss: 2.7618 - val_accuracy: 0.3631\n",
      "Epoch 726/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4468 - accuracy: 0.5306 - val_loss: 2.7359 - val_accuracy: 0.3717\n",
      "Epoch 727/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4681 - accuracy: 0.5211 - val_loss: 2.7454 - val_accuracy: 0.3668\n",
      "Epoch 728/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4324 - accuracy: 0.5368 - val_loss: 2.7477 - val_accuracy: 0.3613\n",
      "Epoch 729/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4400 - accuracy: 0.5365 - val_loss: 2.7810 - val_accuracy: 0.3686\n",
      "Epoch 730/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4343 - accuracy: 0.5286 - val_loss: 2.7884 - val_accuracy: 0.3589\n",
      "Epoch 731/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4343 - accuracy: 0.5347 - val_loss: 2.7476 - val_accuracy: 0.3631\n",
      "Epoch 732/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4501 - accuracy: 0.5217 - val_loss: 2.7527 - val_accuracy: 0.3710\n",
      "Epoch 733/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4664 - accuracy: 0.5218 - val_loss: 2.7689 - val_accuracy: 0.3729\n",
      "Epoch 734/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4573 - accuracy: 0.5135 - val_loss: 2.7533 - val_accuracy: 0.3619\n",
      "Epoch 735/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4361 - accuracy: 0.5338 - val_loss: 2.7687 - val_accuracy: 0.3540\n",
      "Epoch 736/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4379 - accuracy: 0.5317 - val_loss: 2.7579 - val_accuracy: 0.3656\n",
      "Epoch 737/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4495 - accuracy: 0.5277 - val_loss: 2.7610 - val_accuracy: 0.3656\n",
      "Epoch 738/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4467 - accuracy: 0.5288 - val_loss: 2.7414 - val_accuracy: 0.3753\n",
      "Epoch 739/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4315 - accuracy: 0.5229 - val_loss: 2.7678 - val_accuracy: 0.3644\n",
      "Epoch 740/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4610 - accuracy: 0.5268 - val_loss: 2.7724 - val_accuracy: 0.3668\n",
      "Epoch 741/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4467 - accuracy: 0.5260 - val_loss: 2.8061 - val_accuracy: 0.3625\n",
      "Epoch 742/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4550 - accuracy: 0.5276 - val_loss: 2.7427 - val_accuracy: 0.3692\n",
      "Epoch 743/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4416 - accuracy: 0.5281 - val_loss: 2.7369 - val_accuracy: 0.3680\n",
      "Epoch 744/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4547 - accuracy: 0.5135 - val_loss: 2.7540 - val_accuracy: 0.3637\n",
      "Epoch 745/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4397 - accuracy: 0.5232 - val_loss: 2.7399 - val_accuracy: 0.3662\n",
      "Epoch 746/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4651 - accuracy: 0.5232 - val_loss: 2.7751 - val_accuracy: 0.3595\n",
      "Epoch 747/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4690 - accuracy: 0.5191 - val_loss: 2.7698 - val_accuracy: 0.3637\n",
      "Epoch 748/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4384 - accuracy: 0.5226 - val_loss: 2.8125 - val_accuracy: 0.3546\n",
      "Epoch 749/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4495 - accuracy: 0.5297 - val_loss: 2.7552 - val_accuracy: 0.3735\n",
      "Epoch 750/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4501 - accuracy: 0.5264 - val_loss: 2.7674 - val_accuracy: 0.3552\n",
      "Epoch 751/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4572 - accuracy: 0.5202 - val_loss: 2.7792 - val_accuracy: 0.3589\n",
      "Epoch 752/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4349 - accuracy: 0.5300 - val_loss: 2.7787 - val_accuracy: 0.3552\n",
      "Epoch 753/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4299 - accuracy: 0.5358 - val_loss: 2.7672 - val_accuracy: 0.3741\n",
      "Epoch 754/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4439 - accuracy: 0.5280 - val_loss: 2.7986 - val_accuracy: 0.3662\n",
      "Epoch 755/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4426 - accuracy: 0.5229 - val_loss: 2.7782 - val_accuracy: 0.3589\n",
      "Epoch 756/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4468 - accuracy: 0.5272 - val_loss: 2.8005 - val_accuracy: 0.3498\n",
      "Epoch 757/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4275 - accuracy: 0.5360 - val_loss: 2.7846 - val_accuracy: 0.3619\n",
      "Epoch 758/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4334 - accuracy: 0.5362 - val_loss: 2.7434 - val_accuracy: 0.3729\n",
      "Epoch 759/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4396 - accuracy: 0.5221 - val_loss: 2.7498 - val_accuracy: 0.3717\n",
      "Epoch 760/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4381 - accuracy: 0.5261 - val_loss: 2.7615 - val_accuracy: 0.3613\n",
      "Epoch 761/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4626 - accuracy: 0.5178 - val_loss: 2.7631 - val_accuracy: 0.3729\n",
      "Epoch 762/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4319 - accuracy: 0.5315 - val_loss: 2.7988 - val_accuracy: 0.3668\n",
      "Epoch 763/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.5334 - val_loss: 2.7774 - val_accuracy: 0.3644\n",
      "Epoch 764/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4249 - accuracy: 0.5339 - val_loss: 2.7836 - val_accuracy: 0.3571\n",
      "Epoch 765/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4208 - accuracy: 0.5370 - val_loss: 2.7673 - val_accuracy: 0.3589\n",
      "Epoch 766/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4356 - accuracy: 0.5283 - val_loss: 2.7742 - val_accuracy: 0.3644\n",
      "Epoch 767/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4393 - accuracy: 0.5267 - val_loss: 2.7758 - val_accuracy: 0.3637\n",
      "Epoch 768/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4195 - accuracy: 0.5386 - val_loss: 2.7772 - val_accuracy: 0.3674\n",
      "Epoch 769/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4315 - accuracy: 0.5273 - val_loss: 2.7583 - val_accuracy: 0.3723\n",
      "Epoch 770/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4552 - accuracy: 0.5249 - val_loss: 2.7721 - val_accuracy: 0.3571\n",
      "Epoch 771/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4304 - accuracy: 0.5308 - val_loss: 2.7899 - val_accuracy: 0.3534\n",
      "Epoch 772/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4268 - accuracy: 0.5367 - val_loss: 2.7721 - val_accuracy: 0.3607\n",
      "Epoch 773/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4132 - accuracy: 0.5324 - val_loss: 2.7445 - val_accuracy: 0.3674\n",
      "Epoch 774/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4375 - accuracy: 0.5270 - val_loss: 2.7501 - val_accuracy: 0.3589\n",
      "Epoch 775/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4401 - accuracy: 0.5295 - val_loss: 2.7968 - val_accuracy: 0.3644\n",
      "Epoch 776/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4436 - accuracy: 0.5235 - val_loss: 2.7964 - val_accuracy: 0.3662\n",
      "Epoch 777/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4224 - accuracy: 0.5275 - val_loss: 2.7572 - val_accuracy: 0.3741\n",
      "Epoch 778/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4322 - accuracy: 0.5232 - val_loss: 2.7811 - val_accuracy: 0.3613\n",
      "Epoch 779/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4265 - accuracy: 0.5301 - val_loss: 2.7576 - val_accuracy: 0.3625\n",
      "Epoch 780/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4466 - accuracy: 0.5301 - val_loss: 2.7714 - val_accuracy: 0.3723\n",
      "Epoch 781/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4231 - accuracy: 0.5273 - val_loss: 2.7922 - val_accuracy: 0.3607\n",
      "Epoch 782/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4315 - accuracy: 0.5275 - val_loss: 2.7780 - val_accuracy: 0.3668\n",
      "Epoch 783/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4242 - accuracy: 0.5342 - val_loss: 2.7998 - val_accuracy: 0.3637\n",
      "Epoch 784/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4224 - accuracy: 0.5312 - val_loss: 2.7863 - val_accuracy: 0.3698\n",
      "Epoch 785/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4183 - accuracy: 0.5340 - val_loss: 2.7955 - val_accuracy: 0.3607\n",
      "Epoch 786/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4313 - accuracy: 0.5247 - val_loss: 2.7769 - val_accuracy: 0.3637\n",
      "Epoch 787/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4210 - accuracy: 0.5329 - val_loss: 2.7892 - val_accuracy: 0.3637\n",
      "Epoch 788/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.4383 - accuracy: 0.5338 - val_loss: 2.7955 - val_accuracy: 0.3552\n",
      "Epoch 789/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4051 - accuracy: 0.5379 - val_loss: 2.7694 - val_accuracy: 0.3704\n",
      "Epoch 790/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4207 - accuracy: 0.5375 - val_loss: 2.7887 - val_accuracy: 0.3637\n",
      "Epoch 791/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4216 - accuracy: 0.5395 - val_loss: 2.7808 - val_accuracy: 0.3650\n",
      "Epoch 792/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4227 - accuracy: 0.5370 - val_loss: 2.7703 - val_accuracy: 0.3631\n",
      "Epoch 793/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4348 - accuracy: 0.5273 - val_loss: 2.7473 - val_accuracy: 0.3686\n",
      "Epoch 794/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4363 - accuracy: 0.5352 - val_loss: 2.7702 - val_accuracy: 0.3546\n",
      "Epoch 795/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4296 - accuracy: 0.5339 - val_loss: 2.7839 - val_accuracy: 0.3710\n",
      "Epoch 796/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4368 - accuracy: 0.5347 - val_loss: 2.8290 - val_accuracy: 0.3485\n",
      "Epoch 797/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4234 - accuracy: 0.5310 - val_loss: 2.7816 - val_accuracy: 0.3698\n",
      "Epoch 798/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4394 - accuracy: 0.5312 - val_loss: 2.7994 - val_accuracy: 0.3698\n",
      "Epoch 799/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4308 - accuracy: 0.5373 - val_loss: 2.7693 - val_accuracy: 0.3619\n",
      "Epoch 800/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4257 - accuracy: 0.5331 - val_loss: 2.7751 - val_accuracy: 0.3577\n",
      "Epoch 801/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4285 - accuracy: 0.5266 - val_loss: 2.7530 - val_accuracy: 0.3662\n",
      "Epoch 802/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4211 - accuracy: 0.5270 - val_loss: 2.7672 - val_accuracy: 0.3619\n",
      "Epoch 803/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4437 - accuracy: 0.5174 - val_loss: 2.7391 - val_accuracy: 0.3783\n",
      "Epoch 804/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4537 - accuracy: 0.5192 - val_loss: 2.8085 - val_accuracy: 0.3625\n",
      "Epoch 805/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4112 - accuracy: 0.5362 - val_loss: 2.7839 - val_accuracy: 0.3644\n",
      "Epoch 806/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4482 - accuracy: 0.5239 - val_loss: 2.7968 - val_accuracy: 0.3686\n",
      "Epoch 807/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4301 - accuracy: 0.5289 - val_loss: 2.7926 - val_accuracy: 0.3631\n",
      "Epoch 808/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4411 - accuracy: 0.5201 - val_loss: 2.7956 - val_accuracy: 0.3631\n",
      "Epoch 809/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4164 - accuracy: 0.5420 - val_loss: 2.8090 - val_accuracy: 0.3656\n",
      "Epoch 810/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4251 - accuracy: 0.5318 - val_loss: 2.7691 - val_accuracy: 0.3680\n",
      "Epoch 811/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4452 - accuracy: 0.5283 - val_loss: 2.8048 - val_accuracy: 0.3656\n",
      "Epoch 812/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4239 - accuracy: 0.5342 - val_loss: 2.7631 - val_accuracy: 0.3735\n",
      "Epoch 813/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4270 - accuracy: 0.5370 - val_loss: 2.8109 - val_accuracy: 0.3595\n",
      "Epoch 814/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4294 - accuracy: 0.5237 - val_loss: 2.8366 - val_accuracy: 0.3564\n",
      "Epoch 815/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4132 - accuracy: 0.5407 - val_loss: 2.7377 - val_accuracy: 0.3704\n",
      "Epoch 816/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4394 - accuracy: 0.5302 - val_loss: 2.7779 - val_accuracy: 0.3662\n",
      "Epoch 817/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4332 - accuracy: 0.5314 - val_loss: 2.7695 - val_accuracy: 0.3625\n",
      "Epoch 818/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4394 - accuracy: 0.5227 - val_loss: 2.8199 - val_accuracy: 0.3564\n",
      "Epoch 819/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4378 - accuracy: 0.5293 - val_loss: 2.8025 - val_accuracy: 0.3540\n",
      "Epoch 820/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4430 - accuracy: 0.5196 - val_loss: 2.8043 - val_accuracy: 0.3583\n",
      "Epoch 821/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4359 - accuracy: 0.5341 - val_loss: 2.7633 - val_accuracy: 0.3741\n",
      "Epoch 822/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4306 - accuracy: 0.5374 - val_loss: 2.8086 - val_accuracy: 0.3583\n",
      "Epoch 823/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4291 - accuracy: 0.5320 - val_loss: 2.7754 - val_accuracy: 0.3656\n",
      "Epoch 824/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4215 - accuracy: 0.5307 - val_loss: 2.8100 - val_accuracy: 0.3564\n",
      "Epoch 825/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4316 - accuracy: 0.5257 - val_loss: 2.7910 - val_accuracy: 0.3686\n",
      "Epoch 826/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4235 - accuracy: 0.5407 - val_loss: 2.8022 - val_accuracy: 0.3595\n",
      "Epoch 827/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4243 - accuracy: 0.5316 - val_loss: 2.8139 - val_accuracy: 0.3607\n",
      "Epoch 828/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4238 - accuracy: 0.5376 - val_loss: 2.7953 - val_accuracy: 0.3686\n",
      "Epoch 829/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4438 - accuracy: 0.5273 - val_loss: 2.7989 - val_accuracy: 0.3607\n",
      "Epoch 830/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4031 - accuracy: 0.5438 - val_loss: 2.7869 - val_accuracy: 0.3571\n",
      "Epoch 831/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4403 - accuracy: 0.5250 - val_loss: 2.8026 - val_accuracy: 0.3564\n",
      "Epoch 832/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4137 - accuracy: 0.5350 - val_loss: 2.7975 - val_accuracy: 0.3723\n",
      "Epoch 833/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4295 - accuracy: 0.5219 - val_loss: 2.7874 - val_accuracy: 0.3613\n",
      "Epoch 834/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4189 - accuracy: 0.5278 - val_loss: 2.7852 - val_accuracy: 0.3650\n",
      "Epoch 835/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4136 - accuracy: 0.5416 - val_loss: 2.8005 - val_accuracy: 0.3644\n",
      "Epoch 836/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4188 - accuracy: 0.5293 - val_loss: 2.7887 - val_accuracy: 0.3723\n",
      "Epoch 837/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4407 - accuracy: 0.5200 - val_loss: 2.8242 - val_accuracy: 0.3589\n",
      "Epoch 838/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4234 - accuracy: 0.5309 - val_loss: 2.8206 - val_accuracy: 0.3583\n",
      "Epoch 839/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4033 - accuracy: 0.5310 - val_loss: 2.7608 - val_accuracy: 0.3698\n",
      "Epoch 840/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4268 - accuracy: 0.5221 - val_loss: 2.7635 - val_accuracy: 0.3644\n",
      "Epoch 841/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4179 - accuracy: 0.5336 - val_loss: 2.7997 - val_accuracy: 0.3668\n",
      "Epoch 842/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4176 - accuracy: 0.5351 - val_loss: 2.8591 - val_accuracy: 0.3516\n",
      "Epoch 843/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4082 - accuracy: 0.5381 - val_loss: 2.8116 - val_accuracy: 0.3607\n",
      "Epoch 844/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4153 - accuracy: 0.5224 - val_loss: 2.8026 - val_accuracy: 0.3607\n",
      "Epoch 845/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4407 - accuracy: 0.5243 - val_loss: 2.7955 - val_accuracy: 0.3613\n",
      "Epoch 846/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4100 - accuracy: 0.5277 - val_loss: 2.8000 - val_accuracy: 0.3723\n",
      "Epoch 847/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4125 - accuracy: 0.5254 - val_loss: 2.8226 - val_accuracy: 0.3522\n",
      "Epoch 848/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4280 - accuracy: 0.5293 - val_loss: 2.7854 - val_accuracy: 0.3625\n",
      "Epoch 849/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.5411 - val_loss: 2.8214 - val_accuracy: 0.3522\n",
      "Epoch 850/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3978 - accuracy: 0.5292 - val_loss: 2.7888 - val_accuracy: 0.3589\n",
      "Epoch 851/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4242 - accuracy: 0.5301 - val_loss: 2.8172 - val_accuracy: 0.3571\n",
      "Epoch 852/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4116 - accuracy: 0.5434 - val_loss: 2.8143 - val_accuracy: 0.3552\n",
      "Epoch 853/1000\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 1.4321 - accuracy: 0.5345 - val_loss: 2.8228 - val_accuracy: 0.3613\n",
      "Epoch 854/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4218 - accuracy: 0.5347 - val_loss: 2.7986 - val_accuracy: 0.3698\n",
      "Epoch 855/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4217 - accuracy: 0.5409 - val_loss: 2.7849 - val_accuracy: 0.3607\n",
      "Epoch 856/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4278 - accuracy: 0.5339 - val_loss: 2.8224 - val_accuracy: 0.3619\n",
      "Epoch 857/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4271 - accuracy: 0.5388 - val_loss: 2.8126 - val_accuracy: 0.3625\n",
      "Epoch 858/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4240 - accuracy: 0.5364 - val_loss: 2.8027 - val_accuracy: 0.3662\n",
      "Epoch 859/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4302 - accuracy: 0.5390 - val_loss: 2.8263 - val_accuracy: 0.3577\n",
      "Epoch 860/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4162 - accuracy: 0.5237 - val_loss: 2.8007 - val_accuracy: 0.3558\n",
      "Epoch 861/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4201 - accuracy: 0.5344 - val_loss: 2.8150 - val_accuracy: 0.3644\n",
      "Epoch 862/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4011 - accuracy: 0.5321 - val_loss: 2.7947 - val_accuracy: 0.3583\n",
      "Epoch 863/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4198 - accuracy: 0.5293 - val_loss: 2.7941 - val_accuracy: 0.3631\n",
      "Epoch 864/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4020 - accuracy: 0.5473 - val_loss: 2.7795 - val_accuracy: 0.3613\n",
      "Epoch 865/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4362 - accuracy: 0.5263 - val_loss: 2.7896 - val_accuracy: 0.3607\n",
      "Epoch 866/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4111 - accuracy: 0.5348 - val_loss: 2.7958 - val_accuracy: 0.3631\n",
      "Epoch 867/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4251 - accuracy: 0.5276 - val_loss: 2.8072 - val_accuracy: 0.3680\n",
      "Epoch 868/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4357 - accuracy: 0.5265 - val_loss: 2.8091 - val_accuracy: 0.3662\n",
      "Epoch 869/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4071 - accuracy: 0.5398 - val_loss: 2.7997 - val_accuracy: 0.3650\n",
      "Epoch 870/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.5379 - val_loss: 2.7707 - val_accuracy: 0.3680\n",
      "Epoch 871/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4191 - accuracy: 0.5301 - val_loss: 2.7937 - val_accuracy: 0.3686\n",
      "Epoch 872/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4294 - accuracy: 0.5152 - val_loss: 2.8269 - val_accuracy: 0.3546\n",
      "Epoch 873/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4297 - accuracy: 0.5327 - val_loss: 2.8138 - val_accuracy: 0.3637\n",
      "Epoch 874/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4307 - accuracy: 0.5295 - val_loss: 2.8113 - val_accuracy: 0.3546\n",
      "Epoch 875/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4061 - accuracy: 0.5420 - val_loss: 2.7703 - val_accuracy: 0.3601\n",
      "Epoch 876/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4307 - accuracy: 0.5346 - val_loss: 2.7992 - val_accuracy: 0.3631\n",
      "Epoch 877/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4259 - accuracy: 0.5315 - val_loss: 2.8041 - val_accuracy: 0.3552\n",
      "Epoch 878/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3944 - accuracy: 0.5389 - val_loss: 2.8011 - val_accuracy: 0.3619\n",
      "Epoch 879/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4180 - accuracy: 0.5291 - val_loss: 2.8137 - val_accuracy: 0.3601\n",
      "Epoch 880/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3943 - accuracy: 0.5453 - val_loss: 2.7805 - val_accuracy: 0.3668\n",
      "Epoch 881/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4200 - accuracy: 0.5265 - val_loss: 2.8248 - val_accuracy: 0.3595\n",
      "Epoch 882/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4239 - accuracy: 0.5281 - val_loss: 2.8185 - val_accuracy: 0.3571\n",
      "Epoch 883/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4092 - accuracy: 0.5391 - val_loss: 2.7949 - val_accuracy: 0.3601\n",
      "Epoch 884/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4206 - accuracy: 0.5282 - val_loss: 2.8258 - val_accuracy: 0.3552\n",
      "Epoch 885/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4283 - accuracy: 0.5250 - val_loss: 2.8130 - val_accuracy: 0.3637\n",
      "Epoch 886/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4115 - accuracy: 0.5340 - val_loss: 2.8257 - val_accuracy: 0.3644\n",
      "Epoch 887/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4163 - accuracy: 0.5406 - val_loss: 2.8259 - val_accuracy: 0.3595\n",
      "Epoch 888/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4134 - accuracy: 0.5412 - val_loss: 2.8125 - val_accuracy: 0.3674\n",
      "Epoch 889/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4118 - accuracy: 0.5424 - val_loss: 2.8375 - val_accuracy: 0.3571\n",
      "Epoch 890/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4236 - accuracy: 0.5246 - val_loss: 2.8362 - val_accuracy: 0.3540\n",
      "Epoch 891/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4069 - accuracy: 0.5312 - val_loss: 2.8482 - val_accuracy: 0.3534\n",
      "Epoch 892/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4259 - accuracy: 0.5276 - val_loss: 2.8214 - val_accuracy: 0.3637\n",
      "Epoch 893/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4100 - accuracy: 0.5352 - val_loss: 2.8041 - val_accuracy: 0.3607\n",
      "Epoch 894/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4169 - accuracy: 0.5316 - val_loss: 2.8361 - val_accuracy: 0.3577\n",
      "Epoch 895/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4097 - accuracy: 0.5325 - val_loss: 2.8729 - val_accuracy: 0.3522\n",
      "Epoch 896/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.5335 - val_loss: 2.8580 - val_accuracy: 0.3491\n",
      "Epoch 897/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4034 - accuracy: 0.5325 - val_loss: 2.8263 - val_accuracy: 0.3552\n",
      "Epoch 898/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4105 - accuracy: 0.5375 - val_loss: 2.8359 - val_accuracy: 0.3552\n",
      "Epoch 899/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.4232 - accuracy: 0.5271 - val_loss: 2.8185 - val_accuracy: 0.3601\n",
      "Epoch 900/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4195 - accuracy: 0.5229 - val_loss: 2.8383 - val_accuracy: 0.3583\n",
      "Epoch 901/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4172 - accuracy: 0.5211 - val_loss: 2.8411 - val_accuracy: 0.3558\n",
      "Epoch 902/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4163 - accuracy: 0.5297 - val_loss: 2.8353 - val_accuracy: 0.3625\n",
      "Epoch 903/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4087 - accuracy: 0.5268 - val_loss: 2.8576 - val_accuracy: 0.3479\n",
      "Epoch 904/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3967 - accuracy: 0.5318 - val_loss: 2.8379 - val_accuracy: 0.3528\n",
      "Epoch 905/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4153 - accuracy: 0.5331 - val_loss: 2.8309 - val_accuracy: 0.3637\n",
      "Epoch 906/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4007 - accuracy: 0.5471 - val_loss: 2.8509 - val_accuracy: 0.3662\n",
      "Epoch 907/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3968 - accuracy: 0.5429 - val_loss: 2.8179 - val_accuracy: 0.3625\n",
      "Epoch 908/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4237 - accuracy: 0.5248 - val_loss: 2.8542 - val_accuracy: 0.3564\n",
      "Epoch 909/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.5304 - val_loss: 2.8582 - val_accuracy: 0.3467\n",
      "Epoch 910/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4065 - accuracy: 0.5330 - val_loss: 2.8138 - val_accuracy: 0.3674\n",
      "Epoch 911/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4094 - accuracy: 0.5378 - val_loss: 2.8170 - val_accuracy: 0.3528\n",
      "Epoch 912/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.5289 - val_loss: 2.8291 - val_accuracy: 0.3571\n",
      "Epoch 913/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4253 - accuracy: 0.5335 - val_loss: 2.8521 - val_accuracy: 0.3498\n",
      "Epoch 914/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3871 - accuracy: 0.5477 - val_loss: 2.8255 - val_accuracy: 0.3577\n",
      "Epoch 915/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4173 - accuracy: 0.5336 - val_loss: 2.8497 - val_accuracy: 0.3552\n",
      "Epoch 916/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4152 - accuracy: 0.5386 - val_loss: 2.8459 - val_accuracy: 0.3583\n",
      "Epoch 917/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4046 - accuracy: 0.5412 - val_loss: 2.8242 - val_accuracy: 0.3644\n",
      "Epoch 918/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4180 - accuracy: 0.5298 - val_loss: 2.8347 - val_accuracy: 0.3625\n",
      "Epoch 919/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3943 - accuracy: 0.5334 - val_loss: 2.8402 - val_accuracy: 0.3528\n",
      "Epoch 920/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4041 - accuracy: 0.5396 - val_loss: 2.8491 - val_accuracy: 0.3431\n",
      "Epoch 921/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4243 - accuracy: 0.5425 - val_loss: 2.8608 - val_accuracy: 0.3571\n",
      "Epoch 922/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4043 - accuracy: 0.5354 - val_loss: 2.8614 - val_accuracy: 0.3479\n",
      "Epoch 923/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4100 - accuracy: 0.5446 - val_loss: 2.8171 - val_accuracy: 0.3583\n",
      "Epoch 924/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4149 - accuracy: 0.5259 - val_loss: 2.8280 - val_accuracy: 0.3595\n",
      "Epoch 925/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4173 - accuracy: 0.5372 - val_loss: 2.8555 - val_accuracy: 0.3558\n",
      "Epoch 926/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4035 - accuracy: 0.5364 - val_loss: 2.8422 - val_accuracy: 0.3650\n",
      "Epoch 927/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4165 - accuracy: 0.5337 - val_loss: 2.8318 - val_accuracy: 0.3650\n",
      "Epoch 928/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4268 - accuracy: 0.5345 - val_loss: 2.8501 - val_accuracy: 0.3546\n",
      "Epoch 929/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4058 - accuracy: 0.5288 - val_loss: 2.8101 - val_accuracy: 0.3601\n",
      "Epoch 930/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3971 - accuracy: 0.5462 - val_loss: 2.8286 - val_accuracy: 0.3589\n",
      "Epoch 931/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4060 - accuracy: 0.5383 - val_loss: 2.8255 - val_accuracy: 0.3595\n",
      "Epoch 932/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4155 - accuracy: 0.5241 - val_loss: 2.8517 - val_accuracy: 0.3668\n",
      "Epoch 933/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4083 - accuracy: 0.5351 - val_loss: 2.8332 - val_accuracy: 0.3668\n",
      "Epoch 934/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4135 - accuracy: 0.5274 - val_loss: 2.8260 - val_accuracy: 0.3631\n",
      "Epoch 935/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3936 - accuracy: 0.5307 - val_loss: 2.8250 - val_accuracy: 0.3601\n",
      "Epoch 936/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4023 - accuracy: 0.5421 - val_loss: 2.8168 - val_accuracy: 0.3656\n",
      "Epoch 937/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4086 - accuracy: 0.5393 - val_loss: 2.8575 - val_accuracy: 0.3491\n",
      "Epoch 938/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4017 - accuracy: 0.5393 - val_loss: 2.8482 - val_accuracy: 0.3577\n",
      "Epoch 939/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4187 - accuracy: 0.5312 - val_loss: 2.8707 - val_accuracy: 0.3692\n",
      "Epoch 940/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4079 - accuracy: 0.5267 - val_loss: 2.8373 - val_accuracy: 0.3558\n",
      "Epoch 941/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4071 - accuracy: 0.5393 - val_loss: 2.8508 - val_accuracy: 0.3540\n",
      "Epoch 942/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4090 - accuracy: 0.5332 - val_loss: 2.8471 - val_accuracy: 0.3504\n",
      "Epoch 943/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4361 - accuracy: 0.5330 - val_loss: 2.8524 - val_accuracy: 0.3589\n",
      "Epoch 944/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3941 - accuracy: 0.5308 - val_loss: 2.8230 - val_accuracy: 0.3528\n",
      "Epoch 945/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4013 - accuracy: 0.5275 - val_loss: 2.8790 - val_accuracy: 0.3558\n",
      "Epoch 946/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4164 - accuracy: 0.5339 - val_loss: 2.8402 - val_accuracy: 0.3504\n",
      "Epoch 947/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4296 - accuracy: 0.5296 - val_loss: 2.8285 - val_accuracy: 0.3692\n",
      "Epoch 948/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4015 - accuracy: 0.5275 - val_loss: 2.8365 - val_accuracy: 0.3540\n",
      "Epoch 949/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4237 - accuracy: 0.5282 - val_loss: 2.7999 - val_accuracy: 0.3735\n",
      "Epoch 950/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4097 - accuracy: 0.5310 - val_loss: 2.8586 - val_accuracy: 0.3540\n",
      "Epoch 951/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4008 - accuracy: 0.5347 - val_loss: 2.8694 - val_accuracy: 0.3595\n",
      "Epoch 952/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4016 - accuracy: 0.5396 - val_loss: 2.7943 - val_accuracy: 0.3668\n",
      "Epoch 953/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4195 - accuracy: 0.5252 - val_loss: 2.8565 - val_accuracy: 0.3595\n",
      "Epoch 954/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4255 - accuracy: 0.5303 - val_loss: 2.8160 - val_accuracy: 0.3613\n",
      "Epoch 955/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.5436 - val_loss: 2.8360 - val_accuracy: 0.3631\n",
      "Epoch 956/1000\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 1.3924 - accuracy: 0.5502 - val_loss: 2.8339 - val_accuracy: 0.3668\n",
      "Epoch 957/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4036 - accuracy: 0.5299 - val_loss: 2.8286 - val_accuracy: 0.3558\n",
      "Epoch 958/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4080 - accuracy: 0.5319 - val_loss: 2.8603 - val_accuracy: 0.3668\n",
      "Epoch 959/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3945 - accuracy: 0.5504 - val_loss: 2.8560 - val_accuracy: 0.3607\n",
      "Epoch 960/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4040 - accuracy: 0.5306 - val_loss: 2.8441 - val_accuracy: 0.3656\n",
      "Epoch 961/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4060 - accuracy: 0.5356 - val_loss: 2.8704 - val_accuracy: 0.3577\n",
      "Epoch 962/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4209 - accuracy: 0.5309 - val_loss: 2.8506 - val_accuracy: 0.3637\n",
      "Epoch 963/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4004 - accuracy: 0.5359 - val_loss: 2.8488 - val_accuracy: 0.3680\n",
      "Epoch 964/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.5304 - val_loss: 2.9031 - val_accuracy: 0.3412\n",
      "Epoch 965/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4163 - accuracy: 0.5299 - val_loss: 2.8175 - val_accuracy: 0.3595\n",
      "Epoch 966/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4276 - accuracy: 0.5260 - val_loss: 2.8537 - val_accuracy: 0.3601\n",
      "Epoch 967/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4148 - accuracy: 0.5332 - val_loss: 2.8425 - val_accuracy: 0.3528\n",
      "Epoch 968/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4095 - accuracy: 0.5328 - val_loss: 2.8929 - val_accuracy: 0.3546\n",
      "Epoch 969/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3902 - accuracy: 0.5451 - val_loss: 2.8568 - val_accuracy: 0.3601\n",
      "Epoch 970/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4225 - accuracy: 0.5247 - val_loss: 2.8546 - val_accuracy: 0.3650\n",
      "Epoch 971/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4074 - accuracy: 0.5304 - val_loss: 2.8720 - val_accuracy: 0.3625\n",
      "Epoch 972/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3974 - accuracy: 0.5407 - val_loss: 2.8736 - val_accuracy: 0.3479\n",
      "Epoch 973/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.5505 - val_loss: 2.8318 - val_accuracy: 0.3619\n",
      "Epoch 974/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4044 - accuracy: 0.5337 - val_loss: 2.8550 - val_accuracy: 0.3564\n",
      "Epoch 975/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4101 - accuracy: 0.5362 - val_loss: 2.8885 - val_accuracy: 0.3564\n",
      "Epoch 976/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4180 - accuracy: 0.5239 - val_loss: 2.8686 - val_accuracy: 0.3607\n",
      "Epoch 977/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4186 - accuracy: 0.5353 - val_loss: 2.8382 - val_accuracy: 0.3589\n",
      "Epoch 978/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4106 - accuracy: 0.5357 - val_loss: 2.8703 - val_accuracy: 0.3577\n",
      "Epoch 979/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4034 - accuracy: 0.5419 - val_loss: 2.8855 - val_accuracy: 0.3546\n",
      "Epoch 980/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4146 - accuracy: 0.5214 - val_loss: 2.8804 - val_accuracy: 0.3583\n",
      "Epoch 981/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4047 - accuracy: 0.5359 - val_loss: 2.8280 - val_accuracy: 0.3637\n",
      "Epoch 982/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4005 - accuracy: 0.5356 - val_loss: 2.8666 - val_accuracy: 0.3571\n",
      "Epoch 983/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4157 - accuracy: 0.5330 - val_loss: 2.8877 - val_accuracy: 0.3571\n",
      "Epoch 984/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3943 - accuracy: 0.5394 - val_loss: 2.8881 - val_accuracy: 0.3589\n",
      "Epoch 985/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4319 - accuracy: 0.5284 - val_loss: 2.8553 - val_accuracy: 0.3571\n",
      "Epoch 986/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3969 - accuracy: 0.5446 - val_loss: 2.8659 - val_accuracy: 0.3619\n",
      "Epoch 987/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4046 - accuracy: 0.5394 - val_loss: 2.8441 - val_accuracy: 0.3558\n",
      "Epoch 988/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4190 - accuracy: 0.5270 - val_loss: 2.8489 - val_accuracy: 0.3601\n",
      "Epoch 989/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4206 - accuracy: 0.5317 - val_loss: 2.8658 - val_accuracy: 0.3498\n",
      "Epoch 990/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3989 - accuracy: 0.5422 - val_loss: 2.8383 - val_accuracy: 0.3607\n",
      "Epoch 991/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4053 - accuracy: 0.5384 - val_loss: 2.8655 - val_accuracy: 0.3534\n",
      "Epoch 992/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4083 - accuracy: 0.5316 - val_loss: 2.8366 - val_accuracy: 0.3522\n",
      "Epoch 993/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4035 - accuracy: 0.5408 - val_loss: 2.8621 - val_accuracy: 0.3613\n",
      "Epoch 994/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4000 - accuracy: 0.5353 - val_loss: 2.8548 - val_accuracy: 0.3522\n",
      "Epoch 995/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3817 - accuracy: 0.5393 - val_loss: 2.8548 - val_accuracy: 0.3546\n",
      "Epoch 996/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3988 - accuracy: 0.5433 - val_loss: 2.8695 - val_accuracy: 0.3485\n",
      "Epoch 997/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.5375 - val_loss: 2.8578 - val_accuracy: 0.3601\n",
      "Epoch 998/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4042 - accuracy: 0.5384 - val_loss: 2.8898 - val_accuracy: 0.3528\n",
      "Epoch 999/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.4118 - accuracy: 0.5262 - val_loss: 2.8670 - val_accuracy: 0.3516\n",
      "Epoch 1000/1000\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.3904 - accuracy: 0.5463 - val_loss: 2.8330 - val_accuracy: 0.3650\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model (batch size 16)\n",
    "history_emb_simple = Emb_model_simple.fit(x_emb_train, y_emb_train,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=16,\n",
    "                                 validation_data=(x_emb_test, y_emb_test)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file_emb_simple = \"many_to_many_LSTM_Emb_baseline_model.h5\"  \n",
    "Emb_model_simple.save(model_file_emb_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_Emb_baseline_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_simple.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print metrics\n",
    "def print_metrics(history):\n",
    "    val_accuracy_per_epoch = history.history['val_accuracy']\n",
    "    train_accuracy_per_epoch = history.history['accuracy']\n",
    "    train_loss_per_epoch = history.history['loss']\n",
    "    val_loss_per_epoch = history.history['val_loss']\n",
    "\n",
    "    best_epoch_val_accuracy = val_accuracy_per_epoch.index(max(val_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_accuracy = train_accuracy_per_epoch.index(max(train_accuracy_per_epoch)) + 1\n",
    "    best_epoch_train_loss = train_loss_per_epoch.index(min(train_loss_per_epoch)) + 1\n",
    "    best_epoch_val_loss = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "\n",
    "    print(f\"Best Epoch for Validation Accuracy: {best_epoch_val_accuracy} (Val Accuracy: {max(val_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Accuracy: {best_epoch_train_accuracy} (Train Accuracy: {max(train_accuracy_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Training Loss: {best_epoch_train_loss} (Train Loss: {min(train_loss_per_epoch)})\")\n",
    "    print(f\"Best Epoch for Validation Loss: {best_epoch_val_loss} (Val Loss: {min(val_loss_per_epoch)})\")\n",
    "    print(\"\\nOverall Best Performance Metrics:\")\n",
    "    print(f\"Maximum Validation Accuracy: {max(val_accuracy_per_epoch)}\")\n",
    "    print(f\"Maximum Training Accuracy: {max(train_accuracy_per_epoch)}\")\n",
    "    print(f\"Minimum Training Loss: {min(train_loss_per_epoch)}\")\n",
    "    print(f\"Minimum Validation Loss: {min(val_loss_per_epoch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 112 (Val Accuracy: 0.4513382017612457)\n",
      "Best Epoch for Training Accuracy: 959 (Train Accuracy: 0.5409063100814819)\n",
      "Best Epoch for Training Loss: 993 (Train Loss: 1.4032548666000366)\n",
      "Best Epoch for Validation Loss: 60 (Val Loss: 2.2048439979553223)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.4513382017612457\n",
      "Maximum Training Accuracy: 0.5409063100814819\n",
      "Minimum Training Loss: 1.4032548666000366\n",
      "Minimum Validation Loss: 2.2048439979553223\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_simple, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     barrel_turn       0.00      0.00      0.00        36\n",
      "    basic_closed       0.63      0.45      0.53       143\n",
      "      basic_open       0.00      0.00      0.00        18\n",
      "           break       0.22      0.08      0.12       106\n",
      "       come_back       0.03      0.02      0.03        81\n",
      "        corridor       0.00      0.00      0.00        11\n",
      " frankie´s_sixes       0.17      0.02      0.04        41\n",
      "     groove_walk       0.00      0.00      0.00        10\n",
      "hallelujah_rocks       0.00      0.00      0.00         4\n",
      "    hand_to_hand       0.00      0.00      0.00         8\n",
      "     inside_spin       0.00      0.00      0.00         4\n",
      "     inside_turn       0.00      0.00      0.00        35\n",
      "    lindy_circle       0.00      0.00      0.00         4\n",
      "    outside_spin       0.00      0.00      0.00        40\n",
      "    outside_turn       0.00      0.00      0.00        24\n",
      "         pass_by       0.46      0.71      0.56       650\n",
      "        pop_turn       0.00      0.00      0.00         1\n",
      "       promenade       0.00      0.00      0.00        12\n",
      "          s_turn       0.00      0.00      0.00         4\n",
      "    sailor_kicks       0.00      0.00      0.00         4\n",
      "        send_out       0.00      0.00      0.00        16\n",
      "      sling_shot       0.00      0.00      0.00         8\n",
      "      sugar_push       0.08      0.03      0.04        64\n",
      "      sweetheart       0.12      0.02      0.03        54\n",
      "        swingout       0.21      0.21      0.21       163\n",
      "        switches       0.00      0.00      0.00         4\n",
      "          tandem       0.00      0.00      0.00         5\n",
      "       tuck_turn       0.28      0.27      0.27        94\n",
      "\n",
      "        accuracy                           0.36      1644\n",
      "       macro avg       0.08      0.07      0.07      1644\n",
      "    weighted avg       0.30      0.36      0.32      1644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict classes on the test set\n",
    "yy_pred = Emb_model_simple.predict(x_emb_test)\n",
    "\n",
    "# Convert predictions from one-hot encoded back to label indices\n",
    "yy_pred_classes = np.argmax(yy_pred, axis=-1)\n",
    "yy_true_classes = np.argmax(y_emb_test, axis=-1)\n",
    "\n",
    "# Convert numeric classes to actual labels\n",
    "yy_pred_labels = [class_labels[i] for i in yy_pred_classes.flatten()]\n",
    "yy_true_labels = [class_labels[i] for i in yy_true_classes.flatten()]\n",
    "\n",
    "# Generate a confusion matrix\n",
    "#conf_matrix = confusion_matrix(yy_true_classes.flatten(), yy_pred_classes.flatten())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "class_report = classification_report(yy_true_labels, yy_pred_labels, zero_division=0)\n",
    "print(class_report)\n",
    "\n",
    "# Write the string to a text file\n",
    "with open('LSTM_classifier_report_baseline-LSTM-embedding-layer.txt', 'w') as file:\n",
    "    file.write(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3957 - accuracy: 0.5363 - val_loss: 2.8607 - val_accuracy: 0.3619\n",
      "Epoch 2/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4053 - accuracy: 0.5318 - val_loss: 2.8754 - val_accuracy: 0.3534\n",
      "Epoch 3/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3981 - accuracy: 0.5443 - val_loss: 2.8518 - val_accuracy: 0.3656\n",
      "Epoch 4/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3960 - accuracy: 0.5371 - val_loss: 2.8636 - val_accuracy: 0.3601\n",
      "Epoch 5/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3961 - accuracy: 0.5366 - val_loss: 2.8700 - val_accuracy: 0.3601\n",
      "Epoch 6/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3891 - accuracy: 0.5351 - val_loss: 2.8749 - val_accuracy: 0.3583\n",
      "Epoch 7/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3947 - accuracy: 0.5376 - val_loss: 2.8745 - val_accuracy: 0.3589\n",
      "Epoch 8/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.5348 - val_loss: 2.8555 - val_accuracy: 0.3674\n",
      "Epoch 9/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3904 - accuracy: 0.5382 - val_loss: 2.8656 - val_accuracy: 0.3540\n",
      "Epoch 10/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3914 - accuracy: 0.5467 - val_loss: 2.8707 - val_accuracy: 0.3577\n",
      "Epoch 11/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3884 - accuracy: 0.5391 - val_loss: 2.8634 - val_accuracy: 0.3571\n",
      "Epoch 12/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3945 - accuracy: 0.5374 - val_loss: 2.8704 - val_accuracy: 0.3601\n",
      "Epoch 13/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3901 - accuracy: 0.5377 - val_loss: 2.8794 - val_accuracy: 0.3558\n",
      "Epoch 14/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3940 - accuracy: 0.5351 - val_loss: 2.8518 - val_accuracy: 0.3644\n",
      "Epoch 15/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3907 - accuracy: 0.5398 - val_loss: 2.8626 - val_accuracy: 0.3564\n",
      "Epoch 16/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3924 - accuracy: 0.5405 - val_loss: 2.8773 - val_accuracy: 0.3564\n",
      "Epoch 17/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3923 - accuracy: 0.5382 - val_loss: 2.8709 - val_accuracy: 0.3595\n",
      "Epoch 18/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3955 - accuracy: 0.5344 - val_loss: 2.8634 - val_accuracy: 0.3625\n",
      "Epoch 19/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3974 - accuracy: 0.5385 - val_loss: 2.8907 - val_accuracy: 0.3607\n",
      "Epoch 20/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3903 - accuracy: 0.5370 - val_loss: 2.8614 - val_accuracy: 0.3631\n",
      "Epoch 21/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.5354 - val_loss: 2.9131 - val_accuracy: 0.3504\n",
      "Epoch 22/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3925 - accuracy: 0.5398 - val_loss: 2.8653 - val_accuracy: 0.3546\n",
      "Epoch 23/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3982 - accuracy: 0.5366 - val_loss: 2.8706 - val_accuracy: 0.3589\n",
      "Epoch 24/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3982 - accuracy: 0.5366 - val_loss: 2.8855 - val_accuracy: 0.3601\n",
      "Epoch 25/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3917 - accuracy: 0.5376 - val_loss: 2.8761 - val_accuracy: 0.3625\n",
      "Epoch 26/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3969 - accuracy: 0.5380 - val_loss: 2.8844 - val_accuracy: 0.3613\n",
      "Epoch 27/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.5359 - val_loss: 2.8863 - val_accuracy: 0.3571\n",
      "Epoch 28/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3983 - accuracy: 0.5360 - val_loss: 2.8619 - val_accuracy: 0.3571\n",
      "Epoch 29/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3940 - accuracy: 0.5400 - val_loss: 2.8830 - val_accuracy: 0.3528\n",
      "Epoch 30/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3942 - accuracy: 0.5359 - val_loss: 2.8634 - val_accuracy: 0.3522\n",
      "Epoch 31/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3975 - accuracy: 0.5348 - val_loss: 2.9015 - val_accuracy: 0.3522\n",
      "Epoch 32/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3996 - accuracy: 0.5368 - val_loss: 2.8838 - val_accuracy: 0.3613\n",
      "Epoch 33/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3919 - accuracy: 0.5417 - val_loss: 2.8887 - val_accuracy: 0.3619\n",
      "Epoch 34/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3963 - accuracy: 0.5389 - val_loss: 2.8684 - val_accuracy: 0.3583\n",
      "Epoch 35/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4032 - accuracy: 0.5386 - val_loss: 2.8566 - val_accuracy: 0.3674\n",
      "Epoch 36/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3960 - accuracy: 0.5377 - val_loss: 2.8787 - val_accuracy: 0.3619\n",
      "Epoch 37/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3894 - accuracy: 0.5388 - val_loss: 2.8540 - val_accuracy: 0.3619\n",
      "Epoch 38/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3996 - accuracy: 0.5377 - val_loss: 2.8888 - val_accuracy: 0.3558\n",
      "Epoch 39/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3964 - accuracy: 0.5426 - val_loss: 2.8683 - val_accuracy: 0.3577\n",
      "Epoch 40/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3966 - accuracy: 0.5373 - val_loss: 2.8974 - val_accuracy: 0.3522\n",
      "Epoch 41/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3933 - accuracy: 0.5351 - val_loss: 2.8789 - val_accuracy: 0.3589\n",
      "Epoch 42/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3972 - accuracy: 0.5385 - val_loss: 2.8959 - val_accuracy: 0.3564\n",
      "Epoch 43/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4023 - accuracy: 0.5335 - val_loss: 2.8807 - val_accuracy: 0.3583\n",
      "Epoch 44/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.5392 - val_loss: 2.8831 - val_accuracy: 0.3577\n",
      "Epoch 45/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3982 - accuracy: 0.5357 - val_loss: 2.8796 - val_accuracy: 0.3583\n",
      "Epoch 46/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4020 - accuracy: 0.5342 - val_loss: 2.8593 - val_accuracy: 0.3540\n",
      "Epoch 47/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3946 - accuracy: 0.5383 - val_loss: 2.9020 - val_accuracy: 0.3558\n",
      "Epoch 48/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3955 - accuracy: 0.5350 - val_loss: 2.8767 - val_accuracy: 0.3504\n",
      "Epoch 49/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3942 - accuracy: 0.5347 - val_loss: 2.8765 - val_accuracy: 0.3595\n",
      "Epoch 50/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3958 - accuracy: 0.5345 - val_loss: 2.8887 - val_accuracy: 0.3571\n",
      "Epoch 51/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4001 - accuracy: 0.5363 - val_loss: 2.8899 - val_accuracy: 0.3656\n",
      "Epoch 52/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3944 - accuracy: 0.5408 - val_loss: 2.8859 - val_accuracy: 0.3571\n",
      "Epoch 53/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3884 - accuracy: 0.5347 - val_loss: 2.8919 - val_accuracy: 0.3564\n",
      "Epoch 54/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3958 - accuracy: 0.5313 - val_loss: 2.8925 - val_accuracy: 0.3595\n",
      "Epoch 55/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3979 - accuracy: 0.5376 - val_loss: 2.8928 - val_accuracy: 0.3607\n",
      "Epoch 56/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3905 - accuracy: 0.5389 - val_loss: 2.8981 - val_accuracy: 0.3552\n",
      "Epoch 57/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4008 - accuracy: 0.5354 - val_loss: 2.8986 - val_accuracy: 0.3516\n",
      "Epoch 58/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3957 - accuracy: 0.5338 - val_loss: 2.8909 - val_accuracy: 0.3577\n",
      "Epoch 59/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3873 - accuracy: 0.5373 - val_loss: 2.8709 - val_accuracy: 0.3637\n",
      "Epoch 60/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5397 - val_loss: 2.8455 - val_accuracy: 0.3644\n",
      "Epoch 61/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3960 - accuracy: 0.5368 - val_loss: 2.9054 - val_accuracy: 0.3601\n",
      "Epoch 62/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3929 - accuracy: 0.5342 - val_loss: 2.8712 - val_accuracy: 0.3516\n",
      "Epoch 63/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3970 - accuracy: 0.5415 - val_loss: 2.8920 - val_accuracy: 0.3595\n",
      "Epoch 64/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.5385 - val_loss: 2.8923 - val_accuracy: 0.3650\n",
      "Epoch 65/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3848 - accuracy: 0.5353 - val_loss: 2.8915 - val_accuracy: 0.3644\n",
      "Epoch 66/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3944 - accuracy: 0.5430 - val_loss: 2.8799 - val_accuracy: 0.3577\n",
      "Epoch 67/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3985 - accuracy: 0.5350 - val_loss: 2.8894 - val_accuracy: 0.3564\n",
      "Epoch 68/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3953 - accuracy: 0.5379 - val_loss: 2.8532 - val_accuracy: 0.3625\n",
      "Epoch 69/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3954 - accuracy: 0.5332 - val_loss: 2.8436 - val_accuracy: 0.3759\n",
      "Epoch 70/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3954 - accuracy: 0.5365 - val_loss: 2.8770 - val_accuracy: 0.3613\n",
      "Epoch 71/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3927 - accuracy: 0.5366 - val_loss: 2.8709 - val_accuracy: 0.3625\n",
      "Epoch 72/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3917 - accuracy: 0.5388 - val_loss: 2.8730 - val_accuracy: 0.3589\n",
      "Epoch 73/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3980 - accuracy: 0.5338 - val_loss: 2.9045 - val_accuracy: 0.3510\n",
      "Epoch 74/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3935 - accuracy: 0.5374 - val_loss: 2.9119 - val_accuracy: 0.3546\n",
      "Epoch 75/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3902 - accuracy: 0.5398 - val_loss: 2.8703 - val_accuracy: 0.3571\n",
      "Epoch 76/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3877 - accuracy: 0.5388 - val_loss: 2.8697 - val_accuracy: 0.3595\n",
      "Epoch 77/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3911 - accuracy: 0.5403 - val_loss: 2.9172 - val_accuracy: 0.3461\n",
      "Epoch 78/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3958 - accuracy: 0.5380 - val_loss: 2.9096 - val_accuracy: 0.3516\n",
      "Epoch 79/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.5374 - val_loss: 2.8759 - val_accuracy: 0.3619\n",
      "Epoch 80/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3951 - accuracy: 0.5350 - val_loss: 2.8870 - val_accuracy: 0.3552\n",
      "Epoch 81/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3942 - accuracy: 0.5401 - val_loss: 2.8847 - val_accuracy: 0.3619\n",
      "Epoch 82/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.5383 - val_loss: 2.8843 - val_accuracy: 0.3571\n",
      "Epoch 83/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3971 - accuracy: 0.5368 - val_loss: 2.8918 - val_accuracy: 0.3662\n",
      "Epoch 84/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.5345 - val_loss: 2.8698 - val_accuracy: 0.3686\n",
      "Epoch 85/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4000 - accuracy: 0.5335 - val_loss: 2.9174 - val_accuracy: 0.3443\n",
      "Epoch 86/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3927 - accuracy: 0.5394 - val_loss: 2.8592 - val_accuracy: 0.3546\n",
      "Epoch 87/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3973 - accuracy: 0.5436 - val_loss: 2.9048 - val_accuracy: 0.3564\n",
      "Epoch 88/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3947 - accuracy: 0.5373 - val_loss: 2.8856 - val_accuracy: 0.3528\n",
      "Epoch 89/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3969 - accuracy: 0.5373 - val_loss: 2.9066 - val_accuracy: 0.3601\n",
      "Epoch 90/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3908 - accuracy: 0.5409 - val_loss: 2.8857 - val_accuracy: 0.3516\n",
      "Epoch 91/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3930 - accuracy: 0.5316 - val_loss: 2.9071 - val_accuracy: 0.3546\n",
      "Epoch 92/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3915 - accuracy: 0.5408 - val_loss: 2.8836 - val_accuracy: 0.3485\n",
      "Epoch 93/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5353 - val_loss: 2.9014 - val_accuracy: 0.3552\n",
      "Epoch 94/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3965 - accuracy: 0.5344 - val_loss: 2.8697 - val_accuracy: 0.3650\n",
      "Epoch 95/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3862 - accuracy: 0.5412 - val_loss: 2.8845 - val_accuracy: 0.3540\n",
      "Epoch 96/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3849 - accuracy: 0.5383 - val_loss: 2.9102 - val_accuracy: 0.3546\n",
      "Epoch 97/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3953 - accuracy: 0.5342 - val_loss: 2.9111 - val_accuracy: 0.3528\n",
      "Epoch 98/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3970 - accuracy: 0.5338 - val_loss: 2.8797 - val_accuracy: 0.3601\n",
      "Epoch 99/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3908 - accuracy: 0.5356 - val_loss: 2.9098 - val_accuracy: 0.3540\n",
      "Epoch 100/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3946 - accuracy: 0.5366 - val_loss: 2.8827 - val_accuracy: 0.3595\n",
      "Epoch 101/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3945 - accuracy: 0.5382 - val_loss: 2.9019 - val_accuracy: 0.3558\n",
      "Epoch 102/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3896 - accuracy: 0.5394 - val_loss: 2.8845 - val_accuracy: 0.3528\n",
      "Epoch 103/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3915 - accuracy: 0.5374 - val_loss: 2.8801 - val_accuracy: 0.3571\n",
      "Epoch 104/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3921 - accuracy: 0.5388 - val_loss: 2.8911 - val_accuracy: 0.3546\n",
      "Epoch 105/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3901 - accuracy: 0.5370 - val_loss: 2.8786 - val_accuracy: 0.3613\n",
      "Epoch 106/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3941 - accuracy: 0.5421 - val_loss: 2.8887 - val_accuracy: 0.3625\n",
      "Epoch 107/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3943 - accuracy: 0.5368 - val_loss: 2.9050 - val_accuracy: 0.3510\n",
      "Epoch 108/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3858 - accuracy: 0.5429 - val_loss: 2.8980 - val_accuracy: 0.3528\n",
      "Epoch 109/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3913 - accuracy: 0.5322 - val_loss: 2.8827 - val_accuracy: 0.3589\n",
      "Epoch 110/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3835 - accuracy: 0.5383 - val_loss: 2.9123 - val_accuracy: 0.3583\n",
      "Epoch 111/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3934 - accuracy: 0.5379 - val_loss: 2.8912 - val_accuracy: 0.3583\n",
      "Epoch 112/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5392 - val_loss: 2.8832 - val_accuracy: 0.3589\n",
      "Epoch 113/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3978 - accuracy: 0.5335 - val_loss: 2.8755 - val_accuracy: 0.3625\n",
      "Epoch 114/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3896 - accuracy: 0.5333 - val_loss: 2.8761 - val_accuracy: 0.3680\n",
      "Epoch 115/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3926 - accuracy: 0.5328 - val_loss: 2.8912 - val_accuracy: 0.3631\n",
      "Epoch 116/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.5356 - val_loss: 2.8914 - val_accuracy: 0.3546\n",
      "Epoch 117/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5408 - val_loss: 2.9064 - val_accuracy: 0.3467\n",
      "Epoch 118/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4003 - accuracy: 0.5370 - val_loss: 2.9065 - val_accuracy: 0.3510\n",
      "Epoch 119/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3823 - accuracy: 0.5423 - val_loss: 2.8868 - val_accuracy: 0.3564\n",
      "Epoch 120/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3876 - accuracy: 0.5386 - val_loss: 2.9315 - val_accuracy: 0.3564\n",
      "Epoch 121/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3972 - accuracy: 0.5335 - val_loss: 2.9314 - val_accuracy: 0.3583\n",
      "Epoch 122/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3890 - accuracy: 0.5424 - val_loss: 2.9006 - val_accuracy: 0.3516\n",
      "Epoch 123/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3930 - accuracy: 0.5395 - val_loss: 2.9241 - val_accuracy: 0.3510\n",
      "Epoch 124/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3891 - accuracy: 0.5380 - val_loss: 2.8939 - val_accuracy: 0.3650\n",
      "Epoch 125/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3955 - accuracy: 0.5382 - val_loss: 2.8877 - val_accuracy: 0.3589\n",
      "Epoch 126/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3885 - accuracy: 0.5363 - val_loss: 2.9142 - val_accuracy: 0.3558\n",
      "Epoch 127/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3933 - accuracy: 0.5371 - val_loss: 2.8967 - val_accuracy: 0.3571\n",
      "Epoch 128/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3980 - accuracy: 0.5356 - val_loss: 2.9077 - val_accuracy: 0.3516\n",
      "Epoch 129/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3913 - accuracy: 0.5370 - val_loss: 2.9110 - val_accuracy: 0.3625\n",
      "Epoch 130/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3853 - accuracy: 0.5420 - val_loss: 2.9006 - val_accuracy: 0.3619\n",
      "Epoch 131/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3924 - accuracy: 0.5400 - val_loss: 2.9097 - val_accuracy: 0.3540\n",
      "Epoch 132/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3931 - accuracy: 0.5436 - val_loss: 2.8977 - val_accuracy: 0.3552\n",
      "Epoch 133/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3938 - accuracy: 0.5377 - val_loss: 2.9120 - val_accuracy: 0.3552\n",
      "Epoch 134/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3880 - accuracy: 0.5389 - val_loss: 2.9259 - val_accuracy: 0.3601\n",
      "Epoch 135/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3864 - accuracy: 0.5406 - val_loss: 2.8976 - val_accuracy: 0.3595\n",
      "Epoch 136/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3873 - accuracy: 0.5385 - val_loss: 2.9046 - val_accuracy: 0.3583\n",
      "Epoch 137/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3844 - accuracy: 0.5386 - val_loss: 2.8890 - val_accuracy: 0.3589\n",
      "Epoch 138/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5389 - val_loss: 2.9185 - val_accuracy: 0.3534\n",
      "Epoch 139/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3930 - accuracy: 0.5366 - val_loss: 2.9183 - val_accuracy: 0.3534\n",
      "Epoch 140/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3796 - accuracy: 0.5411 - val_loss: 2.9020 - val_accuracy: 0.3674\n",
      "Epoch 141/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3907 - accuracy: 0.5379 - val_loss: 2.9038 - val_accuracy: 0.3637\n",
      "Epoch 142/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3837 - accuracy: 0.5397 - val_loss: 2.8972 - val_accuracy: 0.3571\n",
      "Epoch 143/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3875 - accuracy: 0.5391 - val_loss: 2.9175 - val_accuracy: 0.3589\n",
      "Epoch 144/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3794 - accuracy: 0.5368 - val_loss: 2.9124 - val_accuracy: 0.3504\n",
      "Epoch 145/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3893 - accuracy: 0.5363 - val_loss: 2.9097 - val_accuracy: 0.3552\n",
      "Epoch 146/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5373 - val_loss: 2.9137 - val_accuracy: 0.3504\n",
      "Epoch 147/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.5370 - val_loss: 2.9125 - val_accuracy: 0.3534\n",
      "Epoch 148/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3829 - accuracy: 0.5408 - val_loss: 2.9030 - val_accuracy: 0.3607\n",
      "Epoch 149/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3921 - accuracy: 0.5386 - val_loss: 2.9155 - val_accuracy: 0.3510\n",
      "Epoch 150/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3882 - accuracy: 0.5418 - val_loss: 2.9282 - val_accuracy: 0.3540\n",
      "Epoch 151/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3876 - accuracy: 0.5398 - val_loss: 2.9086 - val_accuracy: 0.3534\n",
      "Epoch 152/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3900 - accuracy: 0.5403 - val_loss: 2.9172 - val_accuracy: 0.3504\n",
      "Epoch 153/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3856 - accuracy: 0.5360 - val_loss: 2.9097 - val_accuracy: 0.3510\n",
      "Epoch 154/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3828 - accuracy: 0.5336 - val_loss: 2.9247 - val_accuracy: 0.3601\n",
      "Epoch 155/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3811 - accuracy: 0.5426 - val_loss: 2.9151 - val_accuracy: 0.3607\n",
      "Epoch 156/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5427 - val_loss: 2.9206 - val_accuracy: 0.3607\n",
      "Epoch 157/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3880 - accuracy: 0.5391 - val_loss: 2.9318 - val_accuracy: 0.3479\n",
      "Epoch 158/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3911 - accuracy: 0.5356 - val_loss: 2.9197 - val_accuracy: 0.3577\n",
      "Epoch 159/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3917 - accuracy: 0.5365 - val_loss: 2.9145 - val_accuracy: 0.3583\n",
      "Epoch 160/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3839 - accuracy: 0.5446 - val_loss: 2.9160 - val_accuracy: 0.3479\n",
      "Epoch 161/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3869 - accuracy: 0.5398 - val_loss: 2.9138 - val_accuracy: 0.3577\n",
      "Epoch 162/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.5376 - val_loss: 2.8946 - val_accuracy: 0.3589\n",
      "Epoch 163/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5392 - val_loss: 2.8897 - val_accuracy: 0.3540\n",
      "Epoch 164/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3862 - accuracy: 0.5415 - val_loss: 2.9302 - val_accuracy: 0.3485\n",
      "Epoch 165/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3807 - accuracy: 0.5386 - val_loss: 2.8951 - val_accuracy: 0.3595\n",
      "Epoch 166/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3853 - accuracy: 0.5382 - val_loss: 2.9128 - val_accuracy: 0.3522\n",
      "Epoch 167/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.5392 - val_loss: 2.8775 - val_accuracy: 0.3637\n",
      "Epoch 168/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3828 - accuracy: 0.5368 - val_loss: 2.8881 - val_accuracy: 0.3571\n",
      "Epoch 169/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3879 - accuracy: 0.5401 - val_loss: 2.8878 - val_accuracy: 0.3662\n",
      "Epoch 170/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3860 - accuracy: 0.5373 - val_loss: 2.8876 - val_accuracy: 0.3619\n",
      "Epoch 171/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3862 - accuracy: 0.5385 - val_loss: 2.9149 - val_accuracy: 0.3625\n",
      "Epoch 172/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3894 - accuracy: 0.5385 - val_loss: 2.8936 - val_accuracy: 0.3613\n",
      "Epoch 173/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3843 - accuracy: 0.5374 - val_loss: 2.9553 - val_accuracy: 0.3504\n",
      "Epoch 174/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3817 - accuracy: 0.5405 - val_loss: 2.9192 - val_accuracy: 0.3607\n",
      "Epoch 175/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5380 - val_loss: 2.9373 - val_accuracy: 0.3516\n",
      "Epoch 176/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3862 - accuracy: 0.5377 - val_loss: 2.9139 - val_accuracy: 0.3552\n",
      "Epoch 177/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3849 - accuracy: 0.5373 - val_loss: 2.9135 - val_accuracy: 0.3589\n",
      "Epoch 178/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3787 - accuracy: 0.5385 - val_loss: 2.9403 - val_accuracy: 0.3504\n",
      "Epoch 179/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3798 - accuracy: 0.5401 - val_loss: 2.9033 - val_accuracy: 0.3577\n",
      "Epoch 180/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3876 - accuracy: 0.5356 - val_loss: 2.9185 - val_accuracy: 0.3564\n",
      "Epoch 181/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3844 - accuracy: 0.5362 - val_loss: 2.9144 - val_accuracy: 0.3595\n",
      "Epoch 182/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3796 - accuracy: 0.5395 - val_loss: 2.9264 - val_accuracy: 0.3498\n",
      "Epoch 183/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3913 - accuracy: 0.5348 - val_loss: 2.9224 - val_accuracy: 0.3528\n",
      "Epoch 184/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3843 - accuracy: 0.5395 - val_loss: 2.9180 - val_accuracy: 0.3577\n",
      "Epoch 185/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3850 - accuracy: 0.5368 - val_loss: 2.9241 - val_accuracy: 0.3552\n",
      "Epoch 186/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3911 - accuracy: 0.5360 - val_loss: 2.9020 - val_accuracy: 0.3692\n",
      "Epoch 187/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3792 - accuracy: 0.5427 - val_loss: 2.9227 - val_accuracy: 0.3558\n",
      "Epoch 188/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3809 - accuracy: 0.5392 - val_loss: 2.9294 - val_accuracy: 0.3619\n",
      "Epoch 189/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3865 - accuracy: 0.5401 - val_loss: 2.9186 - val_accuracy: 0.3583\n",
      "Epoch 190/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3900 - accuracy: 0.5377 - val_loss: 2.9265 - val_accuracy: 0.3522\n",
      "Epoch 191/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3753 - accuracy: 0.5409 - val_loss: 2.8892 - val_accuracy: 0.3631\n",
      "Epoch 192/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3873 - accuracy: 0.5382 - val_loss: 2.9343 - val_accuracy: 0.3564\n",
      "Epoch 193/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3811 - accuracy: 0.5430 - val_loss: 2.9234 - val_accuracy: 0.3516\n",
      "Epoch 194/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3847 - accuracy: 0.5427 - val_loss: 2.9156 - val_accuracy: 0.3577\n",
      "Epoch 195/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3850 - accuracy: 0.5406 - val_loss: 2.9578 - val_accuracy: 0.3479\n",
      "Epoch 196/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3939 - accuracy: 0.5341 - val_loss: 2.9174 - val_accuracy: 0.3571\n",
      "Epoch 197/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3858 - accuracy: 0.5412 - val_loss: 2.9152 - val_accuracy: 0.3564\n",
      "Epoch 198/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3818 - accuracy: 0.5373 - val_loss: 2.9676 - val_accuracy: 0.3455\n",
      "Epoch 199/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3836 - accuracy: 0.5426 - val_loss: 2.9080 - val_accuracy: 0.3571\n",
      "Epoch 200/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3754 - accuracy: 0.5452 - val_loss: 2.9083 - val_accuracy: 0.3516\n",
      "Epoch 201/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3846 - accuracy: 0.5401 - val_loss: 2.9107 - val_accuracy: 0.3577\n",
      "Epoch 202/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3869 - accuracy: 0.5363 - val_loss: 2.9029 - val_accuracy: 0.3607\n",
      "Epoch 203/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3735 - accuracy: 0.5432 - val_loss: 2.9155 - val_accuracy: 0.3595\n",
      "Epoch 204/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3758 - accuracy: 0.5400 - val_loss: 2.9102 - val_accuracy: 0.3607\n",
      "Epoch 205/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3815 - accuracy: 0.5359 - val_loss: 2.9316 - val_accuracy: 0.3589\n",
      "Epoch 206/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3810 - accuracy: 0.5426 - val_loss: 2.9496 - val_accuracy: 0.3516\n",
      "Epoch 207/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3875 - accuracy: 0.5405 - val_loss: 2.9272 - val_accuracy: 0.3601\n",
      "Epoch 208/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3845 - accuracy: 0.5403 - val_loss: 2.9055 - val_accuracy: 0.3662\n",
      "Epoch 209/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3881 - accuracy: 0.5415 - val_loss: 2.9236 - val_accuracy: 0.3546\n",
      "Epoch 210/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3790 - accuracy: 0.5392 - val_loss: 2.9318 - val_accuracy: 0.3656\n",
      "Epoch 211/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3819 - accuracy: 0.5420 - val_loss: 2.9241 - val_accuracy: 0.3577\n",
      "Epoch 212/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3864 - accuracy: 0.5339 - val_loss: 2.9131 - val_accuracy: 0.3571\n",
      "Epoch 213/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3841 - accuracy: 0.5385 - val_loss: 2.9383 - val_accuracy: 0.3577\n",
      "Epoch 214/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3865 - accuracy: 0.5400 - val_loss: 2.9348 - val_accuracy: 0.3601\n",
      "Epoch 215/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3793 - accuracy: 0.5436 - val_loss: 2.9276 - val_accuracy: 0.3644\n",
      "Epoch 216/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3833 - accuracy: 0.5377 - val_loss: 2.9318 - val_accuracy: 0.3631\n",
      "Epoch 217/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3901 - accuracy: 0.5409 - val_loss: 2.9216 - val_accuracy: 0.3656\n",
      "Epoch 218/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3826 - accuracy: 0.5376 - val_loss: 2.9171 - val_accuracy: 0.3589\n",
      "Epoch 219/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3770 - accuracy: 0.5400 - val_loss: 2.9086 - val_accuracy: 0.3577\n",
      "Epoch 220/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3763 - accuracy: 0.5470 - val_loss: 2.9303 - val_accuracy: 0.3571\n",
      "Epoch 221/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3877 - accuracy: 0.5398 - val_loss: 2.9150 - val_accuracy: 0.3589\n",
      "Epoch 222/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3874 - accuracy: 0.5348 - val_loss: 2.9134 - val_accuracy: 0.3534\n",
      "Epoch 223/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3834 - accuracy: 0.5409 - val_loss: 2.9118 - val_accuracy: 0.3577\n",
      "Epoch 224/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3828 - accuracy: 0.5391 - val_loss: 2.9322 - val_accuracy: 0.3577\n",
      "Epoch 225/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3788 - accuracy: 0.5379 - val_loss: 2.9229 - val_accuracy: 0.3589\n",
      "Epoch 226/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3795 - accuracy: 0.5408 - val_loss: 2.9184 - val_accuracy: 0.3595\n",
      "Epoch 227/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.5439 - val_loss: 2.9285 - val_accuracy: 0.3601\n",
      "Epoch 228/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3914 - accuracy: 0.5356 - val_loss: 2.9290 - val_accuracy: 0.3546\n",
      "Epoch 229/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3735 - accuracy: 0.5420 - val_loss: 2.9388 - val_accuracy: 0.3473\n",
      "Epoch 230/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3917 - accuracy: 0.5350 - val_loss: 2.9251 - val_accuracy: 0.3485\n",
      "Epoch 231/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3719 - accuracy: 0.5429 - val_loss: 2.9317 - val_accuracy: 0.3577\n",
      "Epoch 232/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3863 - accuracy: 0.5371 - val_loss: 2.9204 - val_accuracy: 0.3577\n",
      "Epoch 233/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3819 - accuracy: 0.5405 - val_loss: 2.8916 - val_accuracy: 0.3662\n",
      "Epoch 234/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3813 - accuracy: 0.5385 - val_loss: 2.9241 - val_accuracy: 0.3528\n",
      "Epoch 235/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3877 - accuracy: 0.5409 - val_loss: 2.9377 - val_accuracy: 0.3583\n",
      "Epoch 236/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3812 - accuracy: 0.5374 - val_loss: 2.9376 - val_accuracy: 0.3558\n",
      "Epoch 237/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3915 - accuracy: 0.5401 - val_loss: 2.9256 - val_accuracy: 0.3546\n",
      "Epoch 238/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5432 - val_loss: 2.9345 - val_accuracy: 0.3461\n",
      "Epoch 239/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3832 - accuracy: 0.5383 - val_loss: 2.9429 - val_accuracy: 0.3583\n",
      "Epoch 240/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3737 - accuracy: 0.5405 - val_loss: 2.9026 - val_accuracy: 0.3619\n",
      "Epoch 241/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3877 - accuracy: 0.5365 - val_loss: 2.9228 - val_accuracy: 0.3625\n",
      "Epoch 242/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3804 - accuracy: 0.5324 - val_loss: 2.9393 - val_accuracy: 0.3558\n",
      "Epoch 243/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3816 - accuracy: 0.5444 - val_loss: 2.9266 - val_accuracy: 0.3552\n",
      "Epoch 244/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3846 - accuracy: 0.5366 - val_loss: 2.9111 - val_accuracy: 0.3613\n",
      "Epoch 245/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3764 - accuracy: 0.5363 - val_loss: 2.8947 - val_accuracy: 0.3613\n",
      "Epoch 246/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3831 - accuracy: 0.5362 - val_loss: 2.9489 - val_accuracy: 0.3467\n",
      "Epoch 247/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3833 - accuracy: 0.5415 - val_loss: 2.9569 - val_accuracy: 0.3510\n",
      "Epoch 248/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3817 - accuracy: 0.5353 - val_loss: 2.9062 - val_accuracy: 0.3662\n",
      "Epoch 249/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3894 - accuracy: 0.5380 - val_loss: 2.9280 - val_accuracy: 0.3601\n",
      "Epoch 250/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3833 - accuracy: 0.5420 - val_loss: 2.9351 - val_accuracy: 0.3510\n",
      "Epoch 251/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3839 - accuracy: 0.5338 - val_loss: 2.9379 - val_accuracy: 0.3601\n",
      "Epoch 252/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3857 - accuracy: 0.5377 - val_loss: 2.9643 - val_accuracy: 0.3528\n",
      "Epoch 253/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3821 - accuracy: 0.5461 - val_loss: 2.9237 - val_accuracy: 0.3601\n",
      "Epoch 254/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3797 - accuracy: 0.5408 - val_loss: 2.9337 - val_accuracy: 0.3540\n",
      "Epoch 255/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3864 - accuracy: 0.5338 - val_loss: 2.9514 - val_accuracy: 0.3546\n",
      "Epoch 256/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3775 - accuracy: 0.5435 - val_loss: 2.9486 - val_accuracy: 0.3546\n",
      "Epoch 257/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3821 - accuracy: 0.5347 - val_loss: 2.9356 - val_accuracy: 0.3583\n",
      "Epoch 258/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3826 - accuracy: 0.5409 - val_loss: 2.9371 - val_accuracy: 0.3595\n",
      "Epoch 259/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3785 - accuracy: 0.5406 - val_loss: 2.9562 - val_accuracy: 0.3589\n",
      "Epoch 260/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3804 - accuracy: 0.5436 - val_loss: 2.9104 - val_accuracy: 0.3619\n",
      "Epoch 261/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3862 - accuracy: 0.5377 - val_loss: 2.8994 - val_accuracy: 0.3656\n",
      "Epoch 262/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3762 - accuracy: 0.5400 - val_loss: 2.9221 - val_accuracy: 0.3577\n",
      "Epoch 263/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3801 - accuracy: 0.5423 - val_loss: 2.9317 - val_accuracy: 0.3601\n",
      "Epoch 264/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3885 - accuracy: 0.5360 - val_loss: 2.9484 - val_accuracy: 0.3498\n",
      "Epoch 265/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3856 - accuracy: 0.5398 - val_loss: 2.8934 - val_accuracy: 0.3577\n",
      "Epoch 266/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3717 - accuracy: 0.5438 - val_loss: 2.9352 - val_accuracy: 0.3540\n",
      "Epoch 267/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3895 - accuracy: 0.5356 - val_loss: 2.9290 - val_accuracy: 0.3692\n",
      "Epoch 268/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3838 - accuracy: 0.5380 - val_loss: 2.9347 - val_accuracy: 0.3577\n",
      "Epoch 269/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3784 - accuracy: 0.5412 - val_loss: 2.9647 - val_accuracy: 0.3522\n",
      "Epoch 270/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3818 - accuracy: 0.5417 - val_loss: 2.9340 - val_accuracy: 0.3552\n",
      "Epoch 271/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3869 - accuracy: 0.5350 - val_loss: 2.9554 - val_accuracy: 0.3571\n",
      "Epoch 272/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3768 - accuracy: 0.5414 - val_loss: 2.9525 - val_accuracy: 0.3607\n",
      "Epoch 273/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3773 - accuracy: 0.5403 - val_loss: 2.9696 - val_accuracy: 0.3522\n",
      "Epoch 274/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3722 - accuracy: 0.5436 - val_loss: 2.9535 - val_accuracy: 0.3558\n",
      "Epoch 275/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3862 - accuracy: 0.5409 - val_loss: 2.9080 - val_accuracy: 0.3656\n",
      "Epoch 276/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3835 - accuracy: 0.5401 - val_loss: 2.9467 - val_accuracy: 0.3577\n",
      "Epoch 277/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3836 - accuracy: 0.5379 - val_loss: 2.9435 - val_accuracy: 0.3498\n",
      "Epoch 278/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3814 - accuracy: 0.5373 - val_loss: 2.9338 - val_accuracy: 0.3540\n",
      "Epoch 279/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3773 - accuracy: 0.5386 - val_loss: 2.9612 - val_accuracy: 0.3571\n",
      "Epoch 280/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3820 - accuracy: 0.5443 - val_loss: 2.9354 - val_accuracy: 0.3558\n",
      "Epoch 281/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.5452 - val_loss: 2.9244 - val_accuracy: 0.3619\n",
      "Epoch 282/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3695 - accuracy: 0.5424 - val_loss: 2.9498 - val_accuracy: 0.3528\n",
      "Epoch 283/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3814 - accuracy: 0.5439 - val_loss: 2.9271 - val_accuracy: 0.3510\n",
      "Epoch 284/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3774 - accuracy: 0.5379 - val_loss: 2.9044 - val_accuracy: 0.3735\n",
      "Epoch 285/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3853 - accuracy: 0.5374 - val_loss: 2.9501 - val_accuracy: 0.3516\n",
      "Epoch 286/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3753 - accuracy: 0.5436 - val_loss: 2.9663 - val_accuracy: 0.3534\n",
      "Epoch 287/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3810 - accuracy: 0.5376 - val_loss: 2.9232 - val_accuracy: 0.3625\n",
      "Epoch 288/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3697 - accuracy: 0.5391 - val_loss: 2.9789 - val_accuracy: 0.3571\n",
      "Epoch 289/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3766 - accuracy: 0.5394 - val_loss: 2.9358 - val_accuracy: 0.3650\n",
      "Epoch 290/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3868 - accuracy: 0.5409 - val_loss: 2.9601 - val_accuracy: 0.3491\n",
      "Epoch 291/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3812 - accuracy: 0.5380 - val_loss: 2.9417 - val_accuracy: 0.3595\n",
      "Epoch 292/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3771 - accuracy: 0.5433 - val_loss: 2.9159 - val_accuracy: 0.3522\n",
      "Epoch 293/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3759 - accuracy: 0.5373 - val_loss: 2.9406 - val_accuracy: 0.3637\n",
      "Epoch 294/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.5447 - val_loss: 2.9505 - val_accuracy: 0.3528\n",
      "Epoch 295/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3799 - accuracy: 0.5424 - val_loss: 2.9447 - val_accuracy: 0.3571\n",
      "Epoch 296/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3756 - accuracy: 0.5421 - val_loss: 2.9623 - val_accuracy: 0.3491\n",
      "Epoch 297/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3799 - accuracy: 0.5411 - val_loss: 2.9349 - val_accuracy: 0.3637\n",
      "Epoch 298/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.5397 - val_loss: 2.9556 - val_accuracy: 0.3534\n",
      "Epoch 299/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3774 - accuracy: 0.5449 - val_loss: 2.9408 - val_accuracy: 0.3583\n",
      "Epoch 300/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3720 - accuracy: 0.5450 - val_loss: 2.9356 - val_accuracy: 0.3625\n",
      "Epoch 301/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3817 - accuracy: 0.5405 - val_loss: 2.9432 - val_accuracy: 0.3625\n",
      "Epoch 302/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3696 - accuracy: 0.5433 - val_loss: 2.9450 - val_accuracy: 0.3631\n",
      "Epoch 303/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3771 - accuracy: 0.5408 - val_loss: 2.9693 - val_accuracy: 0.3571\n",
      "Epoch 304/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3851 - accuracy: 0.5411 - val_loss: 2.9488 - val_accuracy: 0.3522\n",
      "Epoch 305/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3834 - accuracy: 0.5351 - val_loss: 2.9267 - val_accuracy: 0.3522\n",
      "Epoch 306/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3831 - accuracy: 0.5379 - val_loss: 2.9779 - val_accuracy: 0.3595\n",
      "Epoch 307/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.5444 - val_loss: 2.9215 - val_accuracy: 0.3589\n",
      "Epoch 308/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3806 - accuracy: 0.5389 - val_loss: 2.9402 - val_accuracy: 0.3546\n",
      "Epoch 309/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.5382 - val_loss: 2.9332 - val_accuracy: 0.3577\n",
      "Epoch 310/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3772 - accuracy: 0.5398 - val_loss: 2.9494 - val_accuracy: 0.3571\n",
      "Epoch 311/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3758 - accuracy: 0.5394 - val_loss: 2.9493 - val_accuracy: 0.3583\n",
      "Epoch 312/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3713 - accuracy: 0.5395 - val_loss: 2.9389 - val_accuracy: 0.3619\n",
      "Epoch 313/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3817 - accuracy: 0.5415 - val_loss: 2.9387 - val_accuracy: 0.3546\n",
      "Epoch 314/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3804 - accuracy: 0.5435 - val_loss: 2.9346 - val_accuracy: 0.3571\n",
      "Epoch 315/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3759 - accuracy: 0.5427 - val_loss: 2.9423 - val_accuracy: 0.3625\n",
      "Epoch 316/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3767 - accuracy: 0.5414 - val_loss: 2.9302 - val_accuracy: 0.3595\n",
      "Epoch 317/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3833 - accuracy: 0.5373 - val_loss: 2.9636 - val_accuracy: 0.3522\n",
      "Epoch 318/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.5430 - val_loss: 2.9331 - val_accuracy: 0.3571\n",
      "Epoch 319/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3774 - accuracy: 0.5436 - val_loss: 2.9435 - val_accuracy: 0.3491\n",
      "Epoch 320/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3876 - accuracy: 0.5380 - val_loss: 2.9541 - val_accuracy: 0.3418\n",
      "Epoch 321/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3740 - accuracy: 0.5464 - val_loss: 2.9585 - val_accuracy: 0.3510\n",
      "Epoch 322/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3801 - accuracy: 0.5391 - val_loss: 2.9712 - val_accuracy: 0.3425\n",
      "Epoch 323/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3821 - accuracy: 0.5365 - val_loss: 2.9652 - val_accuracy: 0.3449\n",
      "Epoch 324/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3738 - accuracy: 0.5424 - val_loss: 2.9482 - val_accuracy: 0.3668\n",
      "Epoch 325/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3839 - accuracy: 0.5380 - val_loss: 2.9465 - val_accuracy: 0.3558\n",
      "Epoch 326/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3750 - accuracy: 0.5383 - val_loss: 2.9555 - val_accuracy: 0.3467\n",
      "Epoch 327/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3766 - accuracy: 0.5389 - val_loss: 2.9495 - val_accuracy: 0.3601\n",
      "Epoch 328/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.5374 - val_loss: 2.9522 - val_accuracy: 0.3534\n",
      "Epoch 329/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3671 - accuracy: 0.5405 - val_loss: 2.9517 - val_accuracy: 0.3491\n",
      "Epoch 330/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3777 - accuracy: 0.5383 - val_loss: 2.9374 - val_accuracy: 0.3546\n",
      "Epoch 331/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3779 - accuracy: 0.5395 - val_loss: 2.9476 - val_accuracy: 0.3577\n",
      "Epoch 332/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3774 - accuracy: 0.5380 - val_loss: 2.9587 - val_accuracy: 0.3546\n",
      "Epoch 333/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3719 - accuracy: 0.5417 - val_loss: 2.9051 - val_accuracy: 0.3650\n",
      "Epoch 334/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3831 - accuracy: 0.5394 - val_loss: 2.9421 - val_accuracy: 0.3589\n",
      "Epoch 335/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3611 - accuracy: 0.5408 - val_loss: 2.9452 - val_accuracy: 0.3571\n",
      "Epoch 336/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3770 - accuracy: 0.5409 - val_loss: 2.9471 - val_accuracy: 0.3595\n",
      "Epoch 337/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3809 - accuracy: 0.5339 - val_loss: 2.9534 - val_accuracy: 0.3552\n",
      "Epoch 338/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3698 - accuracy: 0.5493 - val_loss: 2.9452 - val_accuracy: 0.3534\n",
      "Epoch 339/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3813 - accuracy: 0.5417 - val_loss: 2.9498 - val_accuracy: 0.3564\n",
      "Epoch 340/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3697 - accuracy: 0.5456 - val_loss: 2.9491 - val_accuracy: 0.3564\n",
      "Epoch 341/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3772 - accuracy: 0.5465 - val_loss: 2.9583 - val_accuracy: 0.3406\n",
      "Epoch 342/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.5403 - val_loss: 2.9568 - val_accuracy: 0.3613\n",
      "Epoch 343/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3725 - accuracy: 0.5383 - val_loss: 2.9563 - val_accuracy: 0.3449\n",
      "Epoch 344/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3756 - accuracy: 0.5423 - val_loss: 2.9793 - val_accuracy: 0.3516\n",
      "Epoch 345/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3778 - accuracy: 0.5403 - val_loss: 2.9335 - val_accuracy: 0.3625\n",
      "Epoch 346/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3741 - accuracy: 0.5420 - val_loss: 2.9824 - val_accuracy: 0.3467\n",
      "Epoch 347/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3696 - accuracy: 0.5444 - val_loss: 2.9568 - val_accuracy: 0.3583\n",
      "Epoch 348/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.5450 - val_loss: 2.9712 - val_accuracy: 0.3510\n",
      "Epoch 349/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3716 - accuracy: 0.5418 - val_loss: 2.9380 - val_accuracy: 0.3607\n",
      "Epoch 350/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3829 - accuracy: 0.5420 - val_loss: 2.9651 - val_accuracy: 0.3571\n",
      "Epoch 351/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3758 - accuracy: 0.5427 - val_loss: 2.9560 - val_accuracy: 0.3510\n",
      "Epoch 352/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3722 - accuracy: 0.5430 - val_loss: 2.9413 - val_accuracy: 0.3564\n",
      "Epoch 353/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3727 - accuracy: 0.5368 - val_loss: 2.9631 - val_accuracy: 0.3528\n",
      "Epoch 354/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3791 - accuracy: 0.5397 - val_loss: 2.9368 - val_accuracy: 0.3516\n",
      "Epoch 355/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3774 - accuracy: 0.5435 - val_loss: 2.9697 - val_accuracy: 0.3607\n",
      "Epoch 356/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3797 - accuracy: 0.5421 - val_loss: 2.9317 - val_accuracy: 0.3571\n",
      "Epoch 357/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3713 - accuracy: 0.5435 - val_loss: 2.9550 - val_accuracy: 0.3583\n",
      "Epoch 358/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3780 - accuracy: 0.5417 - val_loss: 2.9497 - val_accuracy: 0.3564\n",
      "Epoch 359/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3718 - accuracy: 0.5433 - val_loss: 2.9595 - val_accuracy: 0.3558\n",
      "Epoch 360/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3739 - accuracy: 0.5348 - val_loss: 2.9589 - val_accuracy: 0.3534\n",
      "Epoch 361/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3823 - accuracy: 0.5400 - val_loss: 2.9349 - val_accuracy: 0.3491\n",
      "Epoch 362/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3794 - accuracy: 0.5365 - val_loss: 2.9527 - val_accuracy: 0.3528\n",
      "Epoch 363/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3805 - accuracy: 0.5405 - val_loss: 2.9673 - val_accuracy: 0.3564\n",
      "Epoch 364/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3739 - accuracy: 0.5363 - val_loss: 2.9470 - val_accuracy: 0.3619\n",
      "Epoch 365/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3745 - accuracy: 0.5391 - val_loss: 2.9489 - val_accuracy: 0.3686\n",
      "Epoch 366/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3798 - accuracy: 0.5339 - val_loss: 2.9418 - val_accuracy: 0.3564\n",
      "Epoch 367/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3764 - accuracy: 0.5414 - val_loss: 2.9578 - val_accuracy: 0.3552\n",
      "Epoch 368/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3819 - accuracy: 0.5389 - val_loss: 2.9531 - val_accuracy: 0.3607\n",
      "Epoch 369/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.5363 - val_loss: 2.9651 - val_accuracy: 0.3540\n",
      "Epoch 370/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3699 - accuracy: 0.5380 - val_loss: 2.9791 - val_accuracy: 0.3418\n",
      "Epoch 371/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3628 - accuracy: 0.5405 - val_loss: 2.9476 - val_accuracy: 0.3595\n",
      "Epoch 372/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3814 - accuracy: 0.5379 - val_loss: 2.9597 - val_accuracy: 0.3564\n",
      "Epoch 373/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3704 - accuracy: 0.5441 - val_loss: 2.9450 - val_accuracy: 0.3613\n",
      "Epoch 374/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3725 - accuracy: 0.5427 - val_loss: 2.9355 - val_accuracy: 0.3546\n",
      "Epoch 375/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3744 - accuracy: 0.5395 - val_loss: 2.9590 - val_accuracy: 0.3558\n",
      "Epoch 376/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3742 - accuracy: 0.5409 - val_loss: 2.9684 - val_accuracy: 0.3577\n",
      "Epoch 377/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3760 - accuracy: 0.5426 - val_loss: 2.9891 - val_accuracy: 0.3534\n",
      "Epoch 378/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3818 - accuracy: 0.5408 - val_loss: 2.9477 - val_accuracy: 0.3601\n",
      "Epoch 379/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3798 - accuracy: 0.5406 - val_loss: 2.9471 - val_accuracy: 0.3571\n",
      "Epoch 380/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3706 - accuracy: 0.5415 - val_loss: 2.9757 - val_accuracy: 0.3564\n",
      "Epoch 381/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.5430 - val_loss: 2.9525 - val_accuracy: 0.3552\n",
      "Epoch 382/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3770 - accuracy: 0.5429 - val_loss: 2.9458 - val_accuracy: 0.3589\n",
      "Epoch 383/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.5403 - val_loss: 2.9618 - val_accuracy: 0.3577\n",
      "Epoch 384/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3778 - accuracy: 0.5353 - val_loss: 2.9476 - val_accuracy: 0.3522\n",
      "Epoch 385/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3679 - accuracy: 0.5427 - val_loss: 2.9461 - val_accuracy: 0.3552\n",
      "Epoch 386/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3714 - accuracy: 0.5443 - val_loss: 2.9271 - val_accuracy: 0.3589\n",
      "Epoch 387/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3713 - accuracy: 0.5464 - val_loss: 2.9664 - val_accuracy: 0.3552\n",
      "Epoch 388/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3719 - accuracy: 0.5446 - val_loss: 2.9499 - val_accuracy: 0.3540\n",
      "Epoch 389/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3639 - accuracy: 0.5467 - val_loss: 2.9564 - val_accuracy: 0.3571\n",
      "Epoch 390/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.5444 - val_loss: 3.0172 - val_accuracy: 0.3425\n",
      "Epoch 391/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3738 - accuracy: 0.5392 - val_loss: 2.9434 - val_accuracy: 0.3607\n",
      "Epoch 392/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3710 - accuracy: 0.5397 - val_loss: 2.9404 - val_accuracy: 0.3589\n",
      "Epoch 393/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3690 - accuracy: 0.5403 - val_loss: 2.9563 - val_accuracy: 0.3619\n",
      "Epoch 394/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.5473 - val_loss: 2.9662 - val_accuracy: 0.3491\n",
      "Epoch 395/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3645 - accuracy: 0.5430 - val_loss: 2.9596 - val_accuracy: 0.3644\n",
      "Epoch 396/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3707 - accuracy: 0.5383 - val_loss: 2.9666 - val_accuracy: 0.3558\n",
      "Epoch 397/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3673 - accuracy: 0.5414 - val_loss: 2.9860 - val_accuracy: 0.3510\n",
      "Epoch 398/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3722 - accuracy: 0.5385 - val_loss: 2.9526 - val_accuracy: 0.3540\n",
      "Epoch 399/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3754 - accuracy: 0.5441 - val_loss: 2.9801 - val_accuracy: 0.3589\n",
      "Epoch 400/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3752 - accuracy: 0.5383 - val_loss: 2.9203 - val_accuracy: 0.3589\n",
      "Epoch 401/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3769 - accuracy: 0.5403 - val_loss: 2.9576 - val_accuracy: 0.3522\n",
      "Epoch 402/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3736 - accuracy: 0.5471 - val_loss: 2.9637 - val_accuracy: 0.3540\n",
      "Epoch 403/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3646 - accuracy: 0.5452 - val_loss: 2.9509 - val_accuracy: 0.3540\n",
      "Epoch 404/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3697 - accuracy: 0.5414 - val_loss: 2.9431 - val_accuracy: 0.3558\n",
      "Epoch 405/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3756 - accuracy: 0.5414 - val_loss: 2.9537 - val_accuracy: 0.3516\n",
      "Epoch 406/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3709 - accuracy: 0.5430 - val_loss: 2.9615 - val_accuracy: 0.3510\n",
      "Epoch 407/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3712 - accuracy: 0.5438 - val_loss: 2.9877 - val_accuracy: 0.3479\n",
      "Epoch 408/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3690 - accuracy: 0.5414 - val_loss: 2.9367 - val_accuracy: 0.3583\n",
      "Epoch 409/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.5408 - val_loss: 2.9715 - val_accuracy: 0.3485\n",
      "Epoch 410/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3657 - accuracy: 0.5441 - val_loss: 2.9630 - val_accuracy: 0.3552\n",
      "Epoch 411/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3780 - accuracy: 0.5382 - val_loss: 2.9538 - val_accuracy: 0.3522\n",
      "Epoch 412/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3716 - accuracy: 0.5423 - val_loss: 2.9659 - val_accuracy: 0.3425\n",
      "Epoch 413/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3665 - accuracy: 0.5415 - val_loss: 2.9660 - val_accuracy: 0.3619\n",
      "Epoch 414/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3816 - accuracy: 0.5351 - val_loss: 2.9724 - val_accuracy: 0.3455\n",
      "Epoch 415/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3702 - accuracy: 0.5411 - val_loss: 2.9543 - val_accuracy: 0.3558\n",
      "Epoch 416/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3768 - accuracy: 0.5356 - val_loss: 2.9507 - val_accuracy: 0.3607\n",
      "Epoch 417/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.5391 - val_loss: 2.9674 - val_accuracy: 0.3552\n",
      "Epoch 418/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3645 - accuracy: 0.5441 - val_loss: 2.9677 - val_accuracy: 0.3479\n",
      "Epoch 419/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3704 - accuracy: 0.5449 - val_loss: 2.9893 - val_accuracy: 0.3510\n",
      "Epoch 420/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3726 - accuracy: 0.5405 - val_loss: 2.9664 - val_accuracy: 0.3546\n",
      "Epoch 421/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3768 - accuracy: 0.5444 - val_loss: 2.9530 - val_accuracy: 0.3564\n",
      "Epoch 422/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.5411 - val_loss: 2.9704 - val_accuracy: 0.3479\n",
      "Epoch 423/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3610 - accuracy: 0.5452 - val_loss: 2.9939 - val_accuracy: 0.3455\n",
      "Epoch 424/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3643 - accuracy: 0.5476 - val_loss: 2.9793 - val_accuracy: 0.3467\n",
      "Epoch 425/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3662 - accuracy: 0.5479 - val_loss: 2.9356 - val_accuracy: 0.3662\n",
      "Epoch 426/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3748 - accuracy: 0.5420 - val_loss: 2.9692 - val_accuracy: 0.3540\n",
      "Epoch 427/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3786 - accuracy: 0.5395 - val_loss: 2.9771 - val_accuracy: 0.3522\n",
      "Epoch 428/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3636 - accuracy: 0.5397 - val_loss: 2.9623 - val_accuracy: 0.3558\n",
      "Epoch 429/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3799 - accuracy: 0.5370 - val_loss: 2.9597 - val_accuracy: 0.3528\n",
      "Epoch 430/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3795 - accuracy: 0.5321 - val_loss: 2.9476 - val_accuracy: 0.3674\n",
      "Epoch 431/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3760 - accuracy: 0.5380 - val_loss: 2.9399 - val_accuracy: 0.3674\n",
      "Epoch 432/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3705 - accuracy: 0.5432 - val_loss: 2.9400 - val_accuracy: 0.3546\n",
      "Epoch 433/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3659 - accuracy: 0.5459 - val_loss: 2.9592 - val_accuracy: 0.3589\n",
      "Epoch 434/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3630 - accuracy: 0.5444 - val_loss: 2.9860 - val_accuracy: 0.3522\n",
      "Epoch 435/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3686 - accuracy: 0.5409 - val_loss: 2.9679 - val_accuracy: 0.3534\n",
      "Epoch 436/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3779 - accuracy: 0.5348 - val_loss: 2.9646 - val_accuracy: 0.3473\n",
      "Epoch 437/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3675 - accuracy: 0.5430 - val_loss: 2.9656 - val_accuracy: 0.3552\n",
      "Epoch 438/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3727 - accuracy: 0.5438 - val_loss: 2.9765 - val_accuracy: 0.3552\n",
      "Epoch 439/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3739 - accuracy: 0.5391 - val_loss: 3.0052 - val_accuracy: 0.3485\n",
      "Epoch 440/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3762 - accuracy: 0.5414 - val_loss: 2.9786 - val_accuracy: 0.3479\n",
      "Epoch 441/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3652 - accuracy: 0.5411 - val_loss: 2.9304 - val_accuracy: 0.3625\n",
      "Epoch 442/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.5424 - val_loss: 3.0285 - val_accuracy: 0.3473\n",
      "Epoch 443/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3727 - accuracy: 0.5389 - val_loss: 2.9658 - val_accuracy: 0.3534\n",
      "Epoch 444/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3788 - accuracy: 0.5371 - val_loss: 2.9739 - val_accuracy: 0.3558\n",
      "Epoch 445/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3786 - accuracy: 0.5376 - val_loss: 2.9730 - val_accuracy: 0.3534\n",
      "Epoch 446/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3720 - accuracy: 0.5392 - val_loss: 2.9710 - val_accuracy: 0.3613\n",
      "Epoch 447/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3741 - accuracy: 0.5389 - val_loss: 2.9547 - val_accuracy: 0.3595\n",
      "Epoch 448/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3758 - accuracy: 0.5414 - val_loss: 2.9813 - val_accuracy: 0.3534\n",
      "Epoch 449/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3627 - accuracy: 0.5485 - val_loss: 2.9785 - val_accuracy: 0.3528\n",
      "Epoch 450/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3653 - accuracy: 0.5414 - val_loss: 2.9872 - val_accuracy: 0.3528\n",
      "Epoch 451/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3630 - accuracy: 0.5452 - val_loss: 2.9677 - val_accuracy: 0.3577\n",
      "Epoch 452/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.5450 - val_loss: 3.0135 - val_accuracy: 0.3461\n",
      "Epoch 453/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3810 - accuracy: 0.5359 - val_loss: 2.9700 - val_accuracy: 0.3546\n",
      "Epoch 454/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3741 - accuracy: 0.5379 - val_loss: 2.9618 - val_accuracy: 0.3571\n",
      "Epoch 455/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3734 - accuracy: 0.5391 - val_loss: 2.9944 - val_accuracy: 0.3522\n",
      "Epoch 456/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.5439 - val_loss: 2.9520 - val_accuracy: 0.3607\n",
      "Epoch 457/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3715 - accuracy: 0.5398 - val_loss: 2.9535 - val_accuracy: 0.3546\n",
      "Epoch 458/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3690 - accuracy: 0.5427 - val_loss: 2.9798 - val_accuracy: 0.3534\n",
      "Epoch 459/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3646 - accuracy: 0.5403 - val_loss: 2.9912 - val_accuracy: 0.3437\n",
      "Epoch 460/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3687 - accuracy: 0.5430 - val_loss: 2.9504 - val_accuracy: 0.3528\n",
      "Epoch 461/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3694 - accuracy: 0.5421 - val_loss: 2.9613 - val_accuracy: 0.3498\n",
      "Epoch 462/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3652 - accuracy: 0.5433 - val_loss: 2.9698 - val_accuracy: 0.3522\n",
      "Epoch 463/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3716 - accuracy: 0.5420 - val_loss: 2.9647 - val_accuracy: 0.3479\n",
      "Epoch 464/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3735 - accuracy: 0.5417 - val_loss: 2.9864 - val_accuracy: 0.3431\n",
      "Epoch 465/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3787 - accuracy: 0.5370 - val_loss: 2.9683 - val_accuracy: 0.3516\n",
      "Epoch 466/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3698 - accuracy: 0.5430 - val_loss: 3.0077 - val_accuracy: 0.3522\n",
      "Epoch 467/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3630 - accuracy: 0.5441 - val_loss: 2.9723 - val_accuracy: 0.3473\n",
      "Epoch 468/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3738 - accuracy: 0.5374 - val_loss: 2.9943 - val_accuracy: 0.3510\n",
      "Epoch 469/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3746 - accuracy: 0.5374 - val_loss: 2.9527 - val_accuracy: 0.3558\n",
      "Epoch 470/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3707 - accuracy: 0.5392 - val_loss: 2.9567 - val_accuracy: 0.3491\n",
      "Epoch 471/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3724 - accuracy: 0.5383 - val_loss: 2.9655 - val_accuracy: 0.3558\n",
      "Epoch 472/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3661 - accuracy: 0.5412 - val_loss: 2.9654 - val_accuracy: 0.3595\n",
      "Epoch 473/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3667 - accuracy: 0.5439 - val_loss: 2.9753 - val_accuracy: 0.3540\n",
      "Epoch 474/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.5420 - val_loss: 2.9644 - val_accuracy: 0.3485\n",
      "Epoch 475/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3670 - accuracy: 0.5424 - val_loss: 2.9640 - val_accuracy: 0.3546\n",
      "Epoch 476/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3675 - accuracy: 0.5411 - val_loss: 2.9861 - val_accuracy: 0.3467\n",
      "Epoch 477/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3627 - accuracy: 0.5449 - val_loss: 2.9827 - val_accuracy: 0.3516\n",
      "Epoch 478/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3752 - accuracy: 0.5360 - val_loss: 2.9636 - val_accuracy: 0.3644\n",
      "Epoch 479/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.5417 - val_loss: 2.9777 - val_accuracy: 0.3516\n",
      "Epoch 480/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3660 - accuracy: 0.5385 - val_loss: 2.9686 - val_accuracy: 0.3540\n",
      "Epoch 481/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3657 - accuracy: 0.5400 - val_loss: 2.9493 - val_accuracy: 0.3540\n",
      "Epoch 482/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3662 - accuracy: 0.5417 - val_loss: 2.9639 - val_accuracy: 0.3564\n",
      "Epoch 483/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3691 - accuracy: 0.5444 - val_loss: 2.9463 - val_accuracy: 0.3589\n",
      "Epoch 484/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3680 - accuracy: 0.5421 - val_loss: 2.9772 - val_accuracy: 0.3491\n",
      "Epoch 485/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.5424 - val_loss: 2.9563 - val_accuracy: 0.3510\n",
      "Epoch 486/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3707 - accuracy: 0.5420 - val_loss: 2.9879 - val_accuracy: 0.3485\n",
      "Epoch 487/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3655 - accuracy: 0.5341 - val_loss: 2.9736 - val_accuracy: 0.3479\n",
      "Epoch 488/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3753 - accuracy: 0.5386 - val_loss: 2.9737 - val_accuracy: 0.3589\n",
      "Epoch 489/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3690 - accuracy: 0.5414 - val_loss: 2.9382 - val_accuracy: 0.3510\n",
      "Epoch 490/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3726 - accuracy: 0.5438 - val_loss: 2.9683 - val_accuracy: 0.3479\n",
      "Epoch 491/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3693 - accuracy: 0.5426 - val_loss: 2.9529 - val_accuracy: 0.3564\n",
      "Epoch 492/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3677 - accuracy: 0.5433 - val_loss: 2.9507 - val_accuracy: 0.3601\n",
      "Epoch 493/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3701 - accuracy: 0.5368 - val_loss: 2.9602 - val_accuracy: 0.3528\n",
      "Epoch 494/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3732 - accuracy: 0.5394 - val_loss: 2.9731 - val_accuracy: 0.3534\n",
      "Epoch 495/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3640 - accuracy: 0.5430 - val_loss: 2.9925 - val_accuracy: 0.3504\n",
      "Epoch 496/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3750 - accuracy: 0.5383 - val_loss: 2.9770 - val_accuracy: 0.3491\n",
      "Epoch 497/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3678 - accuracy: 0.5376 - val_loss: 2.9723 - val_accuracy: 0.3522\n",
      "Epoch 498/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3736 - accuracy: 0.5447 - val_loss: 2.9641 - val_accuracy: 0.3485\n",
      "Epoch 499/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3710 - accuracy: 0.5395 - val_loss: 2.9873 - val_accuracy: 0.3540\n",
      "Epoch 500/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3711 - accuracy: 0.5417 - val_loss: 2.9808 - val_accuracy: 0.3491\n",
      "Epoch 501/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3708 - accuracy: 0.5432 - val_loss: 2.9882 - val_accuracy: 0.3498\n",
      "Epoch 502/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3663 - accuracy: 0.5432 - val_loss: 3.0215 - val_accuracy: 0.3485\n",
      "Epoch 503/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3731 - accuracy: 0.5408 - val_loss: 2.9874 - val_accuracy: 0.3558\n",
      "Epoch 504/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.5446 - val_loss: 2.9994 - val_accuracy: 0.3534\n",
      "Epoch 505/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3763 - accuracy: 0.5415 - val_loss: 2.9573 - val_accuracy: 0.3558\n",
      "Epoch 506/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3595 - accuracy: 0.5487 - val_loss: 2.9558 - val_accuracy: 0.3595\n",
      "Epoch 507/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3661 - accuracy: 0.5456 - val_loss: 2.9874 - val_accuracy: 0.3577\n",
      "Epoch 508/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.5395 - val_loss: 2.9792 - val_accuracy: 0.3644\n",
      "Epoch 509/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3687 - accuracy: 0.5360 - val_loss: 2.9624 - val_accuracy: 0.3558\n",
      "Epoch 510/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3695 - accuracy: 0.5330 - val_loss: 2.9824 - val_accuracy: 0.3534\n",
      "Epoch 511/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3621 - accuracy: 0.5415 - val_loss: 2.9646 - val_accuracy: 0.3601\n",
      "Epoch 512/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3664 - accuracy: 0.5412 - val_loss: 2.9414 - val_accuracy: 0.3698\n",
      "Epoch 513/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.5423 - val_loss: 3.0002 - val_accuracy: 0.3583\n",
      "Epoch 514/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3727 - accuracy: 0.5409 - val_loss: 2.9623 - val_accuracy: 0.3558\n",
      "Epoch 515/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.5458 - val_loss: 3.0166 - val_accuracy: 0.3425\n",
      "Epoch 516/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3714 - accuracy: 0.5385 - val_loss: 2.9631 - val_accuracy: 0.3589\n",
      "Epoch 517/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3703 - accuracy: 0.5424 - val_loss: 2.9777 - val_accuracy: 0.3534\n",
      "Epoch 518/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3777 - accuracy: 0.5397 - val_loss: 2.9564 - val_accuracy: 0.3619\n",
      "Epoch 519/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3626 - accuracy: 0.5450 - val_loss: 2.9712 - val_accuracy: 0.3534\n",
      "Epoch 520/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3708 - accuracy: 0.5456 - val_loss: 2.9784 - val_accuracy: 0.3552\n",
      "Epoch 521/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3619 - accuracy: 0.5420 - val_loss: 2.9799 - val_accuracy: 0.3583\n",
      "Epoch 522/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3632 - accuracy: 0.5400 - val_loss: 2.9766 - val_accuracy: 0.3601\n",
      "Epoch 523/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3694 - accuracy: 0.5397 - val_loss: 2.9452 - val_accuracy: 0.3607\n",
      "Epoch 524/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3713 - accuracy: 0.5415 - val_loss: 2.9701 - val_accuracy: 0.3534\n",
      "Epoch 525/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3703 - accuracy: 0.5403 - val_loss: 2.9900 - val_accuracy: 0.3461\n",
      "Epoch 526/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3646 - accuracy: 0.5426 - val_loss: 3.0030 - val_accuracy: 0.3461\n",
      "Epoch 527/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3587 - accuracy: 0.5432 - val_loss: 2.9372 - val_accuracy: 0.3534\n",
      "Epoch 528/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3577 - accuracy: 0.5417 - val_loss: 2.9702 - val_accuracy: 0.3625\n",
      "Epoch 529/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3655 - accuracy: 0.5411 - val_loss: 2.9690 - val_accuracy: 0.3595\n",
      "Epoch 530/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3665 - accuracy: 0.5405 - val_loss: 3.0150 - val_accuracy: 0.3552\n",
      "Epoch 531/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3656 - accuracy: 0.5412 - val_loss: 2.9934 - val_accuracy: 0.3595\n",
      "Epoch 532/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3652 - accuracy: 0.5389 - val_loss: 2.9866 - val_accuracy: 0.3498\n",
      "Epoch 533/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3643 - accuracy: 0.5450 - val_loss: 2.9978 - val_accuracy: 0.3528\n",
      "Epoch 534/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.5401 - val_loss: 2.9980 - val_accuracy: 0.3522\n",
      "Epoch 535/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3656 - accuracy: 0.5420 - val_loss: 2.9999 - val_accuracy: 0.3552\n",
      "Epoch 536/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.5464 - val_loss: 3.0142 - val_accuracy: 0.3571\n",
      "Epoch 537/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.5420 - val_loss: 2.9657 - val_accuracy: 0.3534\n",
      "Epoch 538/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3608 - accuracy: 0.5459 - val_loss: 2.9873 - val_accuracy: 0.3571\n",
      "Epoch 539/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3705 - accuracy: 0.5401 - val_loss: 2.9798 - val_accuracy: 0.3491\n",
      "Epoch 540/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3578 - accuracy: 0.5417 - val_loss: 2.9811 - val_accuracy: 0.3552\n",
      "Epoch 541/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3682 - accuracy: 0.5421 - val_loss: 2.9813 - val_accuracy: 0.3607\n",
      "Epoch 542/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3623 - accuracy: 0.5427 - val_loss: 2.9944 - val_accuracy: 0.3571\n",
      "Epoch 543/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3733 - accuracy: 0.5368 - val_loss: 2.9713 - val_accuracy: 0.3546\n",
      "Epoch 544/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3690 - accuracy: 0.5386 - val_loss: 2.9844 - val_accuracy: 0.3595\n",
      "Epoch 545/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3684 - accuracy: 0.5366 - val_loss: 2.9983 - val_accuracy: 0.3406\n",
      "Epoch 546/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.5436 - val_loss: 2.9904 - val_accuracy: 0.3613\n",
      "Epoch 547/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.5423 - val_loss: 2.9572 - val_accuracy: 0.3571\n",
      "Epoch 548/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3660 - accuracy: 0.5439 - val_loss: 2.9866 - val_accuracy: 0.3540\n",
      "Epoch 549/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.5403 - val_loss: 2.9778 - val_accuracy: 0.3546\n",
      "Epoch 550/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3687 - accuracy: 0.5398 - val_loss: 3.0151 - val_accuracy: 0.3467\n",
      "Epoch 551/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3660 - accuracy: 0.5411 - val_loss: 2.9840 - val_accuracy: 0.3564\n",
      "Epoch 552/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3661 - accuracy: 0.5449 - val_loss: 3.0048 - val_accuracy: 0.3504\n",
      "Epoch 553/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3667 - accuracy: 0.5417 - val_loss: 2.9856 - val_accuracy: 0.3504\n",
      "Epoch 554/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3724 - accuracy: 0.5397 - val_loss: 2.9572 - val_accuracy: 0.3583\n",
      "Epoch 555/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3658 - accuracy: 0.5408 - val_loss: 2.9762 - val_accuracy: 0.3546\n",
      "Epoch 556/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3651 - accuracy: 0.5420 - val_loss: 2.9963 - val_accuracy: 0.3443\n",
      "Epoch 557/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3621 - accuracy: 0.5450 - val_loss: 2.9843 - val_accuracy: 0.3504\n",
      "Epoch 558/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3598 - accuracy: 0.5435 - val_loss: 3.0182 - val_accuracy: 0.3449\n",
      "Epoch 559/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3612 - accuracy: 0.5414 - val_loss: 2.9735 - val_accuracy: 0.3504\n",
      "Epoch 560/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3598 - accuracy: 0.5484 - val_loss: 2.9992 - val_accuracy: 0.3595\n",
      "Epoch 561/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3581 - accuracy: 0.5408 - val_loss: 2.9881 - val_accuracy: 0.3607\n",
      "Epoch 562/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3665 - accuracy: 0.5456 - val_loss: 2.9787 - val_accuracy: 0.3613\n",
      "Epoch 563/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3580 - accuracy: 0.5426 - val_loss: 3.0102 - val_accuracy: 0.3479\n",
      "Epoch 564/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3676 - accuracy: 0.5453 - val_loss: 2.9936 - val_accuracy: 0.3467\n",
      "Epoch 565/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3693 - accuracy: 0.5406 - val_loss: 2.9726 - val_accuracy: 0.3644\n",
      "Epoch 566/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.5473 - val_loss: 3.0055 - val_accuracy: 0.3558\n",
      "Epoch 567/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3594 - accuracy: 0.5439 - val_loss: 2.9961 - val_accuracy: 0.3473\n",
      "Epoch 568/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3623 - accuracy: 0.5444 - val_loss: 3.0051 - val_accuracy: 0.3619\n",
      "Epoch 569/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3666 - accuracy: 0.5449 - val_loss: 3.0294 - val_accuracy: 0.3491\n",
      "Epoch 570/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3598 - accuracy: 0.5455 - val_loss: 2.9644 - val_accuracy: 0.3528\n",
      "Epoch 571/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5411 - val_loss: 3.0068 - val_accuracy: 0.3461\n",
      "Epoch 572/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3582 - accuracy: 0.5494 - val_loss: 2.9768 - val_accuracy: 0.3583\n",
      "Epoch 573/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3585 - accuracy: 0.5484 - val_loss: 2.9879 - val_accuracy: 0.3491\n",
      "Epoch 574/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3656 - accuracy: 0.5462 - val_loss: 3.0062 - val_accuracy: 0.3607\n",
      "Epoch 575/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3669 - accuracy: 0.5406 - val_loss: 3.0089 - val_accuracy: 0.3437\n",
      "Epoch 576/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3601 - accuracy: 0.5491 - val_loss: 3.0048 - val_accuracy: 0.3644\n",
      "Epoch 577/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3712 - accuracy: 0.5363 - val_loss: 2.9809 - val_accuracy: 0.3619\n",
      "Epoch 578/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5420 - val_loss: 2.9815 - val_accuracy: 0.3546\n",
      "Epoch 579/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3591 - accuracy: 0.5479 - val_loss: 2.9827 - val_accuracy: 0.3583\n",
      "Epoch 580/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3653 - accuracy: 0.5405 - val_loss: 2.9677 - val_accuracy: 0.3637\n",
      "Epoch 581/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3578 - accuracy: 0.5423 - val_loss: 2.9843 - val_accuracy: 0.3504\n",
      "Epoch 582/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3667 - accuracy: 0.5389 - val_loss: 3.0012 - val_accuracy: 0.3479\n",
      "Epoch 583/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3674 - accuracy: 0.5383 - val_loss: 2.9670 - val_accuracy: 0.3546\n",
      "Epoch 584/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3579 - accuracy: 0.5450 - val_loss: 3.0043 - val_accuracy: 0.3412\n",
      "Epoch 585/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3643 - accuracy: 0.5363 - val_loss: 2.9905 - val_accuracy: 0.3577\n",
      "Epoch 586/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3711 - accuracy: 0.5415 - val_loss: 2.9618 - val_accuracy: 0.3680\n",
      "Epoch 587/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3696 - accuracy: 0.5423 - val_loss: 2.9845 - val_accuracy: 0.3534\n",
      "Epoch 588/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3615 - accuracy: 0.5441 - val_loss: 2.9653 - val_accuracy: 0.3564\n",
      "Epoch 589/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3676 - accuracy: 0.5441 - val_loss: 2.9846 - val_accuracy: 0.3522\n",
      "Epoch 590/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3644 - accuracy: 0.5395 - val_loss: 3.0086 - val_accuracy: 0.3522\n",
      "Epoch 591/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.5414 - val_loss: 2.9970 - val_accuracy: 0.3510\n",
      "Epoch 592/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3674 - accuracy: 0.5397 - val_loss: 2.9857 - val_accuracy: 0.3498\n",
      "Epoch 593/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3614 - accuracy: 0.5470 - val_loss: 2.9883 - val_accuracy: 0.3540\n",
      "Epoch 594/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3566 - accuracy: 0.5455 - val_loss: 2.9930 - val_accuracy: 0.3595\n",
      "Epoch 595/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3628 - accuracy: 0.5477 - val_loss: 2.9886 - val_accuracy: 0.3601\n",
      "Epoch 596/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3586 - accuracy: 0.5447 - val_loss: 3.0064 - val_accuracy: 0.3431\n",
      "Epoch 597/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3654 - accuracy: 0.5429 - val_loss: 3.0026 - val_accuracy: 0.3510\n",
      "Epoch 598/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5409 - val_loss: 2.9764 - val_accuracy: 0.3577\n",
      "Epoch 599/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3659 - accuracy: 0.5449 - val_loss: 2.9773 - val_accuracy: 0.3589\n",
      "Epoch 600/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3676 - accuracy: 0.5417 - val_loss: 3.0172 - val_accuracy: 0.3406\n",
      "Epoch 601/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3757 - accuracy: 0.5319 - val_loss: 3.0445 - val_accuracy: 0.3498\n",
      "Epoch 602/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3593 - accuracy: 0.5446 - val_loss: 3.0345 - val_accuracy: 0.3400\n",
      "Epoch 603/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3594 - accuracy: 0.5456 - val_loss: 2.9850 - val_accuracy: 0.3546\n",
      "Epoch 604/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5408 - val_loss: 2.9833 - val_accuracy: 0.3540\n",
      "Epoch 605/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3670 - accuracy: 0.5432 - val_loss: 3.0009 - val_accuracy: 0.3625\n",
      "Epoch 606/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3580 - accuracy: 0.5468 - val_loss: 2.9796 - val_accuracy: 0.3552\n",
      "Epoch 607/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3655 - accuracy: 0.5417 - val_loss: 3.0120 - val_accuracy: 0.3504\n",
      "Epoch 608/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3714 - accuracy: 0.5403 - val_loss: 3.0020 - val_accuracy: 0.3485\n",
      "Epoch 609/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.5441 - val_loss: 2.9653 - val_accuracy: 0.3583\n",
      "Epoch 610/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3595 - accuracy: 0.5430 - val_loss: 3.0053 - val_accuracy: 0.3467\n",
      "Epoch 611/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.5397 - val_loss: 2.9983 - val_accuracy: 0.3534\n",
      "Epoch 612/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3564 - accuracy: 0.5455 - val_loss: 2.9851 - val_accuracy: 0.3589\n",
      "Epoch 613/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3568 - accuracy: 0.5411 - val_loss: 3.0051 - val_accuracy: 0.3540\n",
      "Epoch 614/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3636 - accuracy: 0.5446 - val_loss: 2.9859 - val_accuracy: 0.3552\n",
      "Epoch 615/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3609 - accuracy: 0.5461 - val_loss: 3.0260 - val_accuracy: 0.3467\n",
      "Epoch 616/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.5429 - val_loss: 2.9937 - val_accuracy: 0.3540\n",
      "Epoch 617/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.5444 - val_loss: 2.9872 - val_accuracy: 0.3540\n",
      "Epoch 618/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3554 - accuracy: 0.5447 - val_loss: 3.0398 - val_accuracy: 0.3425\n",
      "Epoch 619/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3688 - accuracy: 0.5374 - val_loss: 2.9768 - val_accuracy: 0.3504\n",
      "Epoch 620/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3642 - accuracy: 0.5433 - val_loss: 2.9831 - val_accuracy: 0.3589\n",
      "Epoch 621/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3657 - accuracy: 0.5417 - val_loss: 3.0052 - val_accuracy: 0.3473\n",
      "Epoch 622/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3583 - accuracy: 0.5453 - val_loss: 2.9945 - val_accuracy: 0.3577\n",
      "Epoch 623/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3697 - accuracy: 0.5335 - val_loss: 2.9726 - val_accuracy: 0.3589\n",
      "Epoch 624/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3619 - accuracy: 0.5417 - val_loss: 3.0138 - val_accuracy: 0.3510\n",
      "Epoch 625/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3727 - accuracy: 0.5376 - val_loss: 2.9679 - val_accuracy: 0.3558\n",
      "Epoch 626/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3608 - accuracy: 0.5412 - val_loss: 2.9792 - val_accuracy: 0.3589\n",
      "Epoch 627/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3667 - accuracy: 0.5411 - val_loss: 2.9933 - val_accuracy: 0.3571\n",
      "Epoch 628/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3654 - accuracy: 0.5427 - val_loss: 2.9777 - val_accuracy: 0.3546\n",
      "Epoch 629/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3576 - accuracy: 0.5424 - val_loss: 3.0262 - val_accuracy: 0.3443\n",
      "Epoch 630/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3678 - accuracy: 0.5411 - val_loss: 2.9991 - val_accuracy: 0.3485\n",
      "Epoch 631/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.5395 - val_loss: 3.0261 - val_accuracy: 0.3485\n",
      "Epoch 632/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3632 - accuracy: 0.5408 - val_loss: 2.9847 - val_accuracy: 0.3534\n",
      "Epoch 633/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3582 - accuracy: 0.5453 - val_loss: 2.9763 - val_accuracy: 0.3637\n",
      "Epoch 634/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3593 - accuracy: 0.5436 - val_loss: 3.0129 - val_accuracy: 0.3540\n",
      "Epoch 635/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3582 - accuracy: 0.5446 - val_loss: 3.0083 - val_accuracy: 0.3528\n",
      "Epoch 636/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3599 - accuracy: 0.5433 - val_loss: 3.0295 - val_accuracy: 0.3473\n",
      "Epoch 637/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3583 - accuracy: 0.5421 - val_loss: 3.0221 - val_accuracy: 0.3461\n",
      "Epoch 638/1000\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.3639 - accuracy: 0.5447 - val_loss: 2.9867 - val_accuracy: 0.3491\n",
      "Epoch 639/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3627 - accuracy: 0.5432 - val_loss: 2.9941 - val_accuracy: 0.3571\n",
      "Epoch 640/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3669 - accuracy: 0.5444 - val_loss: 2.9818 - val_accuracy: 0.3528\n",
      "Epoch 641/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3603 - accuracy: 0.5444 - val_loss: 2.9954 - val_accuracy: 0.3571\n",
      "Epoch 642/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3669 - accuracy: 0.5415 - val_loss: 3.0127 - val_accuracy: 0.3607\n",
      "Epoch 643/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3520 - accuracy: 0.5471 - val_loss: 3.0173 - val_accuracy: 0.3522\n",
      "Epoch 644/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3614 - accuracy: 0.5403 - val_loss: 3.0092 - val_accuracy: 0.3418\n",
      "Epoch 645/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3615 - accuracy: 0.5401 - val_loss: 3.0285 - val_accuracy: 0.3522\n",
      "Epoch 646/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3630 - accuracy: 0.5394 - val_loss: 2.9964 - val_accuracy: 0.3491\n",
      "Epoch 647/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3649 - accuracy: 0.5421 - val_loss: 3.0228 - val_accuracy: 0.3522\n",
      "Epoch 648/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3612 - accuracy: 0.5411 - val_loss: 2.9938 - val_accuracy: 0.3528\n",
      "Epoch 649/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3604 - accuracy: 0.5417 - val_loss: 2.9956 - val_accuracy: 0.3491\n",
      "Epoch 650/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3641 - accuracy: 0.5461 - val_loss: 3.0137 - val_accuracy: 0.3583\n",
      "Epoch 651/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3621 - accuracy: 0.5441 - val_loss: 2.9986 - val_accuracy: 0.3510\n",
      "Epoch 652/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5421 - val_loss: 3.0072 - val_accuracy: 0.3534\n",
      "Epoch 653/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3490 - accuracy: 0.5435 - val_loss: 2.9998 - val_accuracy: 0.3589\n",
      "Epoch 654/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3601 - accuracy: 0.5446 - val_loss: 3.0073 - val_accuracy: 0.3473\n",
      "Epoch 655/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3579 - accuracy: 0.5439 - val_loss: 3.0139 - val_accuracy: 0.3479\n",
      "Epoch 656/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3579 - accuracy: 0.5455 - val_loss: 2.9889 - val_accuracy: 0.3571\n",
      "Epoch 657/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3602 - accuracy: 0.5471 - val_loss: 3.0294 - val_accuracy: 0.3534\n",
      "Epoch 658/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3619 - accuracy: 0.5453 - val_loss: 3.0268 - val_accuracy: 0.3418\n",
      "Epoch 659/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3617 - accuracy: 0.5429 - val_loss: 3.0141 - val_accuracy: 0.3564\n",
      "Epoch 660/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3596 - accuracy: 0.5405 - val_loss: 2.9906 - val_accuracy: 0.3546\n",
      "Epoch 661/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3660 - accuracy: 0.5468 - val_loss: 3.0287 - val_accuracy: 0.3443\n",
      "Epoch 662/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3632 - accuracy: 0.5417 - val_loss: 2.9970 - val_accuracy: 0.3540\n",
      "Epoch 663/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3653 - accuracy: 0.5395 - val_loss: 3.0154 - val_accuracy: 0.3510\n",
      "Epoch 664/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3687 - accuracy: 0.5385 - val_loss: 3.0049 - val_accuracy: 0.3613\n",
      "Epoch 665/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3609 - accuracy: 0.5389 - val_loss: 2.9991 - val_accuracy: 0.3473\n",
      "Epoch 666/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3576 - accuracy: 0.5408 - val_loss: 3.0151 - val_accuracy: 0.3528\n",
      "Epoch 667/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3740 - accuracy: 0.5363 - val_loss: 2.9719 - val_accuracy: 0.3564\n",
      "Epoch 668/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3531 - accuracy: 0.5398 - val_loss: 3.0045 - val_accuracy: 0.3485\n",
      "Epoch 669/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3639 - accuracy: 0.5418 - val_loss: 2.9846 - val_accuracy: 0.3534\n",
      "Epoch 670/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3526 - accuracy: 0.5447 - val_loss: 2.9725 - val_accuracy: 0.3637\n",
      "Epoch 671/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3451 - accuracy: 0.5481 - val_loss: 2.9829 - val_accuracy: 0.3589\n",
      "Epoch 672/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3504 - accuracy: 0.5470 - val_loss: 3.0116 - val_accuracy: 0.3546\n",
      "Epoch 673/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3611 - accuracy: 0.5429 - val_loss: 3.0300 - val_accuracy: 0.3461\n",
      "Epoch 674/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3580 - accuracy: 0.5435 - val_loss: 2.9947 - val_accuracy: 0.3534\n",
      "Epoch 675/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.5471 - val_loss: 3.0116 - val_accuracy: 0.3479\n",
      "Epoch 676/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3568 - accuracy: 0.5462 - val_loss: 3.0027 - val_accuracy: 0.3564\n",
      "Epoch 677/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3584 - accuracy: 0.5395 - val_loss: 3.0063 - val_accuracy: 0.3449\n",
      "Epoch 678/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3579 - accuracy: 0.5414 - val_loss: 3.0282 - val_accuracy: 0.3491\n",
      "Epoch 679/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3656 - accuracy: 0.5411 - val_loss: 3.0249 - val_accuracy: 0.3528\n",
      "Epoch 680/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3621 - accuracy: 0.5461 - val_loss: 2.9956 - val_accuracy: 0.3552\n",
      "Epoch 681/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.5435 - val_loss: 2.9930 - val_accuracy: 0.3589\n",
      "Epoch 682/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3579 - accuracy: 0.5433 - val_loss: 2.9884 - val_accuracy: 0.3656\n",
      "Epoch 683/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.5420 - val_loss: 3.0274 - val_accuracy: 0.3510\n",
      "Epoch 684/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3597 - accuracy: 0.5462 - val_loss: 3.0443 - val_accuracy: 0.3522\n",
      "Epoch 685/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3708 - accuracy: 0.5408 - val_loss: 3.0295 - val_accuracy: 0.3504\n",
      "Epoch 686/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3477 - accuracy: 0.5435 - val_loss: 3.0192 - val_accuracy: 0.3522\n",
      "Epoch 687/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3603 - accuracy: 0.5430 - val_loss: 3.0215 - val_accuracy: 0.3431\n",
      "Epoch 688/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.5427 - val_loss: 3.0060 - val_accuracy: 0.3540\n",
      "Epoch 689/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3638 - accuracy: 0.5470 - val_loss: 3.0101 - val_accuracy: 0.3479\n",
      "Epoch 690/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3566 - accuracy: 0.5479 - val_loss: 3.0269 - val_accuracy: 0.3485\n",
      "Epoch 691/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3585 - accuracy: 0.5406 - val_loss: 2.9987 - val_accuracy: 0.3498\n",
      "Epoch 692/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3495 - accuracy: 0.5443 - val_loss: 3.0288 - val_accuracy: 0.3437\n",
      "Epoch 693/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3545 - accuracy: 0.5433 - val_loss: 3.0034 - val_accuracy: 0.3522\n",
      "Epoch 694/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3599 - accuracy: 0.5412 - val_loss: 3.0084 - val_accuracy: 0.3607\n",
      "Epoch 695/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3547 - accuracy: 0.5450 - val_loss: 2.9785 - val_accuracy: 0.3650\n",
      "Epoch 696/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.5430 - val_loss: 2.9791 - val_accuracy: 0.3589\n",
      "Epoch 697/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3619 - accuracy: 0.5436 - val_loss: 3.0192 - val_accuracy: 0.3473\n",
      "Epoch 698/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.5427 - val_loss: 3.0015 - val_accuracy: 0.3540\n",
      "Epoch 699/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3585 - accuracy: 0.5458 - val_loss: 3.0116 - val_accuracy: 0.3504\n",
      "Epoch 700/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3616 - accuracy: 0.5412 - val_loss: 3.0085 - val_accuracy: 0.3558\n",
      "Epoch 701/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3516 - accuracy: 0.5441 - val_loss: 2.9976 - val_accuracy: 0.3491\n",
      "Epoch 702/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3667 - accuracy: 0.5438 - val_loss: 2.9921 - val_accuracy: 0.3479\n",
      "Epoch 703/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.5418 - val_loss: 2.9828 - val_accuracy: 0.3528\n",
      "Epoch 704/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3578 - accuracy: 0.5423 - val_loss: 3.0094 - val_accuracy: 0.3577\n",
      "Epoch 705/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3548 - accuracy: 0.5436 - val_loss: 3.0224 - val_accuracy: 0.3461\n",
      "Epoch 706/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5490 - val_loss: 3.0117 - val_accuracy: 0.3571\n",
      "Epoch 707/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5449 - val_loss: 3.0308 - val_accuracy: 0.3522\n",
      "Epoch 708/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5401 - val_loss: 3.0152 - val_accuracy: 0.3516\n",
      "Epoch 709/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3579 - accuracy: 0.5494 - val_loss: 3.0165 - val_accuracy: 0.3534\n",
      "Epoch 710/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3643 - accuracy: 0.5394 - val_loss: 3.0035 - val_accuracy: 0.3546\n",
      "Epoch 711/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3546 - accuracy: 0.5447 - val_loss: 3.0078 - val_accuracy: 0.3479\n",
      "Epoch 712/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3670 - accuracy: 0.5412 - val_loss: 3.0063 - val_accuracy: 0.3528\n",
      "Epoch 713/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3664 - accuracy: 0.5371 - val_loss: 3.0036 - val_accuracy: 0.3516\n",
      "Epoch 714/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3478 - accuracy: 0.5433 - val_loss: 2.9974 - val_accuracy: 0.3571\n",
      "Epoch 715/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3570 - accuracy: 0.5436 - val_loss: 3.0365 - val_accuracy: 0.3504\n",
      "Epoch 716/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3615 - accuracy: 0.5414 - val_loss: 3.0199 - val_accuracy: 0.3522\n",
      "Epoch 717/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.5408 - val_loss: 3.0058 - val_accuracy: 0.3558\n",
      "Epoch 718/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3588 - accuracy: 0.5435 - val_loss: 3.0154 - val_accuracy: 0.3558\n",
      "Epoch 719/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3620 - accuracy: 0.5467 - val_loss: 3.0163 - val_accuracy: 0.3491\n",
      "Epoch 720/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3596 - accuracy: 0.5444 - val_loss: 3.0074 - val_accuracy: 0.3534\n",
      "Epoch 721/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3546 - accuracy: 0.5488 - val_loss: 3.0404 - val_accuracy: 0.3491\n",
      "Epoch 722/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3506 - accuracy: 0.5470 - val_loss: 3.0112 - val_accuracy: 0.3564\n",
      "Epoch 723/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.5450 - val_loss: 3.0122 - val_accuracy: 0.3504\n",
      "Epoch 724/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3554 - accuracy: 0.5468 - val_loss: 3.0363 - val_accuracy: 0.3504\n",
      "Epoch 725/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.5453 - val_loss: 3.0183 - val_accuracy: 0.3516\n",
      "Epoch 726/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3486 - accuracy: 0.5458 - val_loss: 3.0362 - val_accuracy: 0.3546\n",
      "Epoch 727/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3568 - accuracy: 0.5443 - val_loss: 3.0151 - val_accuracy: 0.3449\n",
      "Epoch 728/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3516 - accuracy: 0.5462 - val_loss: 3.0445 - val_accuracy: 0.3491\n",
      "Epoch 729/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3644 - accuracy: 0.5406 - val_loss: 3.0487 - val_accuracy: 0.3467\n",
      "Epoch 730/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3622 - accuracy: 0.5426 - val_loss: 3.0552 - val_accuracy: 0.3516\n",
      "Epoch 731/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3484 - accuracy: 0.5493 - val_loss: 3.0293 - val_accuracy: 0.3473\n",
      "Epoch 732/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.5435 - val_loss: 2.9915 - val_accuracy: 0.3710\n",
      "Epoch 733/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3569 - accuracy: 0.5441 - val_loss: 3.0058 - val_accuracy: 0.3668\n",
      "Epoch 734/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3586 - accuracy: 0.5446 - val_loss: 3.0407 - val_accuracy: 0.3516\n",
      "Epoch 735/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3607 - accuracy: 0.5455 - val_loss: 3.0540 - val_accuracy: 0.3467\n",
      "Epoch 736/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3606 - accuracy: 0.5450 - val_loss: 3.0106 - val_accuracy: 0.3577\n",
      "Epoch 737/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.5453 - val_loss: 3.0238 - val_accuracy: 0.3467\n",
      "Epoch 738/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3619 - accuracy: 0.5467 - val_loss: 2.9851 - val_accuracy: 0.3583\n",
      "Epoch 739/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3601 - accuracy: 0.5415 - val_loss: 3.0378 - val_accuracy: 0.3546\n",
      "Epoch 740/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3548 - accuracy: 0.5429 - val_loss: 3.0326 - val_accuracy: 0.3455\n",
      "Epoch 741/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3657 - accuracy: 0.5433 - val_loss: 3.0156 - val_accuracy: 0.3522\n",
      "Epoch 742/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3517 - accuracy: 0.5426 - val_loss: 3.0285 - val_accuracy: 0.3540\n",
      "Epoch 743/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3524 - accuracy: 0.5523 - val_loss: 3.0169 - val_accuracy: 0.3443\n",
      "Epoch 744/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3577 - accuracy: 0.5441 - val_loss: 3.0236 - val_accuracy: 0.3479\n",
      "Epoch 745/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3600 - accuracy: 0.5415 - val_loss: 2.9910 - val_accuracy: 0.3510\n",
      "Epoch 746/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.5447 - val_loss: 2.9977 - val_accuracy: 0.3564\n",
      "Epoch 747/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3524 - accuracy: 0.5488 - val_loss: 3.0375 - val_accuracy: 0.3467\n",
      "Epoch 748/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3570 - accuracy: 0.5406 - val_loss: 3.0283 - val_accuracy: 0.3491\n",
      "Epoch 749/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3650 - accuracy: 0.5389 - val_loss: 3.0436 - val_accuracy: 0.3467\n",
      "Epoch 750/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3644 - accuracy: 0.5430 - val_loss: 3.0064 - val_accuracy: 0.3498\n",
      "Epoch 751/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5415 - val_loss: 3.0338 - val_accuracy: 0.3522\n",
      "Epoch 752/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3581 - accuracy: 0.5430 - val_loss: 3.0480 - val_accuracy: 0.3504\n",
      "Epoch 753/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3538 - accuracy: 0.5459 - val_loss: 3.0071 - val_accuracy: 0.3577\n",
      "Epoch 754/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3602 - accuracy: 0.5438 - val_loss: 3.0339 - val_accuracy: 0.3473\n",
      "Epoch 755/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.5432 - val_loss: 3.0249 - val_accuracy: 0.3510\n",
      "Epoch 756/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3528 - accuracy: 0.5455 - val_loss: 3.0426 - val_accuracy: 0.3498\n",
      "Epoch 757/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3572 - accuracy: 0.5462 - val_loss: 3.0371 - val_accuracy: 0.3546\n",
      "Epoch 758/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3556 - accuracy: 0.5468 - val_loss: 3.0059 - val_accuracy: 0.3674\n",
      "Epoch 759/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3532 - accuracy: 0.5435 - val_loss: 3.0296 - val_accuracy: 0.3546\n",
      "Epoch 760/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3619 - accuracy: 0.5421 - val_loss: 3.0129 - val_accuracy: 0.3552\n",
      "Epoch 761/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3505 - accuracy: 0.5424 - val_loss: 3.0235 - val_accuracy: 0.3498\n",
      "Epoch 762/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3612 - accuracy: 0.5452 - val_loss: 3.0504 - val_accuracy: 0.3546\n",
      "Epoch 763/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3540 - accuracy: 0.5461 - val_loss: 3.0335 - val_accuracy: 0.3552\n",
      "Epoch 764/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.5462 - val_loss: 3.0112 - val_accuracy: 0.3546\n",
      "Epoch 765/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3629 - accuracy: 0.5432 - val_loss: 3.0307 - val_accuracy: 0.3522\n",
      "Epoch 766/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3584 - accuracy: 0.5405 - val_loss: 3.0319 - val_accuracy: 0.3510\n",
      "Epoch 767/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.5462 - val_loss: 3.0193 - val_accuracy: 0.3601\n",
      "Epoch 768/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3620 - accuracy: 0.5405 - val_loss: 3.0395 - val_accuracy: 0.3479\n",
      "Epoch 769/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3537 - accuracy: 0.5429 - val_loss: 3.0364 - val_accuracy: 0.3540\n",
      "Epoch 770/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3593 - accuracy: 0.5426 - val_loss: 3.0206 - val_accuracy: 0.3516\n",
      "Epoch 771/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3468 - accuracy: 0.5447 - val_loss: 3.0294 - val_accuracy: 0.3571\n",
      "Epoch 772/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3456 - accuracy: 0.5482 - val_loss: 3.0455 - val_accuracy: 0.3394\n",
      "Epoch 773/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5490 - val_loss: 3.0478 - val_accuracy: 0.3504\n",
      "Epoch 774/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3666 - accuracy: 0.5395 - val_loss: 3.0096 - val_accuracy: 0.3540\n",
      "Epoch 775/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3554 - accuracy: 0.5395 - val_loss: 3.0437 - val_accuracy: 0.3504\n",
      "Epoch 776/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3487 - accuracy: 0.5462 - val_loss: 3.0398 - val_accuracy: 0.3437\n",
      "Epoch 777/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.5383 - val_loss: 3.0314 - val_accuracy: 0.3552\n",
      "Epoch 778/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3603 - accuracy: 0.5444 - val_loss: 3.0131 - val_accuracy: 0.3571\n",
      "Epoch 779/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3597 - accuracy: 0.5453 - val_loss: 3.0170 - val_accuracy: 0.3504\n",
      "Epoch 780/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3489 - accuracy: 0.5421 - val_loss: 3.0114 - val_accuracy: 0.3595\n",
      "Epoch 781/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3600 - accuracy: 0.5432 - val_loss: 3.0254 - val_accuracy: 0.3558\n",
      "Epoch 782/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3605 - accuracy: 0.5418 - val_loss: 3.0238 - val_accuracy: 0.3528\n",
      "Epoch 783/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3587 - accuracy: 0.5444 - val_loss: 3.0144 - val_accuracy: 0.3504\n",
      "Epoch 784/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3527 - accuracy: 0.5414 - val_loss: 3.0331 - val_accuracy: 0.3558\n",
      "Epoch 785/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3536 - accuracy: 0.5453 - val_loss: 3.0363 - val_accuracy: 0.3528\n",
      "Epoch 786/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3612 - accuracy: 0.5446 - val_loss: 3.0398 - val_accuracy: 0.3485\n",
      "Epoch 787/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3587 - accuracy: 0.5452 - val_loss: 3.0252 - val_accuracy: 0.3516\n",
      "Epoch 788/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3563 - accuracy: 0.5458 - val_loss: 3.0268 - val_accuracy: 0.3479\n",
      "Epoch 789/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3573 - accuracy: 0.5432 - val_loss: 3.0368 - val_accuracy: 0.3534\n",
      "Epoch 790/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5473 - val_loss: 3.0088 - val_accuracy: 0.3583\n",
      "Epoch 791/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5383 - val_loss: 3.0333 - val_accuracy: 0.3455\n",
      "Epoch 792/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3515 - accuracy: 0.5395 - val_loss: 3.0205 - val_accuracy: 0.3534\n",
      "Epoch 793/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3608 - accuracy: 0.5432 - val_loss: 3.0241 - val_accuracy: 0.3546\n",
      "Epoch 794/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3607 - accuracy: 0.5456 - val_loss: 2.9999 - val_accuracy: 0.3583\n",
      "Epoch 795/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3530 - accuracy: 0.5446 - val_loss: 3.0335 - val_accuracy: 0.3540\n",
      "Epoch 796/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5467 - val_loss: 3.0421 - val_accuracy: 0.3607\n",
      "Epoch 797/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5452 - val_loss: 3.0444 - val_accuracy: 0.3552\n",
      "Epoch 798/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3589 - accuracy: 0.5418 - val_loss: 3.0597 - val_accuracy: 0.3552\n",
      "Epoch 799/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3466 - accuracy: 0.5450 - val_loss: 3.0440 - val_accuracy: 0.3534\n",
      "Epoch 800/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3469 - accuracy: 0.5494 - val_loss: 3.0238 - val_accuracy: 0.3637\n",
      "Epoch 801/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3530 - accuracy: 0.5432 - val_loss: 3.0335 - val_accuracy: 0.3577\n",
      "Epoch 802/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3521 - accuracy: 0.5447 - val_loss: 3.0252 - val_accuracy: 0.3504\n",
      "Epoch 803/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3507 - accuracy: 0.5405 - val_loss: 2.9863 - val_accuracy: 0.3656\n",
      "Epoch 804/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5455 - val_loss: 3.0259 - val_accuracy: 0.3607\n",
      "Epoch 805/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3599 - accuracy: 0.5433 - val_loss: 3.0070 - val_accuracy: 0.3571\n",
      "Epoch 806/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3594 - accuracy: 0.5400 - val_loss: 3.0561 - val_accuracy: 0.3498\n",
      "Epoch 807/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3586 - accuracy: 0.5432 - val_loss: 2.9945 - val_accuracy: 0.3540\n",
      "Epoch 808/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3490 - accuracy: 0.5471 - val_loss: 3.0309 - val_accuracy: 0.3564\n",
      "Epoch 809/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3521 - accuracy: 0.5470 - val_loss: 3.0220 - val_accuracy: 0.3564\n",
      "Epoch 810/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3555 - accuracy: 0.5435 - val_loss: 3.0489 - val_accuracy: 0.3552\n",
      "Epoch 811/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3649 - accuracy: 0.5400 - val_loss: 3.0054 - val_accuracy: 0.3546\n",
      "Epoch 812/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3581 - accuracy: 0.5400 - val_loss: 3.0252 - val_accuracy: 0.3504\n",
      "Epoch 813/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3530 - accuracy: 0.5439 - val_loss: 3.0445 - val_accuracy: 0.3552\n",
      "Epoch 814/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5433 - val_loss: 3.0344 - val_accuracy: 0.3534\n",
      "Epoch 815/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3554 - accuracy: 0.5441 - val_loss: 3.0165 - val_accuracy: 0.3516\n",
      "Epoch 816/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3547 - accuracy: 0.5415 - val_loss: 3.0519 - val_accuracy: 0.3546\n",
      "Epoch 817/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3578 - accuracy: 0.5356 - val_loss: 3.0173 - val_accuracy: 0.3498\n",
      "Epoch 818/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3513 - accuracy: 0.5418 - val_loss: 3.0337 - val_accuracy: 0.3522\n",
      "Epoch 819/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3607 - accuracy: 0.5438 - val_loss: 3.0603 - val_accuracy: 0.3528\n",
      "Epoch 820/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3474 - accuracy: 0.5490 - val_loss: 3.0349 - val_accuracy: 0.3485\n",
      "Epoch 821/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3512 - accuracy: 0.5430 - val_loss: 3.0313 - val_accuracy: 0.3564\n",
      "Epoch 822/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3592 - accuracy: 0.5401 - val_loss: 3.0465 - val_accuracy: 0.3437\n",
      "Epoch 823/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3510 - accuracy: 0.5511 - val_loss: 3.0332 - val_accuracy: 0.3491\n",
      "Epoch 824/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3589 - accuracy: 0.5441 - val_loss: 3.0329 - val_accuracy: 0.3540\n",
      "Epoch 825/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3537 - accuracy: 0.5405 - val_loss: 3.0286 - val_accuracy: 0.3510\n",
      "Epoch 826/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3574 - accuracy: 0.5392 - val_loss: 3.0291 - val_accuracy: 0.3546\n",
      "Epoch 827/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3500 - accuracy: 0.5467 - val_loss: 3.0243 - val_accuracy: 0.3461\n",
      "Epoch 828/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3524 - accuracy: 0.5458 - val_loss: 3.0504 - val_accuracy: 0.3498\n",
      "Epoch 829/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.5421 - val_loss: 3.0285 - val_accuracy: 0.3534\n",
      "Epoch 830/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3493 - accuracy: 0.5417 - val_loss: 3.0571 - val_accuracy: 0.3485\n",
      "Epoch 831/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5426 - val_loss: 3.0345 - val_accuracy: 0.3516\n",
      "Epoch 832/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3502 - accuracy: 0.5502 - val_loss: 3.0265 - val_accuracy: 0.3510\n",
      "Epoch 833/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5414 - val_loss: 3.0276 - val_accuracy: 0.3546\n",
      "Epoch 834/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5417 - val_loss: 3.0184 - val_accuracy: 0.3485\n",
      "Epoch 835/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3562 - accuracy: 0.5383 - val_loss: 3.0423 - val_accuracy: 0.3485\n",
      "Epoch 836/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5414 - val_loss: 3.0394 - val_accuracy: 0.3552\n",
      "Epoch 837/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.5444 - val_loss: 3.0130 - val_accuracy: 0.3625\n",
      "Epoch 838/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3556 - accuracy: 0.5467 - val_loss: 3.0523 - val_accuracy: 0.3425\n",
      "Epoch 839/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3548 - accuracy: 0.5443 - val_loss: 3.0114 - val_accuracy: 0.3516\n",
      "Epoch 840/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3578 - accuracy: 0.5405 - val_loss: 2.9945 - val_accuracy: 0.3668\n",
      "Epoch 841/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3548 - accuracy: 0.5444 - val_loss: 3.0194 - val_accuracy: 0.3577\n",
      "Epoch 842/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3555 - accuracy: 0.5432 - val_loss: 3.0044 - val_accuracy: 0.3577\n",
      "Epoch 843/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3486 - accuracy: 0.5450 - val_loss: 3.0222 - val_accuracy: 0.3601\n",
      "Epoch 844/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3650 - accuracy: 0.5424 - val_loss: 3.0494 - val_accuracy: 0.3437\n",
      "Epoch 845/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3511 - accuracy: 0.5505 - val_loss: 3.0342 - val_accuracy: 0.3522\n",
      "Epoch 846/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3614 - accuracy: 0.5392 - val_loss: 3.0386 - val_accuracy: 0.3473\n",
      "Epoch 847/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3592 - accuracy: 0.5423 - val_loss: 3.0137 - val_accuracy: 0.3546\n",
      "Epoch 848/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3553 - accuracy: 0.5446 - val_loss: 3.0070 - val_accuracy: 0.3601\n",
      "Epoch 849/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.5438 - val_loss: 3.0313 - val_accuracy: 0.3491\n",
      "Epoch 850/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5400 - val_loss: 3.0384 - val_accuracy: 0.3479\n",
      "Epoch 851/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3515 - accuracy: 0.5385 - val_loss: 3.0230 - val_accuracy: 0.3613\n",
      "Epoch 852/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3573 - accuracy: 0.5397 - val_loss: 3.0266 - val_accuracy: 0.3540\n",
      "Epoch 853/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5438 - val_loss: 3.0491 - val_accuracy: 0.3449\n",
      "Epoch 854/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3492 - accuracy: 0.5427 - val_loss: 3.0260 - val_accuracy: 0.3498\n",
      "Epoch 855/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3462 - accuracy: 0.5464 - val_loss: 3.0289 - val_accuracy: 0.3491\n",
      "Epoch 856/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3460 - accuracy: 0.5459 - val_loss: 3.0614 - val_accuracy: 0.3479\n",
      "Epoch 857/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3540 - accuracy: 0.5455 - val_loss: 3.0003 - val_accuracy: 0.3607\n",
      "Epoch 858/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3615 - accuracy: 0.5376 - val_loss: 3.0176 - val_accuracy: 0.3485\n",
      "Epoch 859/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3518 - accuracy: 0.5438 - val_loss: 3.0317 - val_accuracy: 0.3473\n",
      "Epoch 860/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3463 - accuracy: 0.5471 - val_loss: 3.0313 - val_accuracy: 0.3491\n",
      "Epoch 861/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3563 - accuracy: 0.5446 - val_loss: 3.0297 - val_accuracy: 0.3498\n",
      "Epoch 862/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3463 - accuracy: 0.5443 - val_loss: 3.0175 - val_accuracy: 0.3540\n",
      "Epoch 863/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3458 - accuracy: 0.5468 - val_loss: 3.0295 - val_accuracy: 0.3485\n",
      "Epoch 864/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3434 - accuracy: 0.5491 - val_loss: 3.0258 - val_accuracy: 0.3498\n",
      "Epoch 865/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3481 - accuracy: 0.5488 - val_loss: 3.0341 - val_accuracy: 0.3498\n",
      "Epoch 866/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3588 - accuracy: 0.5432 - val_loss: 3.0083 - val_accuracy: 0.3558\n",
      "Epoch 867/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3514 - accuracy: 0.5447 - val_loss: 3.0144 - val_accuracy: 0.3564\n",
      "Epoch 868/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5430 - val_loss: 3.0316 - val_accuracy: 0.3473\n",
      "Epoch 869/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3452 - accuracy: 0.5494 - val_loss: 3.0299 - val_accuracy: 0.3546\n",
      "Epoch 870/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3525 - accuracy: 0.5476 - val_loss: 3.0103 - val_accuracy: 0.3522\n",
      "Epoch 871/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3561 - accuracy: 0.5400 - val_loss: 3.0271 - val_accuracy: 0.3571\n",
      "Epoch 872/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.5417 - val_loss: 3.0507 - val_accuracy: 0.3516\n",
      "Epoch 873/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3540 - accuracy: 0.5409 - val_loss: 3.0339 - val_accuracy: 0.3595\n",
      "Epoch 874/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5453 - val_loss: 3.0021 - val_accuracy: 0.3479\n",
      "Epoch 875/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3685 - accuracy: 0.5405 - val_loss: 2.9864 - val_accuracy: 0.3656\n",
      "Epoch 876/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3506 - accuracy: 0.5456 - val_loss: 3.0280 - val_accuracy: 0.3589\n",
      "Epoch 877/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3445 - accuracy: 0.5528 - val_loss: 3.0579 - val_accuracy: 0.3498\n",
      "Epoch 878/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3569 - accuracy: 0.5482 - val_loss: 3.0398 - val_accuracy: 0.3510\n",
      "Epoch 879/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3572 - accuracy: 0.5406 - val_loss: 3.0490 - val_accuracy: 0.3504\n",
      "Epoch 880/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3545 - accuracy: 0.5449 - val_loss: 3.0251 - val_accuracy: 0.3504\n",
      "Epoch 881/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3480 - accuracy: 0.5415 - val_loss: 3.0596 - val_accuracy: 0.3425\n",
      "Epoch 882/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3558 - accuracy: 0.5459 - val_loss: 3.0340 - val_accuracy: 0.3510\n",
      "Epoch 883/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3501 - accuracy: 0.5488 - val_loss: 3.0479 - val_accuracy: 0.3473\n",
      "Epoch 884/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3541 - accuracy: 0.5429 - val_loss: 3.0028 - val_accuracy: 0.3595\n",
      "Epoch 885/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.5461 - val_loss: 3.0349 - val_accuracy: 0.3577\n",
      "Epoch 886/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5427 - val_loss: 3.0528 - val_accuracy: 0.3412\n",
      "Epoch 887/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3478 - accuracy: 0.5449 - val_loss: 3.0600 - val_accuracy: 0.3510\n",
      "Epoch 888/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3563 - accuracy: 0.5417 - val_loss: 3.0407 - val_accuracy: 0.3577\n",
      "Epoch 889/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3523 - accuracy: 0.5443 - val_loss: 3.0297 - val_accuracy: 0.3510\n",
      "Epoch 890/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5424 - val_loss: 3.0369 - val_accuracy: 0.3540\n",
      "Epoch 891/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5484 - val_loss: 3.0505 - val_accuracy: 0.3534\n",
      "Epoch 892/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3628 - accuracy: 0.5443 - val_loss: 3.0106 - val_accuracy: 0.3583\n",
      "Epoch 893/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3553 - accuracy: 0.5446 - val_loss: 3.0321 - val_accuracy: 0.3431\n",
      "Epoch 894/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3500 - accuracy: 0.5436 - val_loss: 3.0386 - val_accuracy: 0.3443\n",
      "Epoch 895/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.5494 - val_loss: 3.0710 - val_accuracy: 0.3461\n",
      "Epoch 896/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3521 - accuracy: 0.5456 - val_loss: 3.0454 - val_accuracy: 0.3595\n",
      "Epoch 897/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3483 - accuracy: 0.5424 - val_loss: 3.0320 - val_accuracy: 0.3516\n",
      "Epoch 898/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.5408 - val_loss: 3.0418 - val_accuracy: 0.3546\n",
      "Epoch 899/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3581 - accuracy: 0.5376 - val_loss: 3.0149 - val_accuracy: 0.3534\n",
      "Epoch 900/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3514 - accuracy: 0.5444 - val_loss: 3.0205 - val_accuracy: 0.3583\n",
      "Epoch 901/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3443 - accuracy: 0.5449 - val_loss: 3.0410 - val_accuracy: 0.3558\n",
      "Epoch 902/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3533 - accuracy: 0.5470 - val_loss: 3.0449 - val_accuracy: 0.3571\n",
      "Epoch 903/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3473 - accuracy: 0.5421 - val_loss: 3.0488 - val_accuracy: 0.3491\n",
      "Epoch 904/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3466 - accuracy: 0.5467 - val_loss: 3.0416 - val_accuracy: 0.3540\n",
      "Epoch 905/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3428 - accuracy: 0.5503 - val_loss: 3.0289 - val_accuracy: 0.3534\n",
      "Epoch 906/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3575 - accuracy: 0.5430 - val_loss: 3.0591 - val_accuracy: 0.3455\n",
      "Epoch 907/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3483 - accuracy: 0.5446 - val_loss: 3.0464 - val_accuracy: 0.3461\n",
      "Epoch 908/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3508 - accuracy: 0.5446 - val_loss: 3.0674 - val_accuracy: 0.3443\n",
      "Epoch 909/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3575 - accuracy: 0.5462 - val_loss: 3.0606 - val_accuracy: 0.3498\n",
      "Epoch 910/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5477 - val_loss: 3.0415 - val_accuracy: 0.3613\n",
      "Epoch 911/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3577 - accuracy: 0.5421 - val_loss: 3.0216 - val_accuracy: 0.3510\n",
      "Epoch 912/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3541 - accuracy: 0.5444 - val_loss: 3.0414 - val_accuracy: 0.3504\n",
      "Epoch 913/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3451 - accuracy: 0.5435 - val_loss: 3.0519 - val_accuracy: 0.3473\n",
      "Epoch 914/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3445 - accuracy: 0.5443 - val_loss: 3.0448 - val_accuracy: 0.3504\n",
      "Epoch 915/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3508 - accuracy: 0.5511 - val_loss: 3.0290 - val_accuracy: 0.3491\n",
      "Epoch 916/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3616 - accuracy: 0.5424 - val_loss: 3.0413 - val_accuracy: 0.3571\n",
      "Epoch 917/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3523 - accuracy: 0.5481 - val_loss: 3.0311 - val_accuracy: 0.3510\n",
      "Epoch 918/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3496 - accuracy: 0.5417 - val_loss: 3.0289 - val_accuracy: 0.3668\n",
      "Epoch 919/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3525 - accuracy: 0.5452 - val_loss: 3.0631 - val_accuracy: 0.3583\n",
      "Epoch 920/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.5429 - val_loss: 3.0422 - val_accuracy: 0.3467\n",
      "Epoch 921/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5430 - val_loss: 3.0512 - val_accuracy: 0.3528\n",
      "Epoch 922/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3557 - accuracy: 0.5415 - val_loss: 3.0232 - val_accuracy: 0.3595\n",
      "Epoch 923/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3512 - accuracy: 0.5439 - val_loss: 3.0521 - val_accuracy: 0.3619\n",
      "Epoch 924/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3481 - accuracy: 0.5462 - val_loss: 3.0412 - val_accuracy: 0.3546\n",
      "Epoch 925/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3445 - accuracy: 0.5485 - val_loss: 3.0370 - val_accuracy: 0.3522\n",
      "Epoch 926/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3438 - accuracy: 0.5508 - val_loss: 3.0504 - val_accuracy: 0.3510\n",
      "Epoch 927/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3522 - accuracy: 0.5433 - val_loss: 3.0443 - val_accuracy: 0.3510\n",
      "Epoch 928/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3491 - accuracy: 0.5443 - val_loss: 3.0488 - val_accuracy: 0.3595\n",
      "Epoch 929/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3605 - accuracy: 0.5420 - val_loss: 3.0290 - val_accuracy: 0.3522\n",
      "Epoch 930/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3567 - accuracy: 0.5452 - val_loss: 3.0885 - val_accuracy: 0.3425\n",
      "Epoch 931/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3495 - accuracy: 0.5505 - val_loss: 3.0543 - val_accuracy: 0.3534\n",
      "Epoch 932/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3518 - accuracy: 0.5467 - val_loss: 3.0751 - val_accuracy: 0.3437\n",
      "Epoch 933/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3602 - accuracy: 0.5415 - val_loss: 3.0517 - val_accuracy: 0.3540\n",
      "Epoch 934/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5485 - val_loss: 3.0604 - val_accuracy: 0.3485\n",
      "Epoch 935/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3528 - accuracy: 0.5458 - val_loss: 3.0501 - val_accuracy: 0.3510\n",
      "Epoch 936/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3441 - accuracy: 0.5452 - val_loss: 3.0448 - val_accuracy: 0.3504\n",
      "Epoch 937/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3445 - accuracy: 0.5479 - val_loss: 3.0557 - val_accuracy: 0.3455\n",
      "Epoch 938/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5424 - val_loss: 3.0424 - val_accuracy: 0.3571\n",
      "Epoch 939/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3520 - accuracy: 0.5473 - val_loss: 3.0350 - val_accuracy: 0.3540\n",
      "Epoch 940/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3610 - accuracy: 0.5459 - val_loss: 3.0495 - val_accuracy: 0.3498\n",
      "Epoch 941/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3425 - accuracy: 0.5465 - val_loss: 3.0314 - val_accuracy: 0.3589\n",
      "Epoch 942/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3469 - accuracy: 0.5485 - val_loss: 3.0495 - val_accuracy: 0.3528\n",
      "Epoch 943/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3472 - accuracy: 0.5464 - val_loss: 3.0331 - val_accuracy: 0.3674\n",
      "Epoch 944/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3501 - accuracy: 0.5465 - val_loss: 3.0420 - val_accuracy: 0.3607\n",
      "Epoch 945/1000\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3503 - accuracy: 0.5468 - val_loss: 3.0625 - val_accuracy: 0.3577\n",
      "Epoch 946/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3456 - accuracy: 0.5429 - val_loss: 3.0592 - val_accuracy: 0.3479\n",
      "Epoch 947/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3532 - accuracy: 0.5459 - val_loss: 3.0675 - val_accuracy: 0.3601\n",
      "Epoch 948/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3596 - accuracy: 0.5452 - val_loss: 3.0610 - val_accuracy: 0.3571\n",
      "Epoch 949/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3415 - accuracy: 0.5456 - val_loss: 3.0376 - val_accuracy: 0.3577\n",
      "Epoch 950/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3469 - accuracy: 0.5506 - val_loss: 3.0713 - val_accuracy: 0.3455\n",
      "Epoch 951/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3487 - accuracy: 0.5438 - val_loss: 3.0743 - val_accuracy: 0.3540\n",
      "Epoch 952/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3505 - accuracy: 0.5458 - val_loss: 3.0242 - val_accuracy: 0.3613\n",
      "Epoch 953/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5411 - val_loss: 3.0502 - val_accuracy: 0.3601\n",
      "Epoch 954/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3547 - accuracy: 0.5409 - val_loss: 3.0595 - val_accuracy: 0.3534\n",
      "Epoch 955/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3492 - accuracy: 0.5435 - val_loss: 3.0560 - val_accuracy: 0.3449\n",
      "Epoch 956/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3481 - accuracy: 0.5444 - val_loss: 3.0275 - val_accuracy: 0.3577\n",
      "Epoch 957/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3451 - accuracy: 0.5433 - val_loss: 3.0440 - val_accuracy: 0.3540\n",
      "Epoch 958/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3486 - accuracy: 0.5481 - val_loss: 3.0513 - val_accuracy: 0.3607\n",
      "Epoch 959/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5473 - val_loss: 3.0519 - val_accuracy: 0.3498\n",
      "Epoch 960/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3454 - accuracy: 0.5459 - val_loss: 3.0648 - val_accuracy: 0.3504\n",
      "Epoch 961/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3526 - accuracy: 0.5429 - val_loss: 3.0532 - val_accuracy: 0.3516\n",
      "Epoch 962/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3633 - accuracy: 0.5406 - val_loss: 3.0502 - val_accuracy: 0.3443\n",
      "Epoch 963/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3459 - accuracy: 0.5488 - val_loss: 3.0512 - val_accuracy: 0.3491\n",
      "Epoch 964/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3514 - accuracy: 0.5452 - val_loss: 3.0778 - val_accuracy: 0.3461\n",
      "Epoch 965/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3549 - accuracy: 0.5453 - val_loss: 3.0377 - val_accuracy: 0.3479\n",
      "Epoch 966/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3508 - accuracy: 0.5439 - val_loss: 3.0641 - val_accuracy: 0.3443\n",
      "Epoch 967/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3438 - accuracy: 0.5446 - val_loss: 3.0816 - val_accuracy: 0.3479\n",
      "Epoch 968/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3529 - accuracy: 0.5446 - val_loss: 3.0790 - val_accuracy: 0.3534\n",
      "Epoch 969/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3559 - accuracy: 0.5371 - val_loss: 3.0460 - val_accuracy: 0.3571\n",
      "Epoch 970/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3483 - accuracy: 0.5465 - val_loss: 3.0813 - val_accuracy: 0.3473\n",
      "Epoch 971/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3509 - accuracy: 0.5465 - val_loss: 3.0637 - val_accuracy: 0.3455\n",
      "Epoch 972/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5459 - val_loss: 3.0545 - val_accuracy: 0.3564\n",
      "Epoch 973/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3478 - accuracy: 0.5426 - val_loss: 3.0630 - val_accuracy: 0.3485\n",
      "Epoch 974/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3504 - accuracy: 0.5443 - val_loss: 3.0801 - val_accuracy: 0.3449\n",
      "Epoch 975/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3525 - accuracy: 0.5468 - val_loss: 3.0631 - val_accuracy: 0.3540\n",
      "Epoch 976/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3425 - accuracy: 0.5519 - val_loss: 3.0362 - val_accuracy: 0.3571\n",
      "Epoch 977/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3550 - accuracy: 0.5415 - val_loss: 3.0053 - val_accuracy: 0.3516\n",
      "Epoch 978/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3519 - accuracy: 0.5471 - val_loss: 3.0370 - val_accuracy: 0.3510\n",
      "Epoch 979/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3589 - accuracy: 0.5459 - val_loss: 3.0994 - val_accuracy: 0.3400\n",
      "Epoch 980/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3554 - accuracy: 0.5450 - val_loss: 3.0410 - val_accuracy: 0.3522\n",
      "Epoch 981/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3400 - accuracy: 0.5464 - val_loss: 3.0427 - val_accuracy: 0.3485\n",
      "Epoch 982/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3477 - accuracy: 0.5432 - val_loss: 3.0466 - val_accuracy: 0.3418\n",
      "Epoch 983/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3489 - accuracy: 0.5447 - val_loss: 3.0720 - val_accuracy: 0.3382\n",
      "Epoch 984/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.5427 - val_loss: 3.0909 - val_accuracy: 0.3504\n",
      "Epoch 985/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3522 - accuracy: 0.5392 - val_loss: 3.0253 - val_accuracy: 0.3589\n",
      "Epoch 986/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3433 - accuracy: 0.5453 - val_loss: 3.0738 - val_accuracy: 0.3601\n",
      "Epoch 987/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3543 - accuracy: 0.5432 - val_loss: 3.0400 - val_accuracy: 0.3522\n",
      "Epoch 988/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.5418 - val_loss: 3.0577 - val_accuracy: 0.3431\n",
      "Epoch 989/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3455 - accuracy: 0.5456 - val_loss: 3.0738 - val_accuracy: 0.3491\n",
      "Epoch 990/1000\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.5438 - val_loss: 3.0444 - val_accuracy: 0.3522\n",
      "Epoch 991/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3507 - accuracy: 0.5456 - val_loss: 3.0332 - val_accuracy: 0.3552\n",
      "Epoch 992/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.5395 - val_loss: 3.0795 - val_accuracy: 0.3418\n",
      "Epoch 993/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3501 - accuracy: 0.5477 - val_loss: 3.0263 - val_accuracy: 0.3571\n",
      "Epoch 994/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3454 - accuracy: 0.5482 - val_loss: 3.0611 - val_accuracy: 0.3516\n",
      "Epoch 995/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3456 - accuracy: 0.5439 - val_loss: 3.0798 - val_accuracy: 0.3491\n",
      "Epoch 996/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3521 - accuracy: 0.5420 - val_loss: 3.0361 - val_accuracy: 0.3546\n",
      "Epoch 997/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3445 - accuracy: 0.5462 - val_loss: 3.0491 - val_accuracy: 0.3498\n",
      "Epoch 998/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3448 - accuracy: 0.5462 - val_loss: 3.0670 - val_accuracy: 0.3571\n",
      "Epoch 999/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3482 - accuracy: 0.5461 - val_loss: 3.0473 - val_accuracy: 0.3522\n",
      "Epoch 1000/1000\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3536 - accuracy: 0.5427 - val_loss: 3.0059 - val_accuracy: 0.3516\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model (batch size 32)\n",
    "history_emb_simple_32 = Emb_model_simple.fit(x_emb_train, y_emb_train,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=32,\n",
    "                                 validation_data=(x_emb_test, y_emb_test)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_Emb_baseline_model_history_bs32.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_simple_32.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 69 (Val Accuracy: 0.3759123980998993)\n",
      "Best Epoch for Training Accuracy: 877 (Train Accuracy: 0.5527676343917847)\n",
      "Best Epoch for Training Loss: 981 (Train Loss: 1.3400225639343262)\n",
      "Best Epoch for Validation Loss: 69 (Val Loss: 2.8436222076416016)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.3759123980998993\n",
      "Maximum Training Accuracy: 0.5527676343917847\n",
      "Minimum Training Loss: 1.3400225639343262\n",
      "Minimum Validation Loss: 2.8436222076416016\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_simple_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_simple_32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3448 - accuracy: 0.5496 - val_loss: 3.0523 - val_accuracy: 0.3540\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3386 - accuracy: 0.5470 - val_loss: 3.0824 - val_accuracy: 0.3455\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5531 - val_loss: 3.0635 - val_accuracy: 0.3540\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3328 - accuracy: 0.5456 - val_loss: 3.0622 - val_accuracy: 0.3528\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3396 - accuracy: 0.5465 - val_loss: 3.0565 - val_accuracy: 0.3491\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.5502 - val_loss: 3.0518 - val_accuracy: 0.3583\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3348 - accuracy: 0.5471 - val_loss: 3.0713 - val_accuracy: 0.3431\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3444 - accuracy: 0.5462 - val_loss: 3.0325 - val_accuracy: 0.3564\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3313 - accuracy: 0.5520 - val_loss: 3.0872 - val_accuracy: 0.3455\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3413 - accuracy: 0.5459 - val_loss: 3.0420 - val_accuracy: 0.3522\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3326 - accuracy: 0.5479 - val_loss: 3.0539 - val_accuracy: 0.3552\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3336 - accuracy: 0.5477 - val_loss: 3.0634 - val_accuracy: 0.3528\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3253 - accuracy: 0.5488 - val_loss: 3.0714 - val_accuracy: 0.3522\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3396 - accuracy: 0.5450 - val_loss: 3.0771 - val_accuracy: 0.3491\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3414 - accuracy: 0.5487 - val_loss: 3.0485 - val_accuracy: 0.3564\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3365 - accuracy: 0.5532 - val_loss: 3.0593 - val_accuracy: 0.3534\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3334 - accuracy: 0.5496 - val_loss: 3.0796 - val_accuracy: 0.3516\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3372 - accuracy: 0.5435 - val_loss: 3.0758 - val_accuracy: 0.3516\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3428 - accuracy: 0.5522 - val_loss: 3.0650 - val_accuracy: 0.3498\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3432 - accuracy: 0.5458 - val_loss: 3.0826 - val_accuracy: 0.3540\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3441 - accuracy: 0.5484 - val_loss: 3.0728 - val_accuracy: 0.3504\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3370 - accuracy: 0.5470 - val_loss: 3.0392 - val_accuracy: 0.3546\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5490 - val_loss: 3.0643 - val_accuracy: 0.3510\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3308 - accuracy: 0.5474 - val_loss: 3.0784 - val_accuracy: 0.3534\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3397 - accuracy: 0.5505 - val_loss: 3.0705 - val_accuracy: 0.3564\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3366 - accuracy: 0.5484 - val_loss: 3.0775 - val_accuracy: 0.3473\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3383 - accuracy: 0.5487 - val_loss: 3.0582 - val_accuracy: 0.3443\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3357 - accuracy: 0.5503 - val_loss: 3.0496 - val_accuracy: 0.3461\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.5465 - val_loss: 3.0843 - val_accuracy: 0.3443\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3393 - accuracy: 0.5462 - val_loss: 3.0793 - val_accuracy: 0.3467\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3354 - accuracy: 0.5467 - val_loss: 3.0914 - val_accuracy: 0.3431\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3403 - accuracy: 0.5471 - val_loss: 3.0900 - val_accuracy: 0.3510\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3388 - accuracy: 0.5487 - val_loss: 3.0639 - val_accuracy: 0.3467\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3414 - accuracy: 0.5430 - val_loss: 3.0375 - val_accuracy: 0.3589\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3353 - accuracy: 0.5450 - val_loss: 3.0764 - val_accuracy: 0.3498\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3417 - accuracy: 0.5488 - val_loss: 3.0502 - val_accuracy: 0.3498\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3466 - accuracy: 0.5446 - val_loss: 3.0548 - val_accuracy: 0.3516\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3411 - accuracy: 0.5443 - val_loss: 3.0893 - val_accuracy: 0.3516\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3380 - accuracy: 0.5427 - val_loss: 3.0649 - val_accuracy: 0.3516\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3443 - accuracy: 0.5490 - val_loss: 3.0586 - val_accuracy: 0.3528\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3405 - accuracy: 0.5459 - val_loss: 3.0866 - val_accuracy: 0.3564\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3398 - accuracy: 0.5465 - val_loss: 3.0930 - val_accuracy: 0.3504\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3410 - accuracy: 0.5450 - val_loss: 3.0731 - val_accuracy: 0.3498\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3419 - accuracy: 0.5421 - val_loss: 3.0745 - val_accuracy: 0.3546\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.5453 - val_loss: 3.0626 - val_accuracy: 0.3516\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3409 - accuracy: 0.5490 - val_loss: 3.0897 - val_accuracy: 0.3485\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3452 - accuracy: 0.5482 - val_loss: 3.0583 - val_accuracy: 0.3534\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3313 - accuracy: 0.5488 - val_loss: 3.0521 - val_accuracy: 0.3564\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3378 - accuracy: 0.5500 - val_loss: 3.0767 - val_accuracy: 0.3473\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3366 - accuracy: 0.5497 - val_loss: 3.0617 - val_accuracy: 0.3485\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3343 - accuracy: 0.5471 - val_loss: 3.0569 - val_accuracy: 0.3455\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.5421 - val_loss: 3.0659 - val_accuracy: 0.3534\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5499 - val_loss: 3.0673 - val_accuracy: 0.3510\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.5522 - val_loss: 3.0650 - val_accuracy: 0.3504\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3413 - accuracy: 0.5473 - val_loss: 3.0782 - val_accuracy: 0.3552\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3388 - accuracy: 0.5461 - val_loss: 3.0772 - val_accuracy: 0.3546\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3406 - accuracy: 0.5452 - val_loss: 3.0846 - val_accuracy: 0.3479\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3350 - accuracy: 0.5464 - val_loss: 3.0781 - val_accuracy: 0.3510\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3400 - accuracy: 0.5426 - val_loss: 3.0786 - val_accuracy: 0.3540\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3354 - accuracy: 0.5479 - val_loss: 3.1096 - val_accuracy: 0.3491\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3372 - accuracy: 0.5479 - val_loss: 3.1028 - val_accuracy: 0.3479\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3392 - accuracy: 0.5502 - val_loss: 3.0856 - val_accuracy: 0.3491\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3399 - accuracy: 0.5484 - val_loss: 3.0838 - val_accuracy: 0.3473\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3391 - accuracy: 0.5503 - val_loss: 3.0899 - val_accuracy: 0.3528\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.3402 - accuracy: 0.5420 - val_loss: 3.0531 - val_accuracy: 0.3479\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3331 - accuracy: 0.5500 - val_loss: 3.0799 - val_accuracy: 0.3540\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3320 - accuracy: 0.5557 - val_loss: 3.0779 - val_accuracy: 0.3528\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3394 - accuracy: 0.5462 - val_loss: 3.0617 - val_accuracy: 0.3534\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3354 - accuracy: 0.5506 - val_loss: 3.0521 - val_accuracy: 0.3577\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3435 - accuracy: 0.5479 - val_loss: 3.0885 - val_accuracy: 0.3498\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3355 - accuracy: 0.5447 - val_loss: 3.0498 - val_accuracy: 0.3546\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3359 - accuracy: 0.5456 - val_loss: 3.0566 - val_accuracy: 0.3534\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3302 - accuracy: 0.5473 - val_loss: 3.0810 - val_accuracy: 0.3577\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3394 - accuracy: 0.5479 - val_loss: 3.0998 - val_accuracy: 0.3467\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3390 - accuracy: 0.5529 - val_loss: 3.0655 - val_accuracy: 0.3558\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3388 - accuracy: 0.5468 - val_loss: 3.0526 - val_accuracy: 0.3589\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3342 - accuracy: 0.5477 - val_loss: 3.0602 - val_accuracy: 0.3571\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3417 - accuracy: 0.5436 - val_loss: 3.0729 - val_accuracy: 0.3534\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3341 - accuracy: 0.5488 - val_loss: 3.0646 - val_accuracy: 0.3473\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3275 - accuracy: 0.5479 - val_loss: 3.0872 - val_accuracy: 0.3552\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3342 - accuracy: 0.5503 - val_loss: 3.0843 - val_accuracy: 0.3546\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3345 - accuracy: 0.5503 - val_loss: 3.0859 - val_accuracy: 0.3485\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3404 - accuracy: 0.5465 - val_loss: 3.0702 - val_accuracy: 0.3467\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3375 - accuracy: 0.5512 - val_loss: 3.0553 - val_accuracy: 0.3528\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3370 - accuracy: 0.5453 - val_loss: 3.1041 - val_accuracy: 0.3516\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3423 - accuracy: 0.5468 - val_loss: 3.0640 - val_accuracy: 0.3583\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3401 - accuracy: 0.5450 - val_loss: 3.0905 - val_accuracy: 0.3449\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3461 - accuracy: 0.5441 - val_loss: 3.0839 - val_accuracy: 0.3528\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3320 - accuracy: 0.5497 - val_loss: 3.0627 - val_accuracy: 0.3564\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5487 - val_loss: 3.0868 - val_accuracy: 0.3491\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3427 - accuracy: 0.5473 - val_loss: 3.0642 - val_accuracy: 0.3613\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3361 - accuracy: 0.5484 - val_loss: 3.0868 - val_accuracy: 0.3583\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3358 - accuracy: 0.5505 - val_loss: 3.0911 - val_accuracy: 0.3540\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3383 - accuracy: 0.5487 - val_loss: 3.0674 - val_accuracy: 0.3607\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3376 - accuracy: 0.5453 - val_loss: 3.0953 - val_accuracy: 0.3540\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3414 - accuracy: 0.5484 - val_loss: 3.1107 - val_accuracy: 0.3400\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3325 - accuracy: 0.5525 - val_loss: 3.0811 - val_accuracy: 0.3516\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3334 - accuracy: 0.5479 - val_loss: 3.0644 - val_accuracy: 0.3552\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.5537 - val_loss: 3.0759 - val_accuracy: 0.3534\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3405 - accuracy: 0.5493 - val_loss: 3.0461 - val_accuracy: 0.3607\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5476 - val_loss: 3.0614 - val_accuracy: 0.3564\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3338 - accuracy: 0.5476 - val_loss: 3.0910 - val_accuracy: 0.3498\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3368 - accuracy: 0.5459 - val_loss: 3.0749 - val_accuracy: 0.3558\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3385 - accuracy: 0.5461 - val_loss: 3.0770 - val_accuracy: 0.3528\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5471 - val_loss: 3.0723 - val_accuracy: 0.3540\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3402 - accuracy: 0.5453 - val_loss: 3.0795 - val_accuracy: 0.3504\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3434 - accuracy: 0.5503 - val_loss: 3.0707 - val_accuracy: 0.3577\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3329 - accuracy: 0.5481 - val_loss: 3.1058 - val_accuracy: 0.3510\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5528 - val_loss: 3.0753 - val_accuracy: 0.3516\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3369 - accuracy: 0.5516 - val_loss: 3.0801 - val_accuracy: 0.3534\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3362 - accuracy: 0.5465 - val_loss: 3.0890 - val_accuracy: 0.3491\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3426 - accuracy: 0.5494 - val_loss: 3.0788 - val_accuracy: 0.3498\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3374 - accuracy: 0.5487 - val_loss: 3.0962 - val_accuracy: 0.3437\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5473 - val_loss: 3.0623 - val_accuracy: 0.3528\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3370 - accuracy: 0.5474 - val_loss: 3.0567 - val_accuracy: 0.3571\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3372 - accuracy: 0.5470 - val_loss: 3.0801 - val_accuracy: 0.3479\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3409 - accuracy: 0.5477 - val_loss: 3.0650 - val_accuracy: 0.3571\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3365 - accuracy: 0.5485 - val_loss: 3.0799 - val_accuracy: 0.3449\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.5458 - val_loss: 3.0956 - val_accuracy: 0.3583\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.5526 - val_loss: 3.1091 - val_accuracy: 0.3516\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3294 - accuracy: 0.5493 - val_loss: 3.0877 - val_accuracy: 0.3504\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3436 - accuracy: 0.5430 - val_loss: 3.0802 - val_accuracy: 0.3546\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3397 - accuracy: 0.5508 - val_loss: 3.0982 - val_accuracy: 0.3498\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3331 - accuracy: 0.5490 - val_loss: 3.0588 - val_accuracy: 0.3516\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3328 - accuracy: 0.5512 - val_loss: 3.0580 - val_accuracy: 0.3540\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3429 - accuracy: 0.5453 - val_loss: 3.0687 - val_accuracy: 0.3589\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3453 - accuracy: 0.5467 - val_loss: 3.0899 - val_accuracy: 0.3540\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3389 - accuracy: 0.5494 - val_loss: 3.1021 - val_accuracy: 0.3455\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3427 - accuracy: 0.5496 - val_loss: 3.0624 - val_accuracy: 0.3558\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3332 - accuracy: 0.5464 - val_loss: 3.1026 - val_accuracy: 0.3406\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3383 - accuracy: 0.5432 - val_loss: 3.0797 - val_accuracy: 0.3473\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3371 - accuracy: 0.5467 - val_loss: 3.0762 - val_accuracy: 0.3571\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3460 - accuracy: 0.5482 - val_loss: 3.0800 - val_accuracy: 0.3510\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3341 - accuracy: 0.5476 - val_loss: 3.0903 - val_accuracy: 0.3498\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3384 - accuracy: 0.5432 - val_loss: 3.0898 - val_accuracy: 0.3516\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3400 - accuracy: 0.5439 - val_loss: 3.0813 - val_accuracy: 0.3473\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3370 - accuracy: 0.5479 - val_loss: 3.0873 - val_accuracy: 0.3473\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3407 - accuracy: 0.5443 - val_loss: 3.0779 - val_accuracy: 0.3504\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3445 - accuracy: 0.5456 - val_loss: 3.0971 - val_accuracy: 0.3498\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.5502 - val_loss: 3.1025 - val_accuracy: 0.3498\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3329 - accuracy: 0.5464 - val_loss: 3.0835 - val_accuracy: 0.3473\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3399 - accuracy: 0.5449 - val_loss: 3.1003 - val_accuracy: 0.3485\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3307 - accuracy: 0.5512 - val_loss: 3.0993 - val_accuracy: 0.3467\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3370 - accuracy: 0.5429 - val_loss: 3.1040 - val_accuracy: 0.3540\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3331 - accuracy: 0.5522 - val_loss: 3.0901 - val_accuracy: 0.3510\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3393 - accuracy: 0.5461 - val_loss: 3.0808 - val_accuracy: 0.3491\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3413 - accuracy: 0.5508 - val_loss: 3.0753 - val_accuracy: 0.3504\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3325 - accuracy: 0.5508 - val_loss: 3.0583 - val_accuracy: 0.3534\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.5476 - val_loss: 3.1055 - val_accuracy: 0.3431\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3407 - accuracy: 0.5479 - val_loss: 3.0904 - val_accuracy: 0.3498\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3386 - accuracy: 0.5429 - val_loss: 3.0915 - val_accuracy: 0.3498\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3351 - accuracy: 0.5487 - val_loss: 3.0750 - val_accuracy: 0.3534\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3340 - accuracy: 0.5456 - val_loss: 3.0787 - val_accuracy: 0.3552\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3374 - accuracy: 0.5473 - val_loss: 3.1202 - val_accuracy: 0.3443\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3337 - accuracy: 0.5505 - val_loss: 3.0968 - val_accuracy: 0.3498\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3367 - accuracy: 0.5485 - val_loss: 3.0962 - val_accuracy: 0.3498\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.5476 - val_loss: 3.1101 - val_accuracy: 0.3406\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3435 - accuracy: 0.5443 - val_loss: 3.0892 - val_accuracy: 0.3571\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3396 - accuracy: 0.5459 - val_loss: 3.1015 - val_accuracy: 0.3479\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3404 - accuracy: 0.5494 - val_loss: 3.0799 - val_accuracy: 0.3540\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3463 - accuracy: 0.5482 - val_loss: 3.0788 - val_accuracy: 0.3449\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3386 - accuracy: 0.5459 - val_loss: 3.0631 - val_accuracy: 0.3589\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.5476 - val_loss: 3.0629 - val_accuracy: 0.3558\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3364 - accuracy: 0.5476 - val_loss: 3.1255 - val_accuracy: 0.3491\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3363 - accuracy: 0.5467 - val_loss: 3.0892 - val_accuracy: 0.3479\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3360 - accuracy: 0.5525 - val_loss: 3.0962 - val_accuracy: 0.3498\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3314 - accuracy: 0.5432 - val_loss: 3.0830 - val_accuracy: 0.3540\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3357 - accuracy: 0.5479 - val_loss: 3.0964 - val_accuracy: 0.3510\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3438 - accuracy: 0.5494 - val_loss: 3.1030 - val_accuracy: 0.3571\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3426 - accuracy: 0.5470 - val_loss: 3.1011 - val_accuracy: 0.3498\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3308 - accuracy: 0.5505 - val_loss: 3.0764 - val_accuracy: 0.3504\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3369 - accuracy: 0.5449 - val_loss: 3.1013 - val_accuracy: 0.3534\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3409 - accuracy: 0.5470 - val_loss: 3.1078 - val_accuracy: 0.3491\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3334 - accuracy: 0.5526 - val_loss: 3.0709 - val_accuracy: 0.3558\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3416 - accuracy: 0.5502 - val_loss: 3.0880 - val_accuracy: 0.3461\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3426 - accuracy: 0.5444 - val_loss: 3.0964 - val_accuracy: 0.3510\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3344 - accuracy: 0.5509 - val_loss: 3.0925 - val_accuracy: 0.3589\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3377 - accuracy: 0.5496 - val_loss: 3.1062 - val_accuracy: 0.3528\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3375 - accuracy: 0.5494 - val_loss: 3.1094 - val_accuracy: 0.3498\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3288 - accuracy: 0.5508 - val_loss: 3.0918 - val_accuracy: 0.3504\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3392 - accuracy: 0.5421 - val_loss: 3.0997 - val_accuracy: 0.3461\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3450 - accuracy: 0.5491 - val_loss: 3.1075 - val_accuracy: 0.3522\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3379 - accuracy: 0.5497 - val_loss: 3.1113 - val_accuracy: 0.3498\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3369 - accuracy: 0.5506 - val_loss: 3.0748 - val_accuracy: 0.3577\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5493 - val_loss: 3.0846 - val_accuracy: 0.3583\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3343 - accuracy: 0.5511 - val_loss: 3.0952 - val_accuracy: 0.3583\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3377 - accuracy: 0.5453 - val_loss: 3.0703 - val_accuracy: 0.3510\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.5491 - val_loss: 3.0961 - val_accuracy: 0.3516\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3403 - accuracy: 0.5493 - val_loss: 3.0487 - val_accuracy: 0.3534\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3309 - accuracy: 0.5506 - val_loss: 3.0908 - val_accuracy: 0.3498\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3397 - accuracy: 0.5496 - val_loss: 3.0670 - val_accuracy: 0.3607\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3428 - accuracy: 0.5493 - val_loss: 3.0961 - val_accuracy: 0.3534\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3399 - accuracy: 0.5450 - val_loss: 3.0744 - val_accuracy: 0.3571\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.5427 - val_loss: 3.0789 - val_accuracy: 0.3546\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.5484 - val_loss: 3.0925 - val_accuracy: 0.3564\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3325 - accuracy: 0.5502 - val_loss: 3.0946 - val_accuracy: 0.3498\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3343 - accuracy: 0.5468 - val_loss: 3.0955 - val_accuracy: 0.3510\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3337 - accuracy: 0.5464 - val_loss: 3.1027 - val_accuracy: 0.3546\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3425 - accuracy: 0.5433 - val_loss: 3.0828 - val_accuracy: 0.3534\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3393 - accuracy: 0.5496 - val_loss: 3.0679 - val_accuracy: 0.3522\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3360 - accuracy: 0.5500 - val_loss: 3.0828 - val_accuracy: 0.3534\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5449 - val_loss: 3.0978 - val_accuracy: 0.3504\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3401 - accuracy: 0.5446 - val_loss: 3.1135 - val_accuracy: 0.3479\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3412 - accuracy: 0.5452 - val_loss: 3.0975 - val_accuracy: 0.3443\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3420 - accuracy: 0.5503 - val_loss: 3.0800 - val_accuracy: 0.3558\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3292 - accuracy: 0.5456 - val_loss: 3.1082 - val_accuracy: 0.3485\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3448 - accuracy: 0.5421 - val_loss: 3.0829 - val_accuracy: 0.3528\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3425 - accuracy: 0.5441 - val_loss: 3.0766 - val_accuracy: 0.3552\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3422 - accuracy: 0.5474 - val_loss: 3.0997 - val_accuracy: 0.3510\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3361 - accuracy: 0.5485 - val_loss: 3.0868 - val_accuracy: 0.3510\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3310 - accuracy: 0.5520 - val_loss: 3.1091 - val_accuracy: 0.3479\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3361 - accuracy: 0.5482 - val_loss: 3.0743 - val_accuracy: 0.3552\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3311 - accuracy: 0.5467 - val_loss: 3.1007 - val_accuracy: 0.3540\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3378 - accuracy: 0.5477 - val_loss: 3.0877 - val_accuracy: 0.3571\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3425 - accuracy: 0.5432 - val_loss: 3.0763 - val_accuracy: 0.3516\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3309 - accuracy: 0.5467 - val_loss: 3.1014 - val_accuracy: 0.3540\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3297 - accuracy: 0.5482 - val_loss: 3.0864 - val_accuracy: 0.3491\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3402 - accuracy: 0.5485 - val_loss: 3.0833 - val_accuracy: 0.3498\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3244 - accuracy: 0.5528 - val_loss: 3.1151 - val_accuracy: 0.3540\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.5446 - val_loss: 3.0888 - val_accuracy: 0.3443\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3302 - accuracy: 0.5471 - val_loss: 3.1115 - val_accuracy: 0.3479\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3317 - accuracy: 0.5453 - val_loss: 3.0874 - val_accuracy: 0.3491\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3287 - accuracy: 0.5485 - val_loss: 3.1190 - val_accuracy: 0.3461\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3297 - accuracy: 0.5506 - val_loss: 3.0859 - val_accuracy: 0.3540\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.5458 - val_loss: 3.0884 - val_accuracy: 0.3510\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3340 - accuracy: 0.5464 - val_loss: 3.1087 - val_accuracy: 0.3534\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3374 - accuracy: 0.5481 - val_loss: 3.1091 - val_accuracy: 0.3522\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3315 - accuracy: 0.5494 - val_loss: 3.1060 - val_accuracy: 0.3522\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3341 - accuracy: 0.5493 - val_loss: 3.0874 - val_accuracy: 0.3504\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3291 - accuracy: 0.5467 - val_loss: 3.0983 - val_accuracy: 0.3528\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3366 - accuracy: 0.5456 - val_loss: 3.0908 - val_accuracy: 0.3504\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3396 - accuracy: 0.5461 - val_loss: 3.0935 - val_accuracy: 0.3583\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3357 - accuracy: 0.5468 - val_loss: 3.0916 - val_accuracy: 0.3522\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3372 - accuracy: 0.5487 - val_loss: 3.1172 - val_accuracy: 0.3504\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3331 - accuracy: 0.5484 - val_loss: 3.1127 - val_accuracy: 0.3534\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.5499 - val_loss: 3.0921 - val_accuracy: 0.3552\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3336 - accuracy: 0.5491 - val_loss: 3.0802 - val_accuracy: 0.3577\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3409 - accuracy: 0.5439 - val_loss: 3.0823 - val_accuracy: 0.3528\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3330 - accuracy: 0.5490 - val_loss: 3.0979 - val_accuracy: 0.3540\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.5519 - val_loss: 3.0808 - val_accuracy: 0.3510\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3358 - accuracy: 0.5484 - val_loss: 3.0867 - val_accuracy: 0.3571\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5511 - val_loss: 3.0781 - val_accuracy: 0.3479\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3390 - accuracy: 0.5496 - val_loss: 3.0813 - val_accuracy: 0.3510\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3330 - accuracy: 0.5474 - val_loss: 3.0956 - val_accuracy: 0.3455\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3369 - accuracy: 0.5476 - val_loss: 3.0725 - val_accuracy: 0.3504\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3314 - accuracy: 0.5470 - val_loss: 3.0996 - val_accuracy: 0.3485\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3418 - accuracy: 0.5450 - val_loss: 3.0769 - val_accuracy: 0.3528\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3383 - accuracy: 0.5537 - val_loss: 3.0922 - val_accuracy: 0.3528\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3338 - accuracy: 0.5503 - val_loss: 3.0831 - val_accuracy: 0.3564\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3333 - accuracy: 0.5502 - val_loss: 3.0710 - val_accuracy: 0.3552\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3339 - accuracy: 0.5458 - val_loss: 3.1090 - val_accuracy: 0.3516\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3309 - accuracy: 0.5522 - val_loss: 3.0922 - val_accuracy: 0.3552\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3325 - accuracy: 0.5464 - val_loss: 3.1011 - val_accuracy: 0.3498\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3385 - accuracy: 0.5497 - val_loss: 3.1155 - val_accuracy: 0.3425\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3321 - accuracy: 0.5494 - val_loss: 3.0928 - val_accuracy: 0.3479\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3355 - accuracy: 0.5505 - val_loss: 3.1018 - val_accuracy: 0.3540\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3298 - accuracy: 0.5493 - val_loss: 3.1134 - val_accuracy: 0.3431\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3321 - accuracy: 0.5488 - val_loss: 3.0640 - val_accuracy: 0.3577\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3439 - accuracy: 0.5406 - val_loss: 3.1165 - val_accuracy: 0.3552\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3375 - accuracy: 0.5496 - val_loss: 3.1160 - val_accuracy: 0.3510\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3315 - accuracy: 0.5528 - val_loss: 3.0908 - val_accuracy: 0.3504\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3305 - accuracy: 0.5471 - val_loss: 3.0856 - val_accuracy: 0.3546\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5519 - val_loss: 3.0997 - val_accuracy: 0.3437\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5488 - val_loss: 3.1028 - val_accuracy: 0.3528\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3307 - accuracy: 0.5494 - val_loss: 3.0900 - val_accuracy: 0.3528\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3421 - accuracy: 0.5465 - val_loss: 3.0855 - val_accuracy: 0.3552\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3377 - accuracy: 0.5449 - val_loss: 3.0941 - val_accuracy: 0.3595\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3373 - accuracy: 0.5462 - val_loss: 3.1030 - val_accuracy: 0.3571\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3307 - accuracy: 0.5459 - val_loss: 3.0931 - val_accuracy: 0.3528\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3294 - accuracy: 0.5488 - val_loss: 3.1137 - val_accuracy: 0.3528\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3350 - accuracy: 0.5511 - val_loss: 3.0947 - val_accuracy: 0.3534\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3256 - accuracy: 0.5508 - val_loss: 3.1231 - val_accuracy: 0.3510\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3396 - accuracy: 0.5502 - val_loss: 3.1247 - val_accuracy: 0.3437\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3348 - accuracy: 0.5468 - val_loss: 3.0972 - val_accuracy: 0.3552\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3384 - accuracy: 0.5511 - val_loss: 3.0870 - val_accuracy: 0.3589\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3316 - accuracy: 0.5505 - val_loss: 3.0889 - val_accuracy: 0.3467\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3336 - accuracy: 0.5473 - val_loss: 3.0999 - val_accuracy: 0.3479\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.5509 - val_loss: 3.0949 - val_accuracy: 0.3485\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3440 - accuracy: 0.5464 - val_loss: 3.1085 - val_accuracy: 0.3491\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3337 - accuracy: 0.5487 - val_loss: 3.0942 - val_accuracy: 0.3528\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3294 - accuracy: 0.5494 - val_loss: 3.1157 - val_accuracy: 0.3516\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3424 - accuracy: 0.5484 - val_loss: 3.0677 - val_accuracy: 0.3528\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3317 - accuracy: 0.5503 - val_loss: 3.0881 - val_accuracy: 0.3479\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3387 - accuracy: 0.5411 - val_loss: 3.1013 - val_accuracy: 0.3516\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3298 - accuracy: 0.5456 - val_loss: 3.0870 - val_accuracy: 0.3540\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.5497 - val_loss: 3.1121 - val_accuracy: 0.3504\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3344 - accuracy: 0.5477 - val_loss: 3.0511 - val_accuracy: 0.3558\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3269 - accuracy: 0.5541 - val_loss: 3.1243 - val_accuracy: 0.3443\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3314 - accuracy: 0.5470 - val_loss: 3.0921 - val_accuracy: 0.3522\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3277 - accuracy: 0.5502 - val_loss: 3.1137 - val_accuracy: 0.3467\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3310 - accuracy: 0.5523 - val_loss: 3.0916 - val_accuracy: 0.3546\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3292 - accuracy: 0.5506 - val_loss: 3.0750 - val_accuracy: 0.3546\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3352 - accuracy: 0.5499 - val_loss: 3.1022 - val_accuracy: 0.3552\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3307 - accuracy: 0.5529 - val_loss: 3.1377 - val_accuracy: 0.3400\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3348 - accuracy: 0.5424 - val_loss: 3.1129 - val_accuracy: 0.3455\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3302 - accuracy: 0.5496 - val_loss: 3.0999 - val_accuracy: 0.3455\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5491 - val_loss: 3.1099 - val_accuracy: 0.3558\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3339 - accuracy: 0.5433 - val_loss: 3.1146 - val_accuracy: 0.3443\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3382 - accuracy: 0.5484 - val_loss: 3.1040 - val_accuracy: 0.3485\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3404 - accuracy: 0.5502 - val_loss: 3.1015 - val_accuracy: 0.3558\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3296 - accuracy: 0.5491 - val_loss: 3.0933 - val_accuracy: 0.3510\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.5511 - val_loss: 3.1207 - val_accuracy: 0.3455\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3370 - accuracy: 0.5485 - val_loss: 3.1159 - val_accuracy: 0.3504\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3306 - accuracy: 0.5487 - val_loss: 3.1390 - val_accuracy: 0.3455\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3271 - accuracy: 0.5525 - val_loss: 3.1142 - val_accuracy: 0.3528\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3258 - accuracy: 0.5506 - val_loss: 3.1113 - val_accuracy: 0.3607\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.5491 - val_loss: 3.1143 - val_accuracy: 0.3491\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3310 - accuracy: 0.5436 - val_loss: 3.1096 - val_accuracy: 0.3485\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3392 - accuracy: 0.5474 - val_loss: 3.1102 - val_accuracy: 0.3504\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3415 - accuracy: 0.5479 - val_loss: 3.0902 - val_accuracy: 0.3491\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3385 - accuracy: 0.5477 - val_loss: 3.1145 - val_accuracy: 0.3473\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3326 - accuracy: 0.5496 - val_loss: 3.1103 - val_accuracy: 0.3498\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3346 - accuracy: 0.5477 - val_loss: 3.1363 - val_accuracy: 0.3479\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3350 - accuracy: 0.5439 - val_loss: 3.1209 - val_accuracy: 0.3455\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3323 - accuracy: 0.5449 - val_loss: 3.1246 - val_accuracy: 0.3412\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3366 - accuracy: 0.5499 - val_loss: 3.1200 - val_accuracy: 0.3461\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3214 - accuracy: 0.5519 - val_loss: 3.1223 - val_accuracy: 0.3443\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.5497 - val_loss: 3.1132 - val_accuracy: 0.3449\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3316 - accuracy: 0.5471 - val_loss: 3.1200 - val_accuracy: 0.3449\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3358 - accuracy: 0.5493 - val_loss: 3.1036 - val_accuracy: 0.3528\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3355 - accuracy: 0.5464 - val_loss: 3.1152 - val_accuracy: 0.3534\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3301 - accuracy: 0.5424 - val_loss: 3.0927 - val_accuracy: 0.3498\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3285 - accuracy: 0.5522 - val_loss: 3.1022 - val_accuracy: 0.3510\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3388 - accuracy: 0.5452 - val_loss: 3.1187 - val_accuracy: 0.3540\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.5497 - val_loss: 3.1187 - val_accuracy: 0.3504\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3217 - accuracy: 0.5550 - val_loss: 3.1185 - val_accuracy: 0.3485\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3349 - accuracy: 0.5426 - val_loss: 3.1018 - val_accuracy: 0.3510\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3292 - accuracy: 0.5517 - val_loss: 3.1231 - val_accuracy: 0.3491\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3354 - accuracy: 0.5487 - val_loss: 3.1160 - val_accuracy: 0.3485\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.5429 - val_loss: 3.1115 - val_accuracy: 0.3491\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3362 - accuracy: 0.5485 - val_loss: 3.1098 - val_accuracy: 0.3516\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3380 - accuracy: 0.5485 - val_loss: 3.1158 - val_accuracy: 0.3449\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.5464 - val_loss: 3.0859 - val_accuracy: 0.3522\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3351 - accuracy: 0.5418 - val_loss: 3.0688 - val_accuracy: 0.3637\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3345 - accuracy: 0.5484 - val_loss: 3.1013 - val_accuracy: 0.3534\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3291 - accuracy: 0.5506 - val_loss: 3.1138 - val_accuracy: 0.3528\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5494 - val_loss: 3.1121 - val_accuracy: 0.3522\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3351 - accuracy: 0.5474 - val_loss: 3.1189 - val_accuracy: 0.3425\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3367 - accuracy: 0.5491 - val_loss: 3.1276 - val_accuracy: 0.3479\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3300 - accuracy: 0.5512 - val_loss: 3.1072 - val_accuracy: 0.3552\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3328 - accuracy: 0.5499 - val_loss: 3.1089 - val_accuracy: 0.3467\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3408 - accuracy: 0.5502 - val_loss: 3.1102 - val_accuracy: 0.3473\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3324 - accuracy: 0.5447 - val_loss: 3.1285 - val_accuracy: 0.3498\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3323 - accuracy: 0.5485 - val_loss: 3.1295 - val_accuracy: 0.3498\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3357 - accuracy: 0.5511 - val_loss: 3.0842 - val_accuracy: 0.3589\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3389 - accuracy: 0.5450 - val_loss: 3.1197 - val_accuracy: 0.3437\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3381 - accuracy: 0.5458 - val_loss: 3.0979 - val_accuracy: 0.3534\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5464 - val_loss: 3.0982 - val_accuracy: 0.3504\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3319 - accuracy: 0.5467 - val_loss: 3.1189 - val_accuracy: 0.3479\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3322 - accuracy: 0.5517 - val_loss: 3.1330 - val_accuracy: 0.3485\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3271 - accuracy: 0.5497 - val_loss: 3.1034 - val_accuracy: 0.3571\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3326 - accuracy: 0.5508 - val_loss: 3.0986 - val_accuracy: 0.3583\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5506 - val_loss: 3.1058 - val_accuracy: 0.3625\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3403 - accuracy: 0.5446 - val_loss: 3.0937 - val_accuracy: 0.3577\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.5470 - val_loss: 3.1272 - val_accuracy: 0.3540\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.5455 - val_loss: 3.1102 - val_accuracy: 0.3510\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3294 - accuracy: 0.5517 - val_loss: 3.1192 - val_accuracy: 0.3564\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5487 - val_loss: 3.0962 - val_accuracy: 0.3631\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3247 - accuracy: 0.5526 - val_loss: 3.1213 - val_accuracy: 0.3540\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3396 - accuracy: 0.5503 - val_loss: 3.1282 - val_accuracy: 0.3431\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3324 - accuracy: 0.5493 - val_loss: 3.1092 - val_accuracy: 0.3412\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3337 - accuracy: 0.5488 - val_loss: 3.1129 - val_accuracy: 0.3613\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5485 - val_loss: 3.1253 - val_accuracy: 0.3394\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3283 - accuracy: 0.5459 - val_loss: 3.1236 - val_accuracy: 0.3473\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3368 - accuracy: 0.5506 - val_loss: 3.0927 - val_accuracy: 0.3522\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3359 - accuracy: 0.5458 - val_loss: 3.1160 - val_accuracy: 0.3528\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3347 - accuracy: 0.5499 - val_loss: 3.1321 - val_accuracy: 0.3485\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3392 - accuracy: 0.5447 - val_loss: 3.1111 - val_accuracy: 0.3546\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.5519 - val_loss: 3.1293 - val_accuracy: 0.3516\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3352 - accuracy: 0.5441 - val_loss: 3.1444 - val_accuracy: 0.3455\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5458 - val_loss: 3.1165 - val_accuracy: 0.3510\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5526 - val_loss: 3.1465 - val_accuracy: 0.3504\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.5464 - val_loss: 3.0836 - val_accuracy: 0.3552\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3304 - accuracy: 0.5519 - val_loss: 3.1050 - val_accuracy: 0.3552\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3419 - accuracy: 0.5462 - val_loss: 3.0910 - val_accuracy: 0.3510\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3300 - accuracy: 0.5499 - val_loss: 3.1264 - val_accuracy: 0.3577\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.5487 - val_loss: 3.1216 - val_accuracy: 0.3516\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3246 - accuracy: 0.5519 - val_loss: 3.1254 - val_accuracy: 0.3540\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3349 - accuracy: 0.5461 - val_loss: 3.1284 - val_accuracy: 0.3412\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3352 - accuracy: 0.5474 - val_loss: 3.1401 - val_accuracy: 0.3522\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.5476 - val_loss: 3.1276 - val_accuracy: 0.3564\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.5474 - val_loss: 3.1170 - val_accuracy: 0.3516\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3353 - accuracy: 0.5502 - val_loss: 3.1279 - val_accuracy: 0.3461\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3311 - accuracy: 0.5499 - val_loss: 3.1243 - val_accuracy: 0.3552\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3283 - accuracy: 0.5526 - val_loss: 3.1308 - val_accuracy: 0.3449\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3290 - accuracy: 0.5490 - val_loss: 3.1354 - val_accuracy: 0.3467\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3270 - accuracy: 0.5526 - val_loss: 3.1307 - val_accuracy: 0.3473\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3279 - accuracy: 0.5464 - val_loss: 3.1377 - val_accuracy: 0.3485\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3387 - accuracy: 0.5511 - val_loss: 3.1265 - val_accuracy: 0.3510\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3318 - accuracy: 0.5487 - val_loss: 3.1500 - val_accuracy: 0.3467\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3393 - accuracy: 0.5481 - val_loss: 3.1193 - val_accuracy: 0.3546\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.5497 - val_loss: 3.1058 - val_accuracy: 0.3491\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3293 - accuracy: 0.5491 - val_loss: 3.0865 - val_accuracy: 0.3546\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3275 - accuracy: 0.5485 - val_loss: 3.1175 - val_accuracy: 0.3516\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3376 - accuracy: 0.5449 - val_loss: 3.1307 - val_accuracy: 0.3412\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3371 - accuracy: 0.5484 - val_loss: 3.1065 - val_accuracy: 0.3510\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3266 - accuracy: 0.5514 - val_loss: 3.1444 - val_accuracy: 0.3516\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3295 - accuracy: 0.5476 - val_loss: 3.1161 - val_accuracy: 0.3528\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3346 - accuracy: 0.5494 - val_loss: 3.1167 - val_accuracy: 0.3528\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3326 - accuracy: 0.5484 - val_loss: 3.1073 - val_accuracy: 0.3504\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3269 - accuracy: 0.5523 - val_loss: 3.1272 - val_accuracy: 0.3394\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5459 - val_loss: 3.0922 - val_accuracy: 0.3619\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3274 - accuracy: 0.5487 - val_loss: 3.1182 - val_accuracy: 0.3516\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3270 - accuracy: 0.5476 - val_loss: 3.1218 - val_accuracy: 0.3461\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3328 - accuracy: 0.5477 - val_loss: 3.1051 - val_accuracy: 0.3552\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.5508 - val_loss: 3.1280 - val_accuracy: 0.3491\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3241 - accuracy: 0.5484 - val_loss: 3.1141 - val_accuracy: 0.3485\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3282 - accuracy: 0.5479 - val_loss: 3.1145 - val_accuracy: 0.3558\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3335 - accuracy: 0.5473 - val_loss: 3.1460 - val_accuracy: 0.3394\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3329 - accuracy: 0.5484 - val_loss: 3.1388 - val_accuracy: 0.3473\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.5476 - val_loss: 3.1099 - val_accuracy: 0.3552\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.5477 - val_loss: 3.1034 - val_accuracy: 0.3491\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3267 - accuracy: 0.5547 - val_loss: 3.1577 - val_accuracy: 0.3485\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3346 - accuracy: 0.5512 - val_loss: 3.1388 - val_accuracy: 0.3443\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3270 - accuracy: 0.5476 - val_loss: 3.1044 - val_accuracy: 0.3540\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3315 - accuracy: 0.5464 - val_loss: 3.1122 - val_accuracy: 0.3546\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3374 - accuracy: 0.5464 - val_loss: 3.1237 - val_accuracy: 0.3467\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3234 - accuracy: 0.5512 - val_loss: 3.1244 - val_accuracy: 0.3394\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3352 - accuracy: 0.5502 - val_loss: 3.1264 - val_accuracy: 0.3473\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3293 - accuracy: 0.5481 - val_loss: 3.1095 - val_accuracy: 0.3491\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3412 - accuracy: 0.5474 - val_loss: 3.1111 - val_accuracy: 0.3485\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3316 - accuracy: 0.5435 - val_loss: 3.1307 - val_accuracy: 0.3522\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3362 - accuracy: 0.5503 - val_loss: 3.1161 - val_accuracy: 0.3443\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3281 - accuracy: 0.5537 - val_loss: 3.1396 - val_accuracy: 0.3455\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3299 - accuracy: 0.5535 - val_loss: 3.1174 - val_accuracy: 0.3552\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3368 - accuracy: 0.5471 - val_loss: 3.1094 - val_accuracy: 0.3558\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3257 - accuracy: 0.5487 - val_loss: 3.0962 - val_accuracy: 0.3528\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3404 - accuracy: 0.5424 - val_loss: 3.1347 - val_accuracy: 0.3522\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3357 - accuracy: 0.5500 - val_loss: 3.1283 - val_accuracy: 0.3491\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3346 - accuracy: 0.5493 - val_loss: 3.1094 - val_accuracy: 0.3631\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3326 - accuracy: 0.5452 - val_loss: 3.1193 - val_accuracy: 0.3516\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3359 - accuracy: 0.5499 - val_loss: 3.1231 - val_accuracy: 0.3522\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.5511 - val_loss: 3.1202 - val_accuracy: 0.3431\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3242 - accuracy: 0.5519 - val_loss: 3.1286 - val_accuracy: 0.3546\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.5458 - val_loss: 3.0887 - val_accuracy: 0.3540\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3341 - accuracy: 0.5467 - val_loss: 3.1139 - val_accuracy: 0.3583\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3266 - accuracy: 0.5494 - val_loss: 3.0929 - val_accuracy: 0.3510\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3352 - accuracy: 0.5461 - val_loss: 3.1588 - val_accuracy: 0.3437\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3390 - accuracy: 0.5446 - val_loss: 3.0970 - val_accuracy: 0.3558\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.5497 - val_loss: 3.0912 - val_accuracy: 0.3577\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3321 - accuracy: 0.5417 - val_loss: 3.1106 - val_accuracy: 0.3607\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3331 - accuracy: 0.5481 - val_loss: 3.1355 - val_accuracy: 0.3510\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3335 - accuracy: 0.5506 - val_loss: 3.1046 - val_accuracy: 0.3540\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3273 - accuracy: 0.5514 - val_loss: 3.1094 - val_accuracy: 0.3571\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3306 - accuracy: 0.5473 - val_loss: 3.1097 - val_accuracy: 0.3558\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3214 - accuracy: 0.5494 - val_loss: 3.1432 - val_accuracy: 0.3491\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.5461 - val_loss: 3.1205 - val_accuracy: 0.3601\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.5582 - val_loss: 3.1454 - val_accuracy: 0.3473\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3234 - accuracy: 0.5484 - val_loss: 3.1138 - val_accuracy: 0.3571\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3272 - accuracy: 0.5467 - val_loss: 3.1112 - val_accuracy: 0.3498\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3293 - accuracy: 0.5500 - val_loss: 3.1311 - val_accuracy: 0.3516\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3277 - accuracy: 0.5490 - val_loss: 3.1209 - val_accuracy: 0.3473\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3287 - accuracy: 0.5477 - val_loss: 3.1290 - val_accuracy: 0.3485\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.5502 - val_loss: 3.1275 - val_accuracy: 0.3455\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3355 - accuracy: 0.5481 - val_loss: 3.1136 - val_accuracy: 0.3546\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3288 - accuracy: 0.5529 - val_loss: 3.1184 - val_accuracy: 0.3516\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3301 - accuracy: 0.5470 - val_loss: 3.1297 - val_accuracy: 0.3473\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3346 - accuracy: 0.5534 - val_loss: 3.1135 - val_accuracy: 0.3558\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3303 - accuracy: 0.5458 - val_loss: 3.1752 - val_accuracy: 0.3388\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3357 - accuracy: 0.5485 - val_loss: 3.1178 - val_accuracy: 0.3485\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3387 - accuracy: 0.5438 - val_loss: 3.1122 - val_accuracy: 0.3516\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3221 - accuracy: 0.5500 - val_loss: 3.1328 - val_accuracy: 0.3479\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3440 - accuracy: 0.5412 - val_loss: 3.1008 - val_accuracy: 0.3485\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3406 - accuracy: 0.5467 - val_loss: 3.1302 - val_accuracy: 0.3473\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3286 - accuracy: 0.5474 - val_loss: 3.0950 - val_accuracy: 0.3540\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3330 - accuracy: 0.5516 - val_loss: 3.1442 - val_accuracy: 0.3449\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3226 - accuracy: 0.5531 - val_loss: 3.1339 - val_accuracy: 0.3461\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3270 - accuracy: 0.5474 - val_loss: 3.1517 - val_accuracy: 0.3461\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3268 - accuracy: 0.5514 - val_loss: 3.0977 - val_accuracy: 0.3522\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3363 - accuracy: 0.5441 - val_loss: 3.1055 - val_accuracy: 0.3546\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3322 - accuracy: 0.5423 - val_loss: 3.1233 - val_accuracy: 0.3528\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3269 - accuracy: 0.5500 - val_loss: 3.1116 - val_accuracy: 0.3571\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3284 - accuracy: 0.5473 - val_loss: 3.1226 - val_accuracy: 0.3522\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3274 - accuracy: 0.5505 - val_loss: 3.1342 - val_accuracy: 0.3479\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3369 - accuracy: 0.5491 - val_loss: 3.1526 - val_accuracy: 0.3504\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3342 - accuracy: 0.5458 - val_loss: 3.1239 - val_accuracy: 0.3491\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3338 - accuracy: 0.5496 - val_loss: 3.1158 - val_accuracy: 0.3491\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5508 - val_loss: 3.1326 - val_accuracy: 0.3498\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3310 - accuracy: 0.5500 - val_loss: 3.1067 - val_accuracy: 0.3534\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3268 - accuracy: 0.5512 - val_loss: 3.1251 - val_accuracy: 0.3546\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3351 - accuracy: 0.5470 - val_loss: 3.1268 - val_accuracy: 0.3552\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3251 - accuracy: 0.5491 - val_loss: 3.1408 - val_accuracy: 0.3485\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.5512 - val_loss: 3.1165 - val_accuracy: 0.3546\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3353 - accuracy: 0.5458 - val_loss: 3.1270 - val_accuracy: 0.3498\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3325 - accuracy: 0.5461 - val_loss: 3.1256 - val_accuracy: 0.3558\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5464 - val_loss: 3.1308 - val_accuracy: 0.3510\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3254 - accuracy: 0.5511 - val_loss: 3.1164 - val_accuracy: 0.3467\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3309 - accuracy: 0.5485 - val_loss: 3.1235 - val_accuracy: 0.3552\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3223 - accuracy: 0.5500 - val_loss: 3.1217 - val_accuracy: 0.3558\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3290 - accuracy: 0.5473 - val_loss: 3.1358 - val_accuracy: 0.3540\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3361 - accuracy: 0.5461 - val_loss: 3.1347 - val_accuracy: 0.3522\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3312 - accuracy: 0.5473 - val_loss: 3.1281 - val_accuracy: 0.3516\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3295 - accuracy: 0.5528 - val_loss: 3.1313 - val_accuracy: 0.3485\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3333 - accuracy: 0.5455 - val_loss: 3.1175 - val_accuracy: 0.3491\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3249 - accuracy: 0.5534 - val_loss: 3.1259 - val_accuracy: 0.3467\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5516 - val_loss: 3.1371 - val_accuracy: 0.3564\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3304 - accuracy: 0.5459 - val_loss: 3.1607 - val_accuracy: 0.3425\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3369 - accuracy: 0.5461 - val_loss: 3.1432 - val_accuracy: 0.3522\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3330 - accuracy: 0.5439 - val_loss: 3.1412 - val_accuracy: 0.3437\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.5491 - val_loss: 3.1479 - val_accuracy: 0.3479\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3274 - accuracy: 0.5523 - val_loss: 3.1327 - val_accuracy: 0.3504\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3320 - accuracy: 0.5482 - val_loss: 3.1266 - val_accuracy: 0.3571\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3287 - accuracy: 0.5459 - val_loss: 3.1371 - val_accuracy: 0.3516\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3349 - accuracy: 0.5476 - val_loss: 3.1486 - val_accuracy: 0.3485\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3247 - accuracy: 0.5468 - val_loss: 3.1414 - val_accuracy: 0.3504\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3244 - accuracy: 0.5546 - val_loss: 3.1101 - val_accuracy: 0.3577\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3297 - accuracy: 0.5433 - val_loss: 3.1258 - val_accuracy: 0.3528\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3221 - accuracy: 0.5516 - val_loss: 3.1346 - val_accuracy: 0.3467\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5544 - val_loss: 3.1379 - val_accuracy: 0.3558\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3372 - accuracy: 0.5465 - val_loss: 3.1426 - val_accuracy: 0.3400\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3321 - accuracy: 0.5470 - val_loss: 3.1290 - val_accuracy: 0.3498\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3362 - accuracy: 0.5485 - val_loss: 3.1390 - val_accuracy: 0.3498\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3320 - accuracy: 0.5479 - val_loss: 3.1491 - val_accuracy: 0.3522\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3302 - accuracy: 0.5502 - val_loss: 3.1352 - val_accuracy: 0.3510\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3243 - accuracy: 0.5479 - val_loss: 3.1424 - val_accuracy: 0.3528\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5450 - val_loss: 3.1341 - val_accuracy: 0.3540\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3318 - accuracy: 0.5487 - val_loss: 3.1265 - val_accuracy: 0.3589\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3266 - accuracy: 0.5566 - val_loss: 3.1204 - val_accuracy: 0.3552\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3217 - accuracy: 0.5491 - val_loss: 3.1339 - val_accuracy: 0.3504\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3341 - accuracy: 0.5511 - val_loss: 3.1314 - val_accuracy: 0.3516\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3315 - accuracy: 0.5522 - val_loss: 3.1301 - val_accuracy: 0.3607\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3299 - accuracy: 0.5476 - val_loss: 3.1500 - val_accuracy: 0.3479\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3315 - accuracy: 0.5479 - val_loss: 3.1177 - val_accuracy: 0.3552\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3310 - accuracy: 0.5512 - val_loss: 3.1293 - val_accuracy: 0.3552\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3326 - accuracy: 0.5464 - val_loss: 3.1091 - val_accuracy: 0.3571\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3299 - accuracy: 0.5455 - val_loss: 3.1665 - val_accuracy: 0.3498\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3282 - accuracy: 0.5482 - val_loss: 3.1316 - val_accuracy: 0.3498\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3314 - accuracy: 0.5446 - val_loss: 3.1441 - val_accuracy: 0.3461\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3245 - accuracy: 0.5535 - val_loss: 3.1620 - val_accuracy: 0.3467\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3398 - accuracy: 0.5468 - val_loss: 3.1466 - val_accuracy: 0.3516\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.5537 - val_loss: 3.1518 - val_accuracy: 0.3461\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3211 - accuracy: 0.5506 - val_loss: 3.1477 - val_accuracy: 0.3418\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5426 - val_loss: 3.1341 - val_accuracy: 0.3534\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3325 - accuracy: 0.5499 - val_loss: 3.1187 - val_accuracy: 0.3510\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3179 - accuracy: 0.5517 - val_loss: 3.1445 - val_accuracy: 0.3528\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3251 - accuracy: 0.5491 - val_loss: 3.1448 - val_accuracy: 0.3564\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3230 - accuracy: 0.5517 - val_loss: 3.1412 - val_accuracy: 0.3491\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3329 - accuracy: 0.5473 - val_loss: 3.1454 - val_accuracy: 0.3485\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3317 - accuracy: 0.5458 - val_loss: 3.1399 - val_accuracy: 0.3522\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3309 - accuracy: 0.5509 - val_loss: 3.1490 - val_accuracy: 0.3571\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3293 - accuracy: 0.5540 - val_loss: 3.1603 - val_accuracy: 0.3485\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3296 - accuracy: 0.5468 - val_loss: 3.1441 - val_accuracy: 0.3522\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.5554 - val_loss: 3.1522 - val_accuracy: 0.3473\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3284 - accuracy: 0.5502 - val_loss: 3.1335 - val_accuracy: 0.3528\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3270 - accuracy: 0.5443 - val_loss: 3.1508 - val_accuracy: 0.3431\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3286 - accuracy: 0.5482 - val_loss: 3.1155 - val_accuracy: 0.3564\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3337 - accuracy: 0.5473 - val_loss: 3.1281 - val_accuracy: 0.3540\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5467 - val_loss: 3.1357 - val_accuracy: 0.3583\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3246 - accuracy: 0.5519 - val_loss: 3.1626 - val_accuracy: 0.3485\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3241 - accuracy: 0.5558 - val_loss: 3.1601 - val_accuracy: 0.3479\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.5494 - val_loss: 3.1397 - val_accuracy: 0.3510\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3288 - accuracy: 0.5479 - val_loss: 3.1247 - val_accuracy: 0.3662\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3215 - accuracy: 0.5496 - val_loss: 3.1475 - val_accuracy: 0.3467\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3185 - accuracy: 0.5491 - val_loss: 3.1305 - val_accuracy: 0.3498\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.5496 - val_loss: 3.1408 - val_accuracy: 0.3498\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3278 - accuracy: 0.5491 - val_loss: 3.1625 - val_accuracy: 0.3510\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3252 - accuracy: 0.5541 - val_loss: 3.1410 - val_accuracy: 0.3498\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3269 - accuracy: 0.5508 - val_loss: 3.1343 - val_accuracy: 0.3504\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3288 - accuracy: 0.5517 - val_loss: 3.1297 - val_accuracy: 0.3504\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3285 - accuracy: 0.5494 - val_loss: 3.1237 - val_accuracy: 0.3546\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3237 - accuracy: 0.5493 - val_loss: 3.1334 - val_accuracy: 0.3540\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.5485 - val_loss: 3.1134 - val_accuracy: 0.3558\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3234 - accuracy: 0.5502 - val_loss: 3.1486 - val_accuracy: 0.3406\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3330 - accuracy: 0.5470 - val_loss: 3.1463 - val_accuracy: 0.3455\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3301 - accuracy: 0.5484 - val_loss: 3.1331 - val_accuracy: 0.3528\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3273 - accuracy: 0.5525 - val_loss: 3.1175 - val_accuracy: 0.3540\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3215 - accuracy: 0.5522 - val_loss: 3.1626 - val_accuracy: 0.3491\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5439 - val_loss: 3.1302 - val_accuracy: 0.3473\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3347 - accuracy: 0.5455 - val_loss: 3.1659 - val_accuracy: 0.3491\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3392 - accuracy: 0.5502 - val_loss: 3.1193 - val_accuracy: 0.3540\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3376 - accuracy: 0.5405 - val_loss: 3.1497 - val_accuracy: 0.3443\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3262 - accuracy: 0.5520 - val_loss: 3.1690 - val_accuracy: 0.3388\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.5467 - val_loss: 3.1346 - val_accuracy: 0.3479\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3321 - accuracy: 0.5458 - val_loss: 3.1515 - val_accuracy: 0.3425\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3272 - accuracy: 0.5470 - val_loss: 3.1629 - val_accuracy: 0.3382\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3225 - accuracy: 0.5519 - val_loss: 3.1338 - val_accuracy: 0.3546\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3238 - accuracy: 0.5485 - val_loss: 3.1393 - val_accuracy: 0.3552\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3242 - accuracy: 0.5484 - val_loss: 3.1312 - val_accuracy: 0.3479\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3301 - accuracy: 0.5485 - val_loss: 3.1349 - val_accuracy: 0.3534\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3256 - accuracy: 0.5502 - val_loss: 3.1241 - val_accuracy: 0.3546\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3175 - accuracy: 0.5500 - val_loss: 3.1293 - val_accuracy: 0.3498\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3363 - accuracy: 0.5465 - val_loss: 3.1401 - val_accuracy: 0.3498\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3283 - accuracy: 0.5481 - val_loss: 3.1340 - val_accuracy: 0.3467\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3346 - accuracy: 0.5520 - val_loss: 3.1587 - val_accuracy: 0.3467\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.5465 - val_loss: 3.1522 - val_accuracy: 0.3546\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3302 - accuracy: 0.5423 - val_loss: 3.1385 - val_accuracy: 0.3473\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3305 - accuracy: 0.5465 - val_loss: 3.1445 - val_accuracy: 0.3516\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3249 - accuracy: 0.5477 - val_loss: 3.1679 - val_accuracy: 0.3431\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3279 - accuracy: 0.5493 - val_loss: 3.1404 - val_accuracy: 0.3473\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3240 - accuracy: 0.5523 - val_loss: 3.1336 - val_accuracy: 0.3540\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3203 - accuracy: 0.5502 - val_loss: 3.1446 - val_accuracy: 0.3485\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3264 - accuracy: 0.5426 - val_loss: 3.1467 - val_accuracy: 0.3455\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3278 - accuracy: 0.5512 - val_loss: 3.1350 - val_accuracy: 0.3467\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3239 - accuracy: 0.5543 - val_loss: 3.1427 - val_accuracy: 0.3516\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3216 - accuracy: 0.5468 - val_loss: 3.1362 - val_accuracy: 0.3613\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3278 - accuracy: 0.5508 - val_loss: 3.1365 - val_accuracy: 0.3455\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3166 - accuracy: 0.5516 - val_loss: 3.1245 - val_accuracy: 0.3516\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3228 - accuracy: 0.5499 - val_loss: 3.1312 - val_accuracy: 0.3528\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3266 - accuracy: 0.5449 - val_loss: 3.1302 - val_accuracy: 0.3546\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3286 - accuracy: 0.5494 - val_loss: 3.1672 - val_accuracy: 0.3449\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.5485 - val_loss: 3.1479 - val_accuracy: 0.3510\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3326 - accuracy: 0.5532 - val_loss: 3.1446 - val_accuracy: 0.3510\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3283 - accuracy: 0.5487 - val_loss: 3.1307 - val_accuracy: 0.3528\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3243 - accuracy: 0.5467 - val_loss: 3.1597 - val_accuracy: 0.3479\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3307 - accuracy: 0.5490 - val_loss: 3.1323 - val_accuracy: 0.3431\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3256 - accuracy: 0.5541 - val_loss: 3.1109 - val_accuracy: 0.3461\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3246 - accuracy: 0.5502 - val_loss: 3.1282 - val_accuracy: 0.3528\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3276 - accuracy: 0.5508 - val_loss: 3.1590 - val_accuracy: 0.3491\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3314 - accuracy: 0.5468 - val_loss: 3.1485 - val_accuracy: 0.3528\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3292 - accuracy: 0.5473 - val_loss: 3.1324 - val_accuracy: 0.3510\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3229 - accuracy: 0.5520 - val_loss: 3.1232 - val_accuracy: 0.3455\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3314 - accuracy: 0.5462 - val_loss: 3.1148 - val_accuracy: 0.3461\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3348 - accuracy: 0.5455 - val_loss: 3.1089 - val_accuracy: 0.3564\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3223 - accuracy: 0.5519 - val_loss: 3.1449 - val_accuracy: 0.3479\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3335 - accuracy: 0.5455 - val_loss: 3.1507 - val_accuracy: 0.3455\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3312 - accuracy: 0.5491 - val_loss: 3.1397 - val_accuracy: 0.3534\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3291 - accuracy: 0.5509 - val_loss: 3.1352 - val_accuracy: 0.3449\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3150 - accuracy: 0.5557 - val_loss: 3.1514 - val_accuracy: 0.3528\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3287 - accuracy: 0.5464 - val_loss: 3.1441 - val_accuracy: 0.3479\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3298 - accuracy: 0.5446 - val_loss: 3.1203 - val_accuracy: 0.3583\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3267 - accuracy: 0.5505 - val_loss: 3.1277 - val_accuracy: 0.3552\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3302 - accuracy: 0.5490 - val_loss: 3.1193 - val_accuracy: 0.3601\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3260 - accuracy: 0.5509 - val_loss: 3.1407 - val_accuracy: 0.3498\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5522 - val_loss: 3.1584 - val_accuracy: 0.3406\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3320 - accuracy: 0.5505 - val_loss: 3.1243 - val_accuracy: 0.3491\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3320 - accuracy: 0.5517 - val_loss: 3.1427 - val_accuracy: 0.3504\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3375 - accuracy: 0.5471 - val_loss: 3.1642 - val_accuracy: 0.3510\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.5484 - val_loss: 3.1406 - val_accuracy: 0.3467\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5499 - val_loss: 3.1735 - val_accuracy: 0.3461\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3325 - accuracy: 0.5464 - val_loss: 3.1390 - val_accuracy: 0.3473\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3241 - accuracy: 0.5525 - val_loss: 3.1369 - val_accuracy: 0.3558\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5436 - val_loss: 3.1597 - val_accuracy: 0.3485\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5496 - val_loss: 3.1290 - val_accuracy: 0.3528\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3285 - accuracy: 0.5511 - val_loss: 3.1675 - val_accuracy: 0.3461\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3272 - accuracy: 0.5502 - val_loss: 3.1609 - val_accuracy: 0.3485\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3263 - accuracy: 0.5502 - val_loss: 3.1655 - val_accuracy: 0.3455\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3207 - accuracy: 0.5481 - val_loss: 3.1551 - val_accuracy: 0.3504\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5497 - val_loss: 3.1125 - val_accuracy: 0.3510\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3238 - accuracy: 0.5474 - val_loss: 3.1660 - val_accuracy: 0.3516\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3218 - accuracy: 0.5499 - val_loss: 3.1492 - val_accuracy: 0.3498\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3263 - accuracy: 0.5508 - val_loss: 3.1316 - val_accuracy: 0.3552\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3172 - accuracy: 0.5528 - val_loss: 3.1553 - val_accuracy: 0.3522\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3273 - accuracy: 0.5519 - val_loss: 3.1262 - val_accuracy: 0.3516\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.5511 - val_loss: 3.1512 - val_accuracy: 0.3516\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3258 - accuracy: 0.5446 - val_loss: 3.1645 - val_accuracy: 0.3418\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3310 - accuracy: 0.5471 - val_loss: 3.1710 - val_accuracy: 0.3461\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3368 - accuracy: 0.5430 - val_loss: 3.1473 - val_accuracy: 0.3461\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3199 - accuracy: 0.5494 - val_loss: 3.1508 - val_accuracy: 0.3516\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5447 - val_loss: 3.1586 - val_accuracy: 0.3504\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5482 - val_loss: 3.1614 - val_accuracy: 0.3485\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3195 - accuracy: 0.5534 - val_loss: 3.1335 - val_accuracy: 0.3516\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3249 - accuracy: 0.5516 - val_loss: 3.1668 - val_accuracy: 0.3498\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3254 - accuracy: 0.5470 - val_loss: 3.1622 - val_accuracy: 0.3461\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3328 - accuracy: 0.5497 - val_loss: 3.1388 - val_accuracy: 0.3498\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3267 - accuracy: 0.5522 - val_loss: 3.1494 - val_accuracy: 0.3522\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3265 - accuracy: 0.5506 - val_loss: 3.1445 - val_accuracy: 0.3498\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.5484 - val_loss: 3.1569 - val_accuracy: 0.3546\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3309 - accuracy: 0.5482 - val_loss: 3.1554 - val_accuracy: 0.3498\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3188 - accuracy: 0.5499 - val_loss: 3.1376 - val_accuracy: 0.3540\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3156 - accuracy: 0.5465 - val_loss: 3.1647 - val_accuracy: 0.3455\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3224 - accuracy: 0.5508 - val_loss: 3.1644 - val_accuracy: 0.3455\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3261 - accuracy: 0.5464 - val_loss: 3.1567 - val_accuracy: 0.3552\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3390 - accuracy: 0.5464 - val_loss: 3.1392 - val_accuracy: 0.3540\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5439 - val_loss: 3.1338 - val_accuracy: 0.3552\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3318 - accuracy: 0.5459 - val_loss: 3.1385 - val_accuracy: 0.3455\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3206 - accuracy: 0.5531 - val_loss: 3.1150 - val_accuracy: 0.3571\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3264 - accuracy: 0.5532 - val_loss: 3.1484 - val_accuracy: 0.3479\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3137 - accuracy: 0.5526 - val_loss: 3.1536 - val_accuracy: 0.3571\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3312 - accuracy: 0.5525 - val_loss: 3.1456 - val_accuracy: 0.3522\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5511 - val_loss: 3.1328 - val_accuracy: 0.3516\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3263 - accuracy: 0.5484 - val_loss: 3.1512 - val_accuracy: 0.3577\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3227 - accuracy: 0.5569 - val_loss: 3.1511 - val_accuracy: 0.3455\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3298 - accuracy: 0.5471 - val_loss: 3.1636 - val_accuracy: 0.3498\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3217 - accuracy: 0.5494 - val_loss: 3.1418 - val_accuracy: 0.3491\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3226 - accuracy: 0.5459 - val_loss: 3.1618 - val_accuracy: 0.3485\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3284 - accuracy: 0.5509 - val_loss: 3.1660 - val_accuracy: 0.3516\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3300 - accuracy: 0.5485 - val_loss: 3.1492 - val_accuracy: 0.3394\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3278 - accuracy: 0.5444 - val_loss: 3.1660 - val_accuracy: 0.3504\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3219 - accuracy: 0.5484 - val_loss: 3.1616 - val_accuracy: 0.3473\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3257 - accuracy: 0.5512 - val_loss: 3.1361 - val_accuracy: 0.3546\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3323 - accuracy: 0.5494 - val_loss: 3.1382 - val_accuracy: 0.3564\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3220 - accuracy: 0.5494 - val_loss: 3.1349 - val_accuracy: 0.3546\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3309 - accuracy: 0.5544 - val_loss: 3.1488 - val_accuracy: 0.3516\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3212 - accuracy: 0.5516 - val_loss: 3.1708 - val_accuracy: 0.3467\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3273 - accuracy: 0.5535 - val_loss: 3.1407 - val_accuracy: 0.3540\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3218 - accuracy: 0.5488 - val_loss: 3.1553 - val_accuracy: 0.3540\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5532 - val_loss: 3.1802 - val_accuracy: 0.3418\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3262 - accuracy: 0.5517 - val_loss: 3.1643 - val_accuracy: 0.3504\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3210 - accuracy: 0.5532 - val_loss: 3.1631 - val_accuracy: 0.3498\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3230 - accuracy: 0.5493 - val_loss: 3.1236 - val_accuracy: 0.3546\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5508 - val_loss: 3.1342 - val_accuracy: 0.3577\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3239 - accuracy: 0.5517 - val_loss: 3.1309 - val_accuracy: 0.3595\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3291 - accuracy: 0.5473 - val_loss: 3.1319 - val_accuracy: 0.3504\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3277 - accuracy: 0.5516 - val_loss: 3.1494 - val_accuracy: 0.3589\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3217 - accuracy: 0.5505 - val_loss: 3.1444 - val_accuracy: 0.3577\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3300 - accuracy: 0.5474 - val_loss: 3.1286 - val_accuracy: 0.3607\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3201 - accuracy: 0.5535 - val_loss: 3.1397 - val_accuracy: 0.3540\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3255 - accuracy: 0.5461 - val_loss: 3.1218 - val_accuracy: 0.3540\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3261 - accuracy: 0.5505 - val_loss: 3.1185 - val_accuracy: 0.3552\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3295 - accuracy: 0.5502 - val_loss: 3.1419 - val_accuracy: 0.3534\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3265 - accuracy: 0.5502 - val_loss: 3.1489 - val_accuracy: 0.3504\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.5520 - val_loss: 3.1396 - val_accuracy: 0.3522\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3259 - accuracy: 0.5506 - val_loss: 3.1499 - val_accuracy: 0.3485\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3269 - accuracy: 0.5508 - val_loss: 3.1622 - val_accuracy: 0.3485\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.5476 - val_loss: 3.1641 - val_accuracy: 0.3437\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5438 - val_loss: 3.1671 - val_accuracy: 0.3467\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3266 - accuracy: 0.5503 - val_loss: 3.1501 - val_accuracy: 0.3516\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3307 - accuracy: 0.5476 - val_loss: 3.1237 - val_accuracy: 0.3479\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3273 - accuracy: 0.5474 - val_loss: 3.1592 - val_accuracy: 0.3443\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3330 - accuracy: 0.5476 - val_loss: 3.1494 - val_accuracy: 0.3540\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3278 - accuracy: 0.5493 - val_loss: 3.1544 - val_accuracy: 0.3522\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3274 - accuracy: 0.5485 - val_loss: 3.1239 - val_accuracy: 0.3546\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3287 - accuracy: 0.5490 - val_loss: 3.1467 - val_accuracy: 0.3595\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3191 - accuracy: 0.5519 - val_loss: 3.1622 - val_accuracy: 0.3534\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3233 - accuracy: 0.5508 - val_loss: 3.1540 - val_accuracy: 0.3528\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3342 - accuracy: 0.5464 - val_loss: 3.1735 - val_accuracy: 0.3400\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3318 - accuracy: 0.5444 - val_loss: 3.1480 - val_accuracy: 0.3516\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5479 - val_loss: 3.1622 - val_accuracy: 0.3479\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3259 - accuracy: 0.5485 - val_loss: 3.1451 - val_accuracy: 0.3522\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3173 - accuracy: 0.5488 - val_loss: 3.1393 - val_accuracy: 0.3595\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3241 - accuracy: 0.5491 - val_loss: 3.1780 - val_accuracy: 0.3400\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3222 - accuracy: 0.5473 - val_loss: 3.1406 - val_accuracy: 0.3534\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3329 - accuracy: 0.5470 - val_loss: 3.1479 - val_accuracy: 0.3449\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3250 - accuracy: 0.5558 - val_loss: 3.1277 - val_accuracy: 0.3510\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3115 - accuracy: 0.5564 - val_loss: 3.1581 - val_accuracy: 0.3540\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5481 - val_loss: 3.1358 - val_accuracy: 0.3571\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3245 - accuracy: 0.5520 - val_loss: 3.1507 - val_accuracy: 0.3546\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3211 - accuracy: 0.5503 - val_loss: 3.1497 - val_accuracy: 0.3510\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3298 - accuracy: 0.5520 - val_loss: 3.1583 - val_accuracy: 0.3485\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3273 - accuracy: 0.5465 - val_loss: 3.1537 - val_accuracy: 0.3528\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3209 - accuracy: 0.5517 - val_loss: 3.1507 - val_accuracy: 0.3558\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3253 - accuracy: 0.5519 - val_loss: 3.1446 - val_accuracy: 0.3589\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3279 - accuracy: 0.5441 - val_loss: 3.1338 - val_accuracy: 0.3516\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3267 - accuracy: 0.5459 - val_loss: 3.1493 - val_accuracy: 0.3583\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3257 - accuracy: 0.5496 - val_loss: 3.1328 - val_accuracy: 0.3516\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3232 - accuracy: 0.5505 - val_loss: 3.1580 - val_accuracy: 0.3528\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3174 - accuracy: 0.5543 - val_loss: 3.1480 - val_accuracy: 0.3546\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3267 - accuracy: 0.5491 - val_loss: 3.1528 - val_accuracy: 0.3558\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3210 - accuracy: 0.5506 - val_loss: 3.1679 - val_accuracy: 0.3467\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3183 - accuracy: 0.5531 - val_loss: 3.1705 - val_accuracy: 0.3498\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3286 - accuracy: 0.5467 - val_loss: 3.1557 - val_accuracy: 0.3558\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3217 - accuracy: 0.5493 - val_loss: 3.1377 - val_accuracy: 0.3650\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3186 - accuracy: 0.5573 - val_loss: 3.1749 - val_accuracy: 0.3479\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.5544 - val_loss: 3.1493 - val_accuracy: 0.3510\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3193 - accuracy: 0.5554 - val_loss: 3.1634 - val_accuracy: 0.3485\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3288 - accuracy: 0.5493 - val_loss: 3.1556 - val_accuracy: 0.3516\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3249 - accuracy: 0.5484 - val_loss: 3.1957 - val_accuracy: 0.3455\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3231 - accuracy: 0.5477 - val_loss: 3.1477 - val_accuracy: 0.3540\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3330 - accuracy: 0.5467 - val_loss: 3.1623 - val_accuracy: 0.3522\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5516 - val_loss: 3.1549 - val_accuracy: 0.3516\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3323 - accuracy: 0.5479 - val_loss: 3.1562 - val_accuracy: 0.3552\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3246 - accuracy: 0.5517 - val_loss: 3.1762 - val_accuracy: 0.3443\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3179 - accuracy: 0.5528 - val_loss: 3.1324 - val_accuracy: 0.3504\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3243 - accuracy: 0.5532 - val_loss: 3.1579 - val_accuracy: 0.3540\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3219 - accuracy: 0.5520 - val_loss: 3.1842 - val_accuracy: 0.3437\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3174 - accuracy: 0.5514 - val_loss: 3.1562 - val_accuracy: 0.3485\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3276 - accuracy: 0.5538 - val_loss: 3.1401 - val_accuracy: 0.3504\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3226 - accuracy: 0.5473 - val_loss: 3.1551 - val_accuracy: 0.3534\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3111 - accuracy: 0.5505 - val_loss: 3.1726 - val_accuracy: 0.3455\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3171 - accuracy: 0.5528 - val_loss: 3.1687 - val_accuracy: 0.3558\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3229 - accuracy: 0.5502 - val_loss: 3.1853 - val_accuracy: 0.3412\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3297 - accuracy: 0.5497 - val_loss: 3.1779 - val_accuracy: 0.3412\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3210 - accuracy: 0.5526 - val_loss: 3.1532 - val_accuracy: 0.3473\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3269 - accuracy: 0.5508 - val_loss: 3.1643 - val_accuracy: 0.3479\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3195 - accuracy: 0.5479 - val_loss: 3.1806 - val_accuracy: 0.3376\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3282 - accuracy: 0.5441 - val_loss: 3.1518 - val_accuracy: 0.3467\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3203 - accuracy: 0.5497 - val_loss: 3.1496 - val_accuracy: 0.3504\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3263 - accuracy: 0.5503 - val_loss: 3.1947 - val_accuracy: 0.3461\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3249 - accuracy: 0.5476 - val_loss: 3.1454 - val_accuracy: 0.3473\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3200 - accuracy: 0.5546 - val_loss: 3.1700 - val_accuracy: 0.3461\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3272 - accuracy: 0.5474 - val_loss: 3.1849 - val_accuracy: 0.3376\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3256 - accuracy: 0.5506 - val_loss: 3.1767 - val_accuracy: 0.3431\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3330 - accuracy: 0.5485 - val_loss: 3.1849 - val_accuracy: 0.3382\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3279 - accuracy: 0.5544 - val_loss: 3.1416 - val_accuracy: 0.3522\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3189 - accuracy: 0.5506 - val_loss: 3.1478 - val_accuracy: 0.3546\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3334 - accuracy: 0.5446 - val_loss: 3.1690 - val_accuracy: 0.3437\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3175 - accuracy: 0.5493 - val_loss: 3.1456 - val_accuracy: 0.3558\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3168 - accuracy: 0.5516 - val_loss: 3.1405 - val_accuracy: 0.3558\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3174 - accuracy: 0.5525 - val_loss: 3.1845 - val_accuracy: 0.3449\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3206 - accuracy: 0.5487 - val_loss: 3.1400 - val_accuracy: 0.3528\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3263 - accuracy: 0.5464 - val_loss: 3.1487 - val_accuracy: 0.3528\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3235 - accuracy: 0.5509 - val_loss: 3.1677 - val_accuracy: 0.3491\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3216 - accuracy: 0.5496 - val_loss: 3.1240 - val_accuracy: 0.3595\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5471 - val_loss: 3.1662 - val_accuracy: 0.3491\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3235 - accuracy: 0.5519 - val_loss: 3.1516 - val_accuracy: 0.3491\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5497 - val_loss: 3.1641 - val_accuracy: 0.3449\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3198 - accuracy: 0.5511 - val_loss: 3.1552 - val_accuracy: 0.3473\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3191 - accuracy: 0.5540 - val_loss: 3.1741 - val_accuracy: 0.3595\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.5467 - val_loss: 3.1531 - val_accuracy: 0.3528\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3209 - accuracy: 0.5458 - val_loss: 3.1286 - val_accuracy: 0.3558\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3294 - accuracy: 0.5484 - val_loss: 3.1478 - val_accuracy: 0.3431\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.5506 - val_loss: 3.1649 - val_accuracy: 0.3437\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3217 - accuracy: 0.5526 - val_loss: 3.1754 - val_accuracy: 0.3485\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3247 - accuracy: 0.5511 - val_loss: 3.1610 - val_accuracy: 0.3400\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3223 - accuracy: 0.5439 - val_loss: 3.1566 - val_accuracy: 0.3504\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3239 - accuracy: 0.5473 - val_loss: 3.1608 - val_accuracy: 0.3498\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5497 - val_loss: 3.1832 - val_accuracy: 0.3352\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3248 - accuracy: 0.5459 - val_loss: 3.1849 - val_accuracy: 0.3534\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3235 - accuracy: 0.5499 - val_loss: 3.1496 - val_accuracy: 0.3510\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3276 - accuracy: 0.5509 - val_loss: 3.1532 - val_accuracy: 0.3522\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3239 - accuracy: 0.5517 - val_loss: 3.1664 - val_accuracy: 0.3504\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3162 - accuracy: 0.5552 - val_loss: 3.1647 - val_accuracy: 0.3528\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3162 - accuracy: 0.5525 - val_loss: 3.1473 - val_accuracy: 0.3491\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3203 - accuracy: 0.5474 - val_loss: 3.1697 - val_accuracy: 0.3491\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3273 - accuracy: 0.5491 - val_loss: 3.1665 - val_accuracy: 0.3522\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3200 - accuracy: 0.5506 - val_loss: 3.1734 - val_accuracy: 0.3522\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3266 - accuracy: 0.5516 - val_loss: 3.1659 - val_accuracy: 0.3455\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3311 - accuracy: 0.5458 - val_loss: 3.1425 - val_accuracy: 0.3485\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3382 - accuracy: 0.5436 - val_loss: 3.1394 - val_accuracy: 0.3552\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3216 - accuracy: 0.5509 - val_loss: 3.1816 - val_accuracy: 0.3485\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3271 - accuracy: 0.5455 - val_loss: 3.1761 - val_accuracy: 0.3504\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3213 - accuracy: 0.5554 - val_loss: 3.1716 - val_accuracy: 0.3516\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3212 - accuracy: 0.5493 - val_loss: 3.1571 - val_accuracy: 0.3504\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.5467 - val_loss: 3.1664 - val_accuracy: 0.3498\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3300 - accuracy: 0.5468 - val_loss: 3.1304 - val_accuracy: 0.3528\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3286 - accuracy: 0.5459 - val_loss: 3.1725 - val_accuracy: 0.3431\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3256 - accuracy: 0.5499 - val_loss: 3.1527 - val_accuracy: 0.3449\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3258 - accuracy: 0.5476 - val_loss: 3.1485 - val_accuracy: 0.3564\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3244 - accuracy: 0.5508 - val_loss: 3.1506 - val_accuracy: 0.3552\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3263 - accuracy: 0.5481 - val_loss: 3.1844 - val_accuracy: 0.3498\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3231 - accuracy: 0.5500 - val_loss: 3.1608 - val_accuracy: 0.3455\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3290 - accuracy: 0.5503 - val_loss: 3.1344 - val_accuracy: 0.3558\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3193 - accuracy: 0.5500 - val_loss: 3.1497 - val_accuracy: 0.3498\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.5516 - val_loss: 3.1631 - val_accuracy: 0.3540\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3269 - accuracy: 0.5516 - val_loss: 3.1522 - val_accuracy: 0.3498\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3302 - accuracy: 0.5476 - val_loss: 3.1495 - val_accuracy: 0.3473\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3205 - accuracy: 0.5499 - val_loss: 3.1797 - val_accuracy: 0.3400\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3177 - accuracy: 0.5526 - val_loss: 3.1345 - val_accuracy: 0.3534\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3218 - accuracy: 0.5494 - val_loss: 3.1690 - val_accuracy: 0.3528\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3302 - accuracy: 0.5449 - val_loss: 3.1816 - val_accuracy: 0.3479\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3281 - accuracy: 0.5459 - val_loss: 3.1425 - val_accuracy: 0.3522\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3153 - accuracy: 0.5502 - val_loss: 3.1439 - val_accuracy: 0.3522\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3185 - accuracy: 0.5520 - val_loss: 3.1547 - val_accuracy: 0.3522\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3244 - accuracy: 0.5516 - val_loss: 3.1441 - val_accuracy: 0.3516\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5503 - val_loss: 3.1434 - val_accuracy: 0.3552\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3243 - accuracy: 0.5465 - val_loss: 3.1244 - val_accuracy: 0.3552\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3211 - accuracy: 0.5514 - val_loss: 3.1656 - val_accuracy: 0.3558\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3258 - accuracy: 0.5496 - val_loss: 3.1766 - val_accuracy: 0.3388\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3208 - accuracy: 0.5502 - val_loss: 3.1649 - val_accuracy: 0.3485\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3233 - accuracy: 0.5516 - val_loss: 3.1454 - val_accuracy: 0.3528\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3198 - accuracy: 0.5555 - val_loss: 3.1572 - val_accuracy: 0.3540\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3229 - accuracy: 0.5511 - val_loss: 3.1350 - val_accuracy: 0.3558\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3216 - accuracy: 0.5508 - val_loss: 3.1896 - val_accuracy: 0.3504\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3285 - accuracy: 0.5494 - val_loss: 3.1819 - val_accuracy: 0.3437\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5443 - val_loss: 3.1712 - val_accuracy: 0.3534\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3281 - accuracy: 0.5491 - val_loss: 3.1569 - val_accuracy: 0.3522\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3181 - accuracy: 0.5532 - val_loss: 3.1673 - val_accuracy: 0.3504\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3200 - accuracy: 0.5503 - val_loss: 3.1460 - val_accuracy: 0.3522\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3234 - accuracy: 0.5508 - val_loss: 3.1379 - val_accuracy: 0.3534\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3275 - accuracy: 0.5500 - val_loss: 3.1590 - val_accuracy: 0.3528\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3168 - accuracy: 0.5502 - val_loss: 3.1773 - val_accuracy: 0.3455\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3173 - accuracy: 0.5499 - val_loss: 3.1678 - val_accuracy: 0.3461\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3233 - accuracy: 0.5491 - val_loss: 3.1697 - val_accuracy: 0.3461\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3248 - accuracy: 0.5464 - val_loss: 3.1589 - val_accuracy: 0.3431\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3303 - accuracy: 0.5468 - val_loss: 3.1584 - val_accuracy: 0.3558\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3232 - accuracy: 0.5505 - val_loss: 3.1656 - val_accuracy: 0.3431\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3169 - accuracy: 0.5526 - val_loss: 3.1820 - val_accuracy: 0.3425\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3160 - accuracy: 0.5544 - val_loss: 3.1545 - val_accuracy: 0.3510\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3192 - accuracy: 0.5499 - val_loss: 3.1749 - val_accuracy: 0.3504\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3310 - accuracy: 0.5471 - val_loss: 3.1380 - val_accuracy: 0.3491\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3258 - accuracy: 0.5455 - val_loss: 3.1663 - val_accuracy: 0.3461\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3231 - accuracy: 0.5485 - val_loss: 3.1363 - val_accuracy: 0.3595\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3182 - accuracy: 0.5564 - val_loss: 3.1893 - val_accuracy: 0.3437\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3275 - accuracy: 0.5503 - val_loss: 3.1463 - val_accuracy: 0.3485\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3176 - accuracy: 0.5550 - val_loss: 3.1523 - val_accuracy: 0.3534\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3267 - accuracy: 0.5543 - val_loss: 3.1820 - val_accuracy: 0.3370\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3236 - accuracy: 0.5519 - val_loss: 3.1865 - val_accuracy: 0.3498\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3188 - accuracy: 0.5555 - val_loss: 3.1729 - val_accuracy: 0.3443\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3196 - accuracy: 0.5503 - val_loss: 3.1855 - val_accuracy: 0.3467\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3326 - accuracy: 0.5441 - val_loss: 3.1758 - val_accuracy: 0.3473\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3258 - accuracy: 0.5493 - val_loss: 3.1771 - val_accuracy: 0.3528\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3216 - accuracy: 0.5549 - val_loss: 3.1735 - val_accuracy: 0.3534\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.5494 - val_loss: 3.1808 - val_accuracy: 0.3425\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3227 - accuracy: 0.5522 - val_loss: 3.1992 - val_accuracy: 0.3473\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.5465 - val_loss: 3.1728 - val_accuracy: 0.3388\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3240 - accuracy: 0.5512 - val_loss: 3.1613 - val_accuracy: 0.3491\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3255 - accuracy: 0.5494 - val_loss: 3.1671 - val_accuracy: 0.3467\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3214 - accuracy: 0.5488 - val_loss: 3.1595 - val_accuracy: 0.3498\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3240 - accuracy: 0.5488 - val_loss: 3.1632 - val_accuracy: 0.3528\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3302 - accuracy: 0.5452 - val_loss: 3.1566 - val_accuracy: 0.3583\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3225 - accuracy: 0.5493 - val_loss: 3.1775 - val_accuracy: 0.3498\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3199 - accuracy: 0.5519 - val_loss: 3.2023 - val_accuracy: 0.3467\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3176 - accuracy: 0.5482 - val_loss: 3.1620 - val_accuracy: 0.3467\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3137 - accuracy: 0.5541 - val_loss: 3.1706 - val_accuracy: 0.3571\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3325 - accuracy: 0.5512 - val_loss: 3.1631 - val_accuracy: 0.3577\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3212 - accuracy: 0.5564 - val_loss: 3.1699 - val_accuracy: 0.3485\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3273 - accuracy: 0.5482 - val_loss: 3.1786 - val_accuracy: 0.3479\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3243 - accuracy: 0.5452 - val_loss: 3.1863 - val_accuracy: 0.3437\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3193 - accuracy: 0.5499 - val_loss: 3.1896 - val_accuracy: 0.3522\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3216 - accuracy: 0.5468 - val_loss: 3.1595 - val_accuracy: 0.3564\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3201 - accuracy: 0.5534 - val_loss: 3.1739 - val_accuracy: 0.3546\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3248 - accuracy: 0.5526 - val_loss: 3.1595 - val_accuracy: 0.3540\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3164 - accuracy: 0.5526 - val_loss: 3.1650 - val_accuracy: 0.3455\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3307 - accuracy: 0.5461 - val_loss: 3.1586 - val_accuracy: 0.3455\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3304 - accuracy: 0.5496 - val_loss: 3.1760 - val_accuracy: 0.3406\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3162 - accuracy: 0.5508 - val_loss: 3.1622 - val_accuracy: 0.3510\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3259 - accuracy: 0.5493 - val_loss: 3.2086 - val_accuracy: 0.3406\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3280 - accuracy: 0.5438 - val_loss: 3.1791 - val_accuracy: 0.3491\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3252 - accuracy: 0.5508 - val_loss: 3.1819 - val_accuracy: 0.3461\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3240 - accuracy: 0.5547 - val_loss: 3.1521 - val_accuracy: 0.3491\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3158 - accuracy: 0.5500 - val_loss: 3.1595 - val_accuracy: 0.3540\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3257 - accuracy: 0.5500 - val_loss: 3.1730 - val_accuracy: 0.3522\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3215 - accuracy: 0.5488 - val_loss: 3.1595 - val_accuracy: 0.3510\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3175 - accuracy: 0.5523 - val_loss: 3.1692 - val_accuracy: 0.3510\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3190 - accuracy: 0.5443 - val_loss: 3.1636 - val_accuracy: 0.3552\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3215 - accuracy: 0.5473 - val_loss: 3.1598 - val_accuracy: 0.3498\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3155 - accuracy: 0.5487 - val_loss: 3.1906 - val_accuracy: 0.3376\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3190 - accuracy: 0.5522 - val_loss: 3.1799 - val_accuracy: 0.3534\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3268 - accuracy: 0.5452 - val_loss: 3.1717 - val_accuracy: 0.3522\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3119 - accuracy: 0.5541 - val_loss: 3.1494 - val_accuracy: 0.3613\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3234 - accuracy: 0.5494 - val_loss: 3.1659 - val_accuracy: 0.3485\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3218 - accuracy: 0.5526 - val_loss: 3.1675 - val_accuracy: 0.3504\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3317 - accuracy: 0.5540 - val_loss: 3.1636 - val_accuracy: 0.3461\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3282 - accuracy: 0.5497 - val_loss: 3.1578 - val_accuracy: 0.3504\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3220 - accuracy: 0.5529 - val_loss: 3.1858 - val_accuracy: 0.3400\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3253 - accuracy: 0.5465 - val_loss: 3.1626 - val_accuracy: 0.3595\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.5488 - val_loss: 3.1239 - val_accuracy: 0.3601\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3268 - accuracy: 0.5476 - val_loss: 3.1684 - val_accuracy: 0.3528\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3180 - accuracy: 0.5500 - val_loss: 3.1708 - val_accuracy: 0.3498\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3193 - accuracy: 0.5496 - val_loss: 3.1655 - val_accuracy: 0.3431\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3281 - accuracy: 0.5436 - val_loss: 3.1768 - val_accuracy: 0.3504\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3294 - accuracy: 0.5503 - val_loss: 3.1557 - val_accuracy: 0.3546\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3151 - accuracy: 0.5535 - val_loss: 3.1905 - val_accuracy: 0.3534\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3219 - accuracy: 0.5535 - val_loss: 3.1743 - val_accuracy: 0.3498\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3207 - accuracy: 0.5522 - val_loss: 3.1626 - val_accuracy: 0.3418\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3279 - accuracy: 0.5476 - val_loss: 3.1714 - val_accuracy: 0.3473\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3199 - accuracy: 0.5529 - val_loss: 3.1630 - val_accuracy: 0.3522\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3191 - accuracy: 0.5467 - val_loss: 3.1825 - val_accuracy: 0.3589\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3140 - accuracy: 0.5514 - val_loss: 3.1702 - val_accuracy: 0.3485\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3235 - accuracy: 0.5500 - val_loss: 3.1710 - val_accuracy: 0.3498\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3244 - accuracy: 0.5500 - val_loss: 3.1792 - val_accuracy: 0.3455\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3235 - accuracy: 0.5455 - val_loss: 3.1979 - val_accuracy: 0.3504\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3168 - accuracy: 0.5471 - val_loss: 3.1570 - val_accuracy: 0.3564\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5444 - val_loss: 3.1805 - val_accuracy: 0.3491\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3233 - accuracy: 0.5514 - val_loss: 3.1675 - val_accuracy: 0.3516\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3220 - accuracy: 0.5487 - val_loss: 3.1572 - val_accuracy: 0.3516\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3141 - accuracy: 0.5508 - val_loss: 3.2007 - val_accuracy: 0.3394\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3226 - accuracy: 0.5506 - val_loss: 3.1960 - val_accuracy: 0.3400\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3186 - accuracy: 0.5516 - val_loss: 3.1829 - val_accuracy: 0.3516\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3287 - accuracy: 0.5488 - val_loss: 3.1768 - val_accuracy: 0.3491\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.3186 - accuracy: 0.5517 - val_loss: 3.1727 - val_accuracy: 0.3540\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3236 - accuracy: 0.5490 - val_loss: 3.2011 - val_accuracy: 0.3437\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3292 - accuracy: 0.5464 - val_loss: 3.1856 - val_accuracy: 0.3540\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3199 - accuracy: 0.5456 - val_loss: 3.1740 - val_accuracy: 0.3443\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3233 - accuracy: 0.5477 - val_loss: 3.1972 - val_accuracy: 0.3522\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3244 - accuracy: 0.5506 - val_loss: 3.1986 - val_accuracy: 0.3443\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3291 - accuracy: 0.5477 - val_loss: 3.1729 - val_accuracy: 0.3498\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3206 - accuracy: 0.5535 - val_loss: 3.1719 - val_accuracy: 0.3510\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3224 - accuracy: 0.5523 - val_loss: 3.1699 - val_accuracy: 0.3558\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3197 - accuracy: 0.5508 - val_loss: 3.2017 - val_accuracy: 0.3449\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3219 - accuracy: 0.5516 - val_loss: 3.1897 - val_accuracy: 0.3479\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3183 - accuracy: 0.5531 - val_loss: 3.1733 - val_accuracy: 0.3522\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3157 - accuracy: 0.5526 - val_loss: 3.2034 - val_accuracy: 0.3388\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3183 - accuracy: 0.5511 - val_loss: 3.1798 - val_accuracy: 0.3528\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3272 - accuracy: 0.5511 - val_loss: 3.1939 - val_accuracy: 0.3504\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3280 - accuracy: 0.5496 - val_loss: 3.1727 - val_accuracy: 0.3534\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3238 - accuracy: 0.5488 - val_loss: 3.1597 - val_accuracy: 0.3516\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3163 - accuracy: 0.5543 - val_loss: 3.1773 - val_accuracy: 0.3473\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3160 - accuracy: 0.5528 - val_loss: 3.1820 - val_accuracy: 0.3491\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3265 - accuracy: 0.5470 - val_loss: 3.1657 - val_accuracy: 0.3491\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.5488 - val_loss: 3.1697 - val_accuracy: 0.3473\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3187 - accuracy: 0.5547 - val_loss: 3.1882 - val_accuracy: 0.3498\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3289 - accuracy: 0.5499 - val_loss: 3.1825 - val_accuracy: 0.3437\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3190 - accuracy: 0.5505 - val_loss: 3.2079 - val_accuracy: 0.3449\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3197 - accuracy: 0.5511 - val_loss: 3.1586 - val_accuracy: 0.3516\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3254 - accuracy: 0.5468 - val_loss: 3.1433 - val_accuracy: 0.3528\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3105 - accuracy: 0.5550 - val_loss: 3.1892 - val_accuracy: 0.3479\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3187 - accuracy: 0.5479 - val_loss: 3.1703 - val_accuracy: 0.3504\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3228 - accuracy: 0.5485 - val_loss: 3.1738 - val_accuracy: 0.3510\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3245 - accuracy: 0.5464 - val_loss: 3.1851 - val_accuracy: 0.3461\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.5481 - val_loss: 3.1555 - val_accuracy: 0.3504\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3187 - accuracy: 0.5479 - val_loss: 3.1992 - val_accuracy: 0.3510\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3277 - accuracy: 0.5516 - val_loss: 3.1983 - val_accuracy: 0.3449\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3195 - accuracy: 0.5544 - val_loss: 3.1899 - val_accuracy: 0.3510\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3214 - accuracy: 0.5497 - val_loss: 3.1800 - val_accuracy: 0.3473\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3277 - accuracy: 0.5481 - val_loss: 3.1573 - val_accuracy: 0.3601\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3303 - accuracy: 0.5497 - val_loss: 3.1656 - val_accuracy: 0.3528\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3233 - accuracy: 0.5547 - val_loss: 3.1487 - val_accuracy: 0.3485\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3275 - accuracy: 0.5506 - val_loss: 3.1476 - val_accuracy: 0.3528\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3268 - accuracy: 0.5477 - val_loss: 3.1686 - val_accuracy: 0.3510\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3191 - accuracy: 0.5485 - val_loss: 3.1745 - val_accuracy: 0.3485\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3290 - accuracy: 0.5455 - val_loss: 3.1679 - val_accuracy: 0.3479\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3230 - accuracy: 0.5502 - val_loss: 3.2058 - val_accuracy: 0.3516\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3232 - accuracy: 0.5512 - val_loss: 3.2002 - val_accuracy: 0.3455\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3218 - accuracy: 0.5512 - val_loss: 3.1731 - val_accuracy: 0.3571\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3190 - accuracy: 0.5526 - val_loss: 3.1815 - val_accuracy: 0.3473\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3147 - accuracy: 0.5522 - val_loss: 3.2097 - val_accuracy: 0.3437\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3182 - accuracy: 0.5471 - val_loss: 3.2034 - val_accuracy: 0.3455\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3142 - accuracy: 0.5482 - val_loss: 3.2171 - val_accuracy: 0.3443\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3224 - accuracy: 0.5464 - val_loss: 3.1821 - val_accuracy: 0.3504\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3231 - accuracy: 0.5550 - val_loss: 3.1404 - val_accuracy: 0.3498\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3165 - accuracy: 0.5500 - val_loss: 3.1983 - val_accuracy: 0.3504\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3231 - accuracy: 0.5487 - val_loss: 3.1676 - val_accuracy: 0.3437\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3219 - accuracy: 0.5523 - val_loss: 3.1765 - val_accuracy: 0.3485\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3233 - accuracy: 0.5487 - val_loss: 3.2055 - val_accuracy: 0.3504\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3235 - accuracy: 0.5470 - val_loss: 3.1689 - val_accuracy: 0.3479\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3233 - accuracy: 0.5500 - val_loss: 3.1621 - val_accuracy: 0.3455\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3196 - accuracy: 0.5534 - val_loss: 3.1913 - val_accuracy: 0.3498\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3130 - accuracy: 0.5549 - val_loss: 3.1557 - val_accuracy: 0.3528\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1.3239 - accuracy: 0.5465 - val_loss: 3.1545 - val_accuracy: 0.3516\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model (batch size 64)\n",
    "history_emb_simple_64 = Emb_model_simple.fit(x_emb_train, y_emb_train,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=64,\n",
    "                                 validation_data=(x_emb_test, y_emb_test)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_Emb_baseline_model_history_bs64.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_simple_64.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 552 (Val Accuracy: 0.36618006229400635)\n",
      "Best Epoch for Training Accuracy: 448 (Train Accuracy: 0.5582420825958252)\n",
      "Best Epoch for Training Loss: 967 (Train Loss: 1.3104995489120483)\n",
      "Best Epoch for Validation Loss: 8 (Val Loss: 3.0324811935424805)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.36618006229400635\n",
      "Maximum Training Accuracy: 0.5582420825958252\n",
      "Minimum Training Loss: 1.3104995489120483\n",
      "Minimum Validation Loss: 3.0324811935424805\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_simple_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_simple_64, epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex LSTM with word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 100)            3200      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 64)             42240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 64)             2112      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 62,048\n",
      "Trainable params: 58,848\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, TimeDistributed\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 77\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Parameters\n",
    "input_length = 4  # Length of input sequences\n",
    "num_moves = len(embedding_matrix)  # Number of unique moves\n",
    "embedding_dim = len(embedding_matrix[0])  # Dimension of Word2Vec embeddings\n",
    "\n",
    "\n",
    "# Define the LSTM model with an Embedding layer\n",
    "Emb_model_complex = Sequential([\n",
    "    # Embedding layer with pre-trained Word2Vec weights\n",
    "    Embedding(input_dim=num_moves, output_dim=embedding_dim,  weights=[embedding_matrix], trainable=False, \n",
    "              input_length=input_length),\n",
    "\n",
    "    # First LSTM layer\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Second LSTM layer\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Dense layer\n",
    "    TimeDistributed(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))),\n",
    "\n",
    "    # Output layer\n",
    "    TimeDistributed(Dense(32, activation='softmax'))  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "Emb_model_complex.compile(optimizer='adam', \n",
    "                                   loss='categorical_crossentropy', \n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "Emb_model_complex.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "103/103 [==============================] - 4s 13ms/step - loss: 3.1370 - accuracy: 0.2415 - val_loss: 2.5007 - val_accuracy: 0.3954\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4933 - accuracy: 0.3074 - val_loss: 2.4726 - val_accuracy: 0.3954\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4608 - accuracy: 0.3032 - val_loss: 2.4577 - val_accuracy: 0.3954\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4315 - accuracy: 0.3148 - val_loss: 2.4614 - val_accuracy: 0.3954\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4294 - accuracy: 0.3047 - val_loss: 2.4512 - val_accuracy: 0.3954\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4250 - accuracy: 0.3106 - val_loss: 2.4545 - val_accuracy: 0.3954\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4090 - accuracy: 0.3029 - val_loss: 2.4307 - val_accuracy: 0.3954\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4431 - accuracy: 0.3092 - val_loss: 2.4520 - val_accuracy: 0.3954\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4564 - accuracy: 0.3046 - val_loss: 2.4277 - val_accuracy: 0.3954\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.4042 - accuracy: 0.3056 - val_loss: 2.4268 - val_accuracy: 0.3954\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.3805 - accuracy: 0.3067 - val_loss: 2.3921 - val_accuracy: 0.3954\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4200 - accuracy: 0.2884 - val_loss: 2.3844 - val_accuracy: 0.3954\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3637 - accuracy: 0.3067 - val_loss: 2.3749 - val_accuracy: 0.3954\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3564 - accuracy: 0.3108 - val_loss: 2.3864 - val_accuracy: 0.3954\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 2.3361 - accuracy: 0.3097 - val_loss: 2.3547 - val_accuracy: 0.3954\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3167 - accuracy: 0.3109 - val_loss: 2.3386 - val_accuracy: 0.3954\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3195 - accuracy: 0.3029 - val_loss: 2.3518 - val_accuracy: 0.3954\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.3119 - accuracy: 0.3172 - val_loss: 2.3630 - val_accuracy: 0.3783\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.2847 - accuracy: 0.3127 - val_loss: 2.3430 - val_accuracy: 0.3954\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.3237 - accuracy: 0.3057 - val_loss: 2.3283 - val_accuracy: 0.3954\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.2793 - accuracy: 0.3030 - val_loss: 2.3146 - val_accuracy: 0.4015\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.2881 - accuracy: 0.3037 - val_loss: 2.2935 - val_accuracy: 0.4294\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.2118 - accuracy: 0.3180 - val_loss: 2.2806 - val_accuracy: 0.4197\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.1994 - accuracy: 0.3244 - val_loss: 2.2325 - val_accuracy: 0.4416\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.1685 - accuracy: 0.3472 - val_loss: 2.2134 - val_accuracy: 0.4471\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.1259 - accuracy: 0.3631 - val_loss: 2.2075 - val_accuracy: 0.4495\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.1127 - accuracy: 0.3595 - val_loss: 2.2177 - val_accuracy: 0.4300\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0985 - accuracy: 0.3551 - val_loss: 2.1889 - val_accuracy: 0.4501\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0975 - accuracy: 0.3563 - val_loss: 2.2272 - val_accuracy: 0.4355\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0961 - accuracy: 0.3618 - val_loss: 2.2006 - val_accuracy: 0.4270\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0627 - accuracy: 0.3781 - val_loss: 2.2003 - val_accuracy: 0.4398\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0586 - accuracy: 0.3716 - val_loss: 2.2254 - val_accuracy: 0.4355\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0212 - accuracy: 0.3783 - val_loss: 2.1858 - val_accuracy: 0.4586\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.0565 - accuracy: 0.3650 - val_loss: 2.2114 - val_accuracy: 0.4343\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0506 - accuracy: 0.3779 - val_loss: 2.2002 - val_accuracy: 0.4392\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0280 - accuracy: 0.3763 - val_loss: 2.2193 - val_accuracy: 0.4605\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0123 - accuracy: 0.3975 - val_loss: 2.2320 - val_accuracy: 0.4410\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0345 - accuracy: 0.3802 - val_loss: 2.2369 - val_accuracy: 0.4349\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.0498 - accuracy: 0.3875 - val_loss: 2.2291 - val_accuracy: 0.4294\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.0216 - accuracy: 0.3803 - val_loss: 2.2134 - val_accuracy: 0.4349\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9897 - accuracy: 0.3976 - val_loss: 2.2209 - val_accuracy: 0.4428\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9862 - accuracy: 0.4034 - val_loss: 2.2275 - val_accuracy: 0.4404\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9822 - accuracy: 0.3929 - val_loss: 2.2185 - val_accuracy: 0.4398\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9888 - accuracy: 0.3946 - val_loss: 2.2171 - val_accuracy: 0.4392\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9991 - accuracy: 0.3884 - val_loss: 2.2199 - val_accuracy: 0.4313\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9526 - accuracy: 0.4140 - val_loss: 2.2321 - val_accuracy: 0.4325\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9888 - accuracy: 0.3959 - val_loss: 2.2323 - val_accuracy: 0.4325\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9687 - accuracy: 0.4005 - val_loss: 2.2333 - val_accuracy: 0.4398\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9594 - accuracy: 0.3977 - val_loss: 2.2282 - val_accuracy: 0.4331\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9688 - accuracy: 0.4038 - val_loss: 2.2221 - val_accuracy: 0.4398\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9490 - accuracy: 0.4114 - val_loss: 2.2171 - val_accuracy: 0.4459\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9435 - accuracy: 0.4034 - val_loss: 2.2455 - val_accuracy: 0.4227\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9738 - accuracy: 0.3992 - val_loss: 2.2287 - val_accuracy: 0.4337\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9299 - accuracy: 0.4139 - val_loss: 2.2217 - val_accuracy: 0.4416\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9504 - accuracy: 0.4112 - val_loss: 2.2312 - val_accuracy: 0.4331\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9211 - accuracy: 0.4103 - val_loss: 2.2240 - val_accuracy: 0.4538\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9304 - accuracy: 0.4138 - val_loss: 2.2524 - val_accuracy: 0.4319\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.9164 - accuracy: 0.4083 - val_loss: 2.2463 - val_accuracy: 0.4258\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9300 - accuracy: 0.4031 - val_loss: 2.2323 - val_accuracy: 0.4495\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9363 - accuracy: 0.4137 - val_loss: 2.2517 - val_accuracy: 0.4313\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9027 - accuracy: 0.4143 - val_loss: 2.2452 - val_accuracy: 0.4392\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9370 - accuracy: 0.4071 - val_loss: 2.2618 - val_accuracy: 0.4288\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9448 - accuracy: 0.4099 - val_loss: 2.2493 - val_accuracy: 0.4276\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8951 - accuracy: 0.4195 - val_loss: 2.2486 - val_accuracy: 0.4264\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9298 - accuracy: 0.4112 - val_loss: 2.2680 - val_accuracy: 0.4252\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9160 - accuracy: 0.4201 - val_loss: 2.2577 - val_accuracy: 0.4331\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8932 - accuracy: 0.4259 - val_loss: 2.2466 - val_accuracy: 0.4367\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9247 - accuracy: 0.4073 - val_loss: 2.2417 - val_accuracy: 0.4349\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8923 - accuracy: 0.4155 - val_loss: 2.2557 - val_accuracy: 0.4434\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8696 - accuracy: 0.4318 - val_loss: 2.2564 - val_accuracy: 0.4373\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9078 - accuracy: 0.4063 - val_loss: 2.2494 - val_accuracy: 0.4325\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9022 - accuracy: 0.4167 - val_loss: 2.2619 - val_accuracy: 0.4361\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8990 - accuracy: 0.4208 - val_loss: 2.2652 - val_accuracy: 0.4300\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8852 - accuracy: 0.4183 - val_loss: 2.2759 - val_accuracy: 0.4361\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9086 - accuracy: 0.4130 - val_loss: 2.2757 - val_accuracy: 0.4477\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9015 - accuracy: 0.4180 - val_loss: 2.2859 - val_accuracy: 0.4088\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8934 - accuracy: 0.4193 - val_loss: 2.2570 - val_accuracy: 0.4538\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8905 - accuracy: 0.4153 - val_loss: 2.2625 - val_accuracy: 0.4495\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.9010 - accuracy: 0.4158 - val_loss: 2.2804 - val_accuracy: 0.4027\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8615 - accuracy: 0.4265 - val_loss: 2.2759 - val_accuracy: 0.4380\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8912 - accuracy: 0.4122 - val_loss: 2.2749 - val_accuracy: 0.4209\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8465 - accuracy: 0.4223 - val_loss: 2.2620 - val_accuracy: 0.4550\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.8749 - accuracy: 0.4195 - val_loss: 2.2824 - val_accuracy: 0.4367\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8770 - accuracy: 0.4173 - val_loss: 2.2918 - val_accuracy: 0.4094\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8641 - accuracy: 0.4252 - val_loss: 2.2821 - val_accuracy: 0.4307\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8793 - accuracy: 0.4244 - val_loss: 2.2981 - val_accuracy: 0.4124\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8736 - accuracy: 0.4185 - val_loss: 2.2900 - val_accuracy: 0.4373\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8637 - accuracy: 0.4121 - val_loss: 2.2784 - val_accuracy: 0.4252\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8552 - accuracy: 0.4201 - val_loss: 2.2853 - val_accuracy: 0.4240\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8747 - accuracy: 0.4239 - val_loss: 2.3057 - val_accuracy: 0.4173\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8598 - accuracy: 0.4319 - val_loss: 2.3112 - val_accuracy: 0.4173\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8418 - accuracy: 0.4251 - val_loss: 2.2919 - val_accuracy: 0.4343\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8900 - accuracy: 0.4147 - val_loss: 2.2955 - val_accuracy: 0.4258\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8574 - accuracy: 0.4212 - val_loss: 2.2919 - val_accuracy: 0.4355\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8511 - accuracy: 0.4276 - val_loss: 2.3083 - val_accuracy: 0.4343\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8312 - accuracy: 0.4335 - val_loss: 2.2906 - val_accuracy: 0.4355\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8425 - accuracy: 0.4256 - val_loss: 2.3231 - val_accuracy: 0.4294\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8436 - accuracy: 0.4260 - val_loss: 2.3011 - val_accuracy: 0.4349\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8258 - accuracy: 0.4327 - val_loss: 2.3004 - val_accuracy: 0.4367\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8201 - accuracy: 0.4378 - val_loss: 2.3017 - val_accuracy: 0.4313\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8440 - accuracy: 0.4336 - val_loss: 2.2997 - val_accuracy: 0.4197\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8409 - accuracy: 0.4292 - val_loss: 2.3099 - val_accuracy: 0.4300\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8540 - accuracy: 0.4273 - val_loss: 2.3037 - val_accuracy: 0.4373\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8551 - accuracy: 0.4208 - val_loss: 2.2926 - val_accuracy: 0.4331\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8707 - accuracy: 0.4160 - val_loss: 2.3125 - val_accuracy: 0.4428\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8235 - accuracy: 0.4433 - val_loss: 2.3148 - val_accuracy: 0.4051\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8474 - accuracy: 0.4160 - val_loss: 2.3269 - val_accuracy: 0.4319\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8387 - accuracy: 0.4382 - val_loss: 2.3133 - val_accuracy: 0.4264\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8421 - accuracy: 0.4226 - val_loss: 2.3210 - val_accuracy: 0.4282\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8230 - accuracy: 0.4366 - val_loss: 2.3320 - val_accuracy: 0.3948\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8725 - accuracy: 0.4219 - val_loss: 2.3242 - val_accuracy: 0.4227\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8416 - accuracy: 0.4303 - val_loss: 2.3125 - val_accuracy: 0.4307\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8078 - accuracy: 0.4406 - val_loss: 2.3281 - val_accuracy: 0.4361\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8425 - accuracy: 0.4285 - val_loss: 2.3047 - val_accuracy: 0.4373\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8324 - accuracy: 0.4258 - val_loss: 2.3082 - val_accuracy: 0.4416\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8262 - accuracy: 0.4369 - val_loss: 2.3174 - val_accuracy: 0.4209\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8242 - accuracy: 0.4293 - val_loss: 2.3124 - val_accuracy: 0.4355\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8276 - accuracy: 0.4292 - val_loss: 2.3076 - val_accuracy: 0.4380\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8431 - accuracy: 0.4291 - val_loss: 2.3206 - val_accuracy: 0.4252\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8218 - accuracy: 0.4254 - val_loss: 2.3311 - val_accuracy: 0.4386\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8306 - accuracy: 0.4337 - val_loss: 2.3237 - val_accuracy: 0.4331\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8221 - accuracy: 0.4255 - val_loss: 2.3168 - val_accuracy: 0.4209\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8085 - accuracy: 0.4445 - val_loss: 2.3297 - val_accuracy: 0.4173\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7982 - accuracy: 0.4401 - val_loss: 2.3428 - val_accuracy: 0.4185\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8174 - accuracy: 0.4334 - val_loss: 2.3312 - val_accuracy: 0.4234\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8585 - accuracy: 0.4216 - val_loss: 2.3173 - val_accuracy: 0.4355\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8169 - accuracy: 0.4374 - val_loss: 2.3413 - val_accuracy: 0.4106\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8331 - accuracy: 0.4288 - val_loss: 2.3342 - val_accuracy: 0.4179\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8414 - accuracy: 0.4229 - val_loss: 2.3442 - val_accuracy: 0.4155\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8172 - accuracy: 0.4266 - val_loss: 2.3064 - val_accuracy: 0.4373\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8138 - accuracy: 0.4326 - val_loss: 2.3366 - val_accuracy: 0.4361\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8313 - accuracy: 0.4257 - val_loss: 2.3544 - val_accuracy: 0.4197\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8225 - accuracy: 0.4283 - val_loss: 2.3371 - val_accuracy: 0.4240\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8118 - accuracy: 0.4321 - val_loss: 2.3267 - val_accuracy: 0.4355\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8054 - accuracy: 0.4309 - val_loss: 2.3248 - val_accuracy: 0.4337\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8335 - accuracy: 0.4241 - val_loss: 2.3616 - val_accuracy: 0.4161\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8089 - accuracy: 0.4389 - val_loss: 2.3511 - val_accuracy: 0.4088\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8061 - accuracy: 0.4389 - val_loss: 2.3352 - val_accuracy: 0.4179\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8412 - accuracy: 0.4294 - val_loss: 2.3409 - val_accuracy: 0.4161\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8234 - accuracy: 0.4304 - val_loss: 2.3376 - val_accuracy: 0.4313\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8043 - accuracy: 0.4348 - val_loss: 2.3221 - val_accuracy: 0.4373\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7895 - accuracy: 0.4366 - val_loss: 2.3383 - val_accuracy: 0.4331\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8191 - accuracy: 0.4232 - val_loss: 2.3396 - val_accuracy: 0.4313\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8048 - accuracy: 0.4301 - val_loss: 2.3306 - val_accuracy: 0.4410\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7706 - accuracy: 0.4335 - val_loss: 2.3648 - val_accuracy: 0.4179\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8116 - accuracy: 0.4402 - val_loss: 2.3594 - val_accuracy: 0.4185\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7911 - accuracy: 0.4298 - val_loss: 2.3393 - val_accuracy: 0.4215\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7923 - accuracy: 0.4419 - val_loss: 2.3435 - val_accuracy: 0.4355\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8093 - accuracy: 0.4318 - val_loss: 2.3759 - val_accuracy: 0.4252\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.7760 - accuracy: 0.4491 - val_loss: 2.3567 - val_accuracy: 0.4240\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7900 - accuracy: 0.4400 - val_loss: 2.3610 - val_accuracy: 0.4258\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7926 - accuracy: 0.4410 - val_loss: 2.3724 - val_accuracy: 0.4300\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8174 - accuracy: 0.4386 - val_loss: 2.3388 - val_accuracy: 0.4380\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8120 - accuracy: 0.4361 - val_loss: 2.3706 - val_accuracy: 0.4009\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7906 - accuracy: 0.4342 - val_loss: 2.3459 - val_accuracy: 0.4258\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7992 - accuracy: 0.4355 - val_loss: 2.3272 - val_accuracy: 0.4221\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8099 - accuracy: 0.4339 - val_loss: 2.3627 - val_accuracy: 0.4173\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7892 - accuracy: 0.4288 - val_loss: 2.3779 - val_accuracy: 0.4136\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8087 - accuracy: 0.4328 - val_loss: 2.3695 - val_accuracy: 0.4215\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8002 - accuracy: 0.4267 - val_loss: 2.3732 - val_accuracy: 0.4300\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7836 - accuracy: 0.4318 - val_loss: 2.3704 - val_accuracy: 0.4142\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7812 - accuracy: 0.4409 - val_loss: 2.3595 - val_accuracy: 0.4246\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7819 - accuracy: 0.4348 - val_loss: 2.3682 - val_accuracy: 0.4142\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7655 - accuracy: 0.4495 - val_loss: 2.3567 - val_accuracy: 0.4240\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7885 - accuracy: 0.4419 - val_loss: 2.3642 - val_accuracy: 0.4161\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7733 - accuracy: 0.4469 - val_loss: 2.3809 - val_accuracy: 0.4167\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7957 - accuracy: 0.4294 - val_loss: 2.3843 - val_accuracy: 0.4234\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7727 - accuracy: 0.4356 - val_loss: 2.3875 - val_accuracy: 0.4057\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7962 - accuracy: 0.4426 - val_loss: 2.3652 - val_accuracy: 0.4167\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7970 - accuracy: 0.4283 - val_loss: 2.3790 - val_accuracy: 0.4264\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7792 - accuracy: 0.4322 - val_loss: 2.3619 - val_accuracy: 0.4142\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.8036 - accuracy: 0.4317 - val_loss: 2.3982 - val_accuracy: 0.4148\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7471 - accuracy: 0.4532 - val_loss: 2.3694 - val_accuracy: 0.4185\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7765 - accuracy: 0.4337 - val_loss: 2.3522 - val_accuracy: 0.4313\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7650 - accuracy: 0.4447 - val_loss: 2.3740 - val_accuracy: 0.4270\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7706 - accuracy: 0.4444 - val_loss: 2.3781 - val_accuracy: 0.4252\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.8048 - accuracy: 0.4328 - val_loss: 2.3771 - val_accuracy: 0.4209\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7705 - accuracy: 0.4363 - val_loss: 2.3902 - val_accuracy: 0.4179\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7862 - accuracy: 0.4362 - val_loss: 2.4163 - val_accuracy: 0.4124\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7726 - accuracy: 0.4306 - val_loss: 2.3953 - val_accuracy: 0.4082\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7809 - accuracy: 0.4372 - val_loss: 2.3909 - val_accuracy: 0.4142\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7722 - accuracy: 0.4401 - val_loss: 2.3923 - val_accuracy: 0.4258\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7707 - accuracy: 0.4426 - val_loss: 2.4021 - val_accuracy: 0.4142\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7873 - accuracy: 0.4359 - val_loss: 2.3766 - val_accuracy: 0.4215\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7522 - accuracy: 0.4469 - val_loss: 2.3906 - val_accuracy: 0.4203\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7719 - accuracy: 0.4386 - val_loss: 2.3863 - val_accuracy: 0.4191\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7599 - accuracy: 0.4442 - val_loss: 2.3865 - val_accuracy: 0.4252\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7672 - accuracy: 0.4484 - val_loss: 2.3932 - val_accuracy: 0.4203\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7673 - accuracy: 0.4426 - val_loss: 2.4042 - val_accuracy: 0.4203\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7686 - accuracy: 0.4476 - val_loss: 2.3912 - val_accuracy: 0.4179\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7580 - accuracy: 0.4473 - val_loss: 2.3758 - val_accuracy: 0.4246\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7871 - accuracy: 0.4314 - val_loss: 2.3743 - val_accuracy: 0.4300\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7547 - accuracy: 0.4533 - val_loss: 2.4128 - val_accuracy: 0.4179\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7480 - accuracy: 0.4571 - val_loss: 2.3934 - val_accuracy: 0.4209\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7875 - accuracy: 0.4433 - val_loss: 2.4093 - val_accuracy: 0.4033\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7601 - accuracy: 0.4427 - val_loss: 2.3993 - val_accuracy: 0.4106\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7747 - accuracy: 0.4416 - val_loss: 2.3883 - val_accuracy: 0.4240\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7756 - accuracy: 0.4451 - val_loss: 2.3972 - val_accuracy: 0.4142\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7602 - accuracy: 0.4411 - val_loss: 2.3866 - val_accuracy: 0.4209\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7623 - accuracy: 0.4478 - val_loss: 2.3783 - val_accuracy: 0.4155\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7564 - accuracy: 0.4427 - val_loss: 2.4085 - val_accuracy: 0.4227\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7438 - accuracy: 0.4494 - val_loss: 2.4118 - val_accuracy: 0.4082\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7784 - accuracy: 0.4455 - val_loss: 2.4193 - val_accuracy: 0.4100\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7534 - accuracy: 0.4446 - val_loss: 2.4008 - val_accuracy: 0.4142\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7517 - accuracy: 0.4423 - val_loss: 2.3928 - val_accuracy: 0.4246\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7791 - accuracy: 0.4362 - val_loss: 2.3946 - val_accuracy: 0.4167\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7426 - accuracy: 0.4514 - val_loss: 2.3740 - val_accuracy: 0.4240\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7427 - accuracy: 0.4508 - val_loss: 2.4000 - val_accuracy: 0.4155\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7593 - accuracy: 0.4518 - val_loss: 2.3988 - val_accuracy: 0.4106\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7697 - accuracy: 0.4415 - val_loss: 2.4022 - val_accuracy: 0.4167\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7350 - accuracy: 0.4535 - val_loss: 2.3842 - val_accuracy: 0.4167\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7521 - accuracy: 0.4463 - val_loss: 2.4046 - val_accuracy: 0.4015\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7684 - accuracy: 0.4388 - val_loss: 2.3987 - val_accuracy: 0.4191\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7758 - accuracy: 0.4452 - val_loss: 2.4150 - val_accuracy: 0.4155\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7598 - accuracy: 0.4343 - val_loss: 2.3955 - val_accuracy: 0.4307\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7497 - accuracy: 0.4525 - val_loss: 2.3989 - val_accuracy: 0.4191\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.7710 - accuracy: 0.4441 - val_loss: 2.3981 - val_accuracy: 0.4148\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7566 - accuracy: 0.4456 - val_loss: 2.4191 - val_accuracy: 0.4221\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7411 - accuracy: 0.4445 - val_loss: 2.4285 - val_accuracy: 0.4082\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7559 - accuracy: 0.4454 - val_loss: 2.4151 - val_accuracy: 0.4094\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7617 - accuracy: 0.4528 - val_loss: 2.4111 - val_accuracy: 0.4057\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7433 - accuracy: 0.4444 - val_loss: 2.3820 - val_accuracy: 0.4191\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7430 - accuracy: 0.4384 - val_loss: 2.3865 - val_accuracy: 0.4221\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7498 - accuracy: 0.4423 - val_loss: 2.4035 - val_accuracy: 0.4118\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7440 - accuracy: 0.4415 - val_loss: 2.4187 - val_accuracy: 0.4051\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7517 - accuracy: 0.4503 - val_loss: 2.4045 - val_accuracy: 0.4057\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7608 - accuracy: 0.4461 - val_loss: 2.4234 - val_accuracy: 0.4155\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7639 - accuracy: 0.4393 - val_loss: 2.4130 - val_accuracy: 0.4094\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7636 - accuracy: 0.4452 - val_loss: 2.4144 - val_accuracy: 0.4118\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7397 - accuracy: 0.4551 - val_loss: 2.3877 - val_accuracy: 0.4185\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7611 - accuracy: 0.4469 - val_loss: 2.4147 - val_accuracy: 0.4106\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7566 - accuracy: 0.4472 - val_loss: 2.3986 - val_accuracy: 0.4234\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7685 - accuracy: 0.4439 - val_loss: 2.4279 - val_accuracy: 0.4039\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7556 - accuracy: 0.4451 - val_loss: 2.4099 - val_accuracy: 0.4100\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7449 - accuracy: 0.4456 - val_loss: 2.4365 - val_accuracy: 0.3984\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7367 - accuracy: 0.4522 - val_loss: 2.4184 - val_accuracy: 0.4167\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7492 - accuracy: 0.4384 - val_loss: 2.4168 - val_accuracy: 0.4106\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7464 - accuracy: 0.4503 - val_loss: 2.4125 - val_accuracy: 0.4057\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7375 - accuracy: 0.4553 - val_loss: 2.4069 - val_accuracy: 0.4221\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7297 - accuracy: 0.4542 - val_loss: 2.3996 - val_accuracy: 0.4240\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7480 - accuracy: 0.4423 - val_loss: 2.4254 - val_accuracy: 0.4002\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7364 - accuracy: 0.4432 - val_loss: 2.4400 - val_accuracy: 0.4209\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7544 - accuracy: 0.4431 - val_loss: 2.4143 - val_accuracy: 0.4161\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7370 - accuracy: 0.4488 - val_loss: 2.4478 - val_accuracy: 0.4124\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7438 - accuracy: 0.4479 - val_loss: 2.3995 - val_accuracy: 0.4197\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7336 - accuracy: 0.4529 - val_loss: 2.4178 - val_accuracy: 0.4240\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7234 - accuracy: 0.4506 - val_loss: 2.4098 - val_accuracy: 0.4227\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7273 - accuracy: 0.4489 - val_loss: 2.4298 - val_accuracy: 0.4209\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7374 - accuracy: 0.4499 - val_loss: 2.4150 - val_accuracy: 0.4142\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7213 - accuracy: 0.4490 - val_loss: 2.4359 - val_accuracy: 0.4106\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7295 - accuracy: 0.4482 - val_loss: 2.4142 - val_accuracy: 0.4155\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7453 - accuracy: 0.4547 - val_loss: 2.4077 - val_accuracy: 0.4185\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7464 - accuracy: 0.4495 - val_loss: 2.4009 - val_accuracy: 0.4148\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7273 - accuracy: 0.4558 - val_loss: 2.4194 - val_accuracy: 0.4185\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7339 - accuracy: 0.4650 - val_loss: 2.4305 - val_accuracy: 0.4112\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7350 - accuracy: 0.4511 - val_loss: 2.4198 - val_accuracy: 0.4063\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7177 - accuracy: 0.4537 - val_loss: 2.4437 - val_accuracy: 0.4118\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7365 - accuracy: 0.4481 - val_loss: 2.4418 - val_accuracy: 0.3966\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7245 - accuracy: 0.4549 - val_loss: 2.4481 - val_accuracy: 0.4021\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7514 - accuracy: 0.4447 - val_loss: 2.4252 - val_accuracy: 0.4185\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7276 - accuracy: 0.4467 - val_loss: 2.4309 - val_accuracy: 0.4173\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7398 - accuracy: 0.4526 - val_loss: 2.4247 - val_accuracy: 0.4124\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7489 - accuracy: 0.4550 - val_loss: 2.4248 - val_accuracy: 0.4173\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7145 - accuracy: 0.4536 - val_loss: 2.4398 - val_accuracy: 0.3966\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7511 - accuracy: 0.4440 - val_loss: 2.4210 - val_accuracy: 0.4155\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7128 - accuracy: 0.4621 - val_loss: 2.4080 - val_accuracy: 0.4197\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7255 - accuracy: 0.4551 - val_loss: 2.4503 - val_accuracy: 0.4039\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7403 - accuracy: 0.4481 - val_loss: 2.4375 - val_accuracy: 0.4124\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7118 - accuracy: 0.4593 - val_loss: 2.4251 - val_accuracy: 0.4063\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7322 - accuracy: 0.4492 - val_loss: 2.4120 - val_accuracy: 0.4246\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6895 - accuracy: 0.4645 - val_loss: 2.4563 - val_accuracy: 0.3978\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7162 - accuracy: 0.4379 - val_loss: 2.4441 - val_accuracy: 0.4002\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7208 - accuracy: 0.4556 - val_loss: 2.4527 - val_accuracy: 0.4039\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7276 - accuracy: 0.4490 - val_loss: 2.4186 - val_accuracy: 0.4209\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7286 - accuracy: 0.4568 - val_loss: 2.4597 - val_accuracy: 0.4015\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7153 - accuracy: 0.4500 - val_loss: 2.4301 - val_accuracy: 0.4197\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7298 - accuracy: 0.4488 - val_loss: 2.4311 - val_accuracy: 0.4179\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7052 - accuracy: 0.4500 - val_loss: 2.4165 - val_accuracy: 0.4197\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7389 - accuracy: 0.4391 - val_loss: 2.4699 - val_accuracy: 0.3954\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7226 - accuracy: 0.4494 - val_loss: 2.4307 - val_accuracy: 0.4094\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7190 - accuracy: 0.4556 - val_loss: 2.4383 - val_accuracy: 0.4082\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7267 - accuracy: 0.4493 - val_loss: 2.4324 - val_accuracy: 0.4148\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7250 - accuracy: 0.4416 - val_loss: 2.4618 - val_accuracy: 0.4069\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6967 - accuracy: 0.4594 - val_loss: 2.4269 - val_accuracy: 0.4227\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.6974 - accuracy: 0.4606 - val_loss: 2.4229 - val_accuracy: 0.4179\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7337 - accuracy: 0.4467 - val_loss: 2.4332 - val_accuracy: 0.4057\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7293 - accuracy: 0.4464 - val_loss: 2.4530 - val_accuracy: 0.4033\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7073 - accuracy: 0.4603 - val_loss: 2.4519 - val_accuracy: 0.4106\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7268 - accuracy: 0.4572 - val_loss: 2.4573 - val_accuracy: 0.4057\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7359 - accuracy: 0.4508 - val_loss: 2.4585 - val_accuracy: 0.4027\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7465 - accuracy: 0.4437 - val_loss: 2.4274 - val_accuracy: 0.4118\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7268 - accuracy: 0.4536 - val_loss: 2.4495 - val_accuracy: 0.4106\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7268 - accuracy: 0.4399 - val_loss: 2.4341 - val_accuracy: 0.4124\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7155 - accuracy: 0.4551 - val_loss: 2.4606 - val_accuracy: 0.4179\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7068 - accuracy: 0.4539 - val_loss: 2.4576 - val_accuracy: 0.4033\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7377 - accuracy: 0.4537 - val_loss: 2.4374 - val_accuracy: 0.4155\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7022 - accuracy: 0.4574 - val_loss: 2.4114 - val_accuracy: 0.4252\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7209 - accuracy: 0.4534 - val_loss: 2.4549 - val_accuracy: 0.4045\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7112 - accuracy: 0.4640 - val_loss: 2.4316 - val_accuracy: 0.4155\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7318 - accuracy: 0.4583 - val_loss: 2.4638 - val_accuracy: 0.3863\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7002 - accuracy: 0.4571 - val_loss: 2.4395 - val_accuracy: 0.4221\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7179 - accuracy: 0.4565 - val_loss: 2.4770 - val_accuracy: 0.4063\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7196 - accuracy: 0.4575 - val_loss: 2.4804 - val_accuracy: 0.3905\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7229 - accuracy: 0.4490 - val_loss: 2.4506 - val_accuracy: 0.4173\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6977 - accuracy: 0.4635 - val_loss: 2.4516 - val_accuracy: 0.4015\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7123 - accuracy: 0.4563 - val_loss: 2.4600 - val_accuracy: 0.3984\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7251 - accuracy: 0.4498 - val_loss: 2.4398 - val_accuracy: 0.4088\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7087 - accuracy: 0.4528 - val_loss: 2.4490 - val_accuracy: 0.4100\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7075 - accuracy: 0.4543 - val_loss: 2.4594 - val_accuracy: 0.4155\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6982 - accuracy: 0.4587 - val_loss: 2.4439 - val_accuracy: 0.4100\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7193 - accuracy: 0.4508 - val_loss: 2.4429 - val_accuracy: 0.4130\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6975 - accuracy: 0.4530 - val_loss: 2.4678 - val_accuracy: 0.4057\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7227 - accuracy: 0.4434 - val_loss: 2.4683 - val_accuracy: 0.4063\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7099 - accuracy: 0.4551 - val_loss: 2.4596 - val_accuracy: 0.4173\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7025 - accuracy: 0.4555 - val_loss: 2.4485 - val_accuracy: 0.4082\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7116 - accuracy: 0.4562 - val_loss: 2.4507 - val_accuracy: 0.4215\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7164 - accuracy: 0.4523 - val_loss: 2.4976 - val_accuracy: 0.3814\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7257 - accuracy: 0.4562 - val_loss: 2.4563 - val_accuracy: 0.4051\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6883 - accuracy: 0.4541 - val_loss: 2.4719 - val_accuracy: 0.4027\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7118 - accuracy: 0.4589 - val_loss: 2.4566 - val_accuracy: 0.4033\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7241 - accuracy: 0.4504 - val_loss: 2.4846 - val_accuracy: 0.4142\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7121 - accuracy: 0.4549 - val_loss: 2.4218 - val_accuracy: 0.4191\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7124 - accuracy: 0.4498 - val_loss: 2.4518 - val_accuracy: 0.4063\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7309 - accuracy: 0.4541 - val_loss: 2.4680 - val_accuracy: 0.3936\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7082 - accuracy: 0.4504 - val_loss: 2.4604 - val_accuracy: 0.4094\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6998 - accuracy: 0.4631 - val_loss: 2.4599 - val_accuracy: 0.4167\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7305 - accuracy: 0.4457 - val_loss: 2.4555 - val_accuracy: 0.4021\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7128 - accuracy: 0.4436 - val_loss: 2.4526 - val_accuracy: 0.4094\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7112 - accuracy: 0.4525 - val_loss: 2.4563 - val_accuracy: 0.4033\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.7115 - accuracy: 0.4529 - val_loss: 2.4739 - val_accuracy: 0.4021\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7034 - accuracy: 0.4541 - val_loss: 2.4556 - val_accuracy: 0.4276\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6816 - accuracy: 0.4601 - val_loss: 2.4902 - val_accuracy: 0.4002\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6895 - accuracy: 0.4630 - val_loss: 2.4909 - val_accuracy: 0.4009\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6900 - accuracy: 0.4572 - val_loss: 2.4464 - val_accuracy: 0.4155\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7222 - accuracy: 0.4536 - val_loss: 2.4679 - val_accuracy: 0.4106\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7177 - accuracy: 0.4449 - val_loss: 2.4670 - val_accuracy: 0.4100\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7228 - accuracy: 0.4454 - val_loss: 2.4894 - val_accuracy: 0.3905\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6952 - accuracy: 0.4556 - val_loss: 2.4469 - val_accuracy: 0.4009\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7259 - accuracy: 0.4548 - val_loss: 2.4853 - val_accuracy: 0.3887\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7035 - accuracy: 0.4542 - val_loss: 2.4725 - val_accuracy: 0.4148\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7101 - accuracy: 0.4536 - val_loss: 2.4604 - val_accuracy: 0.4021\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6870 - accuracy: 0.4734 - val_loss: 2.4713 - val_accuracy: 0.3972\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6856 - accuracy: 0.4700 - val_loss: 2.4634 - val_accuracy: 0.4033\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6905 - accuracy: 0.4618 - val_loss: 2.4901 - val_accuracy: 0.3972\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6989 - accuracy: 0.4665 - val_loss: 2.4611 - val_accuracy: 0.4106\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7045 - accuracy: 0.4636 - val_loss: 2.4949 - val_accuracy: 0.4021\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6916 - accuracy: 0.4660 - val_loss: 2.4918 - val_accuracy: 0.3929\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6962 - accuracy: 0.4650 - val_loss: 2.4790 - val_accuracy: 0.4185\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7178 - accuracy: 0.4511 - val_loss: 2.4907 - val_accuracy: 0.4094\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7048 - accuracy: 0.4555 - val_loss: 2.4904 - val_accuracy: 0.3948\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6906 - accuracy: 0.4554 - val_loss: 2.4859 - val_accuracy: 0.4069\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6880 - accuracy: 0.4641 - val_loss: 2.5024 - val_accuracy: 0.4027\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7055 - accuracy: 0.4539 - val_loss: 2.4659 - val_accuracy: 0.3996\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7315 - accuracy: 0.4549 - val_loss: 2.4878 - val_accuracy: 0.4002\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6879 - accuracy: 0.4573 - val_loss: 2.4650 - val_accuracy: 0.4130\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6712 - accuracy: 0.4550 - val_loss: 2.4762 - val_accuracy: 0.4063\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6759 - accuracy: 0.4678 - val_loss: 2.5043 - val_accuracy: 0.3972\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6946 - accuracy: 0.4592 - val_loss: 2.5099 - val_accuracy: 0.3978\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6971 - accuracy: 0.4593 - val_loss: 2.4790 - val_accuracy: 0.4039\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6775 - accuracy: 0.4614 - val_loss: 2.4986 - val_accuracy: 0.3917\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6850 - accuracy: 0.4508 - val_loss: 2.5216 - val_accuracy: 0.3978\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7069 - accuracy: 0.4496 - val_loss: 2.4875 - val_accuracy: 0.4063\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6947 - accuracy: 0.4613 - val_loss: 2.4824 - val_accuracy: 0.4173\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6903 - accuracy: 0.4635 - val_loss: 2.4790 - val_accuracy: 0.4148\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6851 - accuracy: 0.4636 - val_loss: 2.5035 - val_accuracy: 0.3948\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6864 - accuracy: 0.4599 - val_loss: 2.4704 - val_accuracy: 0.4227\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6875 - accuracy: 0.4574 - val_loss: 2.4595 - val_accuracy: 0.4203\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6929 - accuracy: 0.4590 - val_loss: 2.4790 - val_accuracy: 0.4045\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7022 - accuracy: 0.4553 - val_loss: 2.4626 - val_accuracy: 0.4033\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6946 - accuracy: 0.4639 - val_loss: 2.4909 - val_accuracy: 0.4021\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6552 - accuracy: 0.4700 - val_loss: 2.4774 - val_accuracy: 0.4082\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7073 - accuracy: 0.4550 - val_loss: 2.4604 - val_accuracy: 0.4155\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6792 - accuracy: 0.4556 - val_loss: 2.4824 - val_accuracy: 0.3899\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7177 - accuracy: 0.4541 - val_loss: 2.4718 - val_accuracy: 0.4057\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6961 - accuracy: 0.4582 - val_loss: 2.4821 - val_accuracy: 0.3911\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6883 - accuracy: 0.4572 - val_loss: 2.4658 - val_accuracy: 0.4130\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6874 - accuracy: 0.4592 - val_loss: 2.4766 - val_accuracy: 0.4088\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7094 - accuracy: 0.4510 - val_loss: 2.4809 - val_accuracy: 0.4094\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6738 - accuracy: 0.4535 - val_loss: 2.4874 - val_accuracy: 0.3966\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6765 - accuracy: 0.4697 - val_loss: 2.5090 - val_accuracy: 0.3960\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6930 - accuracy: 0.4591 - val_loss: 2.5021 - val_accuracy: 0.3923\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6776 - accuracy: 0.4626 - val_loss: 2.4976 - val_accuracy: 0.3996\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6945 - accuracy: 0.4571 - val_loss: 2.5006 - val_accuracy: 0.4082\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6823 - accuracy: 0.4661 - val_loss: 2.4861 - val_accuracy: 0.4027\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6826 - accuracy: 0.4660 - val_loss: 2.4797 - val_accuracy: 0.4130\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6917 - accuracy: 0.4576 - val_loss: 2.4918 - val_accuracy: 0.4100\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6634 - accuracy: 0.4679 - val_loss: 2.4971 - val_accuracy: 0.3996\n",
      "Epoch 388/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6778 - accuracy: 0.4603 - val_loss: 2.4885 - val_accuracy: 0.4002\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7066 - accuracy: 0.4484 - val_loss: 2.4620 - val_accuracy: 0.4136\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7011 - accuracy: 0.4530 - val_loss: 2.4730 - val_accuracy: 0.4118\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6718 - accuracy: 0.4626 - val_loss: 2.4600 - val_accuracy: 0.4136\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6913 - accuracy: 0.4563 - val_loss: 2.5183 - val_accuracy: 0.4045\n",
      "Epoch 393/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6652 - accuracy: 0.4665 - val_loss: 2.4999 - val_accuracy: 0.4015\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6573 - accuracy: 0.4658 - val_loss: 2.4814 - val_accuracy: 0.4088\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6727 - accuracy: 0.4687 - val_loss: 2.4821 - val_accuracy: 0.4142\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6988 - accuracy: 0.4617 - val_loss: 2.4915 - val_accuracy: 0.4063\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7004 - accuracy: 0.4515 - val_loss: 2.4864 - val_accuracy: 0.4234\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6853 - accuracy: 0.4583 - val_loss: 2.5027 - val_accuracy: 0.4106\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7044 - accuracy: 0.4575 - val_loss: 2.4844 - val_accuracy: 0.3984\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6820 - accuracy: 0.4584 - val_loss: 2.5250 - val_accuracy: 0.3905\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6941 - accuracy: 0.4564 - val_loss: 2.4788 - val_accuracy: 0.4063\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6931 - accuracy: 0.4514 - val_loss: 2.4861 - val_accuracy: 0.4021\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6860 - accuracy: 0.4569 - val_loss: 2.5025 - val_accuracy: 0.4033\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6594 - accuracy: 0.4629 - val_loss: 2.5129 - val_accuracy: 0.4033\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6764 - accuracy: 0.4672 - val_loss: 2.4981 - val_accuracy: 0.3923\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.7101 - accuracy: 0.4447 - val_loss: 2.4897 - val_accuracy: 0.4075\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6837 - accuracy: 0.4619 - val_loss: 2.4617 - val_accuracy: 0.4057\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6776 - accuracy: 0.4639 - val_loss: 2.5296 - val_accuracy: 0.3936\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6877 - accuracy: 0.4602 - val_loss: 2.5092 - val_accuracy: 0.3978\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6771 - accuracy: 0.4557 - val_loss: 2.5317 - val_accuracy: 0.4051\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6958 - accuracy: 0.4577 - val_loss: 2.5060 - val_accuracy: 0.4045\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6751 - accuracy: 0.4573 - val_loss: 2.5215 - val_accuracy: 0.3869\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6576 - accuracy: 0.4533 - val_loss: 2.5061 - val_accuracy: 0.4106\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6956 - accuracy: 0.4390 - val_loss: 2.4943 - val_accuracy: 0.4112\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6898 - accuracy: 0.4602 - val_loss: 2.5083 - val_accuracy: 0.4136\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6753 - accuracy: 0.4550 - val_loss: 2.4891 - val_accuracy: 0.4063\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6641 - accuracy: 0.4697 - val_loss: 2.5010 - val_accuracy: 0.4148\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6843 - accuracy: 0.4531 - val_loss: 2.4955 - val_accuracy: 0.4106\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.6882 - accuracy: 0.4581 - val_loss: 2.5240 - val_accuracy: 0.4094\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6652 - accuracy: 0.4515 - val_loss: 2.4813 - val_accuracy: 0.4209\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6688 - accuracy: 0.4710 - val_loss: 2.4995 - val_accuracy: 0.4021\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6703 - accuracy: 0.4760 - val_loss: 2.4955 - val_accuracy: 0.4075\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6746 - accuracy: 0.4591 - val_loss: 2.5045 - val_accuracy: 0.4082\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6905 - accuracy: 0.4596 - val_loss: 2.5091 - val_accuracy: 0.4027\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6396 - accuracy: 0.4814 - val_loss: 2.4871 - val_accuracy: 0.4033\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6727 - accuracy: 0.4652 - val_loss: 2.5209 - val_accuracy: 0.4069\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6619 - accuracy: 0.4723 - val_loss: 2.5072 - val_accuracy: 0.4112\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6788 - accuracy: 0.4689 - val_loss: 2.5137 - val_accuracy: 0.4057\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6801 - accuracy: 0.4582 - val_loss: 2.5057 - val_accuracy: 0.4021\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6702 - accuracy: 0.4690 - val_loss: 2.5169 - val_accuracy: 0.3948\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6779 - accuracy: 0.4629 - val_loss: 2.5152 - val_accuracy: 0.3978\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6505 - accuracy: 0.4714 - val_loss: 2.5135 - val_accuracy: 0.3972\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6688 - accuracy: 0.4726 - val_loss: 2.5140 - val_accuracy: 0.3948\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6512 - accuracy: 0.4707 - val_loss: 2.5206 - val_accuracy: 0.3881\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6787 - accuracy: 0.4717 - val_loss: 2.5105 - val_accuracy: 0.4094\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6698 - accuracy: 0.4702 - val_loss: 2.5192 - val_accuracy: 0.4082\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6904 - accuracy: 0.4563 - val_loss: 2.5128 - val_accuracy: 0.4045\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6835 - accuracy: 0.4632 - val_loss: 2.5201 - val_accuracy: 0.4051\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6738 - accuracy: 0.4592 - val_loss: 2.5117 - val_accuracy: 0.4057\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6488 - accuracy: 0.4718 - val_loss: 2.5468 - val_accuracy: 0.3917\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6872 - accuracy: 0.4515 - val_loss: 2.5089 - val_accuracy: 0.4112\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6665 - accuracy: 0.4645 - val_loss: 2.5070 - val_accuracy: 0.4027\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6844 - accuracy: 0.4665 - val_loss: 2.5352 - val_accuracy: 0.3990\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6857 - accuracy: 0.4522 - val_loss: 2.5125 - val_accuracy: 0.4002\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6840 - accuracy: 0.4562 - val_loss: 2.5401 - val_accuracy: 0.4106\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6832 - accuracy: 0.4622 - val_loss: 2.4871 - val_accuracy: 0.3960\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6882 - accuracy: 0.4606 - val_loss: 2.4904 - val_accuracy: 0.4106\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6607 - accuracy: 0.4657 - val_loss: 2.5269 - val_accuracy: 0.3942\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6683 - accuracy: 0.4690 - val_loss: 2.4913 - val_accuracy: 0.4118\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6536 - accuracy: 0.4719 - val_loss: 2.5195 - val_accuracy: 0.4057\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6617 - accuracy: 0.4754 - val_loss: 2.5289 - val_accuracy: 0.3984\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6792 - accuracy: 0.4605 - val_loss: 2.5241 - val_accuracy: 0.3996\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6837 - accuracy: 0.4654 - val_loss: 2.5208 - val_accuracy: 0.4100\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6658 - accuracy: 0.4608 - val_loss: 2.5141 - val_accuracy: 0.4240\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6656 - accuracy: 0.4613 - val_loss: 2.5074 - val_accuracy: 0.4039\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6746 - accuracy: 0.4586 - val_loss: 2.5324 - val_accuracy: 0.3996\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6547 - accuracy: 0.4650 - val_loss: 2.5372 - val_accuracy: 0.3996\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6866 - accuracy: 0.4571 - val_loss: 2.5074 - val_accuracy: 0.3966\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6821 - accuracy: 0.4629 - val_loss: 2.4997 - val_accuracy: 0.4027\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6581 - accuracy: 0.4699 - val_loss: 2.5199 - val_accuracy: 0.3990\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6961 - accuracy: 0.4484 - val_loss: 2.5067 - val_accuracy: 0.4124\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6778 - accuracy: 0.4628 - val_loss: 2.5140 - val_accuracy: 0.3966\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6705 - accuracy: 0.4659 - val_loss: 2.5333 - val_accuracy: 0.3972\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6679 - accuracy: 0.4619 - val_loss: 2.5397 - val_accuracy: 0.3972\n",
      "Epoch 465/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6703 - accuracy: 0.4570 - val_loss: 2.5361 - val_accuracy: 0.3990\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6539 - accuracy: 0.4662 - val_loss: 2.5116 - val_accuracy: 0.4045\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6744 - accuracy: 0.4674 - val_loss: 2.5335 - val_accuracy: 0.4033\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6624 - accuracy: 0.4657 - val_loss: 2.5278 - val_accuracy: 0.4069\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6463 - accuracy: 0.4794 - val_loss: 2.5427 - val_accuracy: 0.3856\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6741 - accuracy: 0.4664 - val_loss: 2.5036 - val_accuracy: 0.4082\n",
      "Epoch 471/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6647 - accuracy: 0.4756 - val_loss: 2.5267 - val_accuracy: 0.3820\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6507 - accuracy: 0.4674 - val_loss: 2.5259 - val_accuracy: 0.4051\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6721 - accuracy: 0.4632 - val_loss: 2.5192 - val_accuracy: 0.3972\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6594 - accuracy: 0.4652 - val_loss: 2.5316 - val_accuracy: 0.4167\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6387 - accuracy: 0.4747 - val_loss: 2.5623 - val_accuracy: 0.4009\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6483 - accuracy: 0.4762 - val_loss: 2.5355 - val_accuracy: 0.4021\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6737 - accuracy: 0.4686 - val_loss: 2.5044 - val_accuracy: 0.4075\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6664 - accuracy: 0.4700 - val_loss: 2.5415 - val_accuracy: 0.3911\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6556 - accuracy: 0.4573 - val_loss: 2.5281 - val_accuracy: 0.4021\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6665 - accuracy: 0.4623 - val_loss: 2.5403 - val_accuracy: 0.4106\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6571 - accuracy: 0.4673 - val_loss: 2.5195 - val_accuracy: 0.3990\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6650 - accuracy: 0.4685 - val_loss: 2.5555 - val_accuracy: 0.3942\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6608 - accuracy: 0.4614 - val_loss: 2.5193 - val_accuracy: 0.4002\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6591 - accuracy: 0.4591 - val_loss: 2.5303 - val_accuracy: 0.4100\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6460 - accuracy: 0.4666 - val_loss: 2.5572 - val_accuracy: 0.3844\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6625 - accuracy: 0.4588 - val_loss: 2.5651 - val_accuracy: 0.3905\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6675 - accuracy: 0.4696 - val_loss: 2.5383 - val_accuracy: 0.3808\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6635 - accuracy: 0.4589 - val_loss: 2.5237 - val_accuracy: 0.4057\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6695 - accuracy: 0.4623 - val_loss: 2.5515 - val_accuracy: 0.3923\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6723 - accuracy: 0.4599 - val_loss: 2.5402 - val_accuracy: 0.4100\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6718 - accuracy: 0.4675 - val_loss: 2.5607 - val_accuracy: 0.4009\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6626 - accuracy: 0.4492 - val_loss: 2.5165 - val_accuracy: 0.4124\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6719 - accuracy: 0.4630 - val_loss: 2.5125 - val_accuracy: 0.4185\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6553 - accuracy: 0.4582 - val_loss: 2.5485 - val_accuracy: 0.4045\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6453 - accuracy: 0.4730 - val_loss: 2.5075 - val_accuracy: 0.4106\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6650 - accuracy: 0.4658 - val_loss: 2.5338 - val_accuracy: 0.4027\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6438 - accuracy: 0.4663 - val_loss: 2.5230 - val_accuracy: 0.4118\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6661 - accuracy: 0.4680 - val_loss: 2.5543 - val_accuracy: 0.4009\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6585 - accuracy: 0.4609 - val_loss: 2.5561 - val_accuracy: 0.3966\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6770 - accuracy: 0.4608 - val_loss: 2.5159 - val_accuracy: 0.4167\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6673 - accuracy: 0.4612 - val_loss: 2.5219 - val_accuracy: 0.3929\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6715 - accuracy: 0.4608 - val_loss: 2.5414 - val_accuracy: 0.4009\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6611 - accuracy: 0.4707 - val_loss: 2.5087 - val_accuracy: 0.3984\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6336 - accuracy: 0.4756 - val_loss: 2.5433 - val_accuracy: 0.3990\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6730 - accuracy: 0.4662 - val_loss: 2.5431 - val_accuracy: 0.3911\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6629 - accuracy: 0.4650 - val_loss: 2.5598 - val_accuracy: 0.4021\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6502 - accuracy: 0.4662 - val_loss: 2.5417 - val_accuracy: 0.3881\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6669 - accuracy: 0.4666 - val_loss: 2.5182 - val_accuracy: 0.4021\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6485 - accuracy: 0.4766 - val_loss: 2.5291 - val_accuracy: 0.4021\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6499 - accuracy: 0.4701 - val_loss: 2.5434 - val_accuracy: 0.3936\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6512 - accuracy: 0.4641 - val_loss: 2.5408 - val_accuracy: 0.3972\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6463 - accuracy: 0.4748 - val_loss: 2.5269 - val_accuracy: 0.3984\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6675 - accuracy: 0.4601 - val_loss: 2.5378 - val_accuracy: 0.3966\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6467 - accuracy: 0.4786 - val_loss: 2.5552 - val_accuracy: 0.3929\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6619 - accuracy: 0.4630 - val_loss: 2.5462 - val_accuracy: 0.3911\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6627 - accuracy: 0.4593 - val_loss: 2.5546 - val_accuracy: 0.3887\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6448 - accuracy: 0.4746 - val_loss: 2.5297 - val_accuracy: 0.4088\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6485 - accuracy: 0.4709 - val_loss: 2.5474 - val_accuracy: 0.3881\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6579 - accuracy: 0.4634 - val_loss: 2.5211 - val_accuracy: 0.4033\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6694 - accuracy: 0.4667 - val_loss: 2.5341 - val_accuracy: 0.3929\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6282 - accuracy: 0.4687 - val_loss: 2.5325 - val_accuracy: 0.3996\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6470 - accuracy: 0.4738 - val_loss: 2.5229 - val_accuracy: 0.4082\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6493 - accuracy: 0.4728 - val_loss: 2.5532 - val_accuracy: 0.3954\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6551 - accuracy: 0.4681 - val_loss: 2.5303 - val_accuracy: 0.4033\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6464 - accuracy: 0.4767 - val_loss: 2.5476 - val_accuracy: 0.4021\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6599 - accuracy: 0.4659 - val_loss: 2.5377 - val_accuracy: 0.3905\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6441 - accuracy: 0.4723 - val_loss: 2.5551 - val_accuracy: 0.3954\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6624 - accuracy: 0.4631 - val_loss: 2.5275 - val_accuracy: 0.4009\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6450 - accuracy: 0.4691 - val_loss: 2.5486 - val_accuracy: 0.3978\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6730 - accuracy: 0.4681 - val_loss: 2.5411 - val_accuracy: 0.4051\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6529 - accuracy: 0.4654 - val_loss: 2.5340 - val_accuracy: 0.4027\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6771 - accuracy: 0.4641 - val_loss: 2.5717 - val_accuracy: 0.3808\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6429 - accuracy: 0.4674 - val_loss: 2.5449 - val_accuracy: 0.3966\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6487 - accuracy: 0.4751 - val_loss: 2.5863 - val_accuracy: 0.3954\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6644 - accuracy: 0.4663 - val_loss: 2.5428 - val_accuracy: 0.4002\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6484 - accuracy: 0.4706 - val_loss: 2.5405 - val_accuracy: 0.4021\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6471 - accuracy: 0.4697 - val_loss: 2.5465 - val_accuracy: 0.4015\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6556 - accuracy: 0.4671 - val_loss: 2.5606 - val_accuracy: 0.3966\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6599 - accuracy: 0.4634 - val_loss: 2.5245 - val_accuracy: 0.4051\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6596 - accuracy: 0.4710 - val_loss: 2.5430 - val_accuracy: 0.3960\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6335 - accuracy: 0.4693 - val_loss: 2.5344 - val_accuracy: 0.4027\n",
      "Epoch 542/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6462 - accuracy: 0.4723 - val_loss: 2.5737 - val_accuracy: 0.3899\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6409 - accuracy: 0.4776 - val_loss: 2.5450 - val_accuracy: 0.3990\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6283 - accuracy: 0.4764 - val_loss: 2.5574 - val_accuracy: 0.3996\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6643 - accuracy: 0.4712 - val_loss: 2.5558 - val_accuracy: 0.4021\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6489 - accuracy: 0.4739 - val_loss: 2.5300 - val_accuracy: 0.4142\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6286 - accuracy: 0.4794 - val_loss: 2.5483 - val_accuracy: 0.4088\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6619 - accuracy: 0.4664 - val_loss: 2.5485 - val_accuracy: 0.4069\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6365 - accuracy: 0.4711 - val_loss: 2.5664 - val_accuracy: 0.3917\n",
      "Epoch 550/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6506 - accuracy: 0.4671 - val_loss: 2.5594 - val_accuracy: 0.3936\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6500 - accuracy: 0.4652 - val_loss: 2.5394 - val_accuracy: 0.3960\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6422 - accuracy: 0.4714 - val_loss: 2.5578 - val_accuracy: 0.3863\n",
      "Epoch 553/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6637 - accuracy: 0.4622 - val_loss: 2.5638 - val_accuracy: 0.3869\n",
      "Epoch 554/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6650 - accuracy: 0.4568 - val_loss: 2.5614 - val_accuracy: 0.4027\n",
      "Epoch 555/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6430 - accuracy: 0.4729 - val_loss: 2.5415 - val_accuracy: 0.3856\n",
      "Epoch 556/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6387 - accuracy: 0.4771 - val_loss: 2.5573 - val_accuracy: 0.3978\n",
      "Epoch 557/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6515 - accuracy: 0.4690 - val_loss: 2.5603 - val_accuracy: 0.3911\n",
      "Epoch 558/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6642 - accuracy: 0.4622 - val_loss: 2.5751 - val_accuracy: 0.4039\n",
      "Epoch 559/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6370 - accuracy: 0.4758 - val_loss: 2.5495 - val_accuracy: 0.4015\n",
      "Epoch 560/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6820 - accuracy: 0.4644 - val_loss: 2.5567 - val_accuracy: 0.3899\n",
      "Epoch 561/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6653 - accuracy: 0.4666 - val_loss: 2.5610 - val_accuracy: 0.3972\n",
      "Epoch 562/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6259 - accuracy: 0.4681 - val_loss: 2.5684 - val_accuracy: 0.3899\n",
      "Epoch 563/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6364 - accuracy: 0.4776 - val_loss: 2.5502 - val_accuracy: 0.3966\n",
      "Epoch 564/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6508 - accuracy: 0.4663 - val_loss: 2.5607 - val_accuracy: 0.4021\n",
      "Epoch 565/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6503 - accuracy: 0.4646 - val_loss: 2.5655 - val_accuracy: 0.3881\n",
      "Epoch 566/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6430 - accuracy: 0.4676 - val_loss: 2.5599 - val_accuracy: 0.4039\n",
      "Epoch 567/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6485 - accuracy: 0.4716 - val_loss: 2.5438 - val_accuracy: 0.3996\n",
      "Epoch 568/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6547 - accuracy: 0.4691 - val_loss: 2.5797 - val_accuracy: 0.3972\n",
      "Epoch 569/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6438 - accuracy: 0.4759 - val_loss: 2.5819 - val_accuracy: 0.3917\n",
      "Epoch 570/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6336 - accuracy: 0.4789 - val_loss: 2.5741 - val_accuracy: 0.3942\n",
      "Epoch 571/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6793 - accuracy: 0.4711 - val_loss: 2.5420 - val_accuracy: 0.3990\n",
      "Epoch 572/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6517 - accuracy: 0.4616 - val_loss: 2.5536 - val_accuracy: 0.4051\n",
      "Epoch 573/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6481 - accuracy: 0.4679 - val_loss: 2.5669 - val_accuracy: 0.3972\n",
      "Epoch 574/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6436 - accuracy: 0.4712 - val_loss: 2.5943 - val_accuracy: 0.3942\n",
      "Epoch 575/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6477 - accuracy: 0.4728 - val_loss: 2.5573 - val_accuracy: 0.4051\n",
      "Epoch 576/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6379 - accuracy: 0.4708 - val_loss: 2.5456 - val_accuracy: 0.4045\n",
      "Epoch 577/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6718 - accuracy: 0.4703 - val_loss: 2.5600 - val_accuracy: 0.3869\n",
      "Epoch 578/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6461 - accuracy: 0.4702 - val_loss: 2.5647 - val_accuracy: 0.3881\n",
      "Epoch 579/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6667 - accuracy: 0.4649 - val_loss: 2.5519 - val_accuracy: 0.3972\n",
      "Epoch 580/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6428 - accuracy: 0.4647 - val_loss: 2.5371 - val_accuracy: 0.4002\n",
      "Epoch 581/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6478 - accuracy: 0.4722 - val_loss: 2.5834 - val_accuracy: 0.3972\n",
      "Epoch 582/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6492 - accuracy: 0.4644 - val_loss: 2.5348 - val_accuracy: 0.4009\n",
      "Epoch 583/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6295 - accuracy: 0.4731 - val_loss: 2.5706 - val_accuracy: 0.3899\n",
      "Epoch 584/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6589 - accuracy: 0.4679 - val_loss: 2.5771 - val_accuracy: 0.3838\n",
      "Epoch 585/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6451 - accuracy: 0.4705 - val_loss: 2.5830 - val_accuracy: 0.3856\n",
      "Epoch 586/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6600 - accuracy: 0.4649 - val_loss: 2.5684 - val_accuracy: 0.3960\n",
      "Epoch 587/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6605 - accuracy: 0.4670 - val_loss: 2.5654 - val_accuracy: 0.3966\n",
      "Epoch 588/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6495 - accuracy: 0.4666 - val_loss: 2.5714 - val_accuracy: 0.3875\n",
      "Epoch 589/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6564 - accuracy: 0.4632 - val_loss: 2.5555 - val_accuracy: 0.3917\n",
      "Epoch 590/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6415 - accuracy: 0.4788 - val_loss: 2.5778 - val_accuracy: 0.3875\n",
      "Epoch 591/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6606 - accuracy: 0.4638 - val_loss: 2.5848 - val_accuracy: 0.3917\n",
      "Epoch 592/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6579 - accuracy: 0.4558 - val_loss: 2.5676 - val_accuracy: 0.4106\n",
      "Epoch 593/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6483 - accuracy: 0.4754 - val_loss: 2.5817 - val_accuracy: 0.3869\n",
      "Epoch 594/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6325 - accuracy: 0.4793 - val_loss: 2.5738 - val_accuracy: 0.3911\n",
      "Epoch 595/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6402 - accuracy: 0.4774 - val_loss: 2.5776 - val_accuracy: 0.3875\n",
      "Epoch 596/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6358 - accuracy: 0.4770 - val_loss: 2.5691 - val_accuracy: 0.3844\n",
      "Epoch 597/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6314 - accuracy: 0.4740 - val_loss: 2.5478 - val_accuracy: 0.3972\n",
      "Epoch 598/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6333 - accuracy: 0.4863 - val_loss: 2.5784 - val_accuracy: 0.3887\n",
      "Epoch 599/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6326 - accuracy: 0.4786 - val_loss: 2.5614 - val_accuracy: 0.3869\n",
      "Epoch 600/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6267 - accuracy: 0.4718 - val_loss: 2.5718 - val_accuracy: 0.3869\n",
      "Epoch 601/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6456 - accuracy: 0.4734 - val_loss: 2.6061 - val_accuracy: 0.3899\n",
      "Epoch 602/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6544 - accuracy: 0.4588 - val_loss: 2.5782 - val_accuracy: 0.3808\n",
      "Epoch 603/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6253 - accuracy: 0.4781 - val_loss: 2.5939 - val_accuracy: 0.3905\n",
      "Epoch 604/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6428 - accuracy: 0.4649 - val_loss: 2.5773 - val_accuracy: 0.3899\n",
      "Epoch 605/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6369 - accuracy: 0.4682 - val_loss: 2.5801 - val_accuracy: 0.3936\n",
      "Epoch 606/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6456 - accuracy: 0.4703 - val_loss: 2.5616 - val_accuracy: 0.3869\n",
      "Epoch 607/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6446 - accuracy: 0.4668 - val_loss: 2.5567 - val_accuracy: 0.4015\n",
      "Epoch 608/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6537 - accuracy: 0.4673 - val_loss: 2.5775 - val_accuracy: 0.3923\n",
      "Epoch 609/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6401 - accuracy: 0.4746 - val_loss: 2.5639 - val_accuracy: 0.3899\n",
      "Epoch 610/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6199 - accuracy: 0.4713 - val_loss: 2.5685 - val_accuracy: 0.3899\n",
      "Epoch 611/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6398 - accuracy: 0.4604 - val_loss: 2.5889 - val_accuracy: 0.3893\n",
      "Epoch 612/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6469 - accuracy: 0.4775 - val_loss: 2.5780 - val_accuracy: 0.3942\n",
      "Epoch 613/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6246 - accuracy: 0.4758 - val_loss: 2.5778 - val_accuracy: 0.3863\n",
      "Epoch 614/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6479 - accuracy: 0.4738 - val_loss: 2.5908 - val_accuracy: 0.3911\n",
      "Epoch 615/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6401 - accuracy: 0.4744 - val_loss: 2.5951 - val_accuracy: 0.3796\n",
      "Epoch 616/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6444 - accuracy: 0.4811 - val_loss: 2.5836 - val_accuracy: 0.3881\n",
      "Epoch 617/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6455 - accuracy: 0.4715 - val_loss: 2.5724 - val_accuracy: 0.3863\n",
      "Epoch 618/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6345 - accuracy: 0.4763 - val_loss: 2.5819 - val_accuracy: 0.3826\n",
      "Epoch 619/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6467 - accuracy: 0.4697 - val_loss: 2.5771 - val_accuracy: 0.3863\n",
      "Epoch 620/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6328 - accuracy: 0.4660 - val_loss: 2.5675 - val_accuracy: 0.3808\n",
      "Epoch 621/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6426 - accuracy: 0.4767 - val_loss: 2.5762 - val_accuracy: 0.3808\n",
      "Epoch 622/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6310 - accuracy: 0.4749 - val_loss: 2.5962 - val_accuracy: 0.3887\n",
      "Epoch 623/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6183 - accuracy: 0.4690 - val_loss: 2.5721 - val_accuracy: 0.3929\n",
      "Epoch 624/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6089 - accuracy: 0.4764 - val_loss: 2.6011 - val_accuracy: 0.3790\n",
      "Epoch 625/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6126 - accuracy: 0.4759 - val_loss: 2.5812 - val_accuracy: 0.3875\n",
      "Epoch 626/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6354 - accuracy: 0.4695 - val_loss: 2.5689 - val_accuracy: 0.3929\n",
      "Epoch 627/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6211 - accuracy: 0.4806 - val_loss: 2.5785 - val_accuracy: 0.3936\n",
      "Epoch 628/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6443 - accuracy: 0.4705 - val_loss: 2.5886 - val_accuracy: 0.3996\n",
      "Epoch 629/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6431 - accuracy: 0.4658 - val_loss: 2.5778 - val_accuracy: 0.3942\n",
      "Epoch 630/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6197 - accuracy: 0.4872 - val_loss: 2.5799 - val_accuracy: 0.3747\n",
      "Epoch 631/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6547 - accuracy: 0.4643 - val_loss: 2.5752 - val_accuracy: 0.3990\n",
      "Epoch 632/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6426 - accuracy: 0.4624 - val_loss: 2.5716 - val_accuracy: 0.3984\n",
      "Epoch 633/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6341 - accuracy: 0.4654 - val_loss: 2.5703 - val_accuracy: 0.3972\n",
      "Epoch 634/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6181 - accuracy: 0.4823 - val_loss: 2.5672 - val_accuracy: 0.3923\n",
      "Epoch 635/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6540 - accuracy: 0.4696 - val_loss: 2.5623 - val_accuracy: 0.3887\n",
      "Epoch 636/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6363 - accuracy: 0.4674 - val_loss: 2.5687 - val_accuracy: 0.3996\n",
      "Epoch 637/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6473 - accuracy: 0.4659 - val_loss: 2.5859 - val_accuracy: 0.3893\n",
      "Epoch 638/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6286 - accuracy: 0.4821 - val_loss: 2.6074 - val_accuracy: 0.3923\n",
      "Epoch 639/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6658 - accuracy: 0.4606 - val_loss: 2.5683 - val_accuracy: 0.3942\n",
      "Epoch 640/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6582 - accuracy: 0.4668 - val_loss: 2.5799 - val_accuracy: 0.3954\n",
      "Epoch 641/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6310 - accuracy: 0.4723 - val_loss: 2.5726 - val_accuracy: 0.3923\n",
      "Epoch 642/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6490 - accuracy: 0.4694 - val_loss: 2.5810 - val_accuracy: 0.3948\n",
      "Epoch 643/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6196 - accuracy: 0.4835 - val_loss: 2.5790 - val_accuracy: 0.4033\n",
      "Epoch 644/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6019 - accuracy: 0.4821 - val_loss: 2.5882 - val_accuracy: 0.3917\n",
      "Epoch 645/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6285 - accuracy: 0.4692 - val_loss: 2.5676 - val_accuracy: 0.3948\n",
      "Epoch 646/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6107 - accuracy: 0.4795 - val_loss: 2.5678 - val_accuracy: 0.3893\n",
      "Epoch 647/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6303 - accuracy: 0.4792 - val_loss: 2.5755 - val_accuracy: 0.3905\n",
      "Epoch 648/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6496 - accuracy: 0.4651 - val_loss: 2.5764 - val_accuracy: 0.3911\n",
      "Epoch 649/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6467 - accuracy: 0.4731 - val_loss: 2.5535 - val_accuracy: 0.3972\n",
      "Epoch 650/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6207 - accuracy: 0.4718 - val_loss: 2.5921 - val_accuracy: 0.3875\n",
      "Epoch 651/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6378 - accuracy: 0.4733 - val_loss: 2.5779 - val_accuracy: 0.3863\n",
      "Epoch 652/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6384 - accuracy: 0.4711 - val_loss: 2.6089 - val_accuracy: 0.3814\n",
      "Epoch 653/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6157 - accuracy: 0.4636 - val_loss: 2.5714 - val_accuracy: 0.3942\n",
      "Epoch 654/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6419 - accuracy: 0.4727 - val_loss: 2.5913 - val_accuracy: 0.3869\n",
      "Epoch 655/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6369 - accuracy: 0.4724 - val_loss: 2.5801 - val_accuracy: 0.3929\n",
      "Epoch 656/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6404 - accuracy: 0.4718 - val_loss: 2.5773 - val_accuracy: 0.3960\n",
      "Epoch 657/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6022 - accuracy: 0.4825 - val_loss: 2.5795 - val_accuracy: 0.3917\n",
      "Epoch 658/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6395 - accuracy: 0.4746 - val_loss: 2.5764 - val_accuracy: 0.4112\n",
      "Epoch 659/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6453 - accuracy: 0.4633 - val_loss: 2.5564 - val_accuracy: 0.3856\n",
      "Epoch 660/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6322 - accuracy: 0.4763 - val_loss: 2.6015 - val_accuracy: 0.3887\n",
      "Epoch 661/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6245 - accuracy: 0.4779 - val_loss: 2.5839 - val_accuracy: 0.3984\n",
      "Epoch 662/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6322 - accuracy: 0.4780 - val_loss: 2.5991 - val_accuracy: 0.3783\n",
      "Epoch 663/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6273 - accuracy: 0.4660 - val_loss: 2.5736 - val_accuracy: 0.4027\n",
      "Epoch 664/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6349 - accuracy: 0.4741 - val_loss: 2.5941 - val_accuracy: 0.3911\n",
      "Epoch 665/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6241 - accuracy: 0.4780 - val_loss: 2.5715 - val_accuracy: 0.3966\n",
      "Epoch 666/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6185 - accuracy: 0.4778 - val_loss: 2.5819 - val_accuracy: 0.3814\n",
      "Epoch 667/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6406 - accuracy: 0.4776 - val_loss: 2.5895 - val_accuracy: 0.3966\n",
      "Epoch 668/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6379 - accuracy: 0.4653 - val_loss: 2.5997 - val_accuracy: 0.3741\n",
      "Epoch 669/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6334 - accuracy: 0.4771 - val_loss: 2.5603 - val_accuracy: 0.3978\n",
      "Epoch 670/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6041 - accuracy: 0.4905 - val_loss: 2.5903 - val_accuracy: 0.3875\n",
      "Epoch 671/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6162 - accuracy: 0.4681 - val_loss: 2.5982 - val_accuracy: 0.3832\n",
      "Epoch 672/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6537 - accuracy: 0.4647 - val_loss: 2.5955 - val_accuracy: 0.3948\n",
      "Epoch 673/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6491 - accuracy: 0.4604 - val_loss: 2.5594 - val_accuracy: 0.3948\n",
      "Epoch 674/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6292 - accuracy: 0.4710 - val_loss: 2.5503 - val_accuracy: 0.3966\n",
      "Epoch 675/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6344 - accuracy: 0.4755 - val_loss: 2.5638 - val_accuracy: 0.3984\n",
      "Epoch 676/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6261 - accuracy: 0.4737 - val_loss: 2.5839 - val_accuracy: 0.3954\n",
      "Epoch 677/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6178 - accuracy: 0.4857 - val_loss: 2.5809 - val_accuracy: 0.3936\n",
      "Epoch 678/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6187 - accuracy: 0.4761 - val_loss: 2.5895 - val_accuracy: 0.3954\n",
      "Epoch 679/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6213 - accuracy: 0.4795 - val_loss: 2.5773 - val_accuracy: 0.3990\n",
      "Epoch 680/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6535 - accuracy: 0.4645 - val_loss: 2.5768 - val_accuracy: 0.3899\n",
      "Epoch 681/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6135 - accuracy: 0.4788 - val_loss: 2.5925 - val_accuracy: 0.3942\n",
      "Epoch 682/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6181 - accuracy: 0.4782 - val_loss: 2.5811 - val_accuracy: 0.3832\n",
      "Epoch 683/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6251 - accuracy: 0.4722 - val_loss: 2.5723 - val_accuracy: 0.3990\n",
      "Epoch 684/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6394 - accuracy: 0.4726 - val_loss: 2.5682 - val_accuracy: 0.3996\n",
      "Epoch 685/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6175 - accuracy: 0.4738 - val_loss: 2.6007 - val_accuracy: 0.3796\n",
      "Epoch 686/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6375 - accuracy: 0.4703 - val_loss: 2.5765 - val_accuracy: 0.3905\n",
      "Epoch 687/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6221 - accuracy: 0.4762 - val_loss: 2.5543 - val_accuracy: 0.3966\n",
      "Epoch 688/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6321 - accuracy: 0.4630 - val_loss: 2.6115 - val_accuracy: 0.3929\n",
      "Epoch 689/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6167 - accuracy: 0.4789 - val_loss: 2.5874 - val_accuracy: 0.3972\n",
      "Epoch 690/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6314 - accuracy: 0.4731 - val_loss: 2.6033 - val_accuracy: 0.3923\n",
      "Epoch 691/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6266 - accuracy: 0.4770 - val_loss: 2.6083 - val_accuracy: 0.3838\n",
      "Epoch 692/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6256 - accuracy: 0.4697 - val_loss: 2.5938 - val_accuracy: 0.4033\n",
      "Epoch 693/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6327 - accuracy: 0.4720 - val_loss: 2.5832 - val_accuracy: 0.3796\n",
      "Epoch 694/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6101 - accuracy: 0.4770 - val_loss: 2.6092 - val_accuracy: 0.3838\n",
      "Epoch 695/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6280 - accuracy: 0.4822 - val_loss: 2.5806 - val_accuracy: 0.3917\n",
      "Epoch 696/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6311 - accuracy: 0.4687 - val_loss: 2.5844 - val_accuracy: 0.3942\n",
      "Epoch 697/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6211 - accuracy: 0.4776 - val_loss: 2.5910 - val_accuracy: 0.4002\n",
      "Epoch 698/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6280 - accuracy: 0.4799 - val_loss: 2.5980 - val_accuracy: 0.3856\n",
      "Epoch 699/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6248 - accuracy: 0.4763 - val_loss: 2.6034 - val_accuracy: 0.3820\n",
      "Epoch 700/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6121 - accuracy: 0.4729 - val_loss: 2.6077 - val_accuracy: 0.3826\n",
      "Epoch 701/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6400 - accuracy: 0.4713 - val_loss: 2.5807 - val_accuracy: 0.3887\n",
      "Epoch 702/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6214 - accuracy: 0.4819 - val_loss: 2.5991 - val_accuracy: 0.3826\n",
      "Epoch 703/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6312 - accuracy: 0.4710 - val_loss: 2.6015 - val_accuracy: 0.3966\n",
      "Epoch 704/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6152 - accuracy: 0.4736 - val_loss: 2.6040 - val_accuracy: 0.3832\n",
      "Epoch 705/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6217 - accuracy: 0.4691 - val_loss: 2.6059 - val_accuracy: 0.3929\n",
      "Epoch 706/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6336 - accuracy: 0.4818 - val_loss: 2.5964 - val_accuracy: 0.3850\n",
      "Epoch 707/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6406 - accuracy: 0.4712 - val_loss: 2.6080 - val_accuracy: 0.3759\n",
      "Epoch 708/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6296 - accuracy: 0.4831 - val_loss: 2.6016 - val_accuracy: 0.3966\n",
      "Epoch 709/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6230 - accuracy: 0.4776 - val_loss: 2.6053 - val_accuracy: 0.3954\n",
      "Epoch 710/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6004 - accuracy: 0.4708 - val_loss: 2.6181 - val_accuracy: 0.3881\n",
      "Epoch 711/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6479 - accuracy: 0.4656 - val_loss: 2.6230 - val_accuracy: 0.3936\n",
      "Epoch 712/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6013 - accuracy: 0.4809 - val_loss: 2.6145 - val_accuracy: 0.3844\n",
      "Epoch 713/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6259 - accuracy: 0.4778 - val_loss: 2.6053 - val_accuracy: 0.3899\n",
      "Epoch 714/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6182 - accuracy: 0.4749 - val_loss: 2.5947 - val_accuracy: 0.3923\n",
      "Epoch 715/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6085 - accuracy: 0.4898 - val_loss: 2.6045 - val_accuracy: 0.3759\n",
      "Epoch 716/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6319 - accuracy: 0.4728 - val_loss: 2.6096 - val_accuracy: 0.3765\n",
      "Epoch 717/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6142 - accuracy: 0.4755 - val_loss: 2.6251 - val_accuracy: 0.3808\n",
      "Epoch 718/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6293 - accuracy: 0.4851 - val_loss: 2.6195 - val_accuracy: 0.3887\n",
      "Epoch 719/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6176 - accuracy: 0.4763 - val_loss: 2.6281 - val_accuracy: 0.3893\n",
      "Epoch 720/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6200 - accuracy: 0.4768 - val_loss: 2.5965 - val_accuracy: 0.3917\n",
      "Epoch 721/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6370 - accuracy: 0.4774 - val_loss: 2.6078 - val_accuracy: 0.3850\n",
      "Epoch 722/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6041 - accuracy: 0.4823 - val_loss: 2.6204 - val_accuracy: 0.3942\n",
      "Epoch 723/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6217 - accuracy: 0.4763 - val_loss: 2.6171 - val_accuracy: 0.3917\n",
      "Epoch 724/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6092 - accuracy: 0.4816 - val_loss: 2.6175 - val_accuracy: 0.3802\n",
      "Epoch 725/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6153 - accuracy: 0.4728 - val_loss: 2.6263 - val_accuracy: 0.3826\n",
      "Epoch 726/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6062 - accuracy: 0.4798 - val_loss: 2.6161 - val_accuracy: 0.3929\n",
      "Epoch 727/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6516 - accuracy: 0.4635 - val_loss: 2.6139 - val_accuracy: 0.3972\n",
      "Epoch 728/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6184 - accuracy: 0.4804 - val_loss: 2.6121 - val_accuracy: 0.3929\n",
      "Epoch 729/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6317 - accuracy: 0.4669 - val_loss: 2.6072 - val_accuracy: 0.3893\n",
      "Epoch 730/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5880 - accuracy: 0.4871 - val_loss: 2.6251 - val_accuracy: 0.3838\n",
      "Epoch 731/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6166 - accuracy: 0.4750 - val_loss: 2.6121 - val_accuracy: 0.3826\n",
      "Epoch 732/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6128 - accuracy: 0.4807 - val_loss: 2.6218 - val_accuracy: 0.3838\n",
      "Epoch 733/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6038 - accuracy: 0.4875 - val_loss: 2.5992 - val_accuracy: 0.3911\n",
      "Epoch 734/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6198 - accuracy: 0.4789 - val_loss: 2.6233 - val_accuracy: 0.3832\n",
      "Epoch 735/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6234 - accuracy: 0.4733 - val_loss: 2.5893 - val_accuracy: 0.3899\n",
      "Epoch 736/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6184 - accuracy: 0.4761 - val_loss: 2.6090 - val_accuracy: 0.3972\n",
      "Epoch 737/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6184 - accuracy: 0.4831 - val_loss: 2.5988 - val_accuracy: 0.3911\n",
      "Epoch 738/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6004 - accuracy: 0.4888 - val_loss: 2.6320 - val_accuracy: 0.3814\n",
      "Epoch 739/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6240 - accuracy: 0.4837 - val_loss: 2.6370 - val_accuracy: 0.3875\n",
      "Epoch 740/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6121 - accuracy: 0.4813 - val_loss: 2.6135 - val_accuracy: 0.3960\n",
      "Epoch 741/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6257 - accuracy: 0.4750 - val_loss: 2.6072 - val_accuracy: 0.3838\n",
      "Epoch 742/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6096 - accuracy: 0.4792 - val_loss: 2.6014 - val_accuracy: 0.3923\n",
      "Epoch 743/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6127 - accuracy: 0.4754 - val_loss: 2.5988 - val_accuracy: 0.3966\n",
      "Epoch 744/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6227 - accuracy: 0.4691 - val_loss: 2.6291 - val_accuracy: 0.3899\n",
      "Epoch 745/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6163 - accuracy: 0.4806 - val_loss: 2.6129 - val_accuracy: 0.3838\n",
      "Epoch 746/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6276 - accuracy: 0.4709 - val_loss: 2.5909 - val_accuracy: 0.4027\n",
      "Epoch 747/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5997 - accuracy: 0.4848 - val_loss: 2.6007 - val_accuracy: 0.3869\n",
      "Epoch 748/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6093 - accuracy: 0.4801 - val_loss: 2.6514 - val_accuracy: 0.3814\n",
      "Epoch 749/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6120 - accuracy: 0.4798 - val_loss: 2.6243 - val_accuracy: 0.3887\n",
      "Epoch 750/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6253 - accuracy: 0.4784 - val_loss: 2.6010 - val_accuracy: 0.3814\n",
      "Epoch 751/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6211 - accuracy: 0.4728 - val_loss: 2.6316 - val_accuracy: 0.3850\n",
      "Epoch 752/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6017 - accuracy: 0.4810 - val_loss: 2.6277 - val_accuracy: 0.3899\n",
      "Epoch 753/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6058 - accuracy: 0.4801 - val_loss: 2.5978 - val_accuracy: 0.3856\n",
      "Epoch 754/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6098 - accuracy: 0.4837 - val_loss: 2.6220 - val_accuracy: 0.3735\n",
      "Epoch 755/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6060 - accuracy: 0.4835 - val_loss: 2.6238 - val_accuracy: 0.3747\n",
      "Epoch 756/1000\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 1.6214 - accuracy: 0.4587 - val_loss: 2.6324 - val_accuracy: 0.3893\n",
      "Epoch 757/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6049 - accuracy: 0.4852 - val_loss: 2.6174 - val_accuracy: 0.3899\n",
      "Epoch 758/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5944 - accuracy: 0.4843 - val_loss: 2.6062 - val_accuracy: 0.3911\n",
      "Epoch 759/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6059 - accuracy: 0.4830 - val_loss: 2.6305 - val_accuracy: 0.3875\n",
      "Epoch 760/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6020 - accuracy: 0.4734 - val_loss: 2.6184 - val_accuracy: 0.3923\n",
      "Epoch 761/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6107 - accuracy: 0.4743 - val_loss: 2.6158 - val_accuracy: 0.3887\n",
      "Epoch 762/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6217 - accuracy: 0.4718 - val_loss: 2.6163 - val_accuracy: 0.3960\n",
      "Epoch 763/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6398 - accuracy: 0.4657 - val_loss: 2.6404 - val_accuracy: 0.3814\n",
      "Epoch 764/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5880 - accuracy: 0.4927 - val_loss: 2.6225 - val_accuracy: 0.3869\n",
      "Epoch 765/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6311 - accuracy: 0.4816 - val_loss: 2.6388 - val_accuracy: 0.3863\n",
      "Epoch 766/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6271 - accuracy: 0.4702 - val_loss: 2.6155 - val_accuracy: 0.3887\n",
      "Epoch 767/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5832 - accuracy: 0.4864 - val_loss: 2.6308 - val_accuracy: 0.3796\n",
      "Epoch 768/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6175 - accuracy: 0.4817 - val_loss: 2.6400 - val_accuracy: 0.3869\n",
      "Epoch 769/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6060 - accuracy: 0.4810 - val_loss: 2.6346 - val_accuracy: 0.3790\n",
      "Epoch 770/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6190 - accuracy: 0.4720 - val_loss: 2.6168 - val_accuracy: 0.3893\n",
      "Epoch 771/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6109 - accuracy: 0.4692 - val_loss: 2.6000 - val_accuracy: 0.3929\n",
      "Epoch 772/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6289 - accuracy: 0.4742 - val_loss: 2.6290 - val_accuracy: 0.3808\n",
      "Epoch 773/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5859 - accuracy: 0.4888 - val_loss: 2.6457 - val_accuracy: 0.3899\n",
      "Epoch 774/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6137 - accuracy: 0.4711 - val_loss: 2.6073 - val_accuracy: 0.3960\n",
      "Epoch 775/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6107 - accuracy: 0.4793 - val_loss: 2.6208 - val_accuracy: 0.3844\n",
      "Epoch 776/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6156 - accuracy: 0.4709 - val_loss: 2.6089 - val_accuracy: 0.3936\n",
      "Epoch 777/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6238 - accuracy: 0.4775 - val_loss: 2.6179 - val_accuracy: 0.3936\n",
      "Epoch 778/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6251 - accuracy: 0.4806 - val_loss: 2.6284 - val_accuracy: 0.3929\n",
      "Epoch 779/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6036 - accuracy: 0.4818 - val_loss: 2.6434 - val_accuracy: 0.3717\n",
      "Epoch 780/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6108 - accuracy: 0.4725 - val_loss: 2.6246 - val_accuracy: 0.3905\n",
      "Epoch 781/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6286 - accuracy: 0.4796 - val_loss: 2.6370 - val_accuracy: 0.3893\n",
      "Epoch 782/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5850 - accuracy: 0.4860 - val_loss: 2.6433 - val_accuracy: 0.3875\n",
      "Epoch 783/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6225 - accuracy: 0.4785 - val_loss: 2.6197 - val_accuracy: 0.3869\n",
      "Epoch 784/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6041 - accuracy: 0.4730 - val_loss: 2.6387 - val_accuracy: 0.3832\n",
      "Epoch 785/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6234 - accuracy: 0.4715 - val_loss: 2.5859 - val_accuracy: 0.3948\n",
      "Epoch 786/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6192 - accuracy: 0.4766 - val_loss: 2.6091 - val_accuracy: 0.3869\n",
      "Epoch 787/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6190 - accuracy: 0.4743 - val_loss: 2.6054 - val_accuracy: 0.3796\n",
      "Epoch 788/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6206 - accuracy: 0.4695 - val_loss: 2.6212 - val_accuracy: 0.3850\n",
      "Epoch 789/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5929 - accuracy: 0.4783 - val_loss: 2.6283 - val_accuracy: 0.3936\n",
      "Epoch 790/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6073 - accuracy: 0.4814 - val_loss: 2.6350 - val_accuracy: 0.3796\n",
      "Epoch 791/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6033 - accuracy: 0.4799 - val_loss: 2.6133 - val_accuracy: 0.3777\n",
      "Epoch 792/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6293 - accuracy: 0.4735 - val_loss: 2.6028 - val_accuracy: 0.3942\n",
      "Epoch 793/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6144 - accuracy: 0.4655 - val_loss: 2.6199 - val_accuracy: 0.3881\n",
      "Epoch 794/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5876 - accuracy: 0.4888 - val_loss: 2.6267 - val_accuracy: 0.3869\n",
      "Epoch 795/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6164 - accuracy: 0.4863 - val_loss: 2.6280 - val_accuracy: 0.3838\n",
      "Epoch 796/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5973 - accuracy: 0.4814 - val_loss: 2.6100 - val_accuracy: 0.3954\n",
      "Epoch 797/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6221 - accuracy: 0.4765 - val_loss: 2.6259 - val_accuracy: 0.3826\n",
      "Epoch 798/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6364 - accuracy: 0.4606 - val_loss: 2.6356 - val_accuracy: 0.3917\n",
      "Epoch 799/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6198 - accuracy: 0.4827 - val_loss: 2.6386 - val_accuracy: 0.3783\n",
      "Epoch 800/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6395 - accuracy: 0.4766 - val_loss: 2.5936 - val_accuracy: 0.4021\n",
      "Epoch 801/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6128 - accuracy: 0.4819 - val_loss: 2.6458 - val_accuracy: 0.3796\n",
      "Epoch 802/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6042 - accuracy: 0.4728 - val_loss: 2.6233 - val_accuracy: 0.3863\n",
      "Epoch 803/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6036 - accuracy: 0.4847 - val_loss: 2.6274 - val_accuracy: 0.3838\n",
      "Epoch 804/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6162 - accuracy: 0.4788 - val_loss: 2.6057 - val_accuracy: 0.3783\n",
      "Epoch 805/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6139 - accuracy: 0.4764 - val_loss: 2.6321 - val_accuracy: 0.3814\n",
      "Epoch 806/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6207 - accuracy: 0.4789 - val_loss: 2.6047 - val_accuracy: 0.3972\n",
      "Epoch 807/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6053 - accuracy: 0.4862 - val_loss: 2.6475 - val_accuracy: 0.3820\n",
      "Epoch 808/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6006 - accuracy: 0.4773 - val_loss: 2.6477 - val_accuracy: 0.3790\n",
      "Epoch 809/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5929 - accuracy: 0.4853 - val_loss: 2.6567 - val_accuracy: 0.3759\n",
      "Epoch 810/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6140 - accuracy: 0.4850 - val_loss: 2.6568 - val_accuracy: 0.3887\n",
      "Epoch 811/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6105 - accuracy: 0.4734 - val_loss: 2.6374 - val_accuracy: 0.3790\n",
      "Epoch 812/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6068 - accuracy: 0.4756 - val_loss: 2.6490 - val_accuracy: 0.3741\n",
      "Epoch 813/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5998 - accuracy: 0.4751 - val_loss: 2.6234 - val_accuracy: 0.3990\n",
      "Epoch 814/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6227 - accuracy: 0.4808 - val_loss: 2.6369 - val_accuracy: 0.3905\n",
      "Epoch 815/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5927 - accuracy: 0.4904 - val_loss: 2.6374 - val_accuracy: 0.3875\n",
      "Epoch 816/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5974 - accuracy: 0.4775 - val_loss: 2.6409 - val_accuracy: 0.3887\n",
      "Epoch 817/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6014 - accuracy: 0.4843 - val_loss: 2.5988 - val_accuracy: 0.3917\n",
      "Epoch 818/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6131 - accuracy: 0.4802 - val_loss: 2.6238 - val_accuracy: 0.3899\n",
      "Epoch 819/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6024 - accuracy: 0.4853 - val_loss: 2.6090 - val_accuracy: 0.3942\n",
      "Epoch 820/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5951 - accuracy: 0.4784 - val_loss: 2.6489 - val_accuracy: 0.3729\n",
      "Epoch 821/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5917 - accuracy: 0.4884 - val_loss: 2.5944 - val_accuracy: 0.3929\n",
      "Epoch 822/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5988 - accuracy: 0.4836 - val_loss: 2.6240 - val_accuracy: 0.3869\n",
      "Epoch 823/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6184 - accuracy: 0.4731 - val_loss: 2.6310 - val_accuracy: 0.3783\n",
      "Epoch 824/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6080 - accuracy: 0.4859 - val_loss: 2.6386 - val_accuracy: 0.3942\n",
      "Epoch 825/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5960 - accuracy: 0.4809 - val_loss: 2.6578 - val_accuracy: 0.3814\n",
      "Epoch 826/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5968 - accuracy: 0.4853 - val_loss: 2.6108 - val_accuracy: 0.3893\n",
      "Epoch 827/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6002 - accuracy: 0.4824 - val_loss: 2.6446 - val_accuracy: 0.3826\n",
      "Epoch 828/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6178 - accuracy: 0.4837 - val_loss: 2.6303 - val_accuracy: 0.3893\n",
      "Epoch 829/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6129 - accuracy: 0.4733 - val_loss: 2.6144 - val_accuracy: 0.3875\n",
      "Epoch 830/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6117 - accuracy: 0.4776 - val_loss: 2.6384 - val_accuracy: 0.3899\n",
      "Epoch 831/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6041 - accuracy: 0.4823 - val_loss: 2.6235 - val_accuracy: 0.3966\n",
      "Epoch 832/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6083 - accuracy: 0.4775 - val_loss: 2.6401 - val_accuracy: 0.3759\n",
      "Epoch 833/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5969 - accuracy: 0.4861 - val_loss: 2.6228 - val_accuracy: 0.3747\n",
      "Epoch 834/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5882 - accuracy: 0.4863 - val_loss: 2.6364 - val_accuracy: 0.3759\n",
      "Epoch 835/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6000 - accuracy: 0.4822 - val_loss: 2.6611 - val_accuracy: 0.3802\n",
      "Epoch 836/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6061 - accuracy: 0.4771 - val_loss: 2.6164 - val_accuracy: 0.3838\n",
      "Epoch 837/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5975 - accuracy: 0.4852 - val_loss: 2.6325 - val_accuracy: 0.3887\n",
      "Epoch 838/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6031 - accuracy: 0.4746 - val_loss: 2.6332 - val_accuracy: 0.3875\n",
      "Epoch 839/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6224 - accuracy: 0.4786 - val_loss: 2.6395 - val_accuracy: 0.3905\n",
      "Epoch 840/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6159 - accuracy: 0.4731 - val_loss: 2.6253 - val_accuracy: 0.3899\n",
      "Epoch 841/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6059 - accuracy: 0.4884 - val_loss: 2.6483 - val_accuracy: 0.3747\n",
      "Epoch 842/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6039 - accuracy: 0.4814 - val_loss: 2.6327 - val_accuracy: 0.3881\n",
      "Epoch 843/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6147 - accuracy: 0.4812 - val_loss: 2.6324 - val_accuracy: 0.3875\n",
      "Epoch 844/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6104 - accuracy: 0.4854 - val_loss: 2.6418 - val_accuracy: 0.3796\n",
      "Epoch 845/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6047 - accuracy: 0.4781 - val_loss: 2.6580 - val_accuracy: 0.3802\n",
      "Epoch 846/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5944 - accuracy: 0.4871 - val_loss: 2.6320 - val_accuracy: 0.3735\n",
      "Epoch 847/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6071 - accuracy: 0.4850 - val_loss: 2.6302 - val_accuracy: 0.3893\n",
      "Epoch 848/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6251 - accuracy: 0.4775 - val_loss: 2.6563 - val_accuracy: 0.3820\n",
      "Epoch 849/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6027 - accuracy: 0.4777 - val_loss: 2.6737 - val_accuracy: 0.3765\n",
      "Epoch 850/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6247 - accuracy: 0.4700 - val_loss: 2.6111 - val_accuracy: 0.3923\n",
      "Epoch 851/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6049 - accuracy: 0.4855 - val_loss: 2.6273 - val_accuracy: 0.3771\n",
      "Epoch 852/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5969 - accuracy: 0.4857 - val_loss: 2.6207 - val_accuracy: 0.3777\n",
      "Epoch 853/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6083 - accuracy: 0.4745 - val_loss: 2.6402 - val_accuracy: 0.3899\n",
      "Epoch 854/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6166 - accuracy: 0.4781 - val_loss: 2.6251 - val_accuracy: 0.3838\n",
      "Epoch 855/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5984 - accuracy: 0.4810 - val_loss: 2.6174 - val_accuracy: 0.3917\n",
      "Epoch 856/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6076 - accuracy: 0.4824 - val_loss: 2.6569 - val_accuracy: 0.3856\n",
      "Epoch 857/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6168 - accuracy: 0.4713 - val_loss: 2.6423 - val_accuracy: 0.3850\n",
      "Epoch 858/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6034 - accuracy: 0.4797 - val_loss: 2.6395 - val_accuracy: 0.3790\n",
      "Epoch 859/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6119 - accuracy: 0.4800 - val_loss: 2.6420 - val_accuracy: 0.3863\n",
      "Epoch 860/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6029 - accuracy: 0.4784 - val_loss: 2.6428 - val_accuracy: 0.3832\n",
      "Epoch 861/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5884 - accuracy: 0.4701 - val_loss: 2.6438 - val_accuracy: 0.3887\n",
      "Epoch 862/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5996 - accuracy: 0.4849 - val_loss: 2.6486 - val_accuracy: 0.3875\n",
      "Epoch 863/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6088 - accuracy: 0.4824 - val_loss: 2.6313 - val_accuracy: 0.4002\n",
      "Epoch 864/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6003 - accuracy: 0.4814 - val_loss: 2.6293 - val_accuracy: 0.3887\n",
      "Epoch 865/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6061 - accuracy: 0.4868 - val_loss: 2.6502 - val_accuracy: 0.3790\n",
      "Epoch 866/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6274 - accuracy: 0.4758 - val_loss: 2.6295 - val_accuracy: 0.3929\n",
      "Epoch 867/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5830 - accuracy: 0.4819 - val_loss: 2.6117 - val_accuracy: 0.3984\n",
      "Epoch 868/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6190 - accuracy: 0.4733 - val_loss: 2.6079 - val_accuracy: 0.4027\n",
      "Epoch 869/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6105 - accuracy: 0.4851 - val_loss: 2.6761 - val_accuracy: 0.3826\n",
      "Epoch 870/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6146 - accuracy: 0.4805 - val_loss: 2.6339 - val_accuracy: 0.3783\n",
      "Epoch 871/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5863 - accuracy: 0.4794 - val_loss: 2.6387 - val_accuracy: 0.3808\n",
      "Epoch 872/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6129 - accuracy: 0.4773 - val_loss: 2.6377 - val_accuracy: 0.3765\n",
      "Epoch 873/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6169 - accuracy: 0.4809 - val_loss: 2.6321 - val_accuracy: 0.3790\n",
      "Epoch 874/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5992 - accuracy: 0.4785 - val_loss: 2.6308 - val_accuracy: 0.3929\n",
      "Epoch 875/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5896 - accuracy: 0.4879 - val_loss: 2.6319 - val_accuracy: 0.3899\n",
      "Epoch 876/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5928 - accuracy: 0.4950 - val_loss: 2.6656 - val_accuracy: 0.3869\n",
      "Epoch 877/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6295 - accuracy: 0.4727 - val_loss: 2.6553 - val_accuracy: 0.3777\n",
      "Epoch 878/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6098 - accuracy: 0.4716 - val_loss: 2.6347 - val_accuracy: 0.3777\n",
      "Epoch 879/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6117 - accuracy: 0.4827 - val_loss: 2.6378 - val_accuracy: 0.3899\n",
      "Epoch 880/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6009 - accuracy: 0.4857 - val_loss: 2.6309 - val_accuracy: 0.3875\n",
      "Epoch 881/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6136 - accuracy: 0.4776 - val_loss: 2.6402 - val_accuracy: 0.3717\n",
      "Epoch 882/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5984 - accuracy: 0.4747 - val_loss: 2.6364 - val_accuracy: 0.3893\n",
      "Epoch 883/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6032 - accuracy: 0.4834 - val_loss: 2.6449 - val_accuracy: 0.3936\n",
      "Epoch 884/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5864 - accuracy: 0.4868 - val_loss: 2.6634 - val_accuracy: 0.3783\n",
      "Epoch 885/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5881 - accuracy: 0.4956 - val_loss: 2.6462 - val_accuracy: 0.3899\n",
      "Epoch 886/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5941 - accuracy: 0.4786 - val_loss: 2.6386 - val_accuracy: 0.3869\n",
      "Epoch 887/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6193 - accuracy: 0.4801 - val_loss: 2.6589 - val_accuracy: 0.3838\n",
      "Epoch 888/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6135 - accuracy: 0.4784 - val_loss: 2.6534 - val_accuracy: 0.3790\n",
      "Epoch 889/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6081 - accuracy: 0.4820 - val_loss: 2.6548 - val_accuracy: 0.3881\n",
      "Epoch 890/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4701 - val_loss: 2.6355 - val_accuracy: 0.3875\n",
      "Epoch 891/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6044 - accuracy: 0.4854 - val_loss: 2.6432 - val_accuracy: 0.3869\n",
      "Epoch 892/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6094 - accuracy: 0.4704 - val_loss: 2.6316 - val_accuracy: 0.3802\n",
      "Epoch 893/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6154 - accuracy: 0.4771 - val_loss: 2.6502 - val_accuracy: 0.3771\n",
      "Epoch 894/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6096 - accuracy: 0.4744 - val_loss: 2.6365 - val_accuracy: 0.3875\n",
      "Epoch 895/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6156 - accuracy: 0.4876 - val_loss: 2.6391 - val_accuracy: 0.3838\n",
      "Epoch 896/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5945 - accuracy: 0.4796 - val_loss: 2.6668 - val_accuracy: 0.3729\n",
      "Epoch 897/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5966 - accuracy: 0.4770 - val_loss: 2.6518 - val_accuracy: 0.3929\n",
      "Epoch 898/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5894 - accuracy: 0.4884 - val_loss: 2.6266 - val_accuracy: 0.3863\n",
      "Epoch 899/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5930 - accuracy: 0.4755 - val_loss: 2.6482 - val_accuracy: 0.3759\n",
      "Epoch 900/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6114 - accuracy: 0.4825 - val_loss: 2.6763 - val_accuracy: 0.3704\n",
      "Epoch 901/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5874 - accuracy: 0.4768 - val_loss: 2.6336 - val_accuracy: 0.3911\n",
      "Epoch 902/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4820 - val_loss: 2.6194 - val_accuracy: 0.3917\n",
      "Epoch 903/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6110 - accuracy: 0.4748 - val_loss: 2.6551 - val_accuracy: 0.3838\n",
      "Epoch 904/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5890 - accuracy: 0.4852 - val_loss: 2.6599 - val_accuracy: 0.3881\n",
      "Epoch 905/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5921 - accuracy: 0.4801 - val_loss: 2.6664 - val_accuracy: 0.3844\n",
      "Epoch 906/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6153 - accuracy: 0.4713 - val_loss: 2.6529 - val_accuracy: 0.3808\n",
      "Epoch 907/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5960 - accuracy: 0.4819 - val_loss: 2.6676 - val_accuracy: 0.3796\n",
      "Epoch 908/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5904 - accuracy: 0.4941 - val_loss: 2.6474 - val_accuracy: 0.3875\n",
      "Epoch 909/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5806 - accuracy: 0.4864 - val_loss: 2.6361 - val_accuracy: 0.3929\n",
      "Epoch 910/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6100 - accuracy: 0.4798 - val_loss: 2.6642 - val_accuracy: 0.3759\n",
      "Epoch 911/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5963 - accuracy: 0.4883 - val_loss: 2.6455 - val_accuracy: 0.3929\n",
      "Epoch 912/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5963 - accuracy: 0.4843 - val_loss: 2.6440 - val_accuracy: 0.3911\n",
      "Epoch 913/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5892 - accuracy: 0.4871 - val_loss: 2.6371 - val_accuracy: 0.3923\n",
      "Epoch 914/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5981 - accuracy: 0.4836 - val_loss: 2.6674 - val_accuracy: 0.3875\n",
      "Epoch 915/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6136 - accuracy: 0.4765 - val_loss: 2.6526 - val_accuracy: 0.3899\n",
      "Epoch 916/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6014 - accuracy: 0.4808 - val_loss: 2.6692 - val_accuracy: 0.3844\n",
      "Epoch 917/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5932 - accuracy: 0.4809 - val_loss: 2.6546 - val_accuracy: 0.3936\n",
      "Epoch 918/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5949 - accuracy: 0.4779 - val_loss: 2.6471 - val_accuracy: 0.3929\n",
      "Epoch 919/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5740 - accuracy: 0.4883 - val_loss: 2.6577 - val_accuracy: 0.3881\n",
      "Epoch 920/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5802 - accuracy: 0.4914 - val_loss: 2.6241 - val_accuracy: 0.3936\n",
      "Epoch 921/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5918 - accuracy: 0.4825 - val_loss: 2.6380 - val_accuracy: 0.3942\n",
      "Epoch 922/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6003 - accuracy: 0.4793 - val_loss: 2.6365 - val_accuracy: 0.3911\n",
      "Epoch 923/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5782 - accuracy: 0.4945 - val_loss: 2.6612 - val_accuracy: 0.3747\n",
      "Epoch 924/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5849 - accuracy: 0.4841 - val_loss: 2.6307 - val_accuracy: 0.3990\n",
      "Epoch 925/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6105 - accuracy: 0.4814 - val_loss: 2.6510 - val_accuracy: 0.3771\n",
      "Epoch 926/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5874 - accuracy: 0.4861 - val_loss: 2.6397 - val_accuracy: 0.3966\n",
      "Epoch 927/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6026 - accuracy: 0.4817 - val_loss: 2.6624 - val_accuracy: 0.3893\n",
      "Epoch 928/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6079 - accuracy: 0.4802 - val_loss: 2.6376 - val_accuracy: 0.3923\n",
      "Epoch 929/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6118 - accuracy: 0.4765 - val_loss: 2.6379 - val_accuracy: 0.3936\n",
      "Epoch 930/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5807 - accuracy: 0.4910 - val_loss: 2.6506 - val_accuracy: 0.3856\n",
      "Epoch 931/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5976 - accuracy: 0.4831 - val_loss: 2.6492 - val_accuracy: 0.3869\n",
      "Epoch 932/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5917 - accuracy: 0.4805 - val_loss: 2.6298 - val_accuracy: 0.3923\n",
      "Epoch 933/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5999 - accuracy: 0.4774 - val_loss: 2.6587 - val_accuracy: 0.3936\n",
      "Epoch 934/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6151 - accuracy: 0.4836 - val_loss: 2.6714 - val_accuracy: 0.3747\n",
      "Epoch 935/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5874 - accuracy: 0.4829 - val_loss: 2.6405 - val_accuracy: 0.3942\n",
      "Epoch 936/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5841 - accuracy: 0.4945 - val_loss: 2.6633 - val_accuracy: 0.3631\n",
      "Epoch 937/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6069 - accuracy: 0.4818 - val_loss: 2.6520 - val_accuracy: 0.3838\n",
      "Epoch 938/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5710 - accuracy: 0.4910 - val_loss: 2.6651 - val_accuracy: 0.3783\n",
      "Epoch 939/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5839 - accuracy: 0.4837 - val_loss: 2.6379 - val_accuracy: 0.3863\n",
      "Epoch 940/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6042 - accuracy: 0.4818 - val_loss: 2.6707 - val_accuracy: 0.3753\n",
      "Epoch 941/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5928 - accuracy: 0.4810 - val_loss: 2.6480 - val_accuracy: 0.3856\n",
      "Epoch 942/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5973 - accuracy: 0.4850 - val_loss: 2.6621 - val_accuracy: 0.3923\n",
      "Epoch 943/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5960 - accuracy: 0.4793 - val_loss: 2.6542 - val_accuracy: 0.3905\n",
      "Epoch 944/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5822 - accuracy: 0.4950 - val_loss: 2.6670 - val_accuracy: 0.3881\n",
      "Epoch 945/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5957 - accuracy: 0.4778 - val_loss: 2.6253 - val_accuracy: 0.3875\n",
      "Epoch 946/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5929 - accuracy: 0.4880 - val_loss: 2.6511 - val_accuracy: 0.3899\n",
      "Epoch 947/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6025 - accuracy: 0.4807 - val_loss: 2.6607 - val_accuracy: 0.3856\n",
      "Epoch 948/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6108 - accuracy: 0.4870 - val_loss: 2.6598 - val_accuracy: 0.3838\n",
      "Epoch 949/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5910 - accuracy: 0.4837 - val_loss: 2.6650 - val_accuracy: 0.3771\n",
      "Epoch 950/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5967 - accuracy: 0.4777 - val_loss: 2.6713 - val_accuracy: 0.3814\n",
      "Epoch 951/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5928 - accuracy: 0.4787 - val_loss: 2.6924 - val_accuracy: 0.3820\n",
      "Epoch 952/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5875 - accuracy: 0.4899 - val_loss: 2.6598 - val_accuracy: 0.3856\n",
      "Epoch 953/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6066 - accuracy: 0.4870 - val_loss: 2.6646 - val_accuracy: 0.3863\n",
      "Epoch 954/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6029 - accuracy: 0.4794 - val_loss: 2.6590 - val_accuracy: 0.3869\n",
      "Epoch 955/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5949 - accuracy: 0.4858 - val_loss: 2.6758 - val_accuracy: 0.3717\n",
      "Epoch 956/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5867 - accuracy: 0.4869 - val_loss: 2.6652 - val_accuracy: 0.3905\n",
      "Epoch 957/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6041 - accuracy: 0.4770 - val_loss: 2.6255 - val_accuracy: 0.3990\n",
      "Epoch 958/1000\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 1.6014 - accuracy: 0.4739 - val_loss: 2.6460 - val_accuracy: 0.3820\n",
      "Epoch 959/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5984 - accuracy: 0.4863 - val_loss: 2.6333 - val_accuracy: 0.3887\n",
      "Epoch 960/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5758 - accuracy: 0.4810 - val_loss: 2.6597 - val_accuracy: 0.3808\n",
      "Epoch 961/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5691 - accuracy: 0.4873 - val_loss: 2.6440 - val_accuracy: 0.3796\n",
      "Epoch 962/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6043 - accuracy: 0.4727 - val_loss: 2.6387 - val_accuracy: 0.3826\n",
      "Epoch 963/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5640 - accuracy: 0.4986 - val_loss: 2.6662 - val_accuracy: 0.3698\n",
      "Epoch 964/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6130 - accuracy: 0.4801 - val_loss: 2.6236 - val_accuracy: 0.3923\n",
      "Epoch 965/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5819 - accuracy: 0.4905 - val_loss: 2.6613 - val_accuracy: 0.3777\n",
      "Epoch 966/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5968 - accuracy: 0.4772 - val_loss: 2.6543 - val_accuracy: 0.3765\n",
      "Epoch 967/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5996 - accuracy: 0.4747 - val_loss: 2.6201 - val_accuracy: 0.3929\n",
      "Epoch 968/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5771 - accuracy: 0.4933 - val_loss: 2.6692 - val_accuracy: 0.3723\n",
      "Epoch 969/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5968 - accuracy: 0.4760 - val_loss: 2.6468 - val_accuracy: 0.3832\n",
      "Epoch 970/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5794 - accuracy: 0.4874 - val_loss: 2.6786 - val_accuracy: 0.3692\n",
      "Epoch 971/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5976 - accuracy: 0.4881 - val_loss: 2.6335 - val_accuracy: 0.3905\n",
      "Epoch 972/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5878 - accuracy: 0.4854 - val_loss: 2.6511 - val_accuracy: 0.3808\n",
      "Epoch 973/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6187 - accuracy: 0.4666 - val_loss: 2.6316 - val_accuracy: 0.3917\n",
      "Epoch 974/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6025 - accuracy: 0.4784 - val_loss: 2.6443 - val_accuracy: 0.3747\n",
      "Epoch 975/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5965 - accuracy: 0.4846 - val_loss: 2.6682 - val_accuracy: 0.3644\n",
      "Epoch 976/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6070 - accuracy: 0.4761 - val_loss: 2.6511 - val_accuracy: 0.3881\n",
      "Epoch 977/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5902 - accuracy: 0.4924 - val_loss: 2.6515 - val_accuracy: 0.3893\n",
      "Epoch 978/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5778 - accuracy: 0.4900 - val_loss: 2.6629 - val_accuracy: 0.3887\n",
      "Epoch 979/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5901 - accuracy: 0.4810 - val_loss: 2.6629 - val_accuracy: 0.3887\n",
      "Epoch 980/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5865 - accuracy: 0.4826 - val_loss: 2.6420 - val_accuracy: 0.3917\n",
      "Epoch 981/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5923 - accuracy: 0.4807 - val_loss: 2.6615 - val_accuracy: 0.3856\n",
      "Epoch 982/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5722 - accuracy: 0.4876 - val_loss: 2.6445 - val_accuracy: 0.3899\n",
      "Epoch 983/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6016 - accuracy: 0.4847 - val_loss: 2.6264 - val_accuracy: 0.3966\n",
      "Epoch 984/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5758 - accuracy: 0.4898 - val_loss: 2.6265 - val_accuracy: 0.3942\n",
      "Epoch 985/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5929 - accuracy: 0.4850 - val_loss: 2.6771 - val_accuracy: 0.3790\n",
      "Epoch 986/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5713 - accuracy: 0.4951 - val_loss: 2.6647 - val_accuracy: 0.3844\n",
      "Epoch 987/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5914 - accuracy: 0.4896 - val_loss: 2.6732 - val_accuracy: 0.3844\n",
      "Epoch 988/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5852 - accuracy: 0.4795 - val_loss: 2.6570 - val_accuracy: 0.3917\n",
      "Epoch 989/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5896 - accuracy: 0.4929 - val_loss: 2.6795 - val_accuracy: 0.3765\n",
      "Epoch 990/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5982 - accuracy: 0.4867 - val_loss: 2.6552 - val_accuracy: 0.3717\n",
      "Epoch 991/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6047 - accuracy: 0.4764 - val_loss: 2.6530 - val_accuracy: 0.3923\n",
      "Epoch 992/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5890 - accuracy: 0.4877 - val_loss: 2.6345 - val_accuracy: 0.3887\n",
      "Epoch 993/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5816 - accuracy: 0.4917 - val_loss: 2.6678 - val_accuracy: 0.3765\n",
      "Epoch 994/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6055 - accuracy: 0.4899 - val_loss: 2.6352 - val_accuracy: 0.4075\n",
      "Epoch 995/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5989 - accuracy: 0.4823 - val_loss: 2.6807 - val_accuracy: 0.3759\n",
      "Epoch 996/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5709 - accuracy: 0.4907 - val_loss: 2.6424 - val_accuracy: 0.3832\n",
      "Epoch 997/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5949 - accuracy: 0.4848 - val_loss: 2.6549 - val_accuracy: 0.3802\n",
      "Epoch 998/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5992 - accuracy: 0.4906 - val_loss: 2.6479 - val_accuracy: 0.3747\n",
      "Epoch 999/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.6006 - accuracy: 0.4871 - val_loss: 2.6535 - val_accuracy: 0.3729\n",
      "Epoch 1000/1000\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.5949 - accuracy: 0.4777 - val_loss: 2.6608 - val_accuracy: 0.3814\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model (batch size 16)\n",
    "history_emb_complex = Emb_model_complex.fit(x_emb_train, y_emb_train,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=16,\n",
    "                                 validation_data=(x_emb_test, y_emb_test)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file_emb_complex = \"many_to_many_LSTM_Emb_complex_model.h5\"  \n",
    "Emb_model_complex.save(model_file_emb_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_Emb_complex_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_complex.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 36 (Val Accuracy: 0.4604623019695282)\n",
      "Best Epoch for Training Accuracy: 994 (Train Accuracy: 0.49011558294296265)\n",
      "Best Epoch for Training Loss: 968 (Train Loss: 1.5816971063613892)\n",
      "Best Epoch for Validation Loss: 33 (Val Loss: 2.185821056365967)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.4604623019695282\n",
      "Maximum Training Accuracy: 0.49011558294296265\n",
      "Minimum Training Loss: 1.5816971063613892\n",
      "Minimum Validation Loss: 2.185821056365967\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_complex, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.3467153284671533\n",
      "Accuracy for Label barrel_turn: 0.0\n",
      "Accuracy for Label basic_charleston: nan\n",
      "Accuracy for Label basic_closed: 0.40559440559440557\n",
      "Accuracy for Label basic_open: 0.0\n",
      "Accuracy for Label break: 0.09433962264150944\n",
      "Accuracy for Label come_back: 0.0\n",
      "Accuracy for Label corridor: 0.0\n",
      "Accuracy for Label frankie´s_points: nan\n",
      "Accuracy for Label frankie´s_sixes: 0.07317073170731707\n",
      "Accuracy for Label groove_walk: 0.0\n",
      "Accuracy for Label hallelujah_rocks: 0.0\n",
      "Accuracy for Label hand_to_hand: 0.0\n",
      "Accuracy for Label hand_to_hand_charleston: nan\n",
      "Accuracy for Label inside_spin: 0.0\n",
      "Accuracy for Label inside_turn: 0.0\n",
      "Accuracy for Label lindy_circle: 0.0\n",
      "Accuracy for Label mini_dip: nan\n",
      "Accuracy for Label outside_spin: 0.025\n",
      "Accuracy for Label outside_turn: 0.0\n",
      "Accuracy for Label pass_by: 0.6753846153846154\n",
      "Accuracy for Label pop_turn: 0.0\n",
      "Accuracy for Label promenade: 0.08333333333333333\n",
      "Accuracy for Label s_turn: 0.0\n",
      "Accuracy for Label sailor_kicks: 0.0\n",
      "Accuracy for Label send_out: 0.0\n",
      "Accuracy for Label sling_shot: 0.0\n",
      "Accuracy for Label sugar_push: 0.0625\n",
      "Accuracy for Label sweetheart: 0.018518518518518517\n",
      "Accuracy for Label swingout: 0.17177914110429449\n",
      "Accuracy for Label switches: 0.0\n",
      "Accuracy for Label tandem: 0.0\n",
      "Accuracy for Label tuck_turn: 0.26595744680851063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Predict labels on the test data\n",
    "predictions = Emb_model_complex.predict(x_emb_test)\n",
    "\n",
    "# Convert one-hot encoded predictions to single labels using TensorFlow's argmax\n",
    "predicted_labels_encoded = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Flatten the arrays for label-wise accuracy calculation\n",
    "predicted_labels_encoded = predicted_labels_encoded.flatten()\n",
    "\n",
    "# Convert one-hot encoded true labels to single labels using TensorFlow's argmax\n",
    "true_labels_encoded = tf.argmax(yy_test, axis=-1).numpy().flatten()\n",
    "\n",
    "# Map predicted labels to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "# Map true labels to original labels\n",
    "true_labels = label_encoder.inverse_transform(true_labels_encoded)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Display label-wise accuracy\n",
    "unique_labels = label_encoder.classes_\n",
    "for label in unique_labels:\n",
    "    label_indices = true_labels == label\n",
    "    label_accuracy = accuracy_score(true_labels[label_indices], predicted_labels[label_indices])\n",
    "    print(f'Accuracy for Label {label}: {label_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chains: generating new sequences based on the transition probabilities observed in the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get transition probabilities between moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Original sequences of dance moves\n",
    "lists_extracted\n",
    "\n",
    "# Train a Markov Chain\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sequence in lists_extracted:\n",
    "    for i in range(len(sequence) - 1):\n",
    "        current_move = sequence[i]\n",
    "        next_move = sequence[i + 1]\n",
    "        transition_counts[current_move][next_move] += 1\n",
    "\n",
    "# Convert counts to probabilities\n",
    "transition_probabilities = defaultdict(dict)\n",
    "for current_move, next_moves in transition_counts.items():\n",
    "    total = sum(next_moves.values())\n",
    "    for next_move, count in next_moves.items():\n",
    "        transition_probabilities[current_move][next_move] = count / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'groove_walk': {'swingout': 0.16326530612244897,\n",
       "              'basic_closed': 0.22448979591836735,\n",
       "              'come_back': 0.08163265306122448,\n",
       "              'lindy_circle': 0.04081632653061224,\n",
       "              'break': 0.061224489795918366,\n",
       "              'tuck_turn': 0.1836734693877551,\n",
       "              'pass_by': 0.14285714285714285,\n",
       "              'inside_spin': 0.02040816326530612,\n",
       "              'corridor': 0.02040816326530612,\n",
       "              'sweetheart': 0.02040816326530612,\n",
       "              'send_out': 0.02040816326530612,\n",
       "              'sugar_push': 0.02040816326530612},\n",
       "             'swingout': {'swingout': 0.4216417910447761,\n",
       "              'lindy_circle': 0.1455223880597015,\n",
       "              'pass_by': 0.21641791044776118,\n",
       "              'come_back': 0.06343283582089553,\n",
       "              'switches': 0.018656716417910446,\n",
       "              'frankie´s_points': 0.0037313432835820895,\n",
       "              'sugar_push': 0.007462686567164179,\n",
       "              'tuck_turn': 0.0037313432835820895,\n",
       "              'outside_turn': 0.018656716417910446,\n",
       "              'hand_to_hand': 0.0037313432835820895,\n",
       "              'outside_spin': 0.007462686567164179,\n",
       "              'break': 0.05223880597014925,\n",
       "              'send_out': 0.007462686567164179,\n",
       "              'basic_closed': 0.011194029850746268,\n",
       "              'corridor': 0.007462686567164179,\n",
       "              'inside_turn': 0.011194029850746268},\n",
       "             'lindy_circle': {'basic_closed': 0.12962962962962962,\n",
       "              'tuck_turn': 0.4444444444444444,\n",
       "              'send_out': 0.07407407407407407,\n",
       "              'swingout': 0.14814814814814814,\n",
       "              'inside_turn': 0.046296296296296294,\n",
       "              'pass_by': 0.009259259259259259,\n",
       "              'groove_walk': 0.027777777777777776,\n",
       "              'inside_spin': 0.009259259259259259,\n",
       "              'promenade': 0.027777777777777776,\n",
       "              'corridor': 0.009259259259259259,\n",
       "              'break': 0.06481481481481481,\n",
       "              'pop_turn': 0.009259259259259259},\n",
       "             'basic_closed': {'tuck_turn': 0.36075949367088606,\n",
       "              'swingout': 0.08227848101265822,\n",
       "              'send_out': 0.12658227848101267,\n",
       "              'basic_closed': 0.25316455696202533,\n",
       "              'promenade': 0.06329113924050633,\n",
       "              'groove_walk': 0.0189873417721519,\n",
       "              'break': 0.0379746835443038,\n",
       "              'outside_spin': 0.006329113924050633,\n",
       "              'lindy_circle': 0.0189873417721519,\n",
       "              'corridor': 0.0189873417721519,\n",
       "              'pass_by': 0.006329113924050633,\n",
       "              'pop_turn': 0.006329113924050633},\n",
       "             'tuck_turn': {'pass_by': 0.6666666666666666,\n",
       "              'basic_closed': 0.023391812865497075,\n",
       "              'outside_spin': 0.1111111111111111,\n",
       "              'tuck_turn': 0.005847953216374269,\n",
       "              'sugar_push': 0.04093567251461988,\n",
       "              'come_back': 0.023391812865497075,\n",
       "              'sweetheart': 0.017543859649122806,\n",
       "              'break': 0.05263157894736842,\n",
       "              'frankie´s_sixes': 0.017543859649122806,\n",
       "              'lindy_circle': 0.005847953216374269,\n",
       "              'switches': 0.005847953216374269,\n",
       "              'inside_turn': 0.005847953216374269,\n",
       "              'swingout': 0.011695906432748537,\n",
       "              'barrel_turn': 0.005847953216374269,\n",
       "              'outside_turn': 0.005847953216374269},\n",
       "             'pass_by': {'come_back': 0.14017341040462428,\n",
       "              'pass_by': 0.36416184971098264,\n",
       "              'sugar_push': 0.07658959537572255,\n",
       "              'outside_spin': 0.05057803468208093,\n",
       "              'swingout': 0.0953757225433526,\n",
       "              'lindy_circle': 0.05491329479768786,\n",
       "              'basic_open': 0.011560693641618497,\n",
       "              'sweetheart': 0.049132947976878616,\n",
       "              'inside_spin': 0.005780346820809248,\n",
       "              'frankie´s_sixes': 0.033236994219653176,\n",
       "              'hand_to_hand': 0.0072254335260115606,\n",
       "              'break': 0.06647398843930635,\n",
       "              'sling_shot': 0.002890173410404624,\n",
       "              'barrel_turn': 0.015895953757225433,\n",
       "              'basic_closed': 0.001445086705202312,\n",
       "              'groove_walk': 0.002890173410404624,\n",
       "              'mini_dip': 0.002890173410404624,\n",
       "              'outside_turn': 0.004335260115606936,\n",
       "              'tuck_turn': 0.002890173410404624,\n",
       "              'inside_turn': 0.002890173410404624,\n",
       "              'sailor_kicks': 0.004335260115606936,\n",
       "              'switches': 0.002890173410404624,\n",
       "              'hallelujah_rocks': 0.001445086705202312},\n",
       "             'come_back': {'basic_closed': 0.42857142857142855,\n",
       "              'swingout': 0.14285714285714285,\n",
       "              'tuck_turn': 0.17857142857142858,\n",
       "              'send_out': 0.07738095238095238,\n",
       "              'break': 0.05952380952380952,\n",
       "              'groove_walk': 0.05357142857142857,\n",
       "              'promenade': 0.02976190476190476,\n",
       "              'outside_turn': 0.011904761904761904,\n",
       "              'basic_charleston': 0.005952380952380952,\n",
       "              'corridor': 0.011904761904761904},\n",
       "             'sugar_push': {'pass_by': 0.5056179775280899,\n",
       "              'come_back': 0.0449438202247191,\n",
       "              'sweetheart': 0.11235955056179775,\n",
       "              'basic_open': 0.011235955056179775,\n",
       "              'sugar_push': 0.14606741573033707,\n",
       "              'tuck_turn': 0.0449438202247191,\n",
       "              'inside_turn': 0.011235955056179775,\n",
       "              'swingout': 0.06741573033707865,\n",
       "              'sailor_kicks': 0.011235955056179775,\n",
       "              's_turn': 0.011235955056179775,\n",
       "              'outside_spin': 0.011235955056179775,\n",
       "              'sling_shot': 0.011235955056179775,\n",
       "              'frankie´s_sixes': 0.011235955056179775},\n",
       "             'outside_spin': {'pass_by': 0.6060606060606061,\n",
       "              'come_back': 0.16666666666666666,\n",
       "              'corridor': 0.015151515151515152,\n",
       "              'sugar_push': 0.030303030303030304,\n",
       "              'lindy_circle': 0.015151515151515152,\n",
       "              'break': 0.06060606060606061,\n",
       "              'outside_spin': 0.015151515151515152,\n",
       "              'barrel_turn': 0.030303030303030304,\n",
       "              'frankie´s_sixes': 0.030303030303030304,\n",
       "              'outside_turn': 0.015151515151515152,\n",
       "              'sweetheart': 0.015151515151515152},\n",
       "             'send_out': {'pass_by': 0.5,\n",
       "              'swingout': 0.07692307692307693,\n",
       "              'sugar_push': 0.11538461538461539,\n",
       "              'frankie´s_sixes': 0.019230769230769232,\n",
       "              'break': 0.21153846153846154,\n",
       "              'outside_spin': 0.038461538461538464,\n",
       "              'come_back': 0.019230769230769232,\n",
       "              'sailor_kicks': 0.019230769230769232},\n",
       "             'basic_open': {'swingout': 0.2727272727272727,\n",
       "              'basic_open': 0.09090909090909091,\n",
       "              'lindy_circle': 0.09090909090909091,\n",
       "              'pass_by': 0.36363636363636365,\n",
       "              'break': 0.18181818181818182},\n",
       "             'corridor': {'swingout': 0.3,\n",
       "              'inside_spin': 0.1,\n",
       "              'hand_to_hand_charleston': 0.1,\n",
       "              'basic_closed': 0.1,\n",
       "              'pass_by': 0.3,\n",
       "              'tuck_turn': 0.1},\n",
       "             'sweetheart': {'pass_by': 0.6428571428571429,\n",
       "              'frankie´s_sixes': 0.03571428571428571,\n",
       "              'come_back': 0.08928571428571429,\n",
       "              'sweetheart': 0.017857142857142856,\n",
       "              'outside_turn': 0.017857142857142856,\n",
       "              'inside_spin': 0.017857142857142856,\n",
       "              'barrel_turn': 0.05357142857142857,\n",
       "              'outside_spin': 0.03571428571428571,\n",
       "              'break': 0.03571428571428571,\n",
       "              'inside_turn': 0.017857142857142856,\n",
       "              'lindy_circle': 0.017857142857142856,\n",
       "              'groove_walk': 0.017857142857142856},\n",
       "             'inside_spin': {'lindy_circle': 0.2857142857142857,\n",
       "              'come_back': 0.42857142857142855,\n",
       "              'outside_turn': 0.14285714285714285,\n",
       "              'pass_by': 0.14285714285714285},\n",
       "             'promenade': {'tuck_turn': 0.5263157894736842,\n",
       "              'groove_walk': 0.15789473684210525,\n",
       "              'promenade': 0.10526315789473684,\n",
       "              'send_out': 0.10526315789473684,\n",
       "              'swingout': 0.05263157894736842,\n",
       "              'basic_closed': 0.05263157894736842},\n",
       "             'frankie´s_sixes': {'come_back': 0.15151515151515152,\n",
       "              'pass_by': 0.5757575757575758,\n",
       "              'hallelujah_rocks': 0.030303030303030304,\n",
       "              'sugar_push': 0.030303030303030304,\n",
       "              'basic_closed': 0.030303030303030304,\n",
       "              'basic_open': 0.030303030303030304,\n",
       "              'lindy_circle': 0.030303030303030304,\n",
       "              'swingout': 0.030303030303030304,\n",
       "              'break': 0.030303030303030304,\n",
       "              'barrel_turn': 0.030303030303030304,\n",
       "              'corridor': 0.030303030303030304},\n",
       "             'switches': {'come_back': 0.1111111111111111,\n",
       "              'pass_by': 0.4444444444444444,\n",
       "              'swingout': 0.1111111111111111,\n",
       "              'lindy_circle': 0.3333333333333333},\n",
       "             'hand_to_hand': {'pass_by': 0.7142857142857143,\n",
       "              'inside_turn': 0.2857142857142857},\n",
       "             'hallelujah_rocks': {'come_back': 0.5, 'break': 0.5},\n",
       "             'break': {'come_back': 0.09836065573770492,\n",
       "              'pass_by': 0.4672131147540984,\n",
       "              'basic_closed': 0.04918032786885246,\n",
       "              'outside_turn': 0.02459016393442623,\n",
       "              'sweetheart': 0.01639344262295082,\n",
       "              'lindy_circle': 0.10655737704918032,\n",
       "              'barrel_turn': 0.02459016393442623,\n",
       "              'swingout': 0.040983606557377046,\n",
       "              'tuck_turn': 0.06557377049180328,\n",
       "              'send_out': 0.04918032786885246,\n",
       "              'switches': 0.00819672131147541,\n",
       "              'outside_spin': 0.01639344262295082,\n",
       "              'inside_turn': 0.02459016393442623,\n",
       "              'promenade': 0.00819672131147541},\n",
       "             'frankie´s_points': {'come_back': 1.0},\n",
       "             'inside_turn': {'pass_by': 0.2857142857142857,\n",
       "              'sugar_push': 0.09523809523809523,\n",
       "              'hand_to_hand': 0.047619047619047616,\n",
       "              'lindy_circle': 0.047619047619047616,\n",
       "              'frankie´s_sixes': 0.047619047619047616,\n",
       "              'come_back': 0.09523809523809523,\n",
       "              'swingout': 0.09523809523809523,\n",
       "              'basic_closed': 0.047619047619047616,\n",
       "              'tuck_turn': 0.047619047619047616,\n",
       "              'inside_turn': 0.14285714285714285,\n",
       "              'barrel_turn': 0.047619047619047616},\n",
       "             'outside_turn': {'lindy_circle': 0.10526315789473684,\n",
       "              'pass_by': 0.631578947368421,\n",
       "              'sweetheart': 0.05263157894736842,\n",
       "              'basic_closed': 0.05263157894736842,\n",
       "              'sugar_push': 0.10526315789473684,\n",
       "              'outside_spin': 0.05263157894736842},\n",
       "             'sling_shot': {'lindy_circle': 0.25,\n",
       "              'pass_by': 0.5,\n",
       "              'sling_shot': 0.25},\n",
       "             'barrel_turn': {'lindy_circle': 0.08695652173913043,\n",
       "              'outside_turn': 0.08695652173913043,\n",
       "              'break': 0.34782608695652173,\n",
       "              'swingout': 0.08695652173913043,\n",
       "              'sweetheart': 0.17391304347826086,\n",
       "              'pass_by': 0.13043478260869565,\n",
       "              'come_back': 0.043478260869565216,\n",
       "              'outside_spin': 0.043478260869565216},\n",
       "             'basic_charleston': {'tuck_turn': 1.0},\n",
       "             'hand_to_hand_charleston': {'frankie´s_sixes': 1.0},\n",
       "             'pop_turn': {'frankie´s_sixes': 1.0},\n",
       "             'mini_dip': {'pass_by': 0.5, 'come_back': 0.5},\n",
       "             'sailor_kicks': {'pass_by': 0.8, 'barrel_turn': 0.2},\n",
       "             's_turn': {'tandem': 1.0},\n",
       "             'tandem': {'tandem': 0.5, 'break': 0.5}})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate new sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 41 new dance sequences\n",
    "\n",
    "A function with some restrictions is created to augment the dance sequences data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating sequences with restrictive rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of repetition rules\n",
    "\n",
    "# Moves that can only be repeated once\n",
    "repeat_once_moves= {'come_back', 'frankie´s_sixes', 'hand_to_hand', 'hand_to_hand_charleston', 'mini_dip', 's_turn', 'send_out', 'tuck_turn', 'switches', 'sweetheart', 'pop_turn', 'corridor', 'break'}  \n",
    "# Maximum repeats for all other moves\n",
    "max_repeats = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moves that should not be followed by specific moves\n",
    "restricted_combinations = {\n",
    "    'sugar_push': {'tuck_turn'},\n",
    "    'pass_by': {'tuck_turn'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(start_move, min_length, max_length, transition_probabilities, repeat_once_moves, max_repeats=2):\n",
    "    sequence_length = random.randint(min_length, max_length)\n",
    "    sequence = [start_move]\n",
    "    current_move = start_move\n",
    "    move_counts = {current_move: 1}\n",
    "\n",
    "    for _ in range(sequence_length - 1):\n",
    "        next_moves = transition_probabilities.get(current_move, {})\n",
    "\n",
    "        # Apply repetition and combination rules\n",
    "        next_moves_filtered = {}\n",
    "        total_prob = 0\n",
    "        for move, prob in next_moves.items():\n",
    "            count = move_counts.get(move, 0)\n",
    "            valid_for_repetition = (move in repeat_once_moves and count < 1) or (move not in repeat_once_moves and count < max_repeats)\n",
    "            valid_for_combination = move not in restricted_combinations.get(current_move, {})\n",
    "            if valid_for_repetition and valid_for_combination:\n",
    "                next_moves_filtered[move] = prob\n",
    "                total_prob += prob\n",
    "\n",
    "        # Adjusting rules for min_length\n",
    "        if not next_moves_filtered and len(sequence) < min_length:\n",
    "            next_moves_filtered = {move: prob for move, prob in next_moves.items() if move_counts.get(move, 0) < max_repeats}\n",
    "            total_prob = sum(next_moves_filtered.values())\n",
    "\n",
    "        # Re-normalize probabilities\n",
    "        if total_prob > 0:\n",
    "            for move in next_moves_filtered:\n",
    "                next_moves_filtered[move] /= total_prob\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # Select the next move\n",
    "        if next_moves_filtered:\n",
    "            next_move = np.random.choice(list(next_moves_filtered.keys()), p=list(next_moves_filtered.values()))\n",
    "            sequence.append(next_move)\n",
    "            move_counts[next_move] = move_counts.get(next_move, 0) + 1\n",
    "            current_move = next_move\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1: ['switches', 'lindy_circle', 'send_out', 'break', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'lindy_circle', 'basic_closed', 'basic_closed', 'swingout', 'swingout', 'inside_turn', 'inside_turn', 'sugar_push', 'sweetheart', 'outside_spin', 'outside_spin', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'groove_walk', 'inside_spin', 'outside_turn', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'sweetheart', 'barrel_turn', 'break', 'promenade', 'groove_walk', 'inside_spin']\n",
      "Sequence 2: ['sweetheart', 'pass_by', 'come_back', 'basic_closed', 'swingout', 'swingout', 'corridor', 'pass_by', 'outside_spin', 'frankie´s_sixes', 'break', 'lindy_circle', 'tuck_turn', 'outside_spin', 'lindy_circle', 'promenade', 'groove_walk', 'basic_closed', 'groove_walk', 'sugar_push', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'send_out', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn']\n",
      "Sequence 3: ['sweetheart', 'pass_by', 'pass_by', 'break', 'swingout', 'swingout', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'outside_spin', 'barrel_turn', 'lindy_circle', 'promenade', 'groove_walk', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'lindy_circle', 'send_out', 'outside_spin', 'sugar_push', 'basic_open', 'basic_open', 'break', 'promenade', 'groove_walk', 'inside_spin', 'outside_turn', 'sweetheart', 'inside_spin', 'outside_turn']\n",
      "Sequence 4: ['hallelujah_rocks', 'break', 'send_out', 'pass_by', 'sweetheart', 'pass_by', 'lindy_circle', 'tuck_turn', 'outside_spin', 'come_back', 'basic_closed', 'swingout', 'swingout', 'outside_spin', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'lindy_circle', 'groove_walk', 'basic_closed', 'groove_walk', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'sweetheart', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'outside_turn']\n",
      "Sequence 5: ['frankie´s_sixes', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'send_out', 'break', 'pass_by', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'sugar_push', 'sugar_push', 'sweetheart', 'inside_spin', 'outside_turn', 'lindy_circle', 'promenade', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'groove_walk', 'inside_spin', 'outside_turn', 'outside_spin', 'barrel_turn', 'outside_spin', 'barrel_turn', 'break', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 6: ['groove_walk', 'basic_closed', 'send_out', 'break', 'pass_by', 'sailor_kicks', 'pass_by', 'come_back', 'groove_walk', 'sugar_push', 'sugar_push', 'swingout', 'swingout', 'corridor', 'tuck_turn', 'switches', 'lindy_circle', 'basic_closed', 'outside_spin', 'sweetheart', 'inside_spin', 'lindy_circle', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 7: ['swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'inside_turn', 'hand_to_hand', 'pass_by', 'frankie´s_sixes', 'corridor', 'basic_closed', 'send_out', 'outside_spin', 'sugar_push', 'sugar_push', 'outside_spin', 'come_back', 'groove_walk', 'basic_closed', 'lindy_circle', 'promenade', 'promenade', 'groove_walk', 'break', 'inside_turn', 'barrel_turn', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn', 'sweetheart', 'inside_spin', 'come_back', 'basic_charleston', 'tuck_turn', 'switches']\n",
      "Sequence 8: ['corridor', 'tuck_turn', 'pass_by', 'break', 'basic_closed', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'swingout', 'lindy_circle', 'swingout', 'lindy_circle', 'groove_walk', 'inside_spin', 'outside_turn', 'outside_spin', 'outside_spin', 'sugar_push', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'outside_turn', 'sweetheart', 'frankie´s_sixes', 'basic_open', 'basic_open']\n",
      "Sequence 9: ['barrel_turn', 'lindy_circle', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'basic_open', 'break', 'basic_closed', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'come_back', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'basic_open', 'break', 'barrel_turn', 'sweetheart', 'outside_spin', 'outside_spin', 'outside_turn', 'sweetheart', 'outside_turn']\n",
      "Sequence 10: ['inside_turn', 'tuck_turn', 'basic_closed', 'send_out', 'break', 'come_back', 'swingout', 'frankie´s_points', 'come_back', 'basic_closed', 'swingout', 'pass_by', 'frankie´s_sixes', 'pass_by', 'sugar_push', 'sweetheart', 'barrel_turn', 'lindy_circle', 'promenade', 'promenade', 'groove_walk', 'lindy_circle', 'pop_turn', 'frankie´s_sixes', 'barrel_turn', 'outside_turn', 'outside_spin', 'outside_spin', 'sugar_push', 'sailor_kicks']\n",
      "Sequence 11: ['sugar_push', 'sweetheart', 'lindy_circle', 'tuck_turn', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'send_out', 'swingout', 'swingout', 'outside_turn', 'basic_closed', 'promenade', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'sugar_push', 'basic_open', 'basic_open', 'lindy_circle', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 12: ['switches', 'pass_by', 'pass_by', 'sweetheart', 'come_back', 'break', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'outside_spin', 'outside_spin', 'outside_turn', 'lindy_circle', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'basic_open', 'basic_open', 'break', 'basic_closed', 'promenade', 'groove_walk', 'corridor', 'inside_spin', 'outside_turn', 'sweetheart', 'barrel_turn', 'come_back', 'groove_walk', 'inside_spin']\n",
      "Sequence 13: ['inside_spin', 'pass_by', 'pass_by', 'sweetheart', 'inside_turn', 'frankie´s_sixes', 'come_back', 'basic_closed', 'tuck_turn', 'outside_spin', 'sugar_push', 'sugar_push', 'outside_spin', 'break', 'swingout', 'swingout', 'lindy_circle', 'send_out', 'sailor_kicks', 'barrel_turn', 'lindy_circle', 'basic_closed', 'groove_walk', 'inside_spin', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn']\n",
      "Sequence 14: ['sweetheart', 'lindy_circle', 'break', 'pass_by', 'frankie´s_sixes', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'outside_spin', 'barrel_turn', 'outside_turn', 'sugar_push', 'sugar_push', 'inside_turn', 'inside_turn', 'come_back', 'basic_closed', 'send_out', 'outside_spin', 'barrel_turn', 'outside_turn', 'basic_closed', 'groove_walk', 'corridor', 'inside_spin', 'come_back', 'groove_walk', 'inside_spin']\n",
      "Sequence 15: ['pass_by', 'barrel_turn', 'break', 'pass_by', 'lindy_circle', 'swingout', 'send_out', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'swingout', 'come_back', 'basic_closed', 'basic_closed', 'tuck_turn', 'sweetheart', 'groove_walk', 'lindy_circle', 'inside_turn', 'frankie´s_sixes', 'basic_open', 'basic_open', 'break', 'outside_turn', 'sugar_push', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 16: ['mini_dip', 'pass_by', 'pass_by', 'come_back', 'promenade', 'groove_walk', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'basic_closed', 'tuck_turn', 'frankie´s_sixes', 'break', 'lindy_circle', 'groove_walk', 'send_out', 'sugar_push', 'sugar_push', 'inside_turn', 'inside_turn', 'barrel_turn', 'outside_turn', 'sweetheart', 'outside_spin', 'barrel_turn', 'outside_spin', 'outside_turn', 'sweetheart', 'inside_spin', 'come_back', 'promenade', 'tuck_turn', 'switches']\n",
      "Sequence 17: ['come_back', 'swingout', 'swingout', 'pass_by', 'lindy_circle', 'basic_closed', 'tuck_turn', 'sweetheart', 'pass_by', 'outside_spin', 'sugar_push', 'sugar_push', 'inside_turn', 'barrel_turn', 'break', 'send_out', 'outside_spin', 'lindy_circle', 'basic_closed', 'groove_walk', 'inside_spin', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn']\n",
      "Sequence 18: ['inside_turn', 'swingout', 'pass_by', 'pass_by', 'sugar_push', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'swingout', 'lindy_circle', 'basic_closed', 'send_out', 'sailor_kicks', 'barrel_turn', 'sweetheart', 'barrel_turn', 'lindy_circle', 'tuck_turn', 'outside_spin', 'come_back', 'promenade', 'groove_walk', 'basic_closed', 'promenade', 'groove_walk', 'corridor', 'inside_spin', 'outside_turn', 'outside_spin', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'basic_charleston', 'tuck_turn', 'outside_turn', 'sweetheart', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 19: ['come_back', 'basic_closed', 'tuck_turn', 'sweetheart', 'pass_by', 'outside_spin', 'pass_by', 'sugar_push', 'sugar_push', 'swingout', 'lindy_circle', 'inside_turn', 'swingout', 'lindy_circle', 'promenade', 'groove_walk', 'basic_closed', 'send_out', 'break', 'switches', 'come_back', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'barrel_turn', 'outside_turn', 'outside_spin', 'barrel_turn', 'outside_turn', 'sweetheart', 'inside_spin']\n",
      "Sequence 20: ['pass_by', 'lindy_circle', 'tuck_turn', 'pass_by', 'come_back', 'promenade', 'promenade', 'send_out', 'break', 'lindy_circle', 'swingout', 'swingout', 'outside_turn', 'sugar_push', 'sugar_push', 'sweetheart', 'inside_spin', 'outside_turn', 'basic_closed', 'basic_closed', 'pop_turn', 'frankie´s_sixes', 'barrel_turn', 'outside_spin', 'barrel_turn', 'outside_spin', 'corridor', 'inside_spin', 'come_back', 'groove_walk', 'tuck_turn', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 21: ['hand_to_hand', 'inside_turn', 'basic_closed', 'basic_closed', 'send_out', 'pass_by', 'come_back', 'tuck_turn', 'outside_spin', 'barrel_turn', 'pass_by', 'swingout', 'lindy_circle', 'inside_spin', 'outside_turn', 'outside_spin', 'break', 'swingout', 'inside_turn', 'barrel_turn', 'lindy_circle', 'groove_walk', 'sugar_push', 'sugar_push', 'frankie´s_sixes', 'hallelujah_rocks', 'break', 'outside_turn', 'sweetheart', 'inside_spin', 'come_back', 'promenade', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks']\n",
      "Sequence 22: ['sugar_push', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'pass_by', 'swingout', 'swingout', 'break', 'outside_turn', 'sweetheart', 'lindy_circle', 'basic_closed', 'promenade', 'promenade', 'groove_walk', 'corridor', 'inside_spin', 'outside_turn', 'outside_spin', 'frankie´s_sixes', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'outside_spin', 'barrel_turn', 'sweetheart', 'inside_spin', 'come_back', 'groove_walk', 'break', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 23: ['basic_closed', 'basic_closed', 'tuck_turn', 'come_back', 'groove_walk', 'pass_by', 'pass_by', 'sugar_push', 'sugar_push', 'inside_turn', 'hand_to_hand', 'inside_turn', 'frankie´s_sixes', 'barrel_turn', 'break', 'lindy_circle', 'swingout', 'lindy_circle', 'swingout', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn', 'outside_spin', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks', 'break', 'send_out', 'outside_spin', 'come_back', 'promenade', 'groove_walk', 'inside_spin']\n",
      "Sequence 24: ['frankie´s_sixes', 'pass_by', 'pass_by', 'come_back', 'basic_closed', 'swingout', 'lindy_circle', 'tuck_turn', 'break', 'sweetheart', 'outside_spin', 'sugar_push', 'swingout', 'lindy_circle', 'basic_closed', 'promenade', 'promenade', 'send_out', 'sugar_push', 'outside_spin', 'barrel_turn', 'outside_turn', 'sweetheart', 'outside_turn']\n",
      "Sequence 25: ['s_turn', 'tandem', 'break', 'pass_by', 'pass_by', 'mini_dip', 'come_back', 'tuck_turn', 'sweetheart', 'inside_turn', 'basic_closed', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'lindy_circle', 'inside_turn', 'barrel_turn', 'outside_turn', 'lindy_circle', 'swingout', 'swingout', 'switches', 'come_back', 'promenade', 'groove_walk', 'corridor', 'inside_spin', 'outside_turn', 'outside_spin', 'frankie´s_sixes', 'hallelujah_rocks', 'break', 'outside_spin', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks']\n",
      "Sequence 26: ['outside_spin', 'pass_by', 'outside_spin', 'pass_by', 'sugar_push', 'sweetheart', 'groove_walk', 'swingout', 'swingout', 'lindy_circle', 'basic_closed', 'basic_closed', 'break', 'come_back', 'promenade', 'tuck_turn', 'sugar_push', 'sling_shot', 'sling_shot', 'lindy_circle', 'inside_turn', 'inside_turn', 'frankie´s_sixes', 'hallelujah_rocks', 'come_back', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'basic_open', 'basic_open', 'break', 'send_out', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'sweetheart', 'barrel_turn', 'outside_turn']\n",
      "Sequence 27: ['groove_walk', 'basic_closed', 'send_out', 'pass_by', 'outside_spin', 'pass_by', 'outside_spin', 'come_back', 'swingout', 'swingout', 'lindy_circle', 'promenade', 'basic_closed', 'tuck_turn', 'sugar_push', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'break', 'outside_turn', 'lindy_circle', 'promenade', 'groove_walk', 'sweetheart', 'inside_spin', 'outside_turn', 'sweetheart', 'inside_spin', 'come_back', 'basic_charleston', 'tuck_turn', 'barrel_turn', 'break', 'inside_turn', 'inside_turn', 'frankie´s_sixes', 'basic_open', 'basic_open']\n",
      "Sequence 28: ['basic_closed', 'swingout', 'swingout', 'pass_by', 'sweetheart', 'pass_by', 'break', 'tuck_turn', 'come_back', 'basic_closed', 'send_out', 'sailor_kicks', 'barrel_turn', 'lindy_circle', 'inside_spin', 'lindy_circle', 'inside_turn', 'sugar_push', 'frankie´s_sixes', 'sugar_push', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 29: ['lindy_circle', 'tuck_turn', 'sweetheart', 'pass_by', 'frankie´s_sixes', 'pass_by', 'basic_open', 'basic_open', 'break', 'barrel_turn', 'lindy_circle', 'basic_closed', 'send_out', 'sugar_push', 'sugar_push', 'come_back', 'groove_walk', 'basic_closed', 'swingout', 'swingout', 'switches', 'come_back', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'hallelujah_rocks', 'break', 'outside_spin', 'outside_turn', 'outside_spin', 'barrel_turn', 'outside_turn', 'sweetheart', 'inside_turn', 'hand_to_hand', 'inside_turn', 'tuck_turn', 'switches']\n",
      "Sequence 30: ['pop_turn', 'frankie´s_sixes', 'pass_by', 'come_back', 'tuck_turn', 'pass_by', 'sweetheart', 'groove_walk', 'swingout', 'swingout', 'send_out', 'sugar_push', 'sugar_push', 'sling_shot', 'sling_shot', 'lindy_circle', 'inside_turn', 'basic_closed', 'lindy_circle', 'inside_turn', 'basic_closed', 'promenade', 'promenade', 'groove_walk', 'inside_spin', 'outside_turn', 'outside_spin', 'break', 'barrel_turn', 'outside_spin', 'barrel_turn', 'outside_turn', 'sweetheart', 'inside_spin', 'come_back', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'basic_open', 'basic_open']\n",
      "Sequence 31: ['switches', 'lindy_circle', 'basic_closed', 'basic_closed', 'send_out', 'sugar_push', 'pass_by', 'pass_by', 'come_back', 'break', 'tuck_turn', 'outside_spin', 'outside_spin', 'frankie´s_sixes', 'sugar_push', 'sweetheart', 'inside_turn', 'inside_turn', 'swingout', 'swingout', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'barrel_turn', 'outside_turn', 'lindy_circle', 'promenade', 'promenade', 'groove_walk', 'inside_spin', 'outside_turn', 'sweetheart', 'barrel_turn', 'break', 'come_back', 'groove_walk', 'inside_spin']\n",
      "Sequence 32: ['basic_closed', 'send_out', 'frankie´s_sixes', 'pass_by', 'lindy_circle', 'basic_closed', 'groove_walk', 'tuck_turn', 'outside_spin', 'pass_by', 'break', 'lindy_circle', 'promenade', 'groove_walk', 'come_back', 'swingout', 'swingout', 'inside_turn', 'inside_turn', 'barrel_turn', 'sweetheart', 'barrel_turn', 'outside_turn', 'outside_spin', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'sugar_push', 'sugar_push', 'sling_shot', 'sling_shot']\n",
      "Sequence 33: ['come_back', 'basic_closed', 'send_out', 'pass_by', 'sugar_push', 'sweetheart', 'pass_by', 'break', 'tuck_turn', 'frankie´s_sixes', 'corridor', 'swingout', 'swingout', 'outside_turn', 'basic_closed', 'promenade', 'groove_walk', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'lindy_circle', 'promenade', 'groove_walk', 'inside_spin', 'lindy_circle', 'inside_turn', 'hand_to_hand', 'inside_turn', 'barrel_turn', 'outside_turn', 'outside_spin', 'barrel_turn', 'outside_spin', 'come_back', 'basic_charleston', 'tuck_turn', 'switches']\n",
      "Sequence 34: ['break', 'pass_by', 'sweetheart', 'outside_spin', 'barrel_turn', 'lindy_circle', 'tuck_turn', 'pass_by', 'lindy_circle', 'send_out', 'sugar_push', 'sugar_push', 'swingout', 'swingout', 'outside_turn', 'basic_closed', 'groove_walk', 'basic_closed', 'promenade', 'groove_walk', 'come_back', 'promenade', 'send_out', 'frankie´s_sixes', 'barrel_turn', 'outside_turn', 'outside_spin', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'basic_open', 'basic_open', 'break', 'switches', 'come_back', 'basic_charleston', 'tuck_turn', 'inside_turn', 'inside_turn', 'hand_to_hand']\n",
      "Sequence 35: ['swingout', 'pass_by', 'swingout', 'pass_by', 'basic_open', 'lindy_circle', 'inside_spin', 'outside_turn', 'sugar_push', 'sugar_push', 'basic_open', 'break', 'come_back', 'basic_closed', 'promenade', 'tuck_turn', 'basic_closed', 'promenade', 'groove_walk', 'corridor', 'hand_to_hand_charleston', 'frankie´s_sixes', 'barrel_turn', 'lindy_circle', 'inside_turn', 'barrel_turn', 'sweetheart', 'outside_turn', 'outside_spin', 'outside_spin', 'come_back', 'send_out', 'sailor_kicks']\n",
      "Sequence 36: ['outside_turn', 'pass_by', 'lindy_circle', 'send_out', 'break', 'pass_by', 'come_back', 'tuck_turn', 'sugar_push', 'sweetheart', 'inside_spin', 'lindy_circle', 'swingout', 'swingout', 'outside_turn', 'sugar_push', 'sling_shot', 'sling_shot']\n",
      "Sequence 37: ['groove_walk', 'basic_closed', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'lindy_circle', 'swingout', 'swingout', 'lindy_circle', 'send_out', 'break', 'outside_turn', 'sugar_push', 'sweetheart', 'frankie´s_sixes', 'come_back', 'groove_walk', 'sugar_push', 's_turn', 'tandem', 'tandem', 'break', 'outside_turn', 'outside_spin', 'barrel_turn', 'outside_spin', 'corridor', 'inside_spin', 'come_back', 'basic_charleston', 'tuck_turn', 'switches']\n",
      "Sequence 38: ['s_turn', 'tandem', 'break', 'pass_by', 'lindy_circle', 'inside_turn', 'frankie´s_sixes', 'barrel_turn', 'swingout', 'pass_by', 'come_back', 'tuck_turn', 'basic_closed', 'groove_walk', 'swingout', 'inside_turn', 'lindy_circle', 'promenade', 'groove_walk', 'basic_closed', 'send_out', 'outside_spin', 'sweetheart', 'outside_spin', 'sugar_push', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'sweetheart', 'inside_spin', 'outside_turn']\n",
      "Sequence 39: ['swingout', 'come_back', 'basic_closed', 'corridor', 'swingout', 'pass_by', 'pass_by', 'sweetheart', 'frankie´s_sixes', 'barrel_turn', 'break', 'lindy_circle', 'inside_turn', 'sugar_push', 'sailor_kicks', 'barrel_turn', 'outside_turn', 'outside_spin', 'sugar_push', 'basic_open', 'basic_open', 'lindy_circle', 'promenade', 'promenade', 'tuck_turn', 'outside_spin', 'outside_turn', 'basic_closed', 'send_out', 'sailor_kicks']\n",
      "Sequence 40: ['frankie´s_sixes', 'come_back', 'basic_closed', 'tuck_turn', 'pass_by', 'pass_by', 'swingout', 'corridor', 'swingout', 'lindy_circle', 'basic_closed', 'send_out', 'break', 'lindy_circle', 'inside_turn', 'inside_turn', 'sugar_push', 'outside_spin', 'outside_spin', 'sweetheart', 'groove_walk', 'inside_spin', 'outside_turn', 'sugar_push', 'sling_shot', 'sling_shot']\n",
      "Sequence 41: ['sailor_kicks', 'pass_by', 'swingout', 'swingout', 'lindy_circle', 'tuck_turn', 'sugar_push', 'sweetheart', 'pass_by', 'barrel_turn', 'come_back', 'promenade', 'groove_walk', 'corridor', 'basic_closed', 'basic_closed', 'send_out', 'outside_spin', 'outside_spin', 'lindy_circle', 'pop_turn', 'frankie´s_sixes', 'hallelujah_rocks', 'break', 'barrel_turn', 'outside_turn', 'sugar_push', 'inside_turn', 'inside_turn', 'hand_to_hand']\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences\n",
    "generated_sequences = []\n",
    "for _ in range(41):\n",
    "    start_move = random.choice(list(transition_probabilities.keys()))\n",
    "    new_sequence = generate_sequence(start_move, 40, 55, transition_probabilities, repeat_once_moves)\n",
    "    generated_sequences.append(new_sequence)\n",
    "\n",
    "# Print the sequences\n",
    "for i, seq in enumerate(generated_sequences):\n",
    "    print(f\"Sequence {i+1}: {seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sailor_kicks',\n",
       " 'pass_by',\n",
       " 'swingout',\n",
       " 'swingout',\n",
       " 'lindy_circle',\n",
       " 'tuck_turn',\n",
       " 'sugar_push',\n",
       " 'sweetheart',\n",
       " 'pass_by',\n",
       " 'barrel_turn',\n",
       " 'come_back',\n",
       " 'promenade',\n",
       " 'groove_walk',\n",
       " 'corridor',\n",
       " 'basic_closed',\n",
       " 'basic_closed',\n",
       " 'send_out',\n",
       " 'outside_spin',\n",
       " 'outside_spin',\n",
       " 'lindy_circle',\n",
       " 'pop_turn',\n",
       " 'frankie´s_sixes',\n",
       " 'hallelujah_rocks',\n",
       " 'break',\n",
       " 'barrel_turn',\n",
       " 'outside_turn',\n",
       " 'sugar_push',\n",
       " 'inside_turn',\n",
       " 'inside_turn',\n",
       " 'hand_to_hand']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sequences[40]\n",
    "\n",
    "# sequence 7 had an improbable move combination, sequene 35 was very short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove above mentiones sequences\n",
    "\n",
    "# Indices of sequences to remove\n",
    "indices_to_remove = [7, 35]\n",
    "\n",
    "# Filter out sequences\n",
    "filtered_sequences = [seq for i, seq in enumerate(generated_sequences) if i not in indices_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2 extra seq\n",
    "\n",
    "add_generated_sequences = []\n",
    "for _ in range(2):\n",
    "    start_move = random.choice(list(transition_probabilities.keys()))\n",
    "    new_sequence = generate_sequence(start_move, 40, 55, transition_probabilities, repeat_once_moves)\n",
    "    add_generated_sequences.append(new_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['come_back',\n",
       " 'basic_closed',\n",
       " 'send_out',\n",
       " 'pass_by',\n",
       " 'pass_by',\n",
       " 'outside_spin',\n",
       " 'barrel_turn',\n",
       " 'sweetheart',\n",
       " 'lindy_circle',\n",
       " 'tuck_turn',\n",
       " 'frankie´s_sixes',\n",
       " 'lindy_circle',\n",
       " 'break',\n",
       " 'outside_turn',\n",
       " 'sugar_push',\n",
       " 'sugar_push',\n",
       " 'outside_spin',\n",
       " 'barrel_turn',\n",
       " 'outside_turn',\n",
       " 'basic_closed',\n",
       " 'groove_walk',\n",
       " 'swingout',\n",
       " 'swingout',\n",
       " 'switches',\n",
       " 'come_back',\n",
       " 'groove_walk',\n",
       " 'corridor',\n",
       " 'hand_to_hand_charleston',\n",
       " 'frankie´s_sixes',\n",
       " 'hallelujah_rocks',\n",
       " 'break',\n",
       " 'promenade',\n",
       " 'promenade',\n",
       " 'tuck_turn',\n",
       " 'inside_turn',\n",
       " 'inside_turn',\n",
       " 'hand_to_hand']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_generated_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all augmented sequences\n",
    "all_augmented_sequences = filtered_sequences + add_generated_sequences\n",
    "\n",
    "# Filter out 16 sequences from original dataset for the validation set (total 81 seq. so 20% is set asside for the test) \n",
    "original_sequences_val = lists_extracted[-16:]\n",
    "# the rest of the original dataset to be used for training\n",
    "original_sequences_train = lists_extracted[:-16]\n",
    "\n",
    "# Combine sequences for the training\n",
    "all_sequences_train = original_sequences_train + all_augmented_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all sequences for embedding matrix\n",
    "all_sequences = all_augmented_sequences + lists_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Saving all_augmented_sequences sequences\n",
    "with open('all_augmented_sequences.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(all_augmented_sequences)\n",
    "\n",
    "    \n",
    "# Saving original_sequences_val sequences\n",
    "with open('original_sequences_val.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(original_sequences_val)\n",
    "    \n",
    "# Saving all_sequences_train sequences\n",
    "with open('all_sequences_train.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(all_sequences_train)    \n",
    "\n",
    "# Saving all augmet sequences merged with all original\n",
    "with open('all_sequences_augmented_original.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(all_sequences)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling after data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a word2vec model for the dance move sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model\n",
    "word2vec_model_augmented = Word2Vec(all_sequences, vector_size=100, window=3, min_count=1, workers=4)\n",
    "\n",
    "# Save the model for later use\n",
    "word2vec_model_augmented.save(\"lindyhop_moves_word2vec_augmented.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f4eb4328c88>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.64474273e-03  1.60651237e-01  1.63596690e-01  6.40599355e-02\n",
      " -1.26433093e-02 -1.47748232e-01  9.99437422e-02  3.89276385e-01\n",
      " -2.24339843e-01 -2.67740995e-01 -2.76259612e-02 -2.32979059e-01\n",
      "  2.39891186e-02  3.83976772e-02 -7.56487064e-03 -3.97672504e-02\n",
      "  2.67559856e-01 -9.58606321e-03 -1.56874746e-01 -6.10023081e-01\n",
      "  3.95981222e-02  4.97586317e-02  2.10622847e-01 -6.62096143e-02\n",
      " -2.44502932e-01  1.13610499e-01 -2.54685998e-01  5.09284399e-02\n",
      " -6.42005056e-02  1.56850070e-01  2.16609493e-01 -1.96707547e-01\n",
      "  3.32984515e-02 -2.65461326e-01 -6.53318241e-02  1.44481957e-01\n",
      "  1.69076487e-01  7.89705813e-02 -1.64456934e-01 -1.05010755e-01\n",
      "  1.41897291e-01 -1.89162835e-01 -1.59927338e-01  2.55636126e-01\n",
      "  5.03181405e-02 -2.92366534e-01 -1.96757242e-01 -1.98210388e-01\n",
      "  1.48105249e-01  1.27245456e-01  4.28319834e-02 -2.05660462e-01\n",
      "  2.55945139e-02 -3.29673924e-02 -1.41095638e-01  6.19842894e-02\n",
      "  7.75536299e-02 -8.07707757e-02 -3.22565958e-02  8.23652819e-02\n",
      "  3.44136561e-06 -1.34015858e-01  3.40154707e-01  1.18896715e-01\n",
      " -1.73416495e-01  3.66740286e-01 -1.01026648e-03  1.64845526e-01\n",
      " -1.88735664e-01 -1.04854302e-02  6.97981864e-02  2.57857442e-01\n",
      "  1.13877416e-01  9.53046903e-02  1.83730841e-01  1.26014858e-01\n",
      "  1.77303419e-01  1.37883112e-01 -1.83793083e-02 -1.02036282e-01\n",
      " -2.52609372e-01  4.58051404e-03 -1.52321497e-03  1.68918267e-01\n",
      " -1.41674608e-01 -7.82420933e-02  9.30724666e-02  7.29210153e-02\n",
      "  1.10811420e-01  1.15115769e-01  2.61611521e-01  9.43504050e-02\n",
      "  8.08606967e-02 -1.38170362e-04  2.67345160e-01 -3.58683802e-02\n",
      "  1.17882669e-01 -5.67211807e-02  3.65554057e-02  8.74291733e-02]\n"
     ]
    }
   ],
   "source": [
    "# Get an embedding for a specific move\n",
    "move_vector_augmented = word2vec_model_augmented.wv['lindy_circle'] \n",
    "print(move_vector_augmented)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_closed: 0.9987438917160034\n",
      "outside_spin: 0.998740553855896\n",
      "swingout: 0.9986775517463684\n",
      "break: 0.9986621141433716\n",
      "come_back: 0.9986563324928284\n"
     ]
    }
   ],
   "source": [
    "# Finding moves similar to a given move (it can be interpreted that those moves co-occured more often in the dataset)\n",
    "similar_moves_augmented = word2vec_model_augmented.wv.most_similar('lindy_circle', topn=5) \n",
    "for move, similarity in similar_moves_augmented:\n",
    "    print(f\"{move}: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass_by\n",
      "swingout\n",
      "come_back\n",
      "basic_closed\n",
      "tuck_turn\n",
      "lindy_circle\n",
      "break\n",
      "sugar_push\n",
      "outside_spin\n",
      "sweetheart\n",
      "groove_walk\n",
      "send_out\n",
      "barrel_turn\n",
      "outside_turn\n",
      "frankie´s_sixes\n",
      "inside_turn\n",
      "promenade\n",
      "inside_spin\n",
      "corridor\n",
      "basic_open\n",
      "sailor_kicks\n",
      "switches\n",
      "hand_to_hand\n",
      "hand_to_hand_charleston\n",
      "hallelujah_rocks\n",
      "tandem\n",
      "sling_shot\n",
      "s_turn\n",
      "basic_charleston\n",
      "pop_turn\n",
      "mini_dip\n",
      "frankie´s_points\n"
     ]
    }
   ],
   "source": [
    "# Check vocabulary of Word2Vec model\n",
    "for move in word2vec_model_augmented.wv.key_to_index:\n",
    "    print(move)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_model_augmented' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-72a8f5c39dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model_augmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec_model_augmented' is not defined"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "print(word2vec_model_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve all vectors from the model\n",
    "vectors_augmented = word2vec_model_augmented.wv.vectors\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2)\n",
    "vectors_2d = tsne.fit_transform(vectors_augmented)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, move in enumerate(word2vec_model_augmented.wv.key_to_index):\n",
    "    plt.scatter(vectors_2d[i, 0], vectors_2d[i, 1])\n",
    "    plt.text(vectors_2d[i, 0]+0.03, vectors_2d[i, 1]+0.03, move, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an embedding matrix for use in LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['basic_closed',\n",
       "  'pop_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'corridor',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sailor_kicks'],\n",
       " ['hand_to_hand_charleston',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'barrel_turn',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'outside_spin',\n",
       "  'corridor',\n",
       "  'inside_spin'],\n",
       " ['pass_by',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sling_shot',\n",
       "  'sling_shot',\n",
       "  'lindy_circle',\n",
       "  'groove_walk'],\n",
       " ['outside_turn',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'basic_closed',\n",
       "  'pop_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'inside_spin'],\n",
       " ['groove_walk',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'outside_turn'],\n",
       " ['promenade',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'corridor',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'hallelujah_rocks'],\n",
       " ['send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'barrel_turn',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks'],\n",
       " ['hallelujah_rocks',\n",
       "  'break',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'frankie´s_sixes',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'sweetheart',\n",
       "  'inside_turn',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'inside_spin'],\n",
       " ['tuck_turn',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'basic_closed',\n",
       "  'corridor',\n",
       "  'hand_to_hand_charleston',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back',\n",
       "  'basic_charleston',\n",
       "  'basic_charleston'],\n",
       " ['s_turn',\n",
       "  'tandem',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'inside_turn',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'inside_spin'],\n",
       " ['frankie´s_points',\n",
       "  'frankie´s_points',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'pass_by',\n",
       "  'inside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'outside_turn',\n",
       "  'barrel_turn',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'inside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_closed'],\n",
       " ['break',\n",
       "  'send_out',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'outside_turn',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'groove_walk',\n",
       "  'inside_spin'],\n",
       " ['promenade',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand'],\n",
       " ['pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks'],\n",
       " ['mini_dip',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'outside_spin',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'basic_open',\n",
       "  'basic_open'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem',\n",
       "  'break',\n",
       "  'promenade',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'lindy_circle',\n",
       "  'inside_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'come_back'],\n",
       " ['barrel_turn',\n",
       "  'break',\n",
       "  'send_out',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand',\n",
       "  'hand_to_hand',\n",
       "  'inside_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open'],\n",
       " ['send_out',\n",
       "  'pass_by',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand'],\n",
       " ['basic_charleston',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'pop_turn',\n",
       "  'frankie´s_sixes',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks'],\n",
       " ['inside_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'outside_spin',\n",
       "  'come_back',\n",
       "  'tuck_turn',\n",
       "  'sugar_push',\n",
       "  'sweetheart',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'send_out',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open'],\n",
       " ['sugar_push',\n",
       "  'come_back',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'break',\n",
       "  'lindy_circle',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'frankie´s_sixes',\n",
       "  'barrel_turn'],\n",
       " ['basic_closed',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'send_out',\n",
       "  'outside_spin',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'pass_by',\n",
       "  'barrel_turn',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sailor_kicks',\n",
       "  'sailor_kicks',\n",
       "  'barrel_turn',\n",
       "  'come_back',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'break',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes'],\n",
       " ['come_back',\n",
       "  'basic_closed',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'barrel_turn',\n",
       "  'barrel_turn',\n",
       "  'break',\n",
       "  'inside_turn',\n",
       "  'hand_to_hand'],\n",
       " ['break',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'come_back',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'corridor',\n",
       "  'basic_closed',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'outside_turn',\n",
       "  'sweetheart',\n",
       "  'outside_spin',\n",
       "  'barrel_turn',\n",
       "  'basic_closed',\n",
       "  'promenade',\n",
       "  'promenade'],\n",
       " ['inside_spin',\n",
       "  'come_back',\n",
       "  'promenade',\n",
       "  'tuck_turn',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'swingout',\n",
       "  'swingout',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'promenade',\n",
       "  'groove_walk',\n",
       "  'break',\n",
       "  'barrel_turn',\n",
       "  'sweetheart',\n",
       "  'frankie´s_sixes',\n",
       "  'basic_open',\n",
       "  'basic_open',\n",
       "  'break',\n",
       "  'outside_turn',\n",
       "  'sugar_push',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem'],\n",
       " ['swingout',\n",
       "  'swingout',\n",
       "  'come_back',\n",
       "  'send_out',\n",
       "  'pass_by',\n",
       "  'pass_by',\n",
       "  'sugar_push',\n",
       "  'sling_shot',\n",
       "  'lindy_circle',\n",
       "  'tuck_turn',\n",
       "  'outside_spin',\n",
       "  'sugar_push',\n",
       "  's_turn',\n",
       "  'tandem',\n",
       "  'tandem',\n",
       "  'break',\n",
       "  'switches',\n",
       "  'lindy_circle',\n",
       "  'basic_closed',\n",
       "  'basic_closed',\n",
       "  'groove_walk',\n",
       "  'groove_walk',\n",
       "  'inside_spin',\n",
       "  'outside_turn',\n",
       "  'sweetheart']]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data\n",
    "all_sequences_train\n",
    "\n",
    "#test data\n",
    "all_augmented_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all sequences into a single list to find unique moves\n",
    "all_moves = [move for sequence in lists_extracted for move in sequence]\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_moves)\n",
    "\n",
    "# Number of unique classes (moves)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Function to convert moves to integers\n",
    "def encode_sequence(sequence):\n",
    "    # Encode the sequence\n",
    "    return label_encoder.transform(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([24, 19, 19, 27,  9,  9, 28,  5, 28,  4, 15, 31, 17, 26, 26,  8,  3,\n",
       "         3,  4, 14, 11, 14,  0,  2,  2, 21, 21, 24, 23, 23,  0, 18, 15, 13,\n",
       "         5,  6, 12,  8, 10, 10]),\n",
       " array([14, 31, 19, 19, 28, 28, 15,  9,  4, 18, 26,  5,  2, 21, 21, 24,  8,\n",
       "         2,  6, 13,  5,  9, 27, 17,  0,  0,  4, 29, 29, 15, 20, 20,  8, 26,\n",
       "        22, 30, 30]),\n",
       " array([10, 10,  8, 19, 19,  5,  2, 28, 18, 28, 11, 14, 31, 17,  0,  4, 29,\n",
       "        15,  2, 21,  9,  9, 13, 15, 24, 26, 27, 27,  5, 21, 31, 26,  3,  3,\n",
       "         4, 29]),\n",
       " array([13,  5, 28, 19, 19, 26, 26, 28,  4, 15, 20,  8,  6, 31, 18, 17,  0,\n",
       "        27, 14, 11, 11, 14,  2,  2, 21, 21, 24, 23, 23,  0,  4, 29, 29,  5,\n",
       "         9,  9, 31, 17, 18, 15]),\n",
       " array([16, 19, 19,  3,  3,  4, 31, 27,  5,  2,  2,  9,  9, 28, 28, 15, 14,\n",
       "        26, 26,  8, 10, 10,  8,  0, 18, 17,  6, 12, 12]),\n",
       " array([11, 19, 19,  4, 14,  5,  2, 28, 28, 15, 31, 29, 29, 15,  2, 20,  8,\n",
       "        26, 26, 27, 17, 18,  0, 17,  6, 13, 13,  5, 21, 21, 24, 23, 23,  0,\n",
       "        27,  9,  9,  4, 31,  8,  3,  3]),\n",
       " array([ 0,  4, 19, 27, 19,  8,  5,  9,  9, 31, 14, 26, 26, 28, 28, 15, 21,\n",
       "        24, 17, 18, 15,  2,  2, 21, 31, 29, 29,  5,  6, 13, 13, 18,  0,  4,\n",
       "        24, 23, 23]),\n",
       " array([ 7,  7,  5,  6, 31, 19, 19, 28, 28, 18, 26, 26, 23, 23,  0,  2,  2,\n",
       "         4, 24,  8, 15, 21,  9,  9, 27, 13,  5, 21, 31, 17,  0,  4, 29, 29,\n",
       "        15, 14, 11, 14, 11]),\n",
       " array([ 3,  3, 28, 28, 19, 19, 15,  9,  9, 31, 17,  5,  2,  2,  4,  0, 27,\n",
       "        14, 26, 26,  8, 10, 10,  8,  6, 13, 18, 18, 27,  0,  4, 24, 23, 23]),\n",
       " array([ 0,  4, 28, 28,  6, 19, 19, 27,  5, 31, 17,  8, 26, 26, 23, 23,  0,\n",
       "         2,  2,  9, 15, 24,  4, 18, 18, 15, 21, 21,  9, 13, 13,  5,  1,  1,\n",
       "        31, 29, 29]),\n",
       " array([11, 19, 19,  5, 18,  0, 15, 31,  2,  2, 24, 28, 28,  4, 21, 21,  9,\n",
       "         9, 26, 26, 27, 13,  5,  6, 12,  8,  3,  3,  4, 14, 14,  8, 10, 10]),\n",
       " array([14, 28, 28, 15, 31, 19,  5,  2,  2,  6, 13, 19,  8, 10,  4, 17,  0,\n",
       "        27, 18, 26, 26,  3,  3,  4, 24, 23, 23,  0, 27,  9,  9, 15, 21, 21,\n",
       "        24,  8, 10]),\n",
       " array([25, 19, 19,  5, 28, 28, 15, 14, 11, 11, 14, 31, 17,  8,  3,  3,  4,\n",
       "        24, 23, 23,  0, 27, 13, 18, 26, 26, 22, 30, 30,  4,  2,  2,  9,  9,\n",
       "         6, 12, 12,  8, 10, 10]),\n",
       " array([10,  4, 17, 19, 19,  5,  2, 31,  8, 10,  8,  3,  3, 28, 28, 18, 26,\n",
       "        26, 27,  9,  9,  2, 24, 23, 23,  0, 15, 14, 11, 11, 14,  5, 21, 21,\n",
       "        24, 17,  6, 13, 15, 20]),\n",
       " array([20,  8, 19, 19, 28, 28,  4,  0,  2,  2, 24, 26, 26, 27,  5,  9,  9,\n",
       "        31, 17,  6, 13, 15, 21, 21, 31, 18, 18,  0, 27, 14, 11, 11, 14,  5,\n",
       "         1,  1]),\n",
       " array([24,  4, 19, 19,  5, 28, 28, 14, 15,  2,  2, 31, 26, 26, 25, 25, 15,\n",
       "        20,  8,  0, 27, 17, 18, 27,  9,  9,  6, 12,  8, 10, 10,  4, 21, 21,\n",
       "        31, 29,  5,  1,  1]),\n",
       " array([23, 19, 18, 26, 26, 27, 15, 31, 19, 28, 28,  5, 24, 23,  0,  4, 17,\n",
       "         8,  3,  3,  4,  2,  2, 21, 21,  9,  9,  6, 12,  8, 10, 10]),\n",
       " array([21, 28, 19, 19,  5, 24, 17, 18,  0, 27,  8,  6, 28,  4, 15, 31, 26,\n",
       "        26, 25, 25, 15,  9,  9,  2,  2, 21, 31, 29, 29,  5,  1,  1]),\n",
       " array([13,  5, 21, 21,  9, 28, 15, 31, 19, 19,  4, 27,  0, 28, 29, 29, 15,\n",
       "        24, 17,  6, 12,  8, 10, 10,  8, 26, 26, 22, 30, 30,  4, 14, 11, 11,\n",
       "        14,  2,  2,  9, 31, 18]),\n",
       " array([21, 21, 31,  4, 19, 28, 28,  5,  2,  2, 24, 19, 27,  9,  9, 15, 14,\n",
       "        11, 11, 14, 26, 26, 23,  0, 17,  8,  3,  3,  4, 18, 18, 15,  6, 12,\n",
       "         8, 10, 10]),\n",
       " array([ 6, 28, 28, 15, 31, 17,  5,  2,  2, 24, 19, 19, 23,  0, 18, 27,  8,\n",
       "         3,  3,  4, 29,  5,  9,  9, 13, 13, 15, 14, 26, 26, 22, 30, 30,  4,\n",
       "        21, 21, 24, 23,  0, 27]),\n",
       " array([ 2,  2, 24, 19, 19,  0, 18, 28, 15,  9,  9, 31,  4, 17,  5, 28, 29,\n",
       "        29, 15, 14, 26, 26, 27,  8, 10, 10,  8,  3,  3,  4, 21, 21, 31, 17,\n",
       "         6, 12, 12]),\n",
       " array([22, 30, 30,  4,  5,  2, 31, 19, 19, 27, 17,  0, 15, 28, 28,  6, 13,\n",
       "        18, 26, 26,  8,  2, 24, 23, 23,  0, 18, 15, 14, 11, 11, 14,  5,  9,\n",
       "         9,  4, 29, 29]),\n",
       " array([ 7,  7,  5, 31,  4,  2,  2, 15, 28, 28, 24,  8, 19, 19, 25, 25, 15,\n",
       "         9, 27, 14, 26, 26, 17, 18,  0,  4, 21, 21,  9, 13, 18, 27,  0, 17,\n",
       "         6, 12, 12,  8,  3,  3]),\n",
       " array([23, 19, 19,  5,  4, 14, 11, 11, 14,  8,  0, 27,  9,  9, 31, 28, 18,\n",
       "        17, 15, 24, 28, 26, 26, 22, 30, 30,  4,  2,  2, 21, 21, 24, 23,  0,\n",
       "        27, 13, 18, 17,  6, 12]),\n",
       " array([31, 19, 19, 17,  5,  2,  2, 28, 28, 18, 27,  8, 10,  4, 24, 26, 26,\n",
       "         3,  3, 15, 14, 11, 11, 14,  0,  0, 15, 21, 21,  9,  9, 13, 13, 18,\n",
       "        27,  8, 10,  4, 29, 29]),\n",
       " array([24,  4, 14,  2, 31, 19, 26, 19,  5,  2, 28, 28, 15,  9,  9,  6, 13,\n",
       "        18,  0, 27,  8,  3,  3,  4, 21, 21, 24, 26, 22, 30, 30]),\n",
       " array([24,  8,  5, 31, 19, 19, 27, 18, 26, 26, 28, 28, 15,  2,  2,  4,  0,\n",
       "        17,  6, 13, 15, 21, 21,  9,  9, 31, 14, 11, 14,  5,  1,  1]),\n",
       " array([13,  5,  2,  2, 21, 21, 31, 19, 19, 28, 15, 14,  8, 28, 29, 15,  6,\n",
       "        12,  8, 10,  4, 27, 17, 18,  0,  0,  4, 24, 23, 23]),\n",
       " array([ 5, 28, 28, 19, 19, 17, 26, 26, 27,  9, 31,  2,  2, 21, 21,  9,  4,\n",
       "        15, 24, 23, 23,  0, 18, 18, 17,  8, 10, 10,  4, 14, 11, 11, 14, 31,\n",
       "        29, 15, 20,  8,  3,  3]),\n",
       " array([27, 19, 26, 19,  5,  2,  2, 31, 17, 15, 28, 28, 18,  0,  4, 21, 21,\n",
       "         9,  9, 13, 18, 26, 22, 30, 30,  4, 29, 15, 24, 23, 23,  0, 17,  8,\n",
       "         3,  3]),\n",
       " array([14, 26, 27,  0, 15, 28, 28,  4, 19, 19, 26, 17,  8,  3,  3,  4, 31,\n",
       "         5, 24, 23, 23,  0,  2,  2, 21, 21,  9,  9,  6, 12, 12,  8, 10, 10]),\n",
       " array([14, 28, 28, 18, 15, 31, 19,  5,  9,  9,  2,  2,  4, 19, 26, 26, 27,\n",
       "         8,  0, 17,  6, 13, 15, 24, 23, 23,  0, 27, 17,  5, 21, 21, 31, 29,\n",
       "        29]),\n",
       " array([27, 19, 19, 28, 28, 15, 31,  5,  2,  2,  6, 12,  8,  4, 18, 26, 26,\n",
       "        17,  0,  0,  4, 24, 23, 23]),\n",
       " array([14, 11, 19, 17,  6, 31, 19,  8,  5, 28, 28, 18, 26, 26, 27,  4, 15,\n",
       "        24, 23, 23,  0,  2,  2, 21, 21,  9,  9, 13, 13, 15, 20, 20,  8, 10,\n",
       "        10,  4, 29, 29,  5,  1,  1]),\n",
       " array([20,  8, 19, 28, 28, 15,  9,  9, 31, 19, 27,  0, 18, 17,  5,  2,  2,\n",
       "        24,  4, 14, 11, 11, 14, 26, 26, 22, 30, 30,  4, 29, 29,  5, 21, 21,\n",
       "        24, 23, 23,  0, 27, 13]),\n",
       " array([25, 15, 31,  5, 28, 28, 19, 19,  4, 27,  9,  2, 21, 21,  2, 24, 26,\n",
       "        26, 23, 23,  0, 18, 17,  8,  6, 13,  5,  1,  1, 31, 29, 29, 15, 14,\n",
       "        11, 14,  0,  4, 24, 17]),\n",
       " array([26, 27,  0,  4, 19, 19,  8,  3,  3, 28, 28, 15,  2,  2, 31, 26, 22,\n",
       "        30, 30,  4,  5, 21, 21, 24, 23, 23,  0, 17, 18, 18, 15, 14, 11, 11,\n",
       "        14,  5,  9,  9,  6, 12]),\n",
       " array([10,  4, 19, 28, 28, 15, 21,  2,  2, 24, 26, 26, 19,  5, 31,  8,  3,\n",
       "         3, 15,  9,  9, 27, 17, 18,  0,  4, 29, 29,  5, 21, 31, 14, 11, 11,\n",
       "        14,  0, 27, 13, 13, 18]),\n",
       " array([29, 19, 28, 28, 15, 31, 19,  5,  4, 24, 26, 26, 17, 27,  8,  6, 12,\n",
       "        12,  8,  0,  2,  2, 21, 21,  9, 13, 18, 27,  9, 15, 14, 11, 11, 14,\n",
       "         5,  1,  1, 31, 17, 18]),\n",
       " array([11, 19,  5, 19, 28, 28,  4, 15, 31,  2,  2, 20,  8,  3,  3,  4, 14,\n",
       "        26, 27, 17, 26, 22, 30, 30]),\n",
       " array([17, 19, 19, 26, 26, 25, 15, 31,  4, 28, 28, 18,  0,  2,  2, 24, 23,\n",
       "        23,  0, 27,  5,  9,  9, 13,  5, 21, 21, 31, 29, 29, 15, 14, 11, 11,\n",
       "        14,  8,  3,  3,  4, 24]),\n",
       " array([ 0, 28, 28,  4,  5,  2,  2, 24, 19, 19, 26, 26, 25, 15, 31, 17, 18,\n",
       "        27,  9,  9, 13, 13,  5,  6, 12,  8, 10, 10,  4, 14, 11, 14,  0, 15,\n",
       "        21, 21, 31, 29, 29]),\n",
       " array([31, 19, 19,  5,  9,  9,  2,  2, 24, 26, 28,  4, 28, 15, 14,  8,  6,\n",
       "        13, 18, 17, 27,  0,  4, 29, 29, 15, 20,  8,  3,  3]),\n",
       " array([27, 19, 19,  5,  2,  2, 24,  4, 28, 28, 15, 31, 26, 26, 17,  8, 10,\n",
       "        10,  8,  3,  3, 15, 14,  0, 18, 18,  0,  4, 21, 21,  9,  9,  6, 12,\n",
       "        12]),\n",
       " array([28, 28, 19,  8, 19, 17,  5, 31,  4, 18,  0, 15,  9,  9,  2, 21, 21,\n",
       "        24, 26, 26, 27, 13, 15,  2,  6, 12,  8,  3,  3,  4, 14, 11, 11, 14,\n",
       "        31, 29, 29,  5,  1,  1]),\n",
       " array([19, 19, 28, 28, 24,  4, 15,  2,  2, 31, 26, 26, 27,  5,  9,  9, 13,\n",
       "        18,  0, 17,  8,  3,  3, 15, 20,  8,  6, 12, 12]),\n",
       " array([ 1, 31, 19, 26, 19,  5,  9,  9,  2,  2, 24,  4, 15, 14, 26,  8, 10,\n",
       "        10,  8,  3,  3, 28, 28, 29, 29, 15, 21, 21, 31,  0, 27, 17,  6, 13,\n",
       "        18, 18,  0,  4, 24, 23, 23]),\n",
       " array([18, 28, 19, 19, 27,  0, 28,  7,  5, 31, 17, 26, 26, 23, 23,  0,  2,\n",
       "         2, 24,  4, 15, 13, 13, 18, 27,  9,  9,  6, 12,  8, 10, 10,  4, 14,\n",
       "        11, 14,  5, 21, 21, 31, 29]),\n",
       " array([31, 19, 28,  5,  9,  2, 21, 21,  2, 28, 19, 27, 13, 18,  0,  4, 24,\n",
       "        26, 26, 17,  6, 12,  8, 10, 10,  4, 15,  9,  5,  1,  1, 31, 29, 15,\n",
       "        14, 11, 14,  8,  3,  3]),\n",
       " array([21, 21, 24, 26, 19, 19,  5, 31, 17,  4, 27,  8, 28, 28, 15,  2,  2,\n",
       "         9,  9,  6, 13, 18,  0,  4, 14, 26,  3,  3, 15, 20, 20,  8, 10, 10]),\n",
       " array([15, 31, 19, 27, 14, 19,  5,  2,  6, 28, 28,  4,  0,  2, 24, 26, 26,\n",
       "         3,  3, 15,  9,  9, 13, 18, 17,  8, 10, 10,  8,  5, 21, 21, 31, 29,\n",
       "        29]),\n",
       " array([14, 19, 28,  5, 31, 19, 15,  2,  2, 28,  4, 18,  0, 27, 13, 13,  5,\n",
       "         9,  9,  6, 12,  8, 26, 26,  3,  3,  4, 17, 17, 15, 24, 23, 23,  0,\n",
       "        18, 27,  8, 10, 10]),\n",
       " array([20,  8,  5, 21, 21, 24,  4, 17, 19, 19,  3,  3, 28, 28, 26, 26, 27,\n",
       "        14, 15, 31, 29,  5,  2,  2,  6, 13, 18,  0,  0,  4, 24, 23, 23]),\n",
       " array([11, 19, 19, 26, 26, 27,  0,  4, 15, 28, 28, 24,  8,  6,  2, 31, 17,\n",
       "         5,  9,  9,  2, 21, 21, 31, 29, 29,  5, 18, 18, 15, 14, 14,  0,  4,\n",
       "        24, 23, 23]),\n",
       " array([26, 19, 19, 15, 31, 17, 27,  0,  4, 21, 21, 24, 26,  5,  2,  2, 20,\n",
       "         8,  6, 12, 12,  8,  3,  3, 28, 28, 18, 18, 27, 14, 11, 11, 14, 15,\n",
       "        13, 13,  5,  9,  9, 31, 29]),\n",
       " array([ 3,  3, 19, 19, 26, 26, 27, 14, 11, 11, 14,  2,  2, 31, 17,  5,  9,\n",
       "        15,  4, 28, 28, 18,  0,  0, 15,  6, 13, 13,  5, 21, 21, 24,  8, 10,\n",
       "        10,  4, 29, 29]),\n",
       " array([26, 26, 17, 19, 19, 28, 28, 15, 31,  8,  2,  2, 21,  9,  9, 13,  5,\n",
       "         4, 14, 11, 11, 14,  0, 27, 18, 27,  5, 21, 24, 23, 23,  0,  4, 29,\n",
       "        29, 15,  6, 12, 12,  8,  3,  3]),\n",
       " array([ 5,  2,  2, 31, 19, 19, 26, 26, 27,  0, 18, 15, 28, 28,  4, 24, 23,\n",
       "        23,  0, 17,  8, 10, 10,  8,  6, 12, 12]),\n",
       " array([25, 19, 19, 15,  9,  5, 28, 28,  4, 17,  8, 26, 26, 27, 13, 18,  0,\n",
       "         2, 21, 21,  9, 31, 29, 29, 15, 24, 23, 23,  0,  2,  6, 12,  8,  3,\n",
       "         3,  4, 14, 11, 11, 14]),\n",
       " array([14, 28, 28,  4, 15, 31, 19, 19, 17,  5,  2,  2, 24, 26, 26, 27,  8,\n",
       "         3,  3, 15,  6, 12,  8,  0, 18, 18,  0,  4, 21, 21,  9,  9, 13,  5,\n",
       "         1,  1, 31, 29, 29]),\n",
       " array([13,  5,  2,  2,  4, 24, 19, 19,  0, 27, 17,  6, 28, 28, 15, 31, 26,\n",
       "        26,  8, 10, 10,  4, 14, 11, 11, 14,  5, 21, 21,  9,  9, 31, 18, 18,\n",
       "         0, 17,  8,  3,  3, 15, 20]),\n",
       " array([15, 24, 19,  8, 19, 17,  0,  4, 31,  5,  2,  2, 28, 28, 18, 26, 26,\n",
       "        27,  9,  9,  6, 12, 12,  8, 10, 10,  4, 29, 29, 15, 21, 21, 31, 14,\n",
       "        11, 11, 14,  5,  1,  1]),\n",
       " array([14,  5,  9, 31,  2,  2, 24,  4, 27, 19, 19, 15, 20,  8, 10, 10,  4,\n",
       "        17,  0, 28, 28, 18, 26, 26, 25, 25, 15, 21, 21,  9,  6, 13, 13,  5,\n",
       "         1,  1, 31, 29, 29]),\n",
       " array([ 7,  7,  5,  9, 31,  4, 19, 19,  8,  3,  3, 28, 28, 15, 24, 17,  0,\n",
       "        27, 14, 11, 11, 14,  2,  2, 21, 21,  9, 26, 26, 25, 25, 15,  6, 13,\n",
       "        18, 18,  0,  4, 29, 29]),\n",
       " array([23, 23, 19, 19, 15, 31, 17,  8, 26, 28, 28,  4,  5, 18, 26, 27, 14,\n",
       "        11, 11, 14,  2,  2,  6, 12,  8, 10, 10,  4,  0,  0,  5, 24, 24, 17,\n",
       "        18, 27,  9,  9, 13, 13]),\n",
       " array([18, 19,  5,  2,  2, 31, 19,  4, 28, 28, 15,  9,  9, 24, 23, 23,  0,\n",
       "        27, 17, 26, 26,  8,  6, 13, 15, 14, 11, 14, 11]),\n",
       " array([10, 10,  4, 19, 19, 17,  5,  2,  2, 31,  0, 15, 24, 23, 23,  0, 28,\n",
       "        28, 29, 29, 15, 14, 11, 11, 14, 26, 26, 27, 18, 18, 17,  8,  3,  3,\n",
       "         4, 21, 21,  9,  9, 13]),\n",
       " array([12,  8, 26, 26, 19, 15, 24, 19, 28,  5,  2,  2, 28, 14,  0, 27,  4,\n",
       "        21, 21, 31, 17,  6, 13, 18, 18, 15,  9,  9, 31, 29, 29,  5,  1,  1]),\n",
       " array([ 5, 28, 28, 15, 31, 19, 19, 26, 26, 27,  4, 14,  8,  0, 18, 17,  6,\n",
       "        12, 12,  8,  3,  3,  4, 24, 23, 23,  0,  2,  2, 21, 21,  9,  9, 13,\n",
       "        13,  5,  1,  1, 31, 29]),\n",
       " array([19, 19, 28, 28,  5,  2,  2, 31, 17,  0, 18, 27,  4, 14, 26, 26, 23,\n",
       "        23,  0, 15, 24,  8,  3,  3,  4, 21, 21,  9,  9,  6, 13, 15, 20,  8,\n",
       "        10, 10]),\n",
       " array([ 6, 28, 28, 19, 19, 11, 14,  5, 24,  4,  0,  2,  2, 31, 26, 26, 27,\n",
       "        17,  8,  3,  3, 15, 13, 18, 18, 17,  4, 21, 21,  9,  9, 27,  5,  1,\n",
       "         1, 31, 29, 29, 15, 20]),\n",
       " array([25, 19, 19, 11, 14, 15, 28, 28, 29,  5, 24, 26, 26, 27,  0, 18, 17,\n",
       "         4, 31,  2,  2, 21, 21,  9,  9,  6, 13, 13, 18, 15, 20,  8,  3,  3,\n",
       "         4, 24, 23, 23,  0, 27]),\n",
       " array([26, 26, 19, 19, 27,  4,  5,  9,  9,  6, 28, 28, 15, 24,  8, 10, 10,\n",
       "         8,  3,  3,  4,  0, 17, 18, 18, 17,  5,  2, 31, 14,  2, 21, 21, 31,\n",
       "        29, 15, 13, 13]),\n",
       " array([24, 19, 15, 28, 28, 19,  4,  5,  9, 31, 26, 26,  8,  6, 13, 18,  0,\n",
       "        17, 27, 14,  2,  2, 21, 21,  9, 31, 29, 29,  5,  1,  1]),\n",
       " array([31, 28, 19, 19,  8,  5,  2, 21,  2, 28,  6, 12,  8, 15,  4,  0, 18,\n",
       "        26, 26, 27, 17,  5, 21,  9,  9, 24, 23, 23,  0,  4, 29, 29, 15, 20,\n",
       "        20]),\n",
       " array([27, 19,  4, 19, 26, 26, 28, 28, 15, 21, 21, 31,  2,  2,  9,  6, 12,\n",
       "         8,  5, 24, 23, 23,  0, 18, 17, 17,  8,  3,  3, 15,  9, 13,  5,  1,\n",
       "         1, 31, 29, 29]),\n",
       " array([25, 19,  5,  2,  2, 31, 19, 17,  4,  0, 27, 13, 15, 24, 28, 28, 18,\n",
       "        26, 26, 23, 23,  0, 27, 14, 11, 14,  8, 10, 10,  4, 21, 21,  9,  9,\n",
       "         6, 12, 12,  8,  3,  3]),\n",
       " array([15, 31, 19, 19,  8,  5, 24,  4,  0, 28, 28,  6,  2, 21, 21,  9,  9,\n",
       "         2, 20, 20,  8,  3,  3, 15, 14, 26, 26, 27, 18, 17, 17,  4, 29, 29,\n",
       "         5,  1,  1, 31, 18,  0]),\n",
       " array([30, 30,  4, 21, 21, 31, 19, 19,  5,  6,  2, 28, 28, 15, 14, 11, 11,\n",
       "        14,  8,  3,  3,  4, 24, 23,  0, 18, 26, 26, 27, 17, 18,  0,  2,  9,\n",
       "         9, 13,  5,  1,  1, 31, 29]),\n",
       " array([22, 30, 30,  4, 19, 17,  5, 31, 19, 26, 26, 28, 28, 15, 24,  8,  3,\n",
       "         3,  4, 29,  5,  2,  2,  9,  9, 13, 18, 27,  0,  0, 15,  6, 12,  8,\n",
       "        10, 10]),\n",
       " array([29, 15, 31, 27,  5,  2,  2, 28, 28,  6, 12,  8, 19, 19,  4, 24, 17,\n",
       "         0, 18, 26, 26, 23, 23,  0, 15, 21, 21,  9,  9, 13, 13,  5,  1,  1,\n",
       "        31, 14, 11, 14,  8,  3,  3]),\n",
       " array([31, 19,  5,  9,  2,  2, 24, 19, 27, 14,  8, 10,  4, 18, 26, 28, 28,\n",
       "        15,  9, 13, 13, 15, 21, 21, 31,  0, 17, 26,  3,  3,  4, 29, 29,  5,\n",
       "         6, 12,  8, 10]),\n",
       " array([ 0,  4, 24, 19, 19, 28, 28, 29, 15,  2,  2, 31, 17,  8,  5,  6, 12,\n",
       "        12,  8, 26, 26, 27, 14, 11, 14,  0, 18, 18, 15, 21, 21,  9,  9, 13,\n",
       "        13,  5,  1,  1, 31,  4]),\n",
       " array([30, 30,  4, 19, 19,  5,  2, 21, 21, 24, 28, 28, 15,  2, 31, 17,  8,\n",
       "         0, 27, 14, 26, 26, 25, 15,  6, 13, 18, 18,  0,  4, 29, 29,  5,  9,\n",
       "         9, 31,  8,  3,  3]),\n",
       " array([18, 26, 26, 19, 19,  0, 27,  8,  4, 31, 17,  5, 28, 28, 15, 24, 23,\n",
       "        23,  0,  2,  2,  6, 12,  8,  3,  3,  4, 29, 29,  5, 21, 21,  9,  9,\n",
       "        13, 18, 15, 20, 20]),\n",
       " array([ 5,  9,  9, 28, 28, 19, 19, 27,  4, 29, 15, 31, 17, 18, 26, 26,  3,\n",
       "         3,  4,  0,  2,  2,  6, 12,  8, 10, 10,  8,  5, 24, 23, 23,  0, 27,\n",
       "        14, 11, 11, 14, 15, 20]),\n",
       " array([22, 30,  4, 19, 19, 17,  8,  0, 28, 28,  5,  2,  2,  6, 12, 12,  8,\n",
       "         3,  3, 15, 31, 26, 26, 27, 13, 18, 18, 15, 14, 11, 11, 14,  0,  4,\n",
       "        29, 29,  5,  9,  9, 24, 23, 23])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply encoding to each sequence for train dataset\n",
    "encoded_sequences_augmented_train = [encode_sequence(sequence) for sequence in all_sequences_train]\n",
    "encoded_sequences_augmented_train\n",
    "\n",
    "# Apply encoding to each sequence for test dataset\n",
    "encoded_sequences_augmented_test = [encode_sequence(sequence) for sequence in all_augmented_sequences_test]\n",
    "encoded_sequences_augmented_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barrel_turn': 0, 'basic_charleston': 1, 'basic_closed': 2, 'basic_open': 3, 'break': 4, 'come_back': 5, 'corridor': 6, 'frankie´s_points': 7, 'frankie´s_sixes': 8, 'groove_walk': 9, 'hallelujah_rocks': 10, 'hand_to_hand': 11, 'hand_to_hand_charleston': 12, 'inside_spin': 13, 'inside_turn': 14, 'lindy_circle': 15, 'mini_dip': 16, 'outside_spin': 17, 'outside_turn': 18, 'pass_by': 19, 'pop_turn': 20, 'promenade': 21, 's_turn': 22, 'sailor_kicks': 23, 'send_out': 24, 'sling_shot': 25, 'sugar_push': 26, 'sweetheart': 27, 'swingout': 28, 'switches': 29, 'tandem': 30, 'tuck_turn': 31}\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from moves to indices using the LabelEncoder\n",
    "move_to_index = {move: index for index, move in enumerate(label_encoder.classes_)}\n",
    "\n",
    "# Print the mapping\n",
    "print(move_to_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding matrix vector size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# load embedding model with augmented data\n",
    "word2vec_model_augmented = FastText.load(\"lindyhop_moves_word2vec_augmented.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create embedding matrix of vector size 100\n",
    "embedding_matrix_augmented = np.zeros((len(move_to_index), 100)) \n",
    "\n",
    "for move, i in move_to_index.items():\n",
    "    if move in word2vec_model_augmented.wv:\n",
    "        embedding_matrix_augmented[i] = word2vec_model_augmented.wv[move]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding_matrix\n",
    "np.save('embedding_matrix_augmented_word2vec_100.npy', embedding_matrix_augmented)\n",
    "\n",
    "# load it\n",
    "#loaded_embedding_matrix = np.load('embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input-output pairs for LSTM\n",
    "\n",
    "Augmented sequences are being used only for the test datasets. Therefore, 15 sequences from augmented sequences were extracted and prepared for test datasets separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all augmented sequences\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open('all_augmented_sequences.csv', newline='', encoding='utf-8') as file:\n",
    "    csvreader_all_augmented_sequences = csv.reader(file)  # Ensure delimiter matches what was used in saving\n",
    "    rows_all_augmented_sequences = list(csvreader_all_augmented_sequences)\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "all_augmented_sequences = pd.DataFrame(rows_all_augmented_sequences)\n",
    "all_augmented_sequences = [list(filter(lambda x: x is not None, row)) for row in all_augmented_sequences.values.tolist()]\n",
    "\n",
    "\n",
    "with open('original_sequences_val.csv', newline='', encoding='utf-8') as file:\n",
    "    csvreader_original_sequences_val = csv.reader(file)  # Ensure delimiter matches what was used in saving\n",
    "    rows_original_sequences_val = list(csvreader_original_sequences_val)\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "original_sequences_val = pd.DataFrame(rows_original_sequences_val)\n",
    "original_sequences_val = [list(filter(lambda x: x is not None, row)) for row in original_sequences_val.values.tolist()]\n",
    "\n",
    "\n",
    "with open('all_sequences_train.csv', newline='', encoding='utf-8') as file:\n",
    "    csvreader_all_sequences_train = csv.reader(file)  # Ensure delimiter matches what was used in saving\n",
    "    rows_all_sequences_train = list(csvreader_all_sequences_train)\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "all_sequences_train = pd.DataFrame(rows_all_sequences_train)\n",
    "all_sequences_train = [list(filter(lambda x: x is not None, row)) for row in all_sequences_train.values.tolist()]\n",
    "\n",
    "\n",
    "with open('all_sequences_augmented_original.csv', newline='', encoding='utf-8') as file:\n",
    "    csvreader_all_sequences_augmented_original = csv.reader(file)  # Ensure delimiter matches what was used in saving\n",
    "    rows_all_sequences_augmented_original = list(csvreader_all_sequences_augmented_original)\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "all_sequences_augmented_original = pd.DataFrame(rows_all_sequences_augmented_original)\n",
    "all_sequences_augmented_original = [list(filter(lambda x: x is not None, row)) for row in all_sequences_augmented_original.values.tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([28, 19,  5, 31, 17, 19,  3, 19,  4, 19, 19, 19, 15, 31, 19,  5, 24,\n",
       "         4, 19, 17, 19,  5, 28, 19, 26, 26, 19,  5,  4, 24, 19, 19, 19,  5,\n",
       "        24, 19, 15, 31,  4, 19, 27, 19,  5, 28, 19,  4, 19,  4, 19,  5,  6,\n",
       "        28,  4, 19, 19,  4, 29, 19,  5,  6]),\n",
       " array([ 2, 31, 19, 19, 27, 19, 17, 19, 28, 19, 19, 19, 26, 19, 19, 28, 19,\n",
       "        19,  8, 19, 28, 19, 19, 27, 19, 19, 19, 19, 15, 31, 19, 19, 23, 19,\n",
       "         8, 19, 19,  8,  4, 19, 28, 19, 19,  8, 19, 28, 19, 19, 19, 19, 28]),\n",
       " array([ 2, 31, 19, 19, 28, 19,  4, 17, 19,  5,  2,  2,  2, 31, 19, 19,  8,\n",
       "        19, 28, 19, 15, 31, 19,  5, 31, 19, 19, 19, 19,  8, 19, 17, 19, 28,\n",
       "        19, 15, 31,  4, 14,  5, 31, 19,  8, 19, 28, 19, 17, 19, 28, 19, 19,\n",
       "        28, 19, 19, 19, 23, 19, 27]),\n",
       " array([ 2, 31, 19, 27, 19, 19, 19, 28, 19, 23, 19,  8,  0, 28, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19,  8, 19, 28, 19, 15, 31, 17, 19, 19, 28, 19,\n",
       "        19, 19, 19, 28, 19, 19,  4, 19, 28, 19, 19, 19, 27, 19, 28, 19, 19,\n",
       "        27, 19]),\n",
       " array([ 9,  2,  2,  2, 24,  4, 19, 26, 19, 15, 24, 19, 19, 28, 28, 28,  4,\n",
       "         0, 27, 17, 19,  4, 28,  4, 19, 15, 24, 19, 17, 19, 26, 19, 15, 31,\n",
       "        17, 19,  4, 19,  0,  4, 19, 15, 31, 19, 29, 19, 15, 31, 19, 28, 19,\n",
       "         4, 19, 17, 19, 15,  2, 31, 19, 19, 15, 31]),\n",
       " array([ 9, 19, 15, 28, 26, 19, 28, 19, 19,  0, 19,  4, 15,  2, 31, 19,  4,\n",
       "        15, 21, 28, 28, 28,  4,  5,  2, 31, 17,  0,  4, 19, 26, 19, 15,  2,\n",
       "        15, 31, 19, 15, 24, 26, 23, 19, 28, 15, 31, 19, 15, 24, 19, 17, 19,\n",
       "        15, 31,  4, 15, 28, 28,  4, 15]),\n",
       " array([ 9, 19, 19, 19, 15, 28, 15, 24, 26, 19, 28,  5, 31, 19]),\n",
       " array([ 9,  2, 31, 19, 16,  5,  2, 31, 17, 19, 28, 15,  4, 31, 19, 19, 18,\n",
       "        19, 28, 19, 28, 19, 19,  0, 18, 26, 26, 27, 19, 28, 14, 28, 17, 18,\n",
       "        19, 19,  4,  5,  9,  2, 19, 27,  4,  0, 27,  0, 27, 14,  2, 28, 28,\n",
       "         2, 20]),\n",
       " array([ 9,  2, 31, 19, 19, 27,  4, 19, 19,  5,  9, 31, 19,  5,  4,  2, 24,\n",
       "        17, 19,  4, 19, 28, 28, 18, 19,  0,  4, 19, 27,  0,  5,  2,  4, 31,\n",
       "        19,  4, 19,  4, 21, 31, 19,  0, 19, 27, 19, 19,  0,  4, 31, 19, 26,\n",
       "        26, 22, 30, 30,  4]),\n",
       " array([ 9, 31, 19, 19,  0, 19, 19, 31, 19, 19, 27, 15,  4, 24, 19, 19, 28,\n",
       "        19, 27,  9, 19, 19, 19, 28,  4, 19, 28,  4, 19, 19,  4, 14, 28, 19,\n",
       "         4, 14, 31, 18, 19,  4, 17, 19, 10,  4, 18, 19, 19, 19, 27, 19, 19,\n",
       "        18, 19,  4, 28, 28, 19, 19, 19]),\n",
       " array([ 9,  2,  2,  2,  2, 31, 19, 19, 14, 14, 14,  0, 17, 27, 19, 19, 28,\n",
       "         5,  2,  2, 31, 19, 19, 19, 28, 28, 28, 19, 19, 19, 19,  5,  2, 24,\n",
       "        23,  0, 27, 19, 19,  5,  2,  2,  2, 31, 19, 19,  5,  2,  2, 31, 28,\n",
       "        28, 14, 14, 19, 19]),\n",
       " array([ 9, 19, 28, 19, 28,  5,  2,  2, 31, 19, 19,  5,  2,  2, 31, 19,  5,\n",
       "         2,  2,  2,  6, 31, 17, 19, 19,  5, 31, 19, 19,  5,  2,  2, 31, 19,\n",
       "        19,  3, 19, 19, 28, 28, 28, 19, 19, 19, 28,  5,  2, 21, 24, 28, 19,\n",
       "         5, 21,  2,  2, 31, 17, 19, 19, 19,  3, 19]),\n",
       " array([ 9,  2, 31, 19,  4, 19, 19,  4, 19, 19, 19,  4, 19,  5,  2,  2, 31,\n",
       "        19, 19,  3,  4, 19, 19, 19, 29, 19, 19, 19,  3,  4, 19,  5,  2,  2,\n",
       "         4,  2, 31, 19,  4, 19,  5,  2, 31,  4, 19, 19,  3, 28,  5, 31, 19,\n",
       "         4, 19, 19,  4]),\n",
       " array([ 9, 19, 27, 19, 26, 27, 19,  8, 19, 19, 19, 28, 19,  8, 19, 19, 11,\n",
       "        19,  5, 31, 19, 28, 28, 19, 28, 18, 19, 28, 14, 19, 19,  8, 19, 26,\n",
       "        19, 19, 26, 17, 19, 26, 28, 28, 19, 19, 19, 19, 19, 26, 28,  6, 19,\n",
       "         8]),\n",
       " array([ 9, 19, 19, 28, 19, 28, 19, 11, 19, 26, 19, 17, 19, 19, 26, 27, 19,\n",
       "        13, 19, 19, 28, 28, 18, 19, 26, 25, 25, 19, 26, 19, 26, 28, 19,  8,\n",
       "         6, 19,  8, 19, 19, 19,  8,  5,  2, 31,  2, 28,  2, 31]),\n",
       " array([ 9, 26, 19, 19, 19, 26,  8, 19, 19, 17, 19,  8, 19, 19,  8, 19, 28,\n",
       "        19, 19, 26, 19, 28, 19, 19, 17, 19, 17,  8, 19, 19, 19, 19, 19, 26,\n",
       "        19, 19, 28, 28, 19, 26, 19, 19])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode sequences to integers\n",
    "# Apply encoding to each sequence for train dataset\n",
    "encoded_sequences_augmented_train = [encode_sequence(sequence) for sequence in all_sequences_train]\n",
    "encoded_sequences_augmented_train\n",
    "\n",
    "# Apply encoding to each sequence for val dataset\n",
    "encoded_sequences_augmented_val = [encode_sequence(sequence) for sequence in original_sequences_val]\n",
    "encoded_sequences_augmented_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2, 20,  8,  5, 28,  4, 19, 19, 28, 15, 31, 17,  6, 13, 18, 26, 26,\n",
       "        27,  0,  2, 24, 23]),\n",
       " array([12,  8,  5, 31, 19, 19, 15,  6, 28, 28, 14,  2,  2,  4, 27, 13, 18,\n",
       "         0, 17, 26, 26, 23, 23]),\n",
       " array([28, 28, 15, 31,  8,  5,  9,  9, 27, 19, 19, 26, 26, 23, 23,  0,  4,\n",
       "        18, 17,  6, 13]),\n",
       " array([19, 19,  3,  3, 15, 31, 17,  4,  2,  2,  6, 28, 28,  5, 24, 26, 26,\n",
       "        25, 25, 15,  9]),\n",
       " array([18, 28, 19,  8,  5, 24,  4, 15, 31, 19, 26, 26, 28, 14,  2, 20,  8,\n",
       "         2,  6, 13]),\n",
       " array([ 9,  9,  2,  2, 21, 21, 28, 28,  6, 19, 19, 17,  8, 15, 31,  4, 24,\n",
       "        26, 26, 23, 23,  0, 27, 18]),\n",
       " array([21, 21, 31, 17, 19, 19,  5,  9, 15, 14, 11, 11, 14, 28, 28,  6, 13,\n",
       "        18, 26, 26, 22, 30, 30,  4,  0, 27,  8, 10]),\n",
       " array([24, 19, 19,  5,  2, 31, 26, 28, 28,  4, 15, 14, 11, 11, 14,  0, 17,\n",
       "        26, 23, 23]),\n",
       " array([10,  4, 31, 17, 19, 19,  5, 28, 28, 15, 24,  8,  0, 18, 27, 14,  2,\n",
       "         2, 21, 21,  9,  9, 13]),\n",
       " array([31, 17, 26, 19, 19, 28, 24,  4, 14, 26, 28, 15,  9,  2,  9, 27,  0,\n",
       "         2,  6, 12,  8,  5,  1,  1]),\n",
       " array([22, 30,  4, 18, 19, 19,  5,  2,  2, 24, 26, 26, 28, 14, 28, 15,  9,\n",
       "         9, 27, 13]),\n",
       " array([ 7,  7,  5, 31,  4, 19, 13, 15, 28, 28, 19, 26, 26, 27, 17, 18,  0,\n",
       "         2, 24, 23, 23]),\n",
       " array([ 5,  2, 28, 28, 17, 19, 19, 27, 14, 26, 26, 23, 23,  0, 18, 15, 31,\n",
       "         4, 24,  8,  2]),\n",
       " array([ 4, 24, 28, 19, 19, 28, 15,  2,  2,  9, 26, 26,  5, 31, 17, 18, 27,\n",
       "         0, 27,  9, 13]),\n",
       " array([21, 21, 31, 19,  4,  2,  2, 19, 26, 27,  0, 17,  5, 24, 26,  8,  3,\n",
       "         3, 28, 28, 18, 15, 14, 11]),\n",
       " array([19, 19, 26, 26,  5, 31, 28, 28, 15,  2,  2, 21, 21,  9,  9, 27, 17,\n",
       "         0,  4, 24, 23, 23]),\n",
       " array([16,  5,  2, 28, 28, 19, 19,  4, 17, 15, 24, 23, 23,  0, 27,  8, 26,\n",
       "        26,  3,  3]),\n",
       " array([28, 28, 19, 19,  4, 24, 26, 26, 22, 30, 30,  4, 21,  2,  2, 21, 31,\n",
       "        17, 15, 14,  8,  5]),\n",
       " array([ 0,  4, 24, 26, 26, 19, 19, 17, 15, 28, 28,  5,  2,  2, 31, 14, 11,\n",
       "        11, 14,  8,  3,  3]),\n",
       " array([24, 19, 15, 28, 28, 29, 19, 27,  0,  4,  5,  2,  2, 31, 17, 26, 26,\n",
       "         3,  3,  4, 14, 11]),\n",
       " array([ 1, 31, 19, 17, 19,  3,  3, 15, 28, 28,  4, 27,  5,  2,  2, 20,  8,\n",
       "        26, 26, 23, 23]),\n",
       " array([14, 19, 19, 17,  5, 31, 26, 27,  0,  4, 18, 26, 28, 28, 29, 15, 24,\n",
       "         8,  3,  3]),\n",
       " array([26,  5,  2,  2, 24, 19, 27, 19, 26, 22, 30,  4, 15, 28, 28, 29, 29,\n",
       "        15, 31, 17,  8,  0]),\n",
       " array([ 2,  2, 21, 24, 17, 19, 26, 19,  0, 18, 26, 23, 23,  0,  5, 28, 28,\n",
       "        15, 31,  4, 27,  8]),\n",
       " array([ 5,  2, 31, 19, 19, 27, 17, 26, 26, 28, 28, 15,  2, 24,  4, 18,  0,\n",
       "         0,  4, 14, 11]),\n",
       " array([ 4, 15, 31, 19,  5,  9,  9,  6,  2, 24, 19, 28, 28, 18, 27, 17,  0,\n",
       "         2, 21, 21]),\n",
       " array([13,  5, 21, 31, 19, 19, 28, 28, 29, 15, 21,  9,  4,  0, 27,  8,  3,\n",
       "         3,  4, 18, 26, 26, 22, 30, 30]),\n",
       " array([28, 28,  5, 24, 19, 19, 26, 25, 15, 31, 17, 26, 22, 30, 30,  4, 29,\n",
       "        15,  2,  2,  9,  9, 13, 18, 27])]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "encoded_sequences_augmented_train\n",
    "\n",
    "# test data\n",
    "encoded_sequences_augmented_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_aug_train, y_emb_aug_train = create_input_output_pairs_mtm(encoded_sequences_augmented_train, 4)\n",
    "x_emb_aug_val, y_emb_aug_val = create_input_output_pairs_mtm(encoded_sequences_augmented_val, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to Numpy Arrays\n",
    "x_emb_aug_train = np.array(x_emb_aug_train)\n",
    "x_emb_aug_val = np.array(x_emb_aug_val)\n",
    "\n",
    "# Convert outputs to a one-hot-encoded vector\n",
    "y_emb_aug_train_one_hot = to_categorical(y_emb_aug_train, num_classes=num_classes)\n",
    "y_emb_aug_val_one_hot = to_categorical(y_emb_aug_val, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_emb_aug_train: (2464, 4)\n",
      "Shape of y_emb_aug_train_one_hot: (2464, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(\"Shape of x_emb_aug_train:\", x_emb_aug_train.shape)\n",
    "print(\"Shape of y_emb_aug_train_one_hot:\", y_emb_aug_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline LSTM with trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 4, 100)            3200      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 4, 64)             42240     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 47,520\n",
      "Trainable params: 44,320\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, TimeDistributed, Dense, Embedding\n",
    "import random\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 25\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Parameters\n",
    "input_length = 4  # Length of input sequences\n",
    "num_moves = len(embedding_matrix_augmented)  # Number of unique moves\n",
    "embedding_dim = len(embedding_matrix_augmented[0])  # Dimension of Word2Vec embeddings\n",
    "\n",
    "# Define the LSTM model with the Embedding layer\n",
    "Emb_model_aug = Sequential([\n",
    "    # Embedding layer with pre-trained Word2Vec weights\n",
    "    Embedding(input_dim=num_moves, output_dim=embedding_dim, weights=[embedding_matrix_augmented], trainable=False, \n",
    "              input_length=input_length),\n",
    "    \n",
    "    # LSTM layer\n",
    "    LSTM(64, return_sequences=True),\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # TimeDistributed Dense layer for output at each time step\n",
    "    TimeDistributed(Dense(num_moves, activation='softmax'))  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "Emb_model_aug.compile(optimizer='adam', \n",
    "                           loss='categorical_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "Emb_model_aug.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "154/154 [==============================] - 2s 6ms/step - loss: 3.1838 - accuracy: 0.1450 - val_loss: 2.5336 - val_accuracy: 0.4066\n",
      "Epoch 2/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8963 - accuracy: 0.1653 - val_loss: 2.5362 - val_accuracy: 0.3937\n",
      "Epoch 3/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8539 - accuracy: 0.1791 - val_loss: 2.5060 - val_accuracy: 0.4021\n",
      "Epoch 4/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8426 - accuracy: 0.1678 - val_loss: 2.4739 - val_accuracy: 0.4037\n",
      "Epoch 5/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8072 - accuracy: 0.1803 - val_loss: 2.4737 - val_accuracy: 0.4034\n",
      "Epoch 6/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8003 - accuracy: 0.1803 - val_loss: 2.4569 - val_accuracy: 0.4027\n",
      "Epoch 7/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7868 - accuracy: 0.1794 - val_loss: 2.4327 - val_accuracy: 0.4030\n",
      "Epoch 8/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7772 - accuracy: 0.1854 - val_loss: 2.4273 - val_accuracy: 0.4040\n",
      "Epoch 9/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7599 - accuracy: 0.1799 - val_loss: 2.4257 - val_accuracy: 0.4014\n",
      "Epoch 10/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.7518 - accuracy: 0.1810 - val_loss: 2.4098 - val_accuracy: 0.3992\n",
      "Epoch 11/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7200 - accuracy: 0.1916 - val_loss: 2.4041 - val_accuracy: 0.3998\n",
      "Epoch 12/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7061 - accuracy: 0.2020 - val_loss: 2.4018 - val_accuracy: 0.3811\n",
      "Epoch 13/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.6861 - accuracy: 0.2056 - val_loss: 2.4021 - val_accuracy: 0.3431\n",
      "Epoch 14/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.6689 - accuracy: 0.2178 - val_loss: 2.3555 - val_accuracy: 0.3911\n",
      "Epoch 15/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.6691 - accuracy: 0.2111 - val_loss: 2.3400 - val_accuracy: 0.4034\n",
      "Epoch 16/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.6138 - accuracy: 0.2252 - val_loss: 2.3525 - val_accuracy: 0.3763\n",
      "Epoch 17/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5891 - accuracy: 0.2341 - val_loss: 2.3130 - val_accuracy: 0.3979\n",
      "Epoch 18/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.5829 - accuracy: 0.2406 - val_loss: 2.3011 - val_accuracy: 0.3992\n",
      "Epoch 19/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5676 - accuracy: 0.2425 - val_loss: 2.3222 - val_accuracy: 0.3566\n",
      "Epoch 20/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5511 - accuracy: 0.2465 - val_loss: 2.2664 - val_accuracy: 0.4059\n",
      "Epoch 21/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5244 - accuracy: 0.2646 - val_loss: 2.3019 - val_accuracy: 0.3744\n",
      "Epoch 22/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4778 - accuracy: 0.2659 - val_loss: 2.3251 - val_accuracy: 0.3744\n",
      "Epoch 23/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4853 - accuracy: 0.2695 - val_loss: 2.2674 - val_accuracy: 0.3966\n",
      "Epoch 24/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4428 - accuracy: 0.2860 - val_loss: 2.2500 - val_accuracy: 0.3995\n",
      "Epoch 25/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4452 - accuracy: 0.2788 - val_loss: 2.2320 - val_accuracy: 0.4005\n",
      "Epoch 26/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4131 - accuracy: 0.2899 - val_loss: 2.2163 - val_accuracy: 0.4072\n",
      "Epoch 27/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4257 - accuracy: 0.2817 - val_loss: 2.2354 - val_accuracy: 0.3966\n",
      "Epoch 28/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3759 - accuracy: 0.2964 - val_loss: 2.2042 - val_accuracy: 0.4072\n",
      "Epoch 29/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3796 - accuracy: 0.2943 - val_loss: 2.2214 - val_accuracy: 0.4027\n",
      "Epoch 30/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3249 - accuracy: 0.3091 - val_loss: 2.2161 - val_accuracy: 0.4069\n",
      "Epoch 31/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3372 - accuracy: 0.3038 - val_loss: 2.2017 - val_accuracy: 0.4124\n",
      "Epoch 32/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.3334 - accuracy: 0.3042 - val_loss: 2.2230 - val_accuracy: 0.3908\n",
      "Epoch 33/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3016 - accuracy: 0.3127 - val_loss: 2.2010 - val_accuracy: 0.4156\n",
      "Epoch 34/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.3034 - accuracy: 0.3096 - val_loss: 2.1830 - val_accuracy: 0.4211\n",
      "Epoch 35/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2931 - accuracy: 0.3147 - val_loss: 2.2234 - val_accuracy: 0.3979\n",
      "Epoch 36/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2584 - accuracy: 0.3221 - val_loss: 2.2190 - val_accuracy: 0.4014\n",
      "Epoch 37/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2530 - accuracy: 0.3163 - val_loss: 2.1918 - val_accuracy: 0.4098\n",
      "Epoch 38/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2353 - accuracy: 0.3250 - val_loss: 2.1859 - val_accuracy: 0.4149\n",
      "Epoch 39/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2411 - accuracy: 0.3261 - val_loss: 2.2123 - val_accuracy: 0.4133\n",
      "Epoch 40/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2334 - accuracy: 0.3266 - val_loss: 2.1945 - val_accuracy: 0.4188\n",
      "Epoch 41/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2268 - accuracy: 0.3308 - val_loss: 2.1975 - val_accuracy: 0.4101\n",
      "Epoch 42/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2449 - accuracy: 0.3166 - val_loss: 2.2232 - val_accuracy: 0.3895\n",
      "Epoch 43/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1820 - accuracy: 0.3392 - val_loss: 2.1986 - val_accuracy: 0.4191\n",
      "Epoch 44/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.2051 - accuracy: 0.3346 - val_loss: 2.1998 - val_accuracy: 0.4146\n",
      "Epoch 45/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1861 - accuracy: 0.3361 - val_loss: 2.1911 - val_accuracy: 0.4053\n",
      "Epoch 46/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1732 - accuracy: 0.3341 - val_loss: 2.1935 - val_accuracy: 0.4198\n",
      "Epoch 47/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1626 - accuracy: 0.3404 - val_loss: 2.1904 - val_accuracy: 0.4117\n",
      "Epoch 48/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1912 - accuracy: 0.3281 - val_loss: 2.1620 - val_accuracy: 0.4224\n",
      "Epoch 49/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.1824 - accuracy: 0.3352 - val_loss: 2.1737 - val_accuracy: 0.4230\n",
      "Epoch 50/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1614 - accuracy: 0.3351 - val_loss: 2.1812 - val_accuracy: 0.4224\n",
      "Epoch 51/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1720 - accuracy: 0.3285 - val_loss: 2.2059 - val_accuracy: 0.4079\n",
      "Epoch 52/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1345 - accuracy: 0.3492 - val_loss: 2.1810 - val_accuracy: 0.4169\n",
      "Epoch 53/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1322 - accuracy: 0.3477 - val_loss: 2.1817 - val_accuracy: 0.4201\n",
      "Epoch 54/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1396 - accuracy: 0.3387 - val_loss: 2.2160 - val_accuracy: 0.4014\n",
      "Epoch 55/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1171 - accuracy: 0.3565 - val_loss: 2.2233 - val_accuracy: 0.3940\n",
      "Epoch 56/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0945 - accuracy: 0.3527 - val_loss: 2.1766 - val_accuracy: 0.4149\n",
      "Epoch 57/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1232 - accuracy: 0.3456 - val_loss: 2.1707 - val_accuracy: 0.4230\n",
      "Epoch 58/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1080 - accuracy: 0.3518 - val_loss: 2.1901 - val_accuracy: 0.4117\n",
      "Epoch 59/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1172 - accuracy: 0.3409 - val_loss: 2.1536 - val_accuracy: 0.4188\n",
      "Epoch 60/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1081 - accuracy: 0.3535 - val_loss: 2.2056 - val_accuracy: 0.4043\n",
      "Epoch 61/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1123 - accuracy: 0.3522 - val_loss: 2.1851 - val_accuracy: 0.4162\n",
      "Epoch 62/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0837 - accuracy: 0.3589 - val_loss: 2.1769 - val_accuracy: 0.4207\n",
      "Epoch 63/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0836 - accuracy: 0.3546 - val_loss: 2.1809 - val_accuracy: 0.4178\n",
      "Epoch 64/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0633 - accuracy: 0.3598 - val_loss: 2.1872 - val_accuracy: 0.4095\n",
      "Epoch 65/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.0749 - accuracy: 0.3594 - val_loss: 2.1598 - val_accuracy: 0.4227\n",
      "Epoch 66/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0893 - accuracy: 0.3558 - val_loss: 2.1763 - val_accuracy: 0.4156\n",
      "Epoch 67/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0559 - accuracy: 0.3654 - val_loss: 2.1871 - val_accuracy: 0.4005\n",
      "Epoch 68/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0681 - accuracy: 0.3543 - val_loss: 2.1712 - val_accuracy: 0.4143\n",
      "Epoch 69/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0646 - accuracy: 0.3623 - val_loss: 2.1683 - val_accuracy: 0.4050\n",
      "Epoch 70/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0763 - accuracy: 0.3563 - val_loss: 2.1965 - val_accuracy: 0.4046\n",
      "Epoch 71/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0565 - accuracy: 0.3592 - val_loss: 2.1670 - val_accuracy: 0.4146\n",
      "Epoch 72/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0522 - accuracy: 0.3616 - val_loss: 2.1770 - val_accuracy: 0.4066\n",
      "Epoch 73/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0343 - accuracy: 0.3556 - val_loss: 2.1799 - val_accuracy: 0.4040\n",
      "Epoch 74/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0518 - accuracy: 0.3651 - val_loss: 2.1845 - val_accuracy: 0.4085\n",
      "Epoch 75/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0391 - accuracy: 0.3604 - val_loss: 2.2138 - val_accuracy: 0.3872\n",
      "Epoch 76/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0467 - accuracy: 0.3630 - val_loss: 2.1768 - val_accuracy: 0.4130\n",
      "Epoch 77/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0326 - accuracy: 0.3684 - val_loss: 2.1517 - val_accuracy: 0.4185\n",
      "Epoch 78/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.0289 - accuracy: 0.3685 - val_loss: 2.1878 - val_accuracy: 0.4069\n",
      "Epoch 79/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0278 - accuracy: 0.3730 - val_loss: 2.1807 - val_accuracy: 0.4082\n",
      "Epoch 80/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0287 - accuracy: 0.3636 - val_loss: 2.1836 - val_accuracy: 0.3992\n",
      "Epoch 81/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0736 - accuracy: 0.3497 - val_loss: 2.1766 - val_accuracy: 0.4111\n",
      "Epoch 82/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0095 - accuracy: 0.3637 - val_loss: 2.1835 - val_accuracy: 0.3889\n",
      "Epoch 83/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0092 - accuracy: 0.3685 - val_loss: 2.1838 - val_accuracy: 0.4043\n",
      "Epoch 84/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9994 - accuracy: 0.3718 - val_loss: 2.1446 - val_accuracy: 0.4166\n",
      "Epoch 85/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.0172 - accuracy: 0.3651 - val_loss: 2.1670 - val_accuracy: 0.4149\n",
      "Epoch 86/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0138 - accuracy: 0.3692 - val_loss: 2.1817 - val_accuracy: 0.4014\n",
      "Epoch 87/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0056 - accuracy: 0.3659 - val_loss: 2.1891 - val_accuracy: 0.3956\n",
      "Epoch 88/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.9791 - accuracy: 0.3727 - val_loss: 2.2015 - val_accuracy: 0.3963\n",
      "Epoch 89/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.0085 - accuracy: 0.3638 - val_loss: 2.1837 - val_accuracy: 0.3930\n",
      "Epoch 90/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9716 - accuracy: 0.3804 - val_loss: 2.2088 - val_accuracy: 0.3760\n",
      "Epoch 91/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9753 - accuracy: 0.3740 - val_loss: 2.1766 - val_accuracy: 0.3982\n",
      "Epoch 92/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9865 - accuracy: 0.3740 - val_loss: 2.1800 - val_accuracy: 0.3921\n",
      "Epoch 93/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9718 - accuracy: 0.3766 - val_loss: 2.1713 - val_accuracy: 0.4114\n",
      "Epoch 94/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9883 - accuracy: 0.3667 - val_loss: 2.1736 - val_accuracy: 0.4069\n",
      "Epoch 95/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.3687 - val_loss: 2.1855 - val_accuracy: 0.4014\n",
      "Epoch 96/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.9873 - accuracy: 0.3803 - val_loss: 2.2386 - val_accuracy: 0.3653\n",
      "Epoch 97/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9732 - accuracy: 0.3737 - val_loss: 2.1729 - val_accuracy: 0.4021\n",
      "Epoch 98/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9779 - accuracy: 0.3793 - val_loss: 2.1783 - val_accuracy: 0.4001\n",
      "Epoch 99/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9386 - accuracy: 0.3791 - val_loss: 2.1754 - val_accuracy: 0.4027\n",
      "Epoch 100/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9528 - accuracy: 0.3791 - val_loss: 2.1730 - val_accuracy: 0.4037\n",
      "Epoch 101/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9416 - accuracy: 0.3813 - val_loss: 2.1806 - val_accuracy: 0.3979\n",
      "Epoch 102/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9560 - accuracy: 0.3723 - val_loss: 2.2028 - val_accuracy: 0.3827\n",
      "Epoch 103/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9769 - accuracy: 0.3686 - val_loss: 2.2017 - val_accuracy: 0.3824\n",
      "Epoch 104/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9523 - accuracy: 0.3803 - val_loss: 2.2095 - val_accuracy: 0.3824\n",
      "Epoch 105/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9536 - accuracy: 0.3827 - val_loss: 2.2012 - val_accuracy: 0.3811\n",
      "Epoch 106/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9667 - accuracy: 0.3787 - val_loss: 2.2036 - val_accuracy: 0.3818\n",
      "Epoch 107/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9296 - accuracy: 0.3811 - val_loss: 2.1797 - val_accuracy: 0.3930\n",
      "Epoch 108/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9226 - accuracy: 0.3941 - val_loss: 2.2206 - val_accuracy: 0.3708\n",
      "Epoch 109/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9350 - accuracy: 0.3815 - val_loss: 2.2010 - val_accuracy: 0.3908\n",
      "Epoch 110/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.9403 - accuracy: 0.3807 - val_loss: 2.1880 - val_accuracy: 0.3956\n",
      "Epoch 111/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9233 - accuracy: 0.3876 - val_loss: 2.1916 - val_accuracy: 0.3889\n",
      "Epoch 112/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9221 - accuracy: 0.3858 - val_loss: 2.2158 - val_accuracy: 0.3760\n",
      "Epoch 113/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9206 - accuracy: 0.3897 - val_loss: 2.2446 - val_accuracy: 0.3544\n",
      "Epoch 114/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9463 - accuracy: 0.3759 - val_loss: 2.1988 - val_accuracy: 0.3895\n",
      "Epoch 115/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9032 - accuracy: 0.4030 - val_loss: 2.2302 - val_accuracy: 0.3727\n",
      "Epoch 116/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9346 - accuracy: 0.3741 - val_loss: 2.1731 - val_accuracy: 0.3985\n",
      "Epoch 117/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9084 - accuracy: 0.3900 - val_loss: 2.1742 - val_accuracy: 0.3959\n",
      "Epoch 118/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.9272 - accuracy: 0.3925 - val_loss: 2.2199 - val_accuracy: 0.3669\n",
      "Epoch 119/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.9134 - accuracy: 0.3793 - val_loss: 2.2189 - val_accuracy: 0.3782\n",
      "Epoch 120/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9049 - accuracy: 0.3868 - val_loss: 2.1817 - val_accuracy: 0.3885\n",
      "Epoch 121/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9092 - accuracy: 0.3959 - val_loss: 2.1961 - val_accuracy: 0.3943\n",
      "Epoch 122/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8952 - accuracy: 0.3919 - val_loss: 2.1931 - val_accuracy: 0.3847\n",
      "Epoch 123/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9011 - accuracy: 0.3823 - val_loss: 2.1877 - val_accuracy: 0.3905\n",
      "Epoch 124/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8843 - accuracy: 0.3899 - val_loss: 2.1811 - val_accuracy: 0.3930\n",
      "Epoch 125/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8953 - accuracy: 0.3926 - val_loss: 2.1826 - val_accuracy: 0.3947\n",
      "Epoch 126/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9042 - accuracy: 0.3898 - val_loss: 2.2235 - val_accuracy: 0.3824\n",
      "Epoch 127/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9004 - accuracy: 0.3912 - val_loss: 2.1901 - val_accuracy: 0.3879\n",
      "Epoch 128/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8860 - accuracy: 0.3972 - val_loss: 2.1857 - val_accuracy: 0.3866\n",
      "Epoch 129/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8864 - accuracy: 0.3853 - val_loss: 2.2502 - val_accuracy: 0.3534\n",
      "Epoch 130/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8842 - accuracy: 0.3996 - val_loss: 2.2106 - val_accuracy: 0.3792\n",
      "Epoch 131/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8641 - accuracy: 0.3948 - val_loss: 2.1979 - val_accuracy: 0.3889\n",
      "Epoch 132/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8850 - accuracy: 0.3932 - val_loss: 2.1958 - val_accuracy: 0.3872\n",
      "Epoch 133/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8722 - accuracy: 0.3902 - val_loss: 2.1918 - val_accuracy: 0.3901\n",
      "Epoch 134/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8956 - accuracy: 0.3903 - val_loss: 2.1986 - val_accuracy: 0.3834\n",
      "Epoch 135/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8888 - accuracy: 0.3870 - val_loss: 2.2208 - val_accuracy: 0.3808\n",
      "Epoch 136/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8720 - accuracy: 0.3917 - val_loss: 2.1812 - val_accuracy: 0.4001\n",
      "Epoch 137/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8707 - accuracy: 0.3956 - val_loss: 2.1982 - val_accuracy: 0.3837\n",
      "Epoch 138/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8545 - accuracy: 0.4015 - val_loss: 2.1999 - val_accuracy: 0.3895\n",
      "Epoch 139/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8645 - accuracy: 0.3937 - val_loss: 2.2137 - val_accuracy: 0.3779\n",
      "Epoch 140/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8699 - accuracy: 0.3926 - val_loss: 2.2099 - val_accuracy: 0.3789\n",
      "Epoch 141/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8689 - accuracy: 0.3923 - val_loss: 2.1849 - val_accuracy: 0.3927\n",
      "Epoch 142/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8558 - accuracy: 0.3994 - val_loss: 2.2138 - val_accuracy: 0.3718\n",
      "Epoch 143/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8843 - accuracy: 0.3911 - val_loss: 2.2362 - val_accuracy: 0.3557\n",
      "Epoch 144/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8495 - accuracy: 0.4067 - val_loss: 2.2048 - val_accuracy: 0.3808\n",
      "Epoch 145/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8698 - accuracy: 0.3963 - val_loss: 2.2108 - val_accuracy: 0.3898\n",
      "Epoch 146/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8319 - accuracy: 0.4045 - val_loss: 2.2239 - val_accuracy: 0.3669\n",
      "Epoch 147/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8309 - accuracy: 0.4107 - val_loss: 2.2343 - val_accuracy: 0.3531\n",
      "Epoch 148/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8576 - accuracy: 0.3946 - val_loss: 2.2263 - val_accuracy: 0.3628\n",
      "Epoch 149/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8683 - accuracy: 0.3987 - val_loss: 2.2477 - val_accuracy: 0.3599\n",
      "Epoch 150/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8499 - accuracy: 0.3994 - val_loss: 2.2168 - val_accuracy: 0.3624\n",
      "Epoch 151/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8326 - accuracy: 0.3984 - val_loss: 2.2170 - val_accuracy: 0.3708\n",
      "Epoch 152/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8404 - accuracy: 0.4050 - val_loss: 2.2159 - val_accuracy: 0.3753\n",
      "Epoch 153/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8416 - accuracy: 0.3958 - val_loss: 2.1956 - val_accuracy: 0.3908\n",
      "Epoch 154/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8251 - accuracy: 0.4099 - val_loss: 2.2325 - val_accuracy: 0.3686\n",
      "Epoch 155/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8209 - accuracy: 0.4066 - val_loss: 2.2416 - val_accuracy: 0.3647\n",
      "Epoch 156/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8590 - accuracy: 0.4015 - val_loss: 2.2032 - val_accuracy: 0.3831\n",
      "Epoch 157/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8339 - accuracy: 0.3993 - val_loss: 2.2451 - val_accuracy: 0.3715\n",
      "Epoch 158/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8290 - accuracy: 0.4026 - val_loss: 2.2863 - val_accuracy: 0.3383\n",
      "Epoch 159/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8297 - accuracy: 0.4007 - val_loss: 2.2186 - val_accuracy: 0.3850\n",
      "Epoch 160/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8390 - accuracy: 0.4001 - val_loss: 2.2215 - val_accuracy: 0.3689\n",
      "Epoch 161/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8265 - accuracy: 0.3995 - val_loss: 2.2277 - val_accuracy: 0.3724\n",
      "Epoch 162/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8210 - accuracy: 0.4118 - val_loss: 2.2336 - val_accuracy: 0.3669\n",
      "Epoch 163/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8131 - accuracy: 0.4170 - val_loss: 2.2390 - val_accuracy: 0.3631\n",
      "Epoch 164/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8163 - accuracy: 0.3989 - val_loss: 2.2339 - val_accuracy: 0.3602\n",
      "Epoch 165/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8223 - accuracy: 0.4026 - val_loss: 2.2147 - val_accuracy: 0.3682\n",
      "Epoch 166/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8176 - accuracy: 0.4099 - val_loss: 2.2521 - val_accuracy: 0.3518\n",
      "Epoch 167/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8308 - accuracy: 0.4110 - val_loss: 2.2158 - val_accuracy: 0.3657\n",
      "Epoch 168/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8146 - accuracy: 0.4147 - val_loss: 2.2220 - val_accuracy: 0.3689\n",
      "Epoch 169/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8259 - accuracy: 0.4067 - val_loss: 2.2457 - val_accuracy: 0.3547\n",
      "Epoch 170/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8124 - accuracy: 0.4031 - val_loss: 2.2349 - val_accuracy: 0.3708\n",
      "Epoch 171/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8127 - accuracy: 0.4122 - val_loss: 2.2511 - val_accuracy: 0.3560\n",
      "Epoch 172/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8186 - accuracy: 0.4042 - val_loss: 2.2506 - val_accuracy: 0.3499\n",
      "Epoch 173/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8143 - accuracy: 0.4081 - val_loss: 2.2304 - val_accuracy: 0.3769\n",
      "Epoch 174/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8197 - accuracy: 0.4082 - val_loss: 2.2167 - val_accuracy: 0.3792\n",
      "Epoch 175/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8128 - accuracy: 0.4043 - val_loss: 2.2524 - val_accuracy: 0.3495\n",
      "Epoch 176/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8155 - accuracy: 0.4071 - val_loss: 2.2228 - val_accuracy: 0.3686\n",
      "Epoch 177/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8096 - accuracy: 0.4067 - val_loss: 2.2398 - val_accuracy: 0.3599\n",
      "Epoch 178/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7970 - accuracy: 0.4164 - val_loss: 2.2398 - val_accuracy: 0.3689\n",
      "Epoch 179/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7946 - accuracy: 0.4143 - val_loss: 2.2348 - val_accuracy: 0.3631\n",
      "Epoch 180/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7985 - accuracy: 0.4089 - val_loss: 2.2557 - val_accuracy: 0.3502\n",
      "Epoch 181/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7948 - accuracy: 0.4133 - val_loss: 2.2425 - val_accuracy: 0.3586\n",
      "Epoch 182/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7897 - accuracy: 0.4093 - val_loss: 2.2716 - val_accuracy: 0.3444\n",
      "Epoch 183/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8169 - accuracy: 0.4109 - val_loss: 2.2361 - val_accuracy: 0.3582\n",
      "Epoch 184/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8015 - accuracy: 0.4058 - val_loss: 2.2685 - val_accuracy: 0.3434\n",
      "Epoch 185/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7888 - accuracy: 0.4138 - val_loss: 2.2578 - val_accuracy: 0.3657\n",
      "Epoch 186/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7854 - accuracy: 0.4178 - val_loss: 2.2624 - val_accuracy: 0.3450\n",
      "Epoch 187/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.4159 - val_loss: 2.2389 - val_accuracy: 0.3634\n",
      "Epoch 188/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7948 - accuracy: 0.4025 - val_loss: 2.2114 - val_accuracy: 0.3756\n",
      "Epoch 189/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.8013 - accuracy: 0.4115 - val_loss: 2.2451 - val_accuracy: 0.3557\n",
      "Epoch 190/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7984 - accuracy: 0.4132 - val_loss: 2.2933 - val_accuracy: 0.3463\n",
      "Epoch 191/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8011 - accuracy: 0.4181 - val_loss: 2.2754 - val_accuracy: 0.3492\n",
      "Epoch 192/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7825 - accuracy: 0.4179 - val_loss: 2.2164 - val_accuracy: 0.3789\n",
      "Epoch 193/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7938 - accuracy: 0.4178 - val_loss: 2.2189 - val_accuracy: 0.3721\n",
      "Epoch 194/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8004 - accuracy: 0.4050 - val_loss: 2.2238 - val_accuracy: 0.3711\n",
      "Epoch 195/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7564 - accuracy: 0.4243 - val_loss: 2.2579 - val_accuracy: 0.3466\n",
      "Epoch 196/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7816 - accuracy: 0.4121 - val_loss: 2.2510 - val_accuracy: 0.3640\n",
      "Epoch 197/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7669 - accuracy: 0.4174 - val_loss: 2.2128 - val_accuracy: 0.3753\n",
      "Epoch 198/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7930 - accuracy: 0.4074 - val_loss: 2.2589 - val_accuracy: 0.3492\n",
      "Epoch 199/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7862 - accuracy: 0.4118 - val_loss: 2.2092 - val_accuracy: 0.3811\n",
      "Epoch 200/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7799 - accuracy: 0.4212 - val_loss: 2.2438 - val_accuracy: 0.3615\n",
      "Epoch 201/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7613 - accuracy: 0.4239 - val_loss: 2.2305 - val_accuracy: 0.3727\n",
      "Epoch 202/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7896 - accuracy: 0.4155 - val_loss: 2.2439 - val_accuracy: 0.3644\n",
      "Epoch 203/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7787 - accuracy: 0.4176 - val_loss: 2.2780 - val_accuracy: 0.3634\n",
      "Epoch 204/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7691 - accuracy: 0.4168 - val_loss: 2.2323 - val_accuracy: 0.3621\n",
      "Epoch 205/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7709 - accuracy: 0.4163 - val_loss: 2.2407 - val_accuracy: 0.3650\n",
      "Epoch 206/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7589 - accuracy: 0.4281 - val_loss: 2.2652 - val_accuracy: 0.3566\n",
      "Epoch 207/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7605 - accuracy: 0.4229 - val_loss: 2.2293 - val_accuracy: 0.3698\n",
      "Epoch 208/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7542 - accuracy: 0.4314 - val_loss: 2.2692 - val_accuracy: 0.3486\n",
      "Epoch 209/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7712 - accuracy: 0.4160 - val_loss: 2.2771 - val_accuracy: 0.3492\n",
      "Epoch 210/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7759 - accuracy: 0.4132 - val_loss: 2.2574 - val_accuracy: 0.3563\n",
      "Epoch 211/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7715 - accuracy: 0.4082 - val_loss: 2.2870 - val_accuracy: 0.3363\n",
      "Epoch 212/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7460 - accuracy: 0.4292 - val_loss: 2.2425 - val_accuracy: 0.3715\n",
      "Epoch 213/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7740 - accuracy: 0.4158 - val_loss: 2.2536 - val_accuracy: 0.3660\n",
      "Epoch 214/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7554 - accuracy: 0.4203 - val_loss: 2.2580 - val_accuracy: 0.3634\n",
      "Epoch 215/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7686 - accuracy: 0.4135 - val_loss: 2.2415 - val_accuracy: 0.3705\n",
      "Epoch 216/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7598 - accuracy: 0.4156 - val_loss: 2.2582 - val_accuracy: 0.3631\n",
      "Epoch 217/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7455 - accuracy: 0.4236 - val_loss: 2.2662 - val_accuracy: 0.3618\n",
      "Epoch 218/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7726 - accuracy: 0.4190 - val_loss: 2.2560 - val_accuracy: 0.3615\n",
      "Epoch 219/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7396 - accuracy: 0.4310 - val_loss: 2.2529 - val_accuracy: 0.3518\n",
      "Epoch 220/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7522 - accuracy: 0.4234 - val_loss: 2.2755 - val_accuracy: 0.3473\n",
      "Epoch 221/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7549 - accuracy: 0.4259 - val_loss: 2.2650 - val_accuracy: 0.3657\n",
      "Epoch 222/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7723 - accuracy: 0.4267 - val_loss: 2.2672 - val_accuracy: 0.3608\n",
      "Epoch 223/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7429 - accuracy: 0.4157 - val_loss: 2.2477 - val_accuracy: 0.3586\n",
      "Epoch 224/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7476 - accuracy: 0.4220 - val_loss: 2.2397 - val_accuracy: 0.3727\n",
      "Epoch 225/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7517 - accuracy: 0.4305 - val_loss: 2.2553 - val_accuracy: 0.3579\n",
      "Epoch 226/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7384 - accuracy: 0.4223 - val_loss: 2.2316 - val_accuracy: 0.3682\n",
      "Epoch 227/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7264 - accuracy: 0.4314 - val_loss: 2.2228 - val_accuracy: 0.3818\n",
      "Epoch 228/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7589 - accuracy: 0.4221 - val_loss: 2.2679 - val_accuracy: 0.3537\n",
      "Epoch 229/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7690 - accuracy: 0.4217 - val_loss: 2.2456 - val_accuracy: 0.3660\n",
      "Epoch 230/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7344 - accuracy: 0.4245 - val_loss: 2.2411 - val_accuracy: 0.3676\n",
      "Epoch 231/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7561 - accuracy: 0.4220 - val_loss: 2.2579 - val_accuracy: 0.3653\n",
      "Epoch 232/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7178 - accuracy: 0.4362 - val_loss: 2.2778 - val_accuracy: 0.3570\n",
      "Epoch 233/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7406 - accuracy: 0.4250 - val_loss: 2.2967 - val_accuracy: 0.3434\n",
      "Epoch 234/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7465 - accuracy: 0.4182 - val_loss: 2.2405 - val_accuracy: 0.3721\n",
      "Epoch 235/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7302 - accuracy: 0.4286 - val_loss: 2.3185 - val_accuracy: 0.3254\n",
      "Epoch 236/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7380 - accuracy: 0.4282 - val_loss: 2.2646 - val_accuracy: 0.3563\n",
      "Epoch 237/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7352 - accuracy: 0.4318 - val_loss: 2.2656 - val_accuracy: 0.3608\n",
      "Epoch 238/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7444 - accuracy: 0.4215 - val_loss: 2.2655 - val_accuracy: 0.3576\n",
      "Epoch 239/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7398 - accuracy: 0.4332 - val_loss: 2.2777 - val_accuracy: 0.3476\n",
      "Epoch 240/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7498 - accuracy: 0.4205 - val_loss: 2.2552 - val_accuracy: 0.3637\n",
      "Epoch 241/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7271 - accuracy: 0.4301 - val_loss: 2.2620 - val_accuracy: 0.3524\n",
      "Epoch 242/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7211 - accuracy: 0.4350 - val_loss: 2.2844 - val_accuracy: 0.3502\n",
      "Epoch 243/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7299 - accuracy: 0.4306 - val_loss: 2.2368 - val_accuracy: 0.3734\n",
      "Epoch 244/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7413 - accuracy: 0.4211 - val_loss: 2.2901 - val_accuracy: 0.3557\n",
      "Epoch 245/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7345 - accuracy: 0.4185 - val_loss: 2.2561 - val_accuracy: 0.3650\n",
      "Epoch 246/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7401 - accuracy: 0.4181 - val_loss: 2.2564 - val_accuracy: 0.3531\n",
      "Epoch 247/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7215 - accuracy: 0.4318 - val_loss: 2.2820 - val_accuracy: 0.3444\n",
      "Epoch 248/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7256 - accuracy: 0.4295 - val_loss: 2.2529 - val_accuracy: 0.3640\n",
      "Epoch 249/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7479 - accuracy: 0.4188 - val_loss: 2.2637 - val_accuracy: 0.3595\n",
      "Epoch 250/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7144 - accuracy: 0.4223 - val_loss: 2.2498 - val_accuracy: 0.3611\n",
      "Epoch 251/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7216 - accuracy: 0.4265 - val_loss: 2.2515 - val_accuracy: 0.3705\n",
      "Epoch 252/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7530 - accuracy: 0.4224 - val_loss: 2.2633 - val_accuracy: 0.3631\n",
      "Epoch 253/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7338 - accuracy: 0.4294 - val_loss: 2.2544 - val_accuracy: 0.3686\n",
      "Epoch 254/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7244 - accuracy: 0.4313 - val_loss: 2.2353 - val_accuracy: 0.3711\n",
      "Epoch 255/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7094 - accuracy: 0.4336 - val_loss: 2.2788 - val_accuracy: 0.3512\n",
      "Epoch 256/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7237 - accuracy: 0.4381 - val_loss: 2.2633 - val_accuracy: 0.3718\n",
      "Epoch 257/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7257 - accuracy: 0.4197 - val_loss: 2.2833 - val_accuracy: 0.3528\n",
      "Epoch 258/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7211 - accuracy: 0.4317 - val_loss: 2.2494 - val_accuracy: 0.3702\n",
      "Epoch 259/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7241 - accuracy: 0.4346 - val_loss: 2.2605 - val_accuracy: 0.3573\n",
      "Epoch 260/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7312 - accuracy: 0.4260 - val_loss: 2.2486 - val_accuracy: 0.3618\n",
      "Epoch 261/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7186 - accuracy: 0.4318 - val_loss: 2.2748 - val_accuracy: 0.3621\n",
      "Epoch 262/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7200 - accuracy: 0.4331 - val_loss: 2.2946 - val_accuracy: 0.3399\n",
      "Epoch 263/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7342 - accuracy: 0.4269 - val_loss: 2.2921 - val_accuracy: 0.3508\n",
      "Epoch 264/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6904 - accuracy: 0.4449 - val_loss: 2.2764 - val_accuracy: 0.3586\n",
      "Epoch 265/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7290 - accuracy: 0.4346 - val_loss: 2.3085 - val_accuracy: 0.3499\n",
      "Epoch 266/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7223 - accuracy: 0.4331 - val_loss: 2.2688 - val_accuracy: 0.3628\n",
      "Epoch 267/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7192 - accuracy: 0.4241 - val_loss: 2.2749 - val_accuracy: 0.3489\n",
      "Epoch 268/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7195 - accuracy: 0.4287 - val_loss: 2.2773 - val_accuracy: 0.3537\n",
      "Epoch 269/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7060 - accuracy: 0.4408 - val_loss: 2.2887 - val_accuracy: 0.3434\n",
      "Epoch 270/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7183 - accuracy: 0.4379 - val_loss: 2.2561 - val_accuracy: 0.3702\n",
      "Epoch 271/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7055 - accuracy: 0.4321 - val_loss: 2.2710 - val_accuracy: 0.3599\n",
      "Epoch 272/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7047 - accuracy: 0.4374 - val_loss: 2.3013 - val_accuracy: 0.3528\n",
      "Epoch 273/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7052 - accuracy: 0.4288 - val_loss: 2.2825 - val_accuracy: 0.3624\n",
      "Epoch 274/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7227 - accuracy: 0.4317 - val_loss: 2.2563 - val_accuracy: 0.3686\n",
      "Epoch 275/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7121 - accuracy: 0.4328 - val_loss: 2.2852 - val_accuracy: 0.3389\n",
      "Epoch 276/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7067 - accuracy: 0.4414 - val_loss: 2.2454 - val_accuracy: 0.3692\n",
      "Epoch 277/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7232 - accuracy: 0.4436 - val_loss: 2.2545 - val_accuracy: 0.3669\n",
      "Epoch 278/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6997 - accuracy: 0.4396 - val_loss: 2.3335 - val_accuracy: 0.3367\n",
      "Epoch 279/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6993 - accuracy: 0.4345 - val_loss: 2.2593 - val_accuracy: 0.3650\n",
      "Epoch 280/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6914 - accuracy: 0.4424 - val_loss: 2.2751 - val_accuracy: 0.3599\n",
      "Epoch 281/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6979 - accuracy: 0.4354 - val_loss: 2.2778 - val_accuracy: 0.3595\n",
      "Epoch 282/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7162 - accuracy: 0.4190 - val_loss: 2.2547 - val_accuracy: 0.3657\n",
      "Epoch 283/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6933 - accuracy: 0.4325 - val_loss: 2.3147 - val_accuracy: 0.3247\n",
      "Epoch 284/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6884 - accuracy: 0.4266 - val_loss: 2.2646 - val_accuracy: 0.3563\n",
      "Epoch 285/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7036 - accuracy: 0.4408 - val_loss: 2.2751 - val_accuracy: 0.3682\n",
      "Epoch 286/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6984 - accuracy: 0.4433 - val_loss: 2.2985 - val_accuracy: 0.3450\n",
      "Epoch 287/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6864 - accuracy: 0.4375 - val_loss: 2.2832 - val_accuracy: 0.3589\n",
      "Epoch 288/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.7088 - accuracy: 0.4308 - val_loss: 2.2982 - val_accuracy: 0.3541\n",
      "Epoch 289/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6921 - accuracy: 0.4350 - val_loss: 2.2957 - val_accuracy: 0.3566\n",
      "Epoch 290/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6990 - accuracy: 0.4379 - val_loss: 2.2678 - val_accuracy: 0.3621\n",
      "Epoch 291/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7086 - accuracy: 0.4229 - val_loss: 2.2638 - val_accuracy: 0.3599\n",
      "Epoch 292/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7075 - accuracy: 0.4302 - val_loss: 2.2590 - val_accuracy: 0.3679\n",
      "Epoch 293/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6913 - accuracy: 0.4319 - val_loss: 2.2775 - val_accuracy: 0.3550\n",
      "Epoch 294/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6932 - accuracy: 0.4444 - val_loss: 2.3054 - val_accuracy: 0.3528\n",
      "Epoch 295/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6967 - accuracy: 0.4324 - val_loss: 2.2927 - val_accuracy: 0.3570\n",
      "Epoch 296/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6849 - accuracy: 0.4370 - val_loss: 2.2773 - val_accuracy: 0.3615\n",
      "Epoch 297/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6901 - accuracy: 0.4368 - val_loss: 2.2749 - val_accuracy: 0.3592\n",
      "Epoch 298/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6924 - accuracy: 0.4428 - val_loss: 2.2959 - val_accuracy: 0.3550\n",
      "Epoch 299/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6676 - accuracy: 0.4405 - val_loss: 2.2652 - val_accuracy: 0.3679\n",
      "Epoch 300/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6925 - accuracy: 0.4431 - val_loss: 2.2869 - val_accuracy: 0.3492\n",
      "Epoch 301/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6895 - accuracy: 0.4401 - val_loss: 2.2986 - val_accuracy: 0.3454\n",
      "Epoch 302/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6691 - accuracy: 0.4495 - val_loss: 2.2793 - val_accuracy: 0.3512\n",
      "Epoch 303/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6710 - accuracy: 0.4419 - val_loss: 2.2820 - val_accuracy: 0.3640\n",
      "Epoch 304/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6831 - accuracy: 0.4372 - val_loss: 2.2743 - val_accuracy: 0.3631\n",
      "Epoch 305/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6900 - accuracy: 0.4377 - val_loss: 2.2705 - val_accuracy: 0.3618\n",
      "Epoch 306/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6899 - accuracy: 0.4389 - val_loss: 2.3051 - val_accuracy: 0.3457\n",
      "Epoch 307/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6833 - accuracy: 0.4371 - val_loss: 2.2823 - val_accuracy: 0.3544\n",
      "Epoch 308/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6819 - accuracy: 0.4363 - val_loss: 2.2770 - val_accuracy: 0.3592\n",
      "Epoch 309/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6734 - accuracy: 0.4437 - val_loss: 2.3087 - val_accuracy: 0.3582\n",
      "Epoch 310/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6840 - accuracy: 0.4390 - val_loss: 2.2837 - val_accuracy: 0.3602\n",
      "Epoch 311/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6853 - accuracy: 0.4495 - val_loss: 2.2761 - val_accuracy: 0.3582\n",
      "Epoch 312/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6897 - accuracy: 0.4378 - val_loss: 2.2686 - val_accuracy: 0.3734\n",
      "Epoch 313/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6701 - accuracy: 0.4454 - val_loss: 2.3002 - val_accuracy: 0.3550\n",
      "Epoch 314/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6924 - accuracy: 0.4333 - val_loss: 2.2711 - val_accuracy: 0.3621\n",
      "Epoch 315/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6669 - accuracy: 0.4495 - val_loss: 2.3100 - val_accuracy: 0.3444\n",
      "Epoch 316/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6684 - accuracy: 0.4456 - val_loss: 2.2908 - val_accuracy: 0.3666\n",
      "Epoch 317/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6912 - accuracy: 0.4345 - val_loss: 2.2940 - val_accuracy: 0.3628\n",
      "Epoch 318/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6709 - accuracy: 0.4407 - val_loss: 2.3054 - val_accuracy: 0.3396\n",
      "Epoch 319/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6887 - accuracy: 0.4399 - val_loss: 2.3307 - val_accuracy: 0.3466\n",
      "Epoch 320/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6673 - accuracy: 0.4445 - val_loss: 2.2902 - val_accuracy: 0.3524\n",
      "Epoch 321/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6526 - accuracy: 0.4501 - val_loss: 2.2861 - val_accuracy: 0.3557\n",
      "Epoch 322/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6917 - accuracy: 0.4416 - val_loss: 2.2979 - val_accuracy: 0.3512\n",
      "Epoch 323/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6839 - accuracy: 0.4363 - val_loss: 2.3159 - val_accuracy: 0.3441\n",
      "Epoch 324/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6880 - accuracy: 0.4428 - val_loss: 2.2817 - val_accuracy: 0.3553\n",
      "Epoch 325/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6699 - accuracy: 0.4472 - val_loss: 2.2759 - val_accuracy: 0.3673\n",
      "Epoch 326/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6787 - accuracy: 0.4440 - val_loss: 2.3016 - val_accuracy: 0.3550\n",
      "Epoch 327/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6714 - accuracy: 0.4439 - val_loss: 2.3141 - val_accuracy: 0.3512\n",
      "Epoch 328/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6817 - accuracy: 0.4438 - val_loss: 2.2948 - val_accuracy: 0.3553\n",
      "Epoch 329/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6560 - accuracy: 0.4465 - val_loss: 2.3279 - val_accuracy: 0.3425\n",
      "Epoch 330/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6672 - accuracy: 0.4394 - val_loss: 2.3175 - val_accuracy: 0.3486\n",
      "Epoch 331/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6620 - accuracy: 0.4428 - val_loss: 2.2912 - val_accuracy: 0.3628\n",
      "Epoch 332/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6698 - accuracy: 0.4371 - val_loss: 2.2808 - val_accuracy: 0.3673\n",
      "Epoch 333/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6561 - accuracy: 0.4491 - val_loss: 2.3343 - val_accuracy: 0.3421\n",
      "Epoch 334/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6756 - accuracy: 0.4468 - val_loss: 2.3082 - val_accuracy: 0.3476\n",
      "Epoch 335/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6571 - accuracy: 0.4461 - val_loss: 2.2757 - val_accuracy: 0.3676\n",
      "Epoch 336/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6658 - accuracy: 0.4434 - val_loss: 2.3084 - val_accuracy: 0.3447\n",
      "Epoch 337/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6602 - accuracy: 0.4414 - val_loss: 2.2899 - val_accuracy: 0.3644\n",
      "Epoch 338/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6419 - accuracy: 0.4548 - val_loss: 2.2905 - val_accuracy: 0.3521\n",
      "Epoch 339/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6683 - accuracy: 0.4407 - val_loss: 2.2819 - val_accuracy: 0.3483\n",
      "Epoch 340/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6496 - accuracy: 0.4479 - val_loss: 2.2833 - val_accuracy: 0.3534\n",
      "Epoch 341/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6756 - accuracy: 0.4394 - val_loss: 2.2995 - val_accuracy: 0.3534\n",
      "Epoch 342/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6472 - accuracy: 0.4476 - val_loss: 2.3317 - val_accuracy: 0.3537\n",
      "Epoch 343/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6630 - accuracy: 0.4445 - val_loss: 2.3123 - val_accuracy: 0.3421\n",
      "Epoch 344/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6390 - accuracy: 0.4491 - val_loss: 2.3172 - val_accuracy: 0.3444\n",
      "Epoch 345/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6540 - accuracy: 0.4500 - val_loss: 2.2958 - val_accuracy: 0.3409\n",
      "Epoch 346/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6705 - accuracy: 0.4357 - val_loss: 2.3144 - val_accuracy: 0.3479\n",
      "Epoch 347/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6619 - accuracy: 0.4417 - val_loss: 2.3079 - val_accuracy: 0.3570\n",
      "Epoch 348/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6686 - accuracy: 0.4443 - val_loss: 2.3006 - val_accuracy: 0.3521\n",
      "Epoch 349/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6479 - accuracy: 0.4555 - val_loss: 2.2993 - val_accuracy: 0.3595\n",
      "Epoch 350/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6655 - accuracy: 0.4446 - val_loss: 2.2725 - val_accuracy: 0.3618\n",
      "Epoch 351/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6568 - accuracy: 0.4502 - val_loss: 2.2837 - val_accuracy: 0.3553\n",
      "Epoch 352/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6490 - accuracy: 0.4489 - val_loss: 2.2967 - val_accuracy: 0.3599\n",
      "Epoch 353/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6520 - accuracy: 0.4470 - val_loss: 2.2995 - val_accuracy: 0.3492\n",
      "Epoch 354/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6456 - accuracy: 0.4483 - val_loss: 2.3275 - val_accuracy: 0.3373\n",
      "Epoch 355/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6553 - accuracy: 0.4451 - val_loss: 2.3072 - val_accuracy: 0.3457\n",
      "Epoch 356/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6327 - accuracy: 0.4474 - val_loss: 2.3484 - val_accuracy: 0.3235\n",
      "Epoch 357/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6618 - accuracy: 0.4413 - val_loss: 2.2980 - val_accuracy: 0.3489\n",
      "Epoch 358/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6539 - accuracy: 0.4452 - val_loss: 2.2749 - val_accuracy: 0.3698\n",
      "Epoch 359/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6559 - accuracy: 0.4467 - val_loss: 2.3061 - val_accuracy: 0.3524\n",
      "Epoch 360/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6351 - accuracy: 0.4522 - val_loss: 2.3136 - val_accuracy: 0.3582\n",
      "Epoch 361/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6456 - accuracy: 0.4455 - val_loss: 2.3168 - val_accuracy: 0.3537\n",
      "Epoch 362/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6483 - accuracy: 0.4521 - val_loss: 2.3241 - val_accuracy: 0.3531\n",
      "Epoch 363/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6454 - accuracy: 0.4496 - val_loss: 2.3121 - val_accuracy: 0.3486\n",
      "Epoch 364/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6581 - accuracy: 0.4508 - val_loss: 2.3280 - val_accuracy: 0.3457\n",
      "Epoch 365/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6481 - accuracy: 0.4428 - val_loss: 2.2957 - val_accuracy: 0.3608\n",
      "Epoch 366/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6542 - accuracy: 0.4457 - val_loss: 2.3008 - val_accuracy: 0.3547\n",
      "Epoch 367/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6282 - accuracy: 0.4534 - val_loss: 2.2925 - val_accuracy: 0.3492\n",
      "Epoch 368/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6376 - accuracy: 0.4604 - val_loss: 2.2976 - val_accuracy: 0.3653\n",
      "Epoch 369/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6535 - accuracy: 0.4536 - val_loss: 2.3062 - val_accuracy: 0.3534\n",
      "Epoch 370/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6440 - accuracy: 0.4484 - val_loss: 2.2957 - val_accuracy: 0.3608\n",
      "Epoch 371/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6664 - accuracy: 0.4378 - val_loss: 2.3032 - val_accuracy: 0.3483\n",
      "Epoch 372/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6172 - accuracy: 0.4555 - val_loss: 2.3169 - val_accuracy: 0.3521\n",
      "Epoch 373/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6546 - accuracy: 0.4544 - val_loss: 2.2845 - val_accuracy: 0.3618\n",
      "Epoch 374/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6488 - accuracy: 0.4477 - val_loss: 2.2970 - val_accuracy: 0.3615\n",
      "Epoch 375/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6517 - accuracy: 0.4447 - val_loss: 2.2945 - val_accuracy: 0.3592\n",
      "Epoch 376/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6523 - accuracy: 0.4453 - val_loss: 2.3038 - val_accuracy: 0.3557\n",
      "Epoch 377/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6465 - accuracy: 0.4490 - val_loss: 2.3221 - val_accuracy: 0.3431\n",
      "Epoch 378/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6302 - accuracy: 0.4624 - val_loss: 2.3182 - val_accuracy: 0.3486\n",
      "Epoch 379/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6448 - accuracy: 0.4505 - val_loss: 2.3159 - val_accuracy: 0.3560\n",
      "Epoch 380/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6386 - accuracy: 0.4461 - val_loss: 2.3037 - val_accuracy: 0.3505\n",
      "Epoch 381/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6586 - accuracy: 0.4518 - val_loss: 2.2802 - val_accuracy: 0.3715\n",
      "Epoch 382/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6474 - accuracy: 0.4568 - val_loss: 2.3079 - val_accuracy: 0.3563\n",
      "Epoch 383/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6515 - accuracy: 0.4461 - val_loss: 2.3160 - val_accuracy: 0.3450\n",
      "Epoch 384/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6308 - accuracy: 0.4550 - val_loss: 2.3111 - val_accuracy: 0.3457\n",
      "Epoch 385/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6335 - accuracy: 0.4524 - val_loss: 2.3283 - val_accuracy: 0.3412\n",
      "Epoch 386/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6391 - accuracy: 0.4519 - val_loss: 2.2891 - val_accuracy: 0.3502\n",
      "Epoch 387/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6227 - accuracy: 0.4529 - val_loss: 2.2959 - val_accuracy: 0.3602\n",
      "Epoch 388/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6493 - accuracy: 0.4453 - val_loss: 2.3208 - val_accuracy: 0.3505\n",
      "Epoch 389/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6338 - accuracy: 0.4499 - val_loss: 2.2936 - val_accuracy: 0.3499\n",
      "Epoch 390/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6372 - accuracy: 0.4467 - val_loss: 2.3113 - val_accuracy: 0.3599\n",
      "Epoch 391/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6501 - accuracy: 0.4413 - val_loss: 2.2880 - val_accuracy: 0.3618\n",
      "Epoch 392/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6326 - accuracy: 0.4552 - val_loss: 2.3092 - val_accuracy: 0.3573\n",
      "Epoch 393/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6550 - accuracy: 0.4423 - val_loss: 2.3176 - val_accuracy: 0.3463\n",
      "Epoch 394/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6220 - accuracy: 0.4510 - val_loss: 2.3066 - val_accuracy: 0.3505\n",
      "Epoch 395/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6370 - accuracy: 0.4520 - val_loss: 2.2967 - val_accuracy: 0.3557\n",
      "Epoch 396/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6295 - accuracy: 0.4504 - val_loss: 2.3383 - val_accuracy: 0.3225\n",
      "Epoch 397/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6411 - accuracy: 0.4488 - val_loss: 2.3175 - val_accuracy: 0.3544\n",
      "Epoch 398/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6289 - accuracy: 0.4537 - val_loss: 2.2971 - val_accuracy: 0.3566\n",
      "Epoch 399/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6330 - accuracy: 0.4542 - val_loss: 2.3509 - val_accuracy: 0.3438\n",
      "Epoch 400/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6248 - accuracy: 0.4568 - val_loss: 2.3112 - val_accuracy: 0.3415\n",
      "Epoch 401/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6308 - accuracy: 0.4495 - val_loss: 2.3218 - val_accuracy: 0.3466\n",
      "Epoch 402/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6371 - accuracy: 0.4546 - val_loss: 2.3179 - val_accuracy: 0.3550\n",
      "Epoch 403/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6343 - accuracy: 0.4558 - val_loss: 2.3642 - val_accuracy: 0.3347\n",
      "Epoch 404/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6362 - accuracy: 0.4561 - val_loss: 2.3423 - val_accuracy: 0.3415\n",
      "Epoch 405/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6142 - accuracy: 0.4613 - val_loss: 2.3402 - val_accuracy: 0.3318\n",
      "Epoch 406/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6353 - accuracy: 0.4516 - val_loss: 2.3309 - val_accuracy: 0.3553\n",
      "Epoch 407/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6226 - accuracy: 0.4574 - val_loss: 2.3108 - val_accuracy: 0.3618\n",
      "Epoch 408/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6373 - accuracy: 0.4547 - val_loss: 2.3176 - val_accuracy: 0.3470\n",
      "Epoch 409/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6295 - accuracy: 0.4600 - val_loss: 2.3043 - val_accuracy: 0.3531\n",
      "Epoch 410/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6321 - accuracy: 0.4587 - val_loss: 2.3038 - val_accuracy: 0.3399\n",
      "Epoch 411/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6405 - accuracy: 0.4434 - val_loss: 2.3208 - val_accuracy: 0.3502\n",
      "Epoch 412/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6207 - accuracy: 0.4531 - val_loss: 2.3325 - val_accuracy: 0.3392\n",
      "Epoch 413/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6149 - accuracy: 0.4553 - val_loss: 2.3357 - val_accuracy: 0.3421\n",
      "Epoch 414/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6455 - accuracy: 0.4497 - val_loss: 2.2912 - val_accuracy: 0.3679\n",
      "Epoch 415/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6141 - accuracy: 0.4632 - val_loss: 2.3031 - val_accuracy: 0.3563\n",
      "Epoch 416/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6295 - accuracy: 0.4538 - val_loss: 2.3339 - val_accuracy: 0.3347\n",
      "Epoch 417/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6152 - accuracy: 0.4604 - val_loss: 2.3296 - val_accuracy: 0.3431\n",
      "Epoch 418/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6265 - accuracy: 0.4547 - val_loss: 2.3063 - val_accuracy: 0.3553\n",
      "Epoch 419/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6239 - accuracy: 0.4568 - val_loss: 2.3068 - val_accuracy: 0.3431\n",
      "Epoch 420/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6508 - accuracy: 0.4466 - val_loss: 2.3136 - val_accuracy: 0.3450\n",
      "Epoch 421/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6294 - accuracy: 0.4529 - val_loss: 2.3447 - val_accuracy: 0.3399\n",
      "Epoch 422/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6173 - accuracy: 0.4555 - val_loss: 2.3156 - val_accuracy: 0.3521\n",
      "Epoch 423/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6182 - accuracy: 0.4601 - val_loss: 2.3206 - val_accuracy: 0.3434\n",
      "Epoch 424/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6132 - accuracy: 0.4645 - val_loss: 2.3481 - val_accuracy: 0.3289\n",
      "Epoch 425/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6072 - accuracy: 0.4592 - val_loss: 2.3245 - val_accuracy: 0.3550\n",
      "Epoch 426/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6101 - accuracy: 0.4676 - val_loss: 2.3355 - val_accuracy: 0.3276\n",
      "Epoch 427/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6302 - accuracy: 0.4551 - val_loss: 2.3173 - val_accuracy: 0.3444\n",
      "Epoch 428/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6243 - accuracy: 0.4572 - val_loss: 2.3153 - val_accuracy: 0.3579\n",
      "Epoch 429/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6168 - accuracy: 0.4576 - val_loss: 2.3484 - val_accuracy: 0.3363\n",
      "Epoch 430/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6155 - accuracy: 0.4508 - val_loss: 2.3380 - val_accuracy: 0.3351\n",
      "Epoch 431/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6096 - accuracy: 0.4589 - val_loss: 2.3101 - val_accuracy: 0.3412\n",
      "Epoch 432/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6215 - accuracy: 0.4570 - val_loss: 2.3379 - val_accuracy: 0.3383\n",
      "Epoch 433/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6225 - accuracy: 0.4562 - val_loss: 2.3428 - val_accuracy: 0.3412\n",
      "Epoch 434/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6220 - accuracy: 0.4573 - val_loss: 2.3512 - val_accuracy: 0.3438\n",
      "Epoch 435/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6283 - accuracy: 0.4522 - val_loss: 2.3450 - val_accuracy: 0.3376\n",
      "Epoch 436/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6198 - accuracy: 0.4597 - val_loss: 2.3322 - val_accuracy: 0.3415\n",
      "Epoch 437/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6288 - accuracy: 0.4584 - val_loss: 2.3071 - val_accuracy: 0.3524\n",
      "Epoch 438/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6189 - accuracy: 0.4545 - val_loss: 2.3582 - val_accuracy: 0.3315\n",
      "Epoch 439/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6184 - accuracy: 0.4621 - val_loss: 2.3159 - val_accuracy: 0.3460\n",
      "Epoch 440/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6080 - accuracy: 0.4533 - val_loss: 2.3328 - val_accuracy: 0.3476\n",
      "Epoch 441/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6154 - accuracy: 0.4631 - val_loss: 2.3090 - val_accuracy: 0.3470\n",
      "Epoch 442/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5984 - accuracy: 0.4599 - val_loss: 2.3426 - val_accuracy: 0.3392\n",
      "Epoch 443/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6160 - accuracy: 0.4623 - val_loss: 2.3404 - val_accuracy: 0.3402\n",
      "Epoch 444/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6125 - accuracy: 0.4642 - val_loss: 2.3672 - val_accuracy: 0.3167\n",
      "Epoch 445/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5946 - accuracy: 0.4568 - val_loss: 2.3298 - val_accuracy: 0.3492\n",
      "Epoch 446/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6374 - accuracy: 0.4495 - val_loss: 2.3332 - val_accuracy: 0.3363\n",
      "Epoch 447/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6314 - accuracy: 0.4548 - val_loss: 2.3297 - val_accuracy: 0.3495\n",
      "Epoch 448/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6100 - accuracy: 0.4548 - val_loss: 2.3167 - val_accuracy: 0.3637\n",
      "Epoch 449/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6015 - accuracy: 0.4570 - val_loss: 2.3214 - val_accuracy: 0.3695\n",
      "Epoch 450/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5979 - accuracy: 0.4651 - val_loss: 2.3469 - val_accuracy: 0.3225\n",
      "Epoch 451/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6219 - accuracy: 0.4559 - val_loss: 2.3562 - val_accuracy: 0.3325\n",
      "Epoch 452/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6242 - accuracy: 0.4614 - val_loss: 2.3558 - val_accuracy: 0.3450\n",
      "Epoch 453/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6139 - accuracy: 0.4572 - val_loss: 2.3290 - val_accuracy: 0.3531\n",
      "Epoch 454/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6075 - accuracy: 0.4633 - val_loss: 2.3581 - val_accuracy: 0.3373\n",
      "Epoch 455/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6055 - accuracy: 0.4656 - val_loss: 2.3544 - val_accuracy: 0.3173\n",
      "Epoch 456/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6083 - accuracy: 0.4572 - val_loss: 2.3378 - val_accuracy: 0.3505\n",
      "Epoch 457/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6246 - accuracy: 0.4558 - val_loss: 2.3516 - val_accuracy: 0.3351\n",
      "Epoch 458/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6165 - accuracy: 0.4477 - val_loss: 2.3469 - val_accuracy: 0.3470\n",
      "Epoch 459/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5979 - accuracy: 0.4609 - val_loss: 2.3418 - val_accuracy: 0.3476\n",
      "Epoch 460/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5966 - accuracy: 0.4659 - val_loss: 2.3435 - val_accuracy: 0.3421\n",
      "Epoch 461/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6156 - accuracy: 0.4557 - val_loss: 2.3386 - val_accuracy: 0.3476\n",
      "Epoch 462/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6078 - accuracy: 0.4636 - val_loss: 2.3421 - val_accuracy: 0.3550\n",
      "Epoch 463/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6002 - accuracy: 0.4596 - val_loss: 2.3645 - val_accuracy: 0.3354\n",
      "Epoch 464/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5920 - accuracy: 0.4641 - val_loss: 2.3160 - val_accuracy: 0.3573\n",
      "Epoch 465/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6225 - accuracy: 0.4512 - val_loss: 2.3564 - val_accuracy: 0.3418\n",
      "Epoch 466/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6013 - accuracy: 0.4587 - val_loss: 2.3464 - val_accuracy: 0.3502\n",
      "Epoch 467/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5869 - accuracy: 0.4674 - val_loss: 2.3572 - val_accuracy: 0.3363\n",
      "Epoch 468/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6166 - accuracy: 0.4594 - val_loss: 2.3348 - val_accuracy: 0.3434\n",
      "Epoch 469/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5926 - accuracy: 0.4642 - val_loss: 2.3249 - val_accuracy: 0.3537\n",
      "Epoch 470/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6127 - accuracy: 0.4616 - val_loss: 2.3101 - val_accuracy: 0.3557\n",
      "Epoch 471/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6094 - accuracy: 0.4563 - val_loss: 2.3185 - val_accuracy: 0.3518\n",
      "Epoch 472/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5923 - accuracy: 0.4632 - val_loss: 2.3437 - val_accuracy: 0.3402\n",
      "Epoch 473/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6075 - accuracy: 0.4607 - val_loss: 2.3384 - val_accuracy: 0.3457\n",
      "Epoch 474/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6142 - accuracy: 0.4597 - val_loss: 2.3108 - val_accuracy: 0.3663\n",
      "Epoch 475/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6081 - accuracy: 0.4483 - val_loss: 2.3276 - val_accuracy: 0.3505\n",
      "Epoch 476/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5847 - accuracy: 0.4696 - val_loss: 2.3495 - val_accuracy: 0.3331\n",
      "Epoch 477/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6195 - accuracy: 0.4648 - val_loss: 2.3275 - val_accuracy: 0.3528\n",
      "Epoch 478/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6143 - accuracy: 0.4549 - val_loss: 2.3300 - val_accuracy: 0.3505\n",
      "Epoch 479/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5915 - accuracy: 0.4656 - val_loss: 2.3312 - val_accuracy: 0.3434\n",
      "Epoch 480/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5903 - accuracy: 0.4640 - val_loss: 2.3819 - val_accuracy: 0.3360\n",
      "Epoch 481/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5885 - accuracy: 0.4639 - val_loss: 2.3498 - val_accuracy: 0.3399\n",
      "Epoch 482/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6081 - accuracy: 0.4611 - val_loss: 2.3623 - val_accuracy: 0.3293\n",
      "Epoch 483/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6070 - accuracy: 0.4496 - val_loss: 2.3273 - val_accuracy: 0.3512\n",
      "Epoch 484/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6073 - accuracy: 0.4502 - val_loss: 2.3166 - val_accuracy: 0.3505\n",
      "Epoch 485/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5937 - accuracy: 0.4535 - val_loss: 2.3307 - val_accuracy: 0.3618\n",
      "Epoch 486/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5946 - accuracy: 0.4541 - val_loss: 2.3363 - val_accuracy: 0.3351\n",
      "Epoch 487/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5948 - accuracy: 0.4564 - val_loss: 2.3536 - val_accuracy: 0.3244\n",
      "Epoch 488/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5986 - accuracy: 0.4637 - val_loss: 2.3585 - val_accuracy: 0.3438\n",
      "Epoch 489/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5943 - accuracy: 0.4615 - val_loss: 2.3292 - val_accuracy: 0.3450\n",
      "Epoch 490/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6054 - accuracy: 0.4557 - val_loss: 2.3468 - val_accuracy: 0.3380\n",
      "Epoch 491/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5770 - accuracy: 0.4740 - val_loss: 2.3646 - val_accuracy: 0.3463\n",
      "Epoch 492/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5984 - accuracy: 0.4535 - val_loss: 2.3315 - val_accuracy: 0.3615\n",
      "Epoch 493/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.6241 - accuracy: 0.4498 - val_loss: 2.3539 - val_accuracy: 0.3302\n",
      "Epoch 494/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5924 - accuracy: 0.4685 - val_loss: 2.3801 - val_accuracy: 0.3215\n",
      "Epoch 495/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6048 - accuracy: 0.4577 - val_loss: 2.3369 - val_accuracy: 0.3412\n",
      "Epoch 496/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6033 - accuracy: 0.4563 - val_loss: 2.3776 - val_accuracy: 0.3296\n",
      "Epoch 497/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5823 - accuracy: 0.4628 - val_loss: 2.3380 - val_accuracy: 0.3409\n",
      "Epoch 498/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6065 - accuracy: 0.4638 - val_loss: 2.3585 - val_accuracy: 0.3370\n",
      "Epoch 499/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5811 - accuracy: 0.4652 - val_loss: 2.3524 - val_accuracy: 0.3315\n",
      "Epoch 500/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5947 - accuracy: 0.4582 - val_loss: 2.3709 - val_accuracy: 0.3305\n",
      "Epoch 501/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5824 - accuracy: 0.4690 - val_loss: 2.3882 - val_accuracy: 0.3251\n",
      "Epoch 502/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6073 - accuracy: 0.4527 - val_loss: 2.3320 - val_accuracy: 0.3557\n",
      "Epoch 503/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5781 - accuracy: 0.4715 - val_loss: 2.3562 - val_accuracy: 0.3341\n",
      "Epoch 504/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5957 - accuracy: 0.4591 - val_loss: 2.3243 - val_accuracy: 0.3592\n",
      "Epoch 505/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5996 - accuracy: 0.4692 - val_loss: 2.3522 - val_accuracy: 0.3351\n",
      "Epoch 506/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5882 - accuracy: 0.4610 - val_loss: 2.3290 - val_accuracy: 0.3505\n",
      "Epoch 507/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5917 - accuracy: 0.4594 - val_loss: 2.3183 - val_accuracy: 0.3521\n",
      "Epoch 508/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5950 - accuracy: 0.4596 - val_loss: 2.3605 - val_accuracy: 0.3373\n",
      "Epoch 509/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5833 - accuracy: 0.4598 - val_loss: 2.3320 - val_accuracy: 0.3299\n",
      "Epoch 510/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5822 - accuracy: 0.4686 - val_loss: 2.3579 - val_accuracy: 0.3367\n",
      "Epoch 511/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5900 - accuracy: 0.4643 - val_loss: 2.3382 - val_accuracy: 0.3499\n",
      "Epoch 512/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5885 - accuracy: 0.4647 - val_loss: 2.3677 - val_accuracy: 0.3428\n",
      "Epoch 513/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5841 - accuracy: 0.4734 - val_loss: 2.3546 - val_accuracy: 0.3470\n",
      "Epoch 514/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6007 - accuracy: 0.4626 - val_loss: 2.3602 - val_accuracy: 0.3305\n",
      "Epoch 515/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5818 - accuracy: 0.4652 - val_loss: 2.3226 - val_accuracy: 0.3502\n",
      "Epoch 516/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5777 - accuracy: 0.4716 - val_loss: 2.3467 - val_accuracy: 0.3447\n",
      "Epoch 517/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5907 - accuracy: 0.4665 - val_loss: 2.3739 - val_accuracy: 0.3386\n",
      "Epoch 518/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5849 - accuracy: 0.4614 - val_loss: 2.3418 - val_accuracy: 0.3441\n",
      "Epoch 519/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5760 - accuracy: 0.4684 - val_loss: 2.3658 - val_accuracy: 0.3370\n",
      "Epoch 520/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5729 - accuracy: 0.4643 - val_loss: 2.3402 - val_accuracy: 0.3495\n",
      "Epoch 521/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5975 - accuracy: 0.4636 - val_loss: 2.3510 - val_accuracy: 0.3363\n",
      "Epoch 522/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5899 - accuracy: 0.4620 - val_loss: 2.3385 - val_accuracy: 0.3447\n",
      "Epoch 523/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5941 - accuracy: 0.4593 - val_loss: 2.3467 - val_accuracy: 0.3499\n",
      "Epoch 524/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5837 - accuracy: 0.4666 - val_loss: 2.3536 - val_accuracy: 0.3444\n",
      "Epoch 525/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6028 - accuracy: 0.4484 - val_loss: 2.3421 - val_accuracy: 0.3483\n",
      "Epoch 526/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5882 - accuracy: 0.4672 - val_loss: 2.3382 - val_accuracy: 0.3476\n",
      "Epoch 527/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5868 - accuracy: 0.4693 - val_loss: 2.3778 - val_accuracy: 0.3251\n",
      "Epoch 528/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5673 - accuracy: 0.4730 - val_loss: 2.3270 - val_accuracy: 0.3566\n",
      "Epoch 529/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5888 - accuracy: 0.4713 - val_loss: 2.3477 - val_accuracy: 0.3425\n",
      "Epoch 530/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5739 - accuracy: 0.4608 - val_loss: 2.3426 - val_accuracy: 0.3505\n",
      "Epoch 531/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5810 - accuracy: 0.4669 - val_loss: 2.3648 - val_accuracy: 0.3521\n",
      "Epoch 532/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5925 - accuracy: 0.4601 - val_loss: 2.3280 - val_accuracy: 0.3518\n",
      "Epoch 533/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5926 - accuracy: 0.4661 - val_loss: 2.3627 - val_accuracy: 0.3428\n",
      "Epoch 534/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5919 - accuracy: 0.4604 - val_loss: 2.3442 - val_accuracy: 0.3518\n",
      "Epoch 535/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5743 - accuracy: 0.4679 - val_loss: 2.3208 - val_accuracy: 0.3573\n",
      "Epoch 536/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5705 - accuracy: 0.4698 - val_loss: 2.3444 - val_accuracy: 0.3428\n",
      "Epoch 537/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5727 - accuracy: 0.4652 - val_loss: 2.3658 - val_accuracy: 0.3396\n",
      "Epoch 538/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5873 - accuracy: 0.4682 - val_loss: 2.3789 - val_accuracy: 0.3392\n",
      "Epoch 539/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5643 - accuracy: 0.4738 - val_loss: 2.3904 - val_accuracy: 0.3296\n",
      "Epoch 540/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5807 - accuracy: 0.4692 - val_loss: 2.3154 - val_accuracy: 0.3502\n",
      "Epoch 541/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5846 - accuracy: 0.4637 - val_loss: 2.3616 - val_accuracy: 0.3344\n",
      "Epoch 542/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5796 - accuracy: 0.4656 - val_loss: 2.3764 - val_accuracy: 0.3431\n",
      "Epoch 543/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5895 - accuracy: 0.4579 - val_loss: 2.3649 - val_accuracy: 0.3428\n",
      "Epoch 544/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5734 - accuracy: 0.4649 - val_loss: 2.3905 - val_accuracy: 0.3299\n",
      "Epoch 545/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5771 - accuracy: 0.4708 - val_loss: 2.3675 - val_accuracy: 0.3360\n",
      "Epoch 546/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5749 - accuracy: 0.4660 - val_loss: 2.3610 - val_accuracy: 0.3341\n",
      "Epoch 547/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5554 - accuracy: 0.4735 - val_loss: 2.3912 - val_accuracy: 0.3344\n",
      "Epoch 548/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5797 - accuracy: 0.4627 - val_loss: 2.3760 - val_accuracy: 0.3360\n",
      "Epoch 549/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5963 - accuracy: 0.4585 - val_loss: 2.3668 - val_accuracy: 0.3450\n",
      "Epoch 550/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5731 - accuracy: 0.4682 - val_loss: 2.3795 - val_accuracy: 0.3373\n",
      "Epoch 551/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5819 - accuracy: 0.4522 - val_loss: 2.3563 - val_accuracy: 0.3373\n",
      "Epoch 552/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5769 - accuracy: 0.4596 - val_loss: 2.3326 - val_accuracy: 0.3647\n",
      "Epoch 553/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5854 - accuracy: 0.4626 - val_loss: 2.3667 - val_accuracy: 0.3428\n",
      "Epoch 554/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5832 - accuracy: 0.4655 - val_loss: 2.3869 - val_accuracy: 0.3425\n",
      "Epoch 555/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5717 - accuracy: 0.4664 - val_loss: 2.3571 - val_accuracy: 0.3541\n",
      "Epoch 556/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5697 - accuracy: 0.4670 - val_loss: 2.3880 - val_accuracy: 0.3363\n",
      "Epoch 557/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5802 - accuracy: 0.4701 - val_loss: 2.3618 - val_accuracy: 0.3402\n",
      "Epoch 558/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5714 - accuracy: 0.4704 - val_loss: 2.3745 - val_accuracy: 0.3412\n",
      "Epoch 559/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5704 - accuracy: 0.4822 - val_loss: 2.4214 - val_accuracy: 0.3238\n",
      "Epoch 560/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5837 - accuracy: 0.4598 - val_loss: 2.3574 - val_accuracy: 0.3466\n",
      "Epoch 561/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5818 - accuracy: 0.4653 - val_loss: 2.3785 - val_accuracy: 0.3305\n",
      "Epoch 562/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5915 - accuracy: 0.4655 - val_loss: 2.3792 - val_accuracy: 0.3341\n",
      "Epoch 563/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5675 - accuracy: 0.4701 - val_loss: 2.3843 - val_accuracy: 0.3296\n",
      "Epoch 564/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5726 - accuracy: 0.4692 - val_loss: 2.3640 - val_accuracy: 0.3325\n",
      "Epoch 565/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5713 - accuracy: 0.4709 - val_loss: 2.3852 - val_accuracy: 0.3518\n",
      "Epoch 566/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5706 - accuracy: 0.4675 - val_loss: 2.4053 - val_accuracy: 0.3238\n",
      "Epoch 567/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5866 - accuracy: 0.4655 - val_loss: 2.3558 - val_accuracy: 0.3409\n",
      "Epoch 568/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5736 - accuracy: 0.4694 - val_loss: 2.3895 - val_accuracy: 0.3331\n",
      "Epoch 569/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5885 - accuracy: 0.4676 - val_loss: 2.3672 - val_accuracy: 0.3405\n",
      "Epoch 570/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5762 - accuracy: 0.4670 - val_loss: 2.3563 - val_accuracy: 0.3505\n",
      "Epoch 571/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5768 - accuracy: 0.4715 - val_loss: 2.3953 - val_accuracy: 0.3425\n",
      "Epoch 572/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5672 - accuracy: 0.4664 - val_loss: 2.3651 - val_accuracy: 0.3344\n",
      "Epoch 573/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5585 - accuracy: 0.4740 - val_loss: 2.3686 - val_accuracy: 0.3328\n",
      "Epoch 574/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5672 - accuracy: 0.4725 - val_loss: 2.3843 - val_accuracy: 0.3293\n",
      "Epoch 575/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5758 - accuracy: 0.4687 - val_loss: 2.4199 - val_accuracy: 0.3267\n",
      "Epoch 576/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5670 - accuracy: 0.4729 - val_loss: 2.3490 - val_accuracy: 0.3463\n",
      "Epoch 577/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5699 - accuracy: 0.4631 - val_loss: 2.3711 - val_accuracy: 0.3415\n",
      "Epoch 578/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5781 - accuracy: 0.4665 - val_loss: 2.3710 - val_accuracy: 0.3428\n",
      "Epoch 579/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5777 - accuracy: 0.4643 - val_loss: 2.3736 - val_accuracy: 0.3376\n",
      "Epoch 580/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5542 - accuracy: 0.4717 - val_loss: 2.3613 - val_accuracy: 0.3367\n",
      "Epoch 581/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5826 - accuracy: 0.4696 - val_loss: 2.3853 - val_accuracy: 0.3347\n",
      "Epoch 582/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5691 - accuracy: 0.4698 - val_loss: 2.3702 - val_accuracy: 0.3454\n",
      "Epoch 583/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5831 - accuracy: 0.4651 - val_loss: 2.3649 - val_accuracy: 0.3460\n",
      "Epoch 584/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5652 - accuracy: 0.4622 - val_loss: 2.3660 - val_accuracy: 0.3412\n",
      "Epoch 585/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5823 - accuracy: 0.4695 - val_loss: 2.3552 - val_accuracy: 0.3492\n",
      "Epoch 586/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5641 - accuracy: 0.4690 - val_loss: 2.3827 - val_accuracy: 0.3370\n",
      "Epoch 587/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5715 - accuracy: 0.4698 - val_loss: 2.3755 - val_accuracy: 0.3367\n",
      "Epoch 588/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5652 - accuracy: 0.4731 - val_loss: 2.3820 - val_accuracy: 0.3283\n",
      "Epoch 589/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5589 - accuracy: 0.4836 - val_loss: 2.3671 - val_accuracy: 0.3495\n",
      "Epoch 590/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5770 - accuracy: 0.4600 - val_loss: 2.3748 - val_accuracy: 0.3479\n",
      "Epoch 591/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5611 - accuracy: 0.4643 - val_loss: 2.3538 - val_accuracy: 0.3508\n",
      "Epoch 592/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5725 - accuracy: 0.4702 - val_loss: 2.3529 - val_accuracy: 0.3444\n",
      "Epoch 593/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5655 - accuracy: 0.4639 - val_loss: 2.3518 - val_accuracy: 0.3460\n",
      "Epoch 594/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5785 - accuracy: 0.4697 - val_loss: 2.3861 - val_accuracy: 0.3241\n",
      "Epoch 595/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5770 - accuracy: 0.4628 - val_loss: 2.3503 - val_accuracy: 0.3438\n",
      "Epoch 596/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5583 - accuracy: 0.4725 - val_loss: 2.3549 - val_accuracy: 0.3470\n",
      "Epoch 597/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5564 - accuracy: 0.4730 - val_loss: 2.3631 - val_accuracy: 0.3428\n",
      "Epoch 598/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5771 - accuracy: 0.4699 - val_loss: 2.4159 - val_accuracy: 0.3067\n",
      "Epoch 599/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5609 - accuracy: 0.4706 - val_loss: 2.4128 - val_accuracy: 0.3131\n",
      "Epoch 600/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5686 - accuracy: 0.4752 - val_loss: 2.3892 - val_accuracy: 0.3341\n",
      "Epoch 601/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5617 - accuracy: 0.4609 - val_loss: 2.3849 - val_accuracy: 0.3360\n",
      "Epoch 602/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5726 - accuracy: 0.4658 - val_loss: 2.3586 - val_accuracy: 0.3428\n",
      "Epoch 603/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5532 - accuracy: 0.4692 - val_loss: 2.3738 - val_accuracy: 0.3463\n",
      "Epoch 604/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5622 - accuracy: 0.4695 - val_loss: 2.3995 - val_accuracy: 0.3328\n",
      "Epoch 605/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5681 - accuracy: 0.4698 - val_loss: 2.3952 - val_accuracy: 0.3441\n",
      "Epoch 606/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5536 - accuracy: 0.4691 - val_loss: 2.4031 - val_accuracy: 0.3454\n",
      "Epoch 607/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5632 - accuracy: 0.4675 - val_loss: 2.3647 - val_accuracy: 0.3396\n",
      "Epoch 608/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5747 - accuracy: 0.4608 - val_loss: 2.3842 - val_accuracy: 0.3383\n",
      "Epoch 609/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5719 - accuracy: 0.4683 - val_loss: 2.3859 - val_accuracy: 0.3383\n",
      "Epoch 610/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5861 - accuracy: 0.4656 - val_loss: 2.3763 - val_accuracy: 0.3392\n",
      "Epoch 611/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5564 - accuracy: 0.4704 - val_loss: 2.3795 - val_accuracy: 0.3402\n",
      "Epoch 612/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5853 - accuracy: 0.4599 - val_loss: 2.3874 - val_accuracy: 0.3370\n",
      "Epoch 613/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5695 - accuracy: 0.4658 - val_loss: 2.3625 - val_accuracy: 0.3476\n",
      "Epoch 614/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5643 - accuracy: 0.4670 - val_loss: 2.3757 - val_accuracy: 0.3376\n",
      "Epoch 615/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5559 - accuracy: 0.4703 - val_loss: 2.3882 - val_accuracy: 0.3409\n",
      "Epoch 616/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5648 - accuracy: 0.4717 - val_loss: 2.3581 - val_accuracy: 0.3431\n",
      "Epoch 617/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5631 - accuracy: 0.4671 - val_loss: 2.3835 - val_accuracy: 0.3460\n",
      "Epoch 618/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5739 - accuracy: 0.4689 - val_loss: 2.3806 - val_accuracy: 0.3412\n",
      "Epoch 619/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5436 - accuracy: 0.4800 - val_loss: 2.3888 - val_accuracy: 0.3370\n",
      "Epoch 620/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5675 - accuracy: 0.4629 - val_loss: 2.3381 - val_accuracy: 0.3499\n",
      "Epoch 621/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5590 - accuracy: 0.4715 - val_loss: 2.3832 - val_accuracy: 0.3360\n",
      "Epoch 622/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5837 - accuracy: 0.4637 - val_loss: 2.3630 - val_accuracy: 0.3495\n",
      "Epoch 623/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5564 - accuracy: 0.4754 - val_loss: 2.3775 - val_accuracy: 0.3312\n",
      "Epoch 624/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5631 - accuracy: 0.4707 - val_loss: 2.3947 - val_accuracy: 0.3428\n",
      "Epoch 625/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5722 - accuracy: 0.4682 - val_loss: 2.3647 - val_accuracy: 0.3537\n",
      "Epoch 626/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5588 - accuracy: 0.4721 - val_loss: 2.3834 - val_accuracy: 0.3405\n",
      "Epoch 627/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5553 - accuracy: 0.4721 - val_loss: 2.3692 - val_accuracy: 0.3334\n",
      "Epoch 628/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5450 - accuracy: 0.4668 - val_loss: 2.3999 - val_accuracy: 0.3363\n",
      "Epoch 629/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5525 - accuracy: 0.4697 - val_loss: 2.3797 - val_accuracy: 0.3363\n",
      "Epoch 630/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5469 - accuracy: 0.4738 - val_loss: 2.3784 - val_accuracy: 0.3399\n",
      "Epoch 631/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5530 - accuracy: 0.4724 - val_loss: 2.3837 - val_accuracy: 0.3415\n",
      "Epoch 632/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5557 - accuracy: 0.4723 - val_loss: 2.3897 - val_accuracy: 0.3322\n",
      "Epoch 633/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5599 - accuracy: 0.4698 - val_loss: 2.3806 - val_accuracy: 0.3473\n",
      "Epoch 634/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5536 - accuracy: 0.4697 - val_loss: 2.4224 - val_accuracy: 0.3157\n",
      "Epoch 635/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5625 - accuracy: 0.4639 - val_loss: 2.3646 - val_accuracy: 0.3428\n",
      "Epoch 636/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5491 - accuracy: 0.4747 - val_loss: 2.3493 - val_accuracy: 0.3505\n",
      "Epoch 637/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5550 - accuracy: 0.4664 - val_loss: 2.3664 - val_accuracy: 0.3409\n",
      "Epoch 638/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5654 - accuracy: 0.4656 - val_loss: 2.3993 - val_accuracy: 0.3293\n",
      "Epoch 639/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5619 - accuracy: 0.4704 - val_loss: 2.3860 - val_accuracy: 0.3457\n",
      "Epoch 640/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5599 - accuracy: 0.4683 - val_loss: 2.3844 - val_accuracy: 0.3347\n",
      "Epoch 641/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5240 - accuracy: 0.4721 - val_loss: 2.3545 - val_accuracy: 0.3454\n",
      "Epoch 642/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5549 - accuracy: 0.4768 - val_loss: 2.3743 - val_accuracy: 0.3473\n",
      "Epoch 643/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5549 - accuracy: 0.4753 - val_loss: 2.3723 - val_accuracy: 0.3415\n",
      "Epoch 644/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5555 - accuracy: 0.4732 - val_loss: 2.3713 - val_accuracy: 0.3486\n",
      "Epoch 645/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5422 - accuracy: 0.4753 - val_loss: 2.3868 - val_accuracy: 0.3447\n",
      "Epoch 646/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5355 - accuracy: 0.4742 - val_loss: 2.3741 - val_accuracy: 0.3473\n",
      "Epoch 647/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5610 - accuracy: 0.4599 - val_loss: 2.3864 - val_accuracy: 0.3463\n",
      "Epoch 648/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5477 - accuracy: 0.4712 - val_loss: 2.4188 - val_accuracy: 0.3357\n",
      "Epoch 649/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5552 - accuracy: 0.4788 - val_loss: 2.4043 - val_accuracy: 0.3380\n",
      "Epoch 650/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5726 - accuracy: 0.4688 - val_loss: 2.3734 - val_accuracy: 0.3438\n",
      "Epoch 651/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5427 - accuracy: 0.4709 - val_loss: 2.3743 - val_accuracy: 0.3457\n",
      "Epoch 652/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5615 - accuracy: 0.4629 - val_loss: 2.4136 - val_accuracy: 0.3264\n",
      "Epoch 653/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5408 - accuracy: 0.4771 - val_loss: 2.3790 - val_accuracy: 0.3534\n",
      "Epoch 654/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5596 - accuracy: 0.4704 - val_loss: 2.3875 - val_accuracy: 0.3405\n",
      "Epoch 655/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5473 - accuracy: 0.4777 - val_loss: 2.3870 - val_accuracy: 0.3351\n",
      "Epoch 656/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5537 - accuracy: 0.4655 - val_loss: 2.4064 - val_accuracy: 0.3289\n",
      "Epoch 657/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.4671 - val_loss: 2.3693 - val_accuracy: 0.3438\n",
      "Epoch 658/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5491 - accuracy: 0.4757 - val_loss: 2.3955 - val_accuracy: 0.3344\n",
      "Epoch 659/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5444 - accuracy: 0.4767 - val_loss: 2.3993 - val_accuracy: 0.3425\n",
      "Epoch 660/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5597 - accuracy: 0.4743 - val_loss: 2.3822 - val_accuracy: 0.3402\n",
      "Epoch 661/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5517 - accuracy: 0.4765 - val_loss: 2.3742 - val_accuracy: 0.3454\n",
      "Epoch 662/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5556 - accuracy: 0.4717 - val_loss: 2.3742 - val_accuracy: 0.3470\n",
      "Epoch 663/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5434 - accuracy: 0.4744 - val_loss: 2.3753 - val_accuracy: 0.3431\n",
      "Epoch 664/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5434 - accuracy: 0.4758 - val_loss: 2.4006 - val_accuracy: 0.3405\n",
      "Epoch 665/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5440 - accuracy: 0.4860 - val_loss: 2.4026 - val_accuracy: 0.3415\n",
      "Epoch 666/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5643 - accuracy: 0.4733 - val_loss: 2.4128 - val_accuracy: 0.3318\n",
      "Epoch 667/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5497 - accuracy: 0.4735 - val_loss: 2.4151 - val_accuracy: 0.3370\n",
      "Epoch 668/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5597 - accuracy: 0.4732 - val_loss: 2.3759 - val_accuracy: 0.3537\n",
      "Epoch 669/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5531 - accuracy: 0.4760 - val_loss: 2.3820 - val_accuracy: 0.3341\n",
      "Epoch 670/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5421 - accuracy: 0.4759 - val_loss: 2.3904 - val_accuracy: 0.3454\n",
      "Epoch 671/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5376 - accuracy: 0.4738 - val_loss: 2.3910 - val_accuracy: 0.3354\n",
      "Epoch 672/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5513 - accuracy: 0.4781 - val_loss: 2.4154 - val_accuracy: 0.3235\n",
      "Epoch 673/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5417 - accuracy: 0.4762 - val_loss: 2.3948 - val_accuracy: 0.3360\n",
      "Epoch 674/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5572 - accuracy: 0.4634 - val_loss: 2.3926 - val_accuracy: 0.3289\n",
      "Epoch 675/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5373 - accuracy: 0.4735 - val_loss: 2.3780 - val_accuracy: 0.3418\n",
      "Epoch 676/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5316 - accuracy: 0.4725 - val_loss: 2.4149 - val_accuracy: 0.3309\n",
      "Epoch 677/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5412 - accuracy: 0.4782 - val_loss: 2.3932 - val_accuracy: 0.3396\n",
      "Epoch 678/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5492 - accuracy: 0.4822 - val_loss: 2.3943 - val_accuracy: 0.3354\n",
      "Epoch 679/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5637 - accuracy: 0.4640 - val_loss: 2.3971 - val_accuracy: 0.3492\n",
      "Epoch 680/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5326 - accuracy: 0.4738 - val_loss: 2.3880 - val_accuracy: 0.3476\n",
      "Epoch 681/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5475 - accuracy: 0.4670 - val_loss: 2.4262 - val_accuracy: 0.3286\n",
      "Epoch 682/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5579 - accuracy: 0.4747 - val_loss: 2.4233 - val_accuracy: 0.3267\n",
      "Epoch 683/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5516 - accuracy: 0.4704 - val_loss: 2.3994 - val_accuracy: 0.3383\n",
      "Epoch 684/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5459 - accuracy: 0.4741 - val_loss: 2.3729 - val_accuracy: 0.3476\n",
      "Epoch 685/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5468 - accuracy: 0.4739 - val_loss: 2.3997 - val_accuracy: 0.3351\n",
      "Epoch 686/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5292 - accuracy: 0.4765 - val_loss: 2.4131 - val_accuracy: 0.3273\n",
      "Epoch 687/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5461 - accuracy: 0.4733 - val_loss: 2.3974 - val_accuracy: 0.3341\n",
      "Epoch 688/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5335 - accuracy: 0.4785 - val_loss: 2.3982 - val_accuracy: 0.3325\n",
      "Epoch 689/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5472 - accuracy: 0.4690 - val_loss: 2.4007 - val_accuracy: 0.3438\n",
      "Epoch 690/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5612 - accuracy: 0.4630 - val_loss: 2.4268 - val_accuracy: 0.3293\n",
      "Epoch 691/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5480 - accuracy: 0.4714 - val_loss: 2.3902 - val_accuracy: 0.3360\n",
      "Epoch 692/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5585 - accuracy: 0.4763 - val_loss: 2.3764 - val_accuracy: 0.3399\n",
      "Epoch 693/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5398 - accuracy: 0.4739 - val_loss: 2.4165 - val_accuracy: 0.3283\n",
      "Epoch 694/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5414 - accuracy: 0.4768 - val_loss: 2.4002 - val_accuracy: 0.3315\n",
      "Epoch 695/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5292 - accuracy: 0.4810 - val_loss: 2.3902 - val_accuracy: 0.3405\n",
      "Epoch 696/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5535 - accuracy: 0.4719 - val_loss: 2.3881 - val_accuracy: 0.3376\n",
      "Epoch 697/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5563 - accuracy: 0.4764 - val_loss: 2.4091 - val_accuracy: 0.3283\n",
      "Epoch 698/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5510 - accuracy: 0.4696 - val_loss: 2.4123 - val_accuracy: 0.3244\n",
      "Epoch 699/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5422 - accuracy: 0.4711 - val_loss: 2.4322 - val_accuracy: 0.3318\n",
      "Epoch 700/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5420 - accuracy: 0.4750 - val_loss: 2.4105 - val_accuracy: 0.3450\n",
      "Epoch 701/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5430 - accuracy: 0.4733 - val_loss: 2.4015 - val_accuracy: 0.3341\n",
      "Epoch 702/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5170 - accuracy: 0.4867 - val_loss: 2.4127 - val_accuracy: 0.3357\n",
      "Epoch 703/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5389 - accuracy: 0.4801 - val_loss: 2.4088 - val_accuracy: 0.3373\n",
      "Epoch 704/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5405 - accuracy: 0.4672 - val_loss: 2.4005 - val_accuracy: 0.3415\n",
      "Epoch 705/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5293 - accuracy: 0.4797 - val_loss: 2.3888 - val_accuracy: 0.3441\n",
      "Epoch 706/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5448 - accuracy: 0.4764 - val_loss: 2.3912 - val_accuracy: 0.3476\n",
      "Epoch 707/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5425 - accuracy: 0.4812 - val_loss: 2.4054 - val_accuracy: 0.3386\n",
      "Epoch 708/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5445 - accuracy: 0.4707 - val_loss: 2.3954 - val_accuracy: 0.3479\n",
      "Epoch 709/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5438 - accuracy: 0.4684 - val_loss: 2.4098 - val_accuracy: 0.3389\n",
      "Epoch 710/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5418 - accuracy: 0.4740 - val_loss: 2.4296 - val_accuracy: 0.3241\n",
      "Epoch 711/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5455 - accuracy: 0.4784 - val_loss: 2.4115 - val_accuracy: 0.3354\n",
      "Epoch 712/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5573 - accuracy: 0.4708 - val_loss: 2.3884 - val_accuracy: 0.3347\n",
      "Epoch 713/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5399 - accuracy: 0.4823 - val_loss: 2.4059 - val_accuracy: 0.3434\n",
      "Epoch 714/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5453 - accuracy: 0.4742 - val_loss: 2.4126 - val_accuracy: 0.3392\n",
      "Epoch 715/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5383 - accuracy: 0.4801 - val_loss: 2.4046 - val_accuracy: 0.3344\n",
      "Epoch 716/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5478 - accuracy: 0.4684 - val_loss: 2.3775 - val_accuracy: 0.3508\n",
      "Epoch 717/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5324 - accuracy: 0.4795 - val_loss: 2.3979 - val_accuracy: 0.3328\n",
      "Epoch 718/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5467 - accuracy: 0.4706 - val_loss: 2.3987 - val_accuracy: 0.3399\n",
      "Epoch 719/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5390 - accuracy: 0.4662 - val_loss: 2.4169 - val_accuracy: 0.3389\n",
      "Epoch 720/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5308 - accuracy: 0.4761 - val_loss: 2.4143 - val_accuracy: 0.3273\n",
      "Epoch 721/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5441 - accuracy: 0.4707 - val_loss: 2.4058 - val_accuracy: 0.3373\n",
      "Epoch 722/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5378 - accuracy: 0.4766 - val_loss: 2.3858 - val_accuracy: 0.3412\n",
      "Epoch 723/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5497 - accuracy: 0.4692 - val_loss: 2.4421 - val_accuracy: 0.3392\n",
      "Epoch 724/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5318 - accuracy: 0.4785 - val_loss: 2.4129 - val_accuracy: 0.3460\n",
      "Epoch 725/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5343 - accuracy: 0.4747 - val_loss: 2.4230 - val_accuracy: 0.3328\n",
      "Epoch 726/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5229 - accuracy: 0.4782 - val_loss: 2.3926 - val_accuracy: 0.3515\n",
      "Epoch 727/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5342 - accuracy: 0.4722 - val_loss: 2.4215 - val_accuracy: 0.3325\n",
      "Epoch 728/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5342 - accuracy: 0.4694 - val_loss: 2.4292 - val_accuracy: 0.3325\n",
      "Epoch 729/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5483 - accuracy: 0.4715 - val_loss: 2.3973 - val_accuracy: 0.3502\n",
      "Epoch 730/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5350 - accuracy: 0.4835 - val_loss: 2.3873 - val_accuracy: 0.3360\n",
      "Epoch 731/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5354 - accuracy: 0.4814 - val_loss: 2.3995 - val_accuracy: 0.3399\n",
      "Epoch 732/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5523 - accuracy: 0.4763 - val_loss: 2.4193 - val_accuracy: 0.3328\n",
      "Epoch 733/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5382 - accuracy: 0.4762 - val_loss: 2.4202 - val_accuracy: 0.3418\n",
      "Epoch 734/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5187 - accuracy: 0.4782 - val_loss: 2.4138 - val_accuracy: 0.3322\n",
      "Epoch 735/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5454 - accuracy: 0.4721 - val_loss: 2.4389 - val_accuracy: 0.3341\n",
      "Epoch 736/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5232 - accuracy: 0.4778 - val_loss: 2.4210 - val_accuracy: 0.3402\n",
      "Epoch 737/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5425 - accuracy: 0.4727 - val_loss: 2.4200 - val_accuracy: 0.3376\n",
      "Epoch 738/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5248 - accuracy: 0.4811 - val_loss: 2.3924 - val_accuracy: 0.3412\n",
      "Epoch 739/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5414 - accuracy: 0.4684 - val_loss: 2.4172 - val_accuracy: 0.3441\n",
      "Epoch 740/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5368 - accuracy: 0.4774 - val_loss: 2.4084 - val_accuracy: 0.3415\n",
      "Epoch 741/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5315 - accuracy: 0.4779 - val_loss: 2.4015 - val_accuracy: 0.3376\n",
      "Epoch 742/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5251 - accuracy: 0.4793 - val_loss: 2.3857 - val_accuracy: 0.3499\n",
      "Epoch 743/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5343 - accuracy: 0.4710 - val_loss: 2.4003 - val_accuracy: 0.3531\n",
      "Epoch 744/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5416 - accuracy: 0.4839 - val_loss: 2.4264 - val_accuracy: 0.3344\n",
      "Epoch 745/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5363 - accuracy: 0.4691 - val_loss: 2.4226 - val_accuracy: 0.3302\n",
      "Epoch 746/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5403 - accuracy: 0.4756 - val_loss: 2.4311 - val_accuracy: 0.3328\n",
      "Epoch 747/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5197 - accuracy: 0.4770 - val_loss: 2.4205 - val_accuracy: 0.3322\n",
      "Epoch 748/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5230 - accuracy: 0.4796 - val_loss: 2.4155 - val_accuracy: 0.3376\n",
      "Epoch 749/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5317 - accuracy: 0.4802 - val_loss: 2.4151 - val_accuracy: 0.3357\n",
      "Epoch 750/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5136 - accuracy: 0.4865 - val_loss: 2.4158 - val_accuracy: 0.3466\n",
      "Epoch 751/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5214 - accuracy: 0.4895 - val_loss: 2.4100 - val_accuracy: 0.3367\n",
      "Epoch 752/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5202 - accuracy: 0.4770 - val_loss: 2.4113 - val_accuracy: 0.3405\n",
      "Epoch 753/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5364 - accuracy: 0.4780 - val_loss: 2.4040 - val_accuracy: 0.3483\n",
      "Epoch 754/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5323 - accuracy: 0.4785 - val_loss: 2.4178 - val_accuracy: 0.3425\n",
      "Epoch 755/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5332 - accuracy: 0.4730 - val_loss: 2.3971 - val_accuracy: 0.3524\n",
      "Epoch 756/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5240 - accuracy: 0.4800 - val_loss: 2.4261 - val_accuracy: 0.3254\n",
      "Epoch 757/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5455 - accuracy: 0.4704 - val_loss: 2.4210 - val_accuracy: 0.3286\n",
      "Epoch 758/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5319 - accuracy: 0.4795 - val_loss: 2.4055 - val_accuracy: 0.3409\n",
      "Epoch 759/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5173 - accuracy: 0.4870 - val_loss: 2.4035 - val_accuracy: 0.3447\n",
      "Epoch 760/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5361 - accuracy: 0.4766 - val_loss: 2.4165 - val_accuracy: 0.3425\n",
      "Epoch 761/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5540 - accuracy: 0.4732 - val_loss: 2.4314 - val_accuracy: 0.3438\n",
      "Epoch 762/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5298 - accuracy: 0.4847 - val_loss: 2.3977 - val_accuracy: 0.3415\n",
      "Epoch 763/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5228 - accuracy: 0.4692 - val_loss: 2.4287 - val_accuracy: 0.3344\n",
      "Epoch 764/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5458 - accuracy: 0.4753 - val_loss: 2.4140 - val_accuracy: 0.3396\n",
      "Epoch 765/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5345 - accuracy: 0.4849 - val_loss: 2.4149 - val_accuracy: 0.3412\n",
      "Epoch 766/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5373 - accuracy: 0.4802 - val_loss: 2.4279 - val_accuracy: 0.3354\n",
      "Epoch 767/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5302 - accuracy: 0.4760 - val_loss: 2.4288 - val_accuracy: 0.3328\n",
      "Epoch 768/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5252 - accuracy: 0.4812 - val_loss: 2.4020 - val_accuracy: 0.3363\n",
      "Epoch 769/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5333 - accuracy: 0.4711 - val_loss: 2.4064 - val_accuracy: 0.3360\n",
      "Epoch 770/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5443 - accuracy: 0.4654 - val_loss: 2.4093 - val_accuracy: 0.3415\n",
      "Epoch 771/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5466 - accuracy: 0.4778 - val_loss: 2.4018 - val_accuracy: 0.3476\n",
      "Epoch 772/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5329 - accuracy: 0.4778 - val_loss: 2.4168 - val_accuracy: 0.3347\n",
      "Epoch 773/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5098 - accuracy: 0.4858 - val_loss: 2.4224 - val_accuracy: 0.3305\n",
      "Epoch 774/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5262 - accuracy: 0.4790 - val_loss: 2.4075 - val_accuracy: 0.3389\n",
      "Epoch 775/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5246 - accuracy: 0.4827 - val_loss: 2.4291 - val_accuracy: 0.3363\n",
      "Epoch 776/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5337 - accuracy: 0.4808 - val_loss: 2.4577 - val_accuracy: 0.3218\n",
      "Epoch 777/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5282 - accuracy: 0.4861 - val_loss: 2.4081 - val_accuracy: 0.3438\n",
      "Epoch 778/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5124 - accuracy: 0.4832 - val_loss: 2.4500 - val_accuracy: 0.3251\n",
      "Epoch 779/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5254 - accuracy: 0.4810 - val_loss: 2.3992 - val_accuracy: 0.3383\n",
      "Epoch 780/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5287 - accuracy: 0.4810 - val_loss: 2.4151 - val_accuracy: 0.3318\n",
      "Epoch 781/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5221 - accuracy: 0.4816 - val_loss: 2.4156 - val_accuracy: 0.3409\n",
      "Epoch 782/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5158 - accuracy: 0.4875 - val_loss: 2.4232 - val_accuracy: 0.3312\n",
      "Epoch 783/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5288 - accuracy: 0.4797 - val_loss: 2.4439 - val_accuracy: 0.3315\n",
      "Epoch 784/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5251 - accuracy: 0.4825 - val_loss: 2.4085 - val_accuracy: 0.3441\n",
      "Epoch 785/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5220 - accuracy: 0.4798 - val_loss: 2.4081 - val_accuracy: 0.3341\n",
      "Epoch 786/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5207 - accuracy: 0.4829 - val_loss: 2.4210 - val_accuracy: 0.3438\n",
      "Epoch 787/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5164 - accuracy: 0.4840 - val_loss: 2.4505 - val_accuracy: 0.3257\n",
      "Epoch 788/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5216 - accuracy: 0.4823 - val_loss: 2.4108 - val_accuracy: 0.3425\n",
      "Epoch 789/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5291 - accuracy: 0.4716 - val_loss: 2.4155 - val_accuracy: 0.3409\n",
      "Epoch 790/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5378 - accuracy: 0.4785 - val_loss: 2.4238 - val_accuracy: 0.3421\n",
      "Epoch 791/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5364 - accuracy: 0.4702 - val_loss: 2.4056 - val_accuracy: 0.3418\n",
      "Epoch 792/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5345 - accuracy: 0.4775 - val_loss: 2.4583 - val_accuracy: 0.3367\n",
      "Epoch 793/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5284 - accuracy: 0.4825 - val_loss: 2.4342 - val_accuracy: 0.3286\n",
      "Epoch 794/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5062 - accuracy: 0.4867 - val_loss: 2.4210 - val_accuracy: 0.3392\n",
      "Epoch 795/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5214 - accuracy: 0.4864 - val_loss: 2.4149 - val_accuracy: 0.3315\n",
      "Epoch 796/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5264 - accuracy: 0.4815 - val_loss: 2.3996 - val_accuracy: 0.3447\n",
      "Epoch 797/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5234 - accuracy: 0.4805 - val_loss: 2.4402 - val_accuracy: 0.3380\n",
      "Epoch 798/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5415 - accuracy: 0.4722 - val_loss: 2.4321 - val_accuracy: 0.3363\n",
      "Epoch 799/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5222 - accuracy: 0.4803 - val_loss: 2.4329 - val_accuracy: 0.3399\n",
      "Epoch 800/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5037 - accuracy: 0.4836 - val_loss: 2.4260 - val_accuracy: 0.3428\n",
      "Epoch 801/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5148 - accuracy: 0.4777 - val_loss: 2.4090 - val_accuracy: 0.3405\n",
      "Epoch 802/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5199 - accuracy: 0.4767 - val_loss: 2.4025 - val_accuracy: 0.3466\n",
      "Epoch 803/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5220 - accuracy: 0.4882 - val_loss: 2.4446 - val_accuracy: 0.3354\n",
      "Epoch 804/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5246 - accuracy: 0.4720 - val_loss: 2.4132 - val_accuracy: 0.3412\n",
      "Epoch 805/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5298 - accuracy: 0.4773 - val_loss: 2.4297 - val_accuracy: 0.3312\n",
      "Epoch 806/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5308 - accuracy: 0.4808 - val_loss: 2.4232 - val_accuracy: 0.3373\n",
      "Epoch 807/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5413 - accuracy: 0.4728 - val_loss: 2.4156 - val_accuracy: 0.3470\n",
      "Epoch 808/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5190 - accuracy: 0.4749 - val_loss: 2.4180 - val_accuracy: 0.3386\n",
      "Epoch 809/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5040 - accuracy: 0.4812 - val_loss: 2.4472 - val_accuracy: 0.3293\n",
      "Epoch 810/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5167 - accuracy: 0.4868 - val_loss: 2.4312 - val_accuracy: 0.3354\n",
      "Epoch 811/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5157 - accuracy: 0.4865 - val_loss: 2.4116 - val_accuracy: 0.3431\n",
      "Epoch 812/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5250 - accuracy: 0.4755 - val_loss: 2.4078 - val_accuracy: 0.3370\n",
      "Epoch 813/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5210 - accuracy: 0.4757 - val_loss: 2.4634 - val_accuracy: 0.3354\n",
      "Epoch 814/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5321 - accuracy: 0.4723 - val_loss: 2.4242 - val_accuracy: 0.3386\n",
      "Epoch 815/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5157 - accuracy: 0.4798 - val_loss: 2.4419 - val_accuracy: 0.3286\n",
      "Epoch 816/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5399 - accuracy: 0.4813 - val_loss: 2.4008 - val_accuracy: 0.3363\n",
      "Epoch 817/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5228 - accuracy: 0.4791 - val_loss: 2.4087 - val_accuracy: 0.3502\n",
      "Epoch 818/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5199 - accuracy: 0.4801 - val_loss: 2.4292 - val_accuracy: 0.3421\n",
      "Epoch 819/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5293 - accuracy: 0.4804 - val_loss: 2.4266 - val_accuracy: 0.3386\n",
      "Epoch 820/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5133 - accuracy: 0.4839 - val_loss: 2.4395 - val_accuracy: 0.3312\n",
      "Epoch 821/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5284 - accuracy: 0.4828 - val_loss: 2.4382 - val_accuracy: 0.3392\n",
      "Epoch 822/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5202 - accuracy: 0.4857 - val_loss: 2.4504 - val_accuracy: 0.3367\n",
      "Epoch 823/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5254 - accuracy: 0.4775 - val_loss: 2.4032 - val_accuracy: 0.3476\n",
      "Epoch 824/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5256 - accuracy: 0.4899 - val_loss: 2.4469 - val_accuracy: 0.3286\n",
      "Epoch 825/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4909 - accuracy: 0.4917 - val_loss: 2.4330 - val_accuracy: 0.3338\n",
      "Epoch 826/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5319 - accuracy: 0.4840 - val_loss: 2.4480 - val_accuracy: 0.3325\n",
      "Epoch 827/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5135 - accuracy: 0.4899 - val_loss: 2.4355 - val_accuracy: 0.3325\n",
      "Epoch 828/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5413 - accuracy: 0.4667 - val_loss: 2.4286 - val_accuracy: 0.3351\n",
      "Epoch 829/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5195 - accuracy: 0.4820 - val_loss: 2.4457 - val_accuracy: 0.3370\n",
      "Epoch 830/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5250 - accuracy: 0.4715 - val_loss: 2.4144 - val_accuracy: 0.3402\n",
      "Epoch 831/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5189 - accuracy: 0.4807 - val_loss: 2.4521 - val_accuracy: 0.3309\n",
      "Epoch 832/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5136 - accuracy: 0.4833 - val_loss: 2.4364 - val_accuracy: 0.3341\n",
      "Epoch 833/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5220 - accuracy: 0.4798 - val_loss: 2.4265 - val_accuracy: 0.3225\n",
      "Epoch 834/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5245 - accuracy: 0.4713 - val_loss: 2.4092 - val_accuracy: 0.3473\n",
      "Epoch 835/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5213 - accuracy: 0.4893 - val_loss: 2.4269 - val_accuracy: 0.3376\n",
      "Epoch 836/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5220 - accuracy: 0.4900 - val_loss: 2.4279 - val_accuracy: 0.3392\n",
      "Epoch 837/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5211 - accuracy: 0.4805 - val_loss: 2.4282 - val_accuracy: 0.3412\n",
      "Epoch 838/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5246 - accuracy: 0.4800 - val_loss: 2.4218 - val_accuracy: 0.3392\n",
      "Epoch 839/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5229 - accuracy: 0.4774 - val_loss: 2.4185 - val_accuracy: 0.3466\n",
      "Epoch 840/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5267 - accuracy: 0.4814 - val_loss: 2.3956 - val_accuracy: 0.3441\n",
      "Epoch 841/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5425 - accuracy: 0.4753 - val_loss: 2.4287 - val_accuracy: 0.3518\n",
      "Epoch 842/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5322 - accuracy: 0.4698 - val_loss: 2.4334 - val_accuracy: 0.3315\n",
      "Epoch 843/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5094 - accuracy: 0.4842 - val_loss: 2.4272 - val_accuracy: 0.3415\n",
      "Epoch 844/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5318 - accuracy: 0.4705 - val_loss: 2.4347 - val_accuracy: 0.3454\n",
      "Epoch 845/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5189 - accuracy: 0.4795 - val_loss: 2.4520 - val_accuracy: 0.3399\n",
      "Epoch 846/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5177 - accuracy: 0.4892 - val_loss: 2.4215 - val_accuracy: 0.3431\n",
      "Epoch 847/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5284 - accuracy: 0.4797 - val_loss: 2.3997 - val_accuracy: 0.3389\n",
      "Epoch 848/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5047 - accuracy: 0.4838 - val_loss: 2.4086 - val_accuracy: 0.3438\n",
      "Epoch 849/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5337 - accuracy: 0.4733 - val_loss: 2.4719 - val_accuracy: 0.3373\n",
      "Epoch 850/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5319 - accuracy: 0.4770 - val_loss: 2.4515 - val_accuracy: 0.3225\n",
      "Epoch 851/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5181 - accuracy: 0.4809 - val_loss: 2.4461 - val_accuracy: 0.3309\n",
      "Epoch 852/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5173 - accuracy: 0.4822 - val_loss: 2.4235 - val_accuracy: 0.3318\n",
      "Epoch 853/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5280 - accuracy: 0.4779 - val_loss: 2.4304 - val_accuracy: 0.3318\n",
      "Epoch 854/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5250 - accuracy: 0.4852 - val_loss: 2.4401 - val_accuracy: 0.3331\n",
      "Epoch 855/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5113 - accuracy: 0.4804 - val_loss: 2.4245 - val_accuracy: 0.3392\n",
      "Epoch 856/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5081 - accuracy: 0.4770 - val_loss: 2.4101 - val_accuracy: 0.3495\n",
      "Epoch 857/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5045 - accuracy: 0.4811 - val_loss: 2.4362 - val_accuracy: 0.3299\n",
      "Epoch 858/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5166 - accuracy: 0.4852 - val_loss: 2.4541 - val_accuracy: 0.3334\n",
      "Epoch 859/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5182 - accuracy: 0.4814 - val_loss: 2.4568 - val_accuracy: 0.3357\n",
      "Epoch 860/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5067 - accuracy: 0.4819 - val_loss: 2.4031 - val_accuracy: 0.3476\n",
      "Epoch 861/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5252 - accuracy: 0.4739 - val_loss: 2.4371 - val_accuracy: 0.3334\n",
      "Epoch 862/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5196 - accuracy: 0.4797 - val_loss: 2.4461 - val_accuracy: 0.3273\n",
      "Epoch 863/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5093 - accuracy: 0.4822 - val_loss: 2.4621 - val_accuracy: 0.3289\n",
      "Epoch 864/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5123 - accuracy: 0.4856 - val_loss: 2.4258 - val_accuracy: 0.3334\n",
      "Epoch 865/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5111 - accuracy: 0.4888 - val_loss: 2.4444 - val_accuracy: 0.3376\n",
      "Epoch 866/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5250 - accuracy: 0.4786 - val_loss: 2.4231 - val_accuracy: 0.3373\n",
      "Epoch 867/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5170 - accuracy: 0.4763 - val_loss: 2.4457 - val_accuracy: 0.3312\n",
      "Epoch 868/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5396 - accuracy: 0.4723 - val_loss: 2.4450 - val_accuracy: 0.3431\n",
      "Epoch 869/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5158 - accuracy: 0.4794 - val_loss: 2.4458 - val_accuracy: 0.3225\n",
      "Epoch 870/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5186 - accuracy: 0.4759 - val_loss: 2.4342 - val_accuracy: 0.3331\n",
      "Epoch 871/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5117 - accuracy: 0.4790 - val_loss: 2.4518 - val_accuracy: 0.3322\n",
      "Epoch 872/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5089 - accuracy: 0.4918 - val_loss: 2.4261 - val_accuracy: 0.3405\n",
      "Epoch 873/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5110 - accuracy: 0.4823 - val_loss: 2.4356 - val_accuracy: 0.3412\n",
      "Epoch 874/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5122 - accuracy: 0.4795 - val_loss: 2.4188 - val_accuracy: 0.3434\n",
      "Epoch 875/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5022 - accuracy: 0.4824 - val_loss: 2.4481 - val_accuracy: 0.3347\n",
      "Epoch 876/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5128 - accuracy: 0.4853 - val_loss: 2.4377 - val_accuracy: 0.3479\n",
      "Epoch 877/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5154 - accuracy: 0.4853 - val_loss: 2.4505 - val_accuracy: 0.3347\n",
      "Epoch 878/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5194 - accuracy: 0.4793 - val_loss: 2.4551 - val_accuracy: 0.3334\n",
      "Epoch 879/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5160 - accuracy: 0.4867 - val_loss: 2.4436 - val_accuracy: 0.3363\n",
      "Epoch 880/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5107 - accuracy: 0.4894 - val_loss: 2.4519 - val_accuracy: 0.3267\n",
      "Epoch 881/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5208 - accuracy: 0.4798 - val_loss: 2.4584 - val_accuracy: 0.3367\n",
      "Epoch 882/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5112 - accuracy: 0.4824 - val_loss: 2.4270 - val_accuracy: 0.3270\n",
      "Epoch 883/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5141 - accuracy: 0.4773 - val_loss: 2.4435 - val_accuracy: 0.3334\n",
      "Epoch 884/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5062 - accuracy: 0.4855 - val_loss: 2.4670 - val_accuracy: 0.3367\n",
      "Epoch 885/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5115 - accuracy: 0.4820 - val_loss: 2.4243 - val_accuracy: 0.3322\n",
      "Epoch 886/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5130 - accuracy: 0.4821 - val_loss: 2.4629 - val_accuracy: 0.3251\n",
      "Epoch 887/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5217 - accuracy: 0.4794 - val_loss: 2.4348 - val_accuracy: 0.3299\n",
      "Epoch 888/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5149 - accuracy: 0.4834 - val_loss: 2.4431 - val_accuracy: 0.3293\n",
      "Epoch 889/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5113 - accuracy: 0.4838 - val_loss: 2.4591 - val_accuracy: 0.3318\n",
      "Epoch 890/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5145 - accuracy: 0.4804 - val_loss: 2.4434 - val_accuracy: 0.3302\n",
      "Epoch 891/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5083 - accuracy: 0.4816 - val_loss: 2.4254 - val_accuracy: 0.3399\n",
      "Epoch 892/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5139 - accuracy: 0.4756 - val_loss: 2.4280 - val_accuracy: 0.3322\n",
      "Epoch 893/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5213 - accuracy: 0.4749 - val_loss: 2.4649 - val_accuracy: 0.3280\n",
      "Epoch 894/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5143 - accuracy: 0.4777 - val_loss: 2.4710 - val_accuracy: 0.3280\n",
      "Epoch 895/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.4877 - accuracy: 0.4892 - val_loss: 2.4500 - val_accuracy: 0.3396\n",
      "Epoch 896/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5043 - accuracy: 0.4847 - val_loss: 2.4457 - val_accuracy: 0.3380\n",
      "Epoch 897/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5011 - accuracy: 0.4940 - val_loss: 2.4355 - val_accuracy: 0.3360\n",
      "Epoch 898/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5119 - accuracy: 0.4806 - val_loss: 2.4334 - val_accuracy: 0.3396\n",
      "Epoch 899/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5110 - accuracy: 0.4772 - val_loss: 2.4259 - val_accuracy: 0.3405\n",
      "Epoch 900/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5279 - accuracy: 0.4770 - val_loss: 2.4559 - val_accuracy: 0.3235\n",
      "Epoch 901/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5182 - accuracy: 0.4790 - val_loss: 2.4612 - val_accuracy: 0.3347\n",
      "Epoch 902/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4957 - accuracy: 0.4917 - val_loss: 2.4559 - val_accuracy: 0.3334\n",
      "Epoch 903/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5253 - accuracy: 0.4877 - val_loss: 2.4663 - val_accuracy: 0.3357\n",
      "Epoch 904/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5115 - accuracy: 0.4869 - val_loss: 2.4453 - val_accuracy: 0.3415\n",
      "Epoch 905/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5049 - accuracy: 0.4902 - val_loss: 2.4497 - val_accuracy: 0.3392\n",
      "Epoch 906/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5218 - accuracy: 0.4870 - val_loss: 2.4657 - val_accuracy: 0.3318\n",
      "Epoch 907/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5190 - accuracy: 0.4813 - val_loss: 2.4376 - val_accuracy: 0.3347\n",
      "Epoch 908/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5147 - accuracy: 0.4771 - val_loss: 2.4249 - val_accuracy: 0.3325\n",
      "Epoch 909/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5196 - accuracy: 0.4726 - val_loss: 2.4559 - val_accuracy: 0.3280\n",
      "Epoch 910/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5253 - accuracy: 0.4809 - val_loss: 2.4235 - val_accuracy: 0.3421\n",
      "Epoch 911/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5060 - accuracy: 0.4815 - val_loss: 2.4453 - val_accuracy: 0.3318\n",
      "Epoch 912/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5162 - accuracy: 0.4843 - val_loss: 2.4494 - val_accuracy: 0.3341\n",
      "Epoch 913/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5171 - accuracy: 0.4891 - val_loss: 2.4402 - val_accuracy: 0.3418\n",
      "Epoch 914/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5167 - accuracy: 0.4795 - val_loss: 2.4366 - val_accuracy: 0.3347\n",
      "Epoch 915/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5072 - accuracy: 0.4909 - val_loss: 2.4574 - val_accuracy: 0.3267\n",
      "Epoch 916/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5105 - accuracy: 0.4802 - val_loss: 2.4410 - val_accuracy: 0.3347\n",
      "Epoch 917/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5146 - accuracy: 0.4843 - val_loss: 2.4527 - val_accuracy: 0.3325\n",
      "Epoch 918/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5124 - accuracy: 0.4769 - val_loss: 2.4656 - val_accuracy: 0.3363\n",
      "Epoch 919/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5054 - accuracy: 0.4885 - val_loss: 2.4567 - val_accuracy: 0.3267\n",
      "Epoch 920/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5032 - accuracy: 0.4802 - val_loss: 2.4446 - val_accuracy: 0.3347\n",
      "Epoch 921/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5111 - accuracy: 0.4772 - val_loss: 2.4684 - val_accuracy: 0.3322\n",
      "Epoch 922/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5150 - accuracy: 0.4756 - val_loss: 2.4461 - val_accuracy: 0.3441\n",
      "Epoch 923/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5077 - accuracy: 0.4860 - val_loss: 2.4678 - val_accuracy: 0.3334\n",
      "Epoch 924/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5358 - accuracy: 0.4708 - val_loss: 2.4390 - val_accuracy: 0.3351\n",
      "Epoch 925/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5121 - accuracy: 0.4825 - val_loss: 2.4705 - val_accuracy: 0.3312\n",
      "Epoch 926/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4966 - accuracy: 0.4902 - val_loss: 2.4432 - val_accuracy: 0.3425\n",
      "Epoch 927/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5100 - accuracy: 0.4877 - val_loss: 2.4619 - val_accuracy: 0.3325\n",
      "Epoch 928/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5142 - accuracy: 0.4783 - val_loss: 2.4417 - val_accuracy: 0.3425\n",
      "Epoch 929/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5119 - accuracy: 0.4853 - val_loss: 2.4647 - val_accuracy: 0.3254\n",
      "Epoch 930/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4887 - accuracy: 0.4874 - val_loss: 2.4600 - val_accuracy: 0.3338\n",
      "Epoch 931/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5030 - accuracy: 0.4868 - val_loss: 2.4723 - val_accuracy: 0.3289\n",
      "Epoch 932/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4962 - accuracy: 0.4823 - val_loss: 2.4618 - val_accuracy: 0.3296\n",
      "Epoch 933/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5051 - accuracy: 0.4847 - val_loss: 2.4664 - val_accuracy: 0.3392\n",
      "Epoch 934/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5113 - accuracy: 0.4846 - val_loss: 2.4590 - val_accuracy: 0.3338\n",
      "Epoch 935/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5096 - accuracy: 0.4830 - val_loss: 2.4587 - val_accuracy: 0.3438\n",
      "Epoch 936/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5067 - accuracy: 0.4839 - val_loss: 2.4657 - val_accuracy: 0.3357\n",
      "Epoch 937/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5118 - accuracy: 0.4790 - val_loss: 2.4675 - val_accuracy: 0.3450\n",
      "Epoch 938/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4991 - accuracy: 0.4786 - val_loss: 2.4463 - val_accuracy: 0.3396\n",
      "Epoch 939/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4913 - accuracy: 0.4884 - val_loss: 2.4248 - val_accuracy: 0.3409\n",
      "Epoch 940/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5013 - accuracy: 0.4883 - val_loss: 2.4456 - val_accuracy: 0.3351\n",
      "Epoch 941/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.4864 - accuracy: 0.4894 - val_loss: 2.4445 - val_accuracy: 0.3373\n",
      "Epoch 942/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5140 - accuracy: 0.4756 - val_loss: 2.4570 - val_accuracy: 0.3367\n",
      "Epoch 943/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5038 - accuracy: 0.4811 - val_loss: 2.4392 - val_accuracy: 0.3315\n",
      "Epoch 944/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4790 - accuracy: 0.4955 - val_loss: 2.4606 - val_accuracy: 0.3293\n",
      "Epoch 945/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.4989 - accuracy: 0.4834 - val_loss: 2.4720 - val_accuracy: 0.3244\n",
      "Epoch 946/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5091 - accuracy: 0.4884 - val_loss: 2.4329 - val_accuracy: 0.3434\n",
      "Epoch 947/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4828 - accuracy: 0.4886 - val_loss: 2.4453 - val_accuracy: 0.3341\n",
      "Epoch 948/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5005 - accuracy: 0.4876 - val_loss: 2.4637 - val_accuracy: 0.3380\n",
      "Epoch 949/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5236 - accuracy: 0.4682 - val_loss: 2.4873 - val_accuracy: 0.3231\n",
      "Epoch 950/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5102 - accuracy: 0.4726 - val_loss: 2.4441 - val_accuracy: 0.3392\n",
      "Epoch 951/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5177 - accuracy: 0.4818 - val_loss: 2.4724 - val_accuracy: 0.3315\n",
      "Epoch 952/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.4811 - val_loss: 2.4728 - val_accuracy: 0.3299\n",
      "Epoch 953/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5010 - accuracy: 0.4822 - val_loss: 2.4576 - val_accuracy: 0.3302\n",
      "Epoch 954/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4941 - accuracy: 0.4857 - val_loss: 2.4460 - val_accuracy: 0.3283\n",
      "Epoch 955/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4980 - accuracy: 0.4881 - val_loss: 2.4740 - val_accuracy: 0.3331\n",
      "Epoch 956/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4988 - accuracy: 0.4897 - val_loss: 2.4781 - val_accuracy: 0.3231\n",
      "Epoch 957/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4870 - accuracy: 0.4871 - val_loss: 2.4470 - val_accuracy: 0.3431\n",
      "Epoch 958/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5085 - accuracy: 0.4794 - val_loss: 2.4733 - val_accuracy: 0.3189\n",
      "Epoch 959/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.4846 - val_loss: 2.4446 - val_accuracy: 0.3370\n",
      "Epoch 960/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5067 - accuracy: 0.4807 - val_loss: 2.4597 - val_accuracy: 0.3370\n",
      "Epoch 961/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5028 - accuracy: 0.4887 - val_loss: 2.4859 - val_accuracy: 0.3286\n",
      "Epoch 962/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5140 - accuracy: 0.4811 - val_loss: 2.4905 - val_accuracy: 0.3260\n",
      "Epoch 963/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5054 - accuracy: 0.4867 - val_loss: 2.4552 - val_accuracy: 0.3492\n",
      "Epoch 964/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5033 - accuracy: 0.4823 - val_loss: 2.4816 - val_accuracy: 0.3260\n",
      "Epoch 965/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5057 - accuracy: 0.4879 - val_loss: 2.4720 - val_accuracy: 0.3289\n",
      "Epoch 966/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5134 - accuracy: 0.4784 - val_loss: 2.4539 - val_accuracy: 0.3296\n",
      "Epoch 967/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4971 - accuracy: 0.4862 - val_loss: 2.4762 - val_accuracy: 0.3225\n",
      "Epoch 968/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.4929 - accuracy: 0.4911 - val_loss: 2.4308 - val_accuracy: 0.3354\n",
      "Epoch 969/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.4978 - accuracy: 0.4858 - val_loss: 2.4835 - val_accuracy: 0.3135\n",
      "Epoch 970/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5210 - accuracy: 0.4822 - val_loss: 2.4508 - val_accuracy: 0.3354\n",
      "Epoch 971/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5024 - accuracy: 0.4853 - val_loss: 2.4916 - val_accuracy: 0.3273\n",
      "Epoch 972/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.4843 - accuracy: 0.4884 - val_loss: 2.4494 - val_accuracy: 0.3389\n",
      "Epoch 973/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5148 - accuracy: 0.4778 - val_loss: 2.4477 - val_accuracy: 0.3363\n",
      "Epoch 974/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4993 - accuracy: 0.4827 - val_loss: 2.4445 - val_accuracy: 0.3392\n",
      "Epoch 975/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5046 - accuracy: 0.4818 - val_loss: 2.4569 - val_accuracy: 0.3289\n",
      "Epoch 976/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5099 - accuracy: 0.4880 - val_loss: 2.4569 - val_accuracy: 0.3351\n",
      "Epoch 977/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5116 - accuracy: 0.4861 - val_loss: 2.4670 - val_accuracy: 0.3296\n",
      "Epoch 978/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5042 - accuracy: 0.4862 - val_loss: 2.4601 - val_accuracy: 0.3425\n",
      "Epoch 979/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4917 - accuracy: 0.4894 - val_loss: 2.4993 - val_accuracy: 0.3254\n",
      "Epoch 980/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4904 - accuracy: 0.4882 - val_loss: 2.4701 - val_accuracy: 0.3206\n",
      "Epoch 981/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4983 - accuracy: 0.4890 - val_loss: 2.4508 - val_accuracy: 0.3425\n",
      "Epoch 982/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4984 - accuracy: 0.4791 - val_loss: 2.4491 - val_accuracy: 0.3354\n",
      "Epoch 983/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.5062 - accuracy: 0.4825 - val_loss: 2.4913 - val_accuracy: 0.3235\n",
      "Epoch 984/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4947 - accuracy: 0.4769 - val_loss: 2.4430 - val_accuracy: 0.3444\n",
      "Epoch 985/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4970 - accuracy: 0.4904 - val_loss: 2.4539 - val_accuracy: 0.3360\n",
      "Epoch 986/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4966 - accuracy: 0.4923 - val_loss: 2.4558 - val_accuracy: 0.3299\n",
      "Epoch 987/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.5051 - accuracy: 0.4886 - val_loss: 2.4520 - val_accuracy: 0.3354\n",
      "Epoch 988/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4889 - accuracy: 0.4910 - val_loss: 2.4548 - val_accuracy: 0.3370\n",
      "Epoch 989/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5011 - accuracy: 0.4826 - val_loss: 2.4835 - val_accuracy: 0.3251\n",
      "Epoch 990/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5058 - accuracy: 0.4851 - val_loss: 2.4513 - val_accuracy: 0.3415\n",
      "Epoch 991/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4918 - accuracy: 0.4881 - val_loss: 2.4952 - val_accuracy: 0.3270\n",
      "Epoch 992/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5048 - accuracy: 0.4866 - val_loss: 2.4527 - val_accuracy: 0.3247\n",
      "Epoch 993/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5209 - accuracy: 0.4851 - val_loss: 2.4604 - val_accuracy: 0.3264\n",
      "Epoch 994/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4985 - accuracy: 0.4879 - val_loss: 2.4686 - val_accuracy: 0.3351\n",
      "Epoch 995/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4972 - accuracy: 0.4802 - val_loss: 2.4589 - val_accuracy: 0.3257\n",
      "Epoch 996/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4885 - accuracy: 0.4891 - val_loss: 2.4450 - val_accuracy: 0.3386\n",
      "Epoch 997/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4878 - accuracy: 0.4748 - val_loss: 2.4649 - val_accuracy: 0.3302\n",
      "Epoch 998/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4854 - accuracy: 0.4817 - val_loss: 2.4816 - val_accuracy: 0.3202\n",
      "Epoch 999/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4964 - accuracy: 0.4857 - val_loss: 2.4777 - val_accuracy: 0.3334\n",
      "Epoch 1000/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4967 - accuracy: 0.4914 - val_loss: 2.4634 - val_accuracy: 0.3363\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_emb_aug = Emb_model_aug.fit(x_emb_aug_train, y_emb_aug_train_one_hot,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=16,\n",
    "                                 validation_data=(x_emb_aug_val, y_emb_aug_val_one_hot)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 49 (Val Accuracy: 0.42300257086753845)\n",
      "Best Epoch for Training Accuracy: 979 (Train Accuracy: 0.48833197355270386)\n",
      "Best Epoch for Training Loss: 999 (Train Loss: 1.4965800046920776)\n",
      "Best Epoch for Validation Loss: 84 (Val Loss: 2.144578456878662)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.42300257086753845\n",
      "Maximum Training Accuracy: 0.48833197355270386\n",
      "Minimum Training Loss: 1.4965800046920776\n",
      "Minimum Validation Loss: 2.144578456878662\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_aug, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file = \"many_to_many_emb_LSTM_baseline_aug_model.h5\"  \n",
    "Emb_model_aug.save(model_file)\n",
    "\n",
    "import pickle\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_emb_LSTM_baseline_aug_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_aug.history, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex LSTM with trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 4, 100)            3200      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 4, 64)             42240     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 4, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4, 64)             2112      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 62,048\n",
      "Trainable params: 58,848\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, TimeDistributed\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 98\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Parameters\n",
    "input_length = 4  # Length of input sequences\n",
    "num_moves = len(embedding_matrix_augmented)  # Number of unique moves\n",
    "embedding_dim = len(embedding_matrix_augmented[0])  # Dimension of Word2Vec embeddings\n",
    "\n",
    "\n",
    "# Define the LSTM model with an Embedding layer\n",
    "Emb_model_aug_complex = Sequential([\n",
    "    # Embedding layer with pre-trained Word2Vec weights\n",
    "    Embedding(input_dim=num_moves, output_dim=embedding_dim,  weights=[embedding_matrix_augmented], trainable=False, \n",
    "              input_length=input_length),\n",
    "\n",
    "    # First LSTM layer\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Second LSTM layer\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Dense layer\n",
    "    TimeDistributed(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))),\n",
    "\n",
    "    # Output layer\n",
    "    TimeDistributed(Dense(32, activation='softmax'))  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "Emb_model_aug_complex.compile(optimizer='adam', \n",
    "                                   loss='categorical_crossentropy', \n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "Emb_model_aug_complex.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "154/154 [==============================] - 4s 10ms/step - loss: 3.2747 - accuracy: 0.1429 - val_loss: 2.5588 - val_accuracy: 0.4069\n",
      "Epoch 2/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9552 - accuracy: 0.1685 - val_loss: 2.5373 - val_accuracy: 0.4069\n",
      "Epoch 3/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9334 - accuracy: 0.1761 - val_loss: 2.5373 - val_accuracy: 0.4069\n",
      "Epoch 4/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9428 - accuracy: 0.1682 - val_loss: 2.5313 - val_accuracy: 0.4069\n",
      "Epoch 5/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9352 - accuracy: 0.1714 - val_loss: 2.5380 - val_accuracy: 0.4069\n",
      "Epoch 6/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9393 - accuracy: 0.1707 - val_loss: 2.4725 - val_accuracy: 0.4069\n",
      "Epoch 7/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9308 - accuracy: 0.1701 - val_loss: 2.5096 - val_accuracy: 0.4069\n",
      "Epoch 8/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8996 - accuracy: 0.1708 - val_loss: 2.5544 - val_accuracy: 0.4062\n",
      "Epoch 9/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9095 - accuracy: 0.1725 - val_loss: 2.5354 - val_accuracy: 0.3895\n",
      "Epoch 10/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8747 - accuracy: 0.1671 - val_loss: 2.4794 - val_accuracy: 0.4046\n",
      "Epoch 11/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8815 - accuracy: 0.1727 - val_loss: 2.5170 - val_accuracy: 0.4034\n",
      "Epoch 12/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8498 - accuracy: 0.1680 - val_loss: 2.4827 - val_accuracy: 0.4027\n",
      "Epoch 13/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8333 - accuracy: 0.1795 - val_loss: 2.4713 - val_accuracy: 0.4001\n",
      "Epoch 14/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8114 - accuracy: 0.1803 - val_loss: 2.5095 - val_accuracy: 0.3808\n",
      "Epoch 15/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8126 - accuracy: 0.1837 - val_loss: 2.4734 - val_accuracy: 0.3747\n",
      "Epoch 16/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.7880 - accuracy: 0.1918 - val_loss: 2.4496 - val_accuracy: 0.3776\n",
      "Epoch 17/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.7570 - accuracy: 0.1927 - val_loss: 2.4157 - val_accuracy: 0.3737\n",
      "Epoch 18/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.7256 - accuracy: 0.1971 - val_loss: 2.3891 - val_accuracy: 0.3953\n",
      "Epoch 19/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.7262 - accuracy: 0.1872 - val_loss: 2.3839 - val_accuracy: 0.3715\n",
      "Epoch 20/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.7140 - accuracy: 0.1909 - val_loss: 2.3951 - val_accuracy: 0.3692\n",
      "Epoch 21/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.6842 - accuracy: 0.2041 - val_loss: 2.3551 - val_accuracy: 0.3605\n",
      "Epoch 22/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.6627 - accuracy: 0.2111 - val_loss: 2.3566 - val_accuracy: 0.3512\n",
      "Epoch 23/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.6613 - accuracy: 0.2060 - val_loss: 2.3412 - val_accuracy: 0.3547\n",
      "Epoch 24/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.6230 - accuracy: 0.2130 - val_loss: 2.3353 - val_accuracy: 0.3686\n",
      "Epoch 25/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.6167 - accuracy: 0.2286 - val_loss: 2.2861 - val_accuracy: 0.4082\n",
      "Epoch 26/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.6047 - accuracy: 0.2220 - val_loss: 2.2961 - val_accuracy: 0.3818\n",
      "Epoch 27/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5724 - accuracy: 0.2362 - val_loss: 2.2780 - val_accuracy: 0.3750\n",
      "Epoch 28/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5947 - accuracy: 0.2212 - val_loss: 2.2395 - val_accuracy: 0.3895\n",
      "Epoch 29/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5603 - accuracy: 0.2417 - val_loss: 2.2476 - val_accuracy: 0.4008\n",
      "Epoch 30/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5354 - accuracy: 0.2492 - val_loss: 2.2485 - val_accuracy: 0.4095\n",
      "Epoch 31/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5221 - accuracy: 0.2493 - val_loss: 2.2842 - val_accuracy: 0.3624\n",
      "Epoch 32/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.5075 - accuracy: 0.2533 - val_loss: 2.2126 - val_accuracy: 0.3998\n",
      "Epoch 33/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.4992 - accuracy: 0.2482 - val_loss: 2.2511 - val_accuracy: 0.3940\n",
      "Epoch 34/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 2.4881 - accuracy: 0.2451 - val_loss: 2.2011 - val_accuracy: 0.4027\n",
      "Epoch 35/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.4661 - accuracy: 0.2515 - val_loss: 2.2421 - val_accuracy: 0.3934\n",
      "Epoch 36/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.4294 - accuracy: 0.2661 - val_loss: 2.2378 - val_accuracy: 0.3950\n",
      "Epoch 37/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.4171 - accuracy: 0.2671 - val_loss: 2.2303 - val_accuracy: 0.4050\n",
      "Epoch 38/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.4109 - accuracy: 0.2661 - val_loss: 2.2535 - val_accuracy: 0.3930\n",
      "Epoch 39/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.4000 - accuracy: 0.2703 - val_loss: 2.2347 - val_accuracy: 0.4037\n",
      "Epoch 40/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3917 - accuracy: 0.2702 - val_loss: 2.2286 - val_accuracy: 0.4050\n",
      "Epoch 41/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3665 - accuracy: 0.2745 - val_loss: 2.2388 - val_accuracy: 0.3992\n",
      "Epoch 42/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3733 - accuracy: 0.2717 - val_loss: 2.2280 - val_accuracy: 0.3995\n",
      "Epoch 43/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3407 - accuracy: 0.2838 - val_loss: 2.2337 - val_accuracy: 0.4140\n",
      "Epoch 44/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3609 - accuracy: 0.2845 - val_loss: 2.2403 - val_accuracy: 0.4030\n",
      "Epoch 45/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3383 - accuracy: 0.2811 - val_loss: 2.2673 - val_accuracy: 0.4005\n",
      "Epoch 46/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3350 - accuracy: 0.2863 - val_loss: 2.2511 - val_accuracy: 0.4111\n",
      "Epoch 47/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3200 - accuracy: 0.2768 - val_loss: 2.2135 - val_accuracy: 0.4140\n",
      "Epoch 48/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3180 - accuracy: 0.2849 - val_loss: 2.2426 - val_accuracy: 0.4082\n",
      "Epoch 49/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3112 - accuracy: 0.2843 - val_loss: 2.2833 - val_accuracy: 0.3950\n",
      "Epoch 50/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2913 - accuracy: 0.2990 - val_loss: 2.2610 - val_accuracy: 0.3847\n",
      "Epoch 51/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.3027 - accuracy: 0.2813 - val_loss: 2.1907 - val_accuracy: 0.4236\n",
      "Epoch 52/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2748 - accuracy: 0.2877 - val_loss: 2.2332 - val_accuracy: 0.4027\n",
      "Epoch 53/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.3022 - accuracy: 0.2862 - val_loss: 2.2024 - val_accuracy: 0.4156\n",
      "Epoch 54/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2967 - accuracy: 0.2875 - val_loss: 2.2254 - val_accuracy: 0.4050\n",
      "Epoch 55/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2792 - accuracy: 0.2978 - val_loss: 2.2064 - val_accuracy: 0.4153\n",
      "Epoch 56/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2705 - accuracy: 0.2978 - val_loss: 2.2583 - val_accuracy: 0.3976\n",
      "Epoch 57/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2545 - accuracy: 0.2940 - val_loss: 2.1892 - val_accuracy: 0.4278\n",
      "Epoch 58/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2801 - accuracy: 0.2942 - val_loss: 2.2188 - val_accuracy: 0.4149\n",
      "Epoch 59/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2386 - accuracy: 0.3077 - val_loss: 2.2063 - val_accuracy: 0.4108\n",
      "Epoch 60/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2365 - accuracy: 0.3069 - val_loss: 2.2145 - val_accuracy: 0.4214\n",
      "Epoch 61/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2434 - accuracy: 0.2932 - val_loss: 2.2250 - val_accuracy: 0.4069\n",
      "Epoch 62/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2378 - accuracy: 0.3010 - val_loss: 2.2036 - val_accuracy: 0.4159\n",
      "Epoch 63/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2423 - accuracy: 0.2948 - val_loss: 2.2243 - val_accuracy: 0.4027\n",
      "Epoch 64/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2452 - accuracy: 0.2954 - val_loss: 2.2270 - val_accuracy: 0.3959\n",
      "Epoch 65/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2212 - accuracy: 0.3175 - val_loss: 2.2650 - val_accuracy: 0.3869\n",
      "Epoch 66/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2092 - accuracy: 0.3019 - val_loss: 2.2117 - val_accuracy: 0.4175\n",
      "Epoch 67/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1848 - accuracy: 0.3128 - val_loss: 2.2533 - val_accuracy: 0.3976\n",
      "Epoch 68/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1989 - accuracy: 0.3100 - val_loss: 2.2060 - val_accuracy: 0.4062\n",
      "Epoch 69/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2054 - accuracy: 0.3012 - val_loss: 2.2674 - val_accuracy: 0.3798\n",
      "Epoch 70/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2064 - accuracy: 0.3127 - val_loss: 2.2226 - val_accuracy: 0.4091\n",
      "Epoch 71/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1994 - accuracy: 0.3101 - val_loss: 2.1938 - val_accuracy: 0.4111\n",
      "Epoch 72/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1857 - accuracy: 0.3094 - val_loss: 2.2051 - val_accuracy: 0.4040\n",
      "Epoch 73/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1993 - accuracy: 0.3114 - val_loss: 2.2092 - val_accuracy: 0.4088\n",
      "Epoch 74/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1969 - accuracy: 0.3031 - val_loss: 2.1867 - val_accuracy: 0.4169\n",
      "Epoch 75/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1758 - accuracy: 0.3112 - val_loss: 2.2107 - val_accuracy: 0.3953\n",
      "Epoch 76/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1739 - accuracy: 0.3196 - val_loss: 2.1733 - val_accuracy: 0.4249\n",
      "Epoch 77/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1819 - accuracy: 0.3185 - val_loss: 2.1780 - val_accuracy: 0.4224\n",
      "Epoch 78/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1423 - accuracy: 0.3276 - val_loss: 2.1968 - val_accuracy: 0.4214\n",
      "Epoch 79/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1726 - accuracy: 0.3202 - val_loss: 2.2118 - val_accuracy: 0.4053\n",
      "Epoch 80/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1485 - accuracy: 0.3251 - val_loss: 2.2030 - val_accuracy: 0.3982\n",
      "Epoch 81/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1662 - accuracy: 0.3287 - val_loss: 2.1933 - val_accuracy: 0.4172\n",
      "Epoch 82/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1715 - accuracy: 0.3224 - val_loss: 2.2214 - val_accuracy: 0.3953\n",
      "Epoch 83/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1508 - accuracy: 0.3189 - val_loss: 2.1708 - val_accuracy: 0.4130\n",
      "Epoch 84/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1456 - accuracy: 0.3212 - val_loss: 2.2458 - val_accuracy: 0.3802\n",
      "Epoch 85/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1871 - accuracy: 0.3135 - val_loss: 2.1842 - val_accuracy: 0.4072\n",
      "Epoch 86/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1567 - accuracy: 0.3171 - val_loss: 2.2050 - val_accuracy: 0.4066\n",
      "Epoch 87/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1580 - accuracy: 0.3205 - val_loss: 2.1646 - val_accuracy: 0.4220\n",
      "Epoch 88/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.1446 - accuracy: 0.3183 - val_loss: 2.1844 - val_accuracy: 0.4091\n",
      "Epoch 89/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1343 - accuracy: 0.3263 - val_loss: 2.1572 - val_accuracy: 0.4256\n",
      "Epoch 90/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1253 - accuracy: 0.3247 - val_loss: 2.1699 - val_accuracy: 0.4137\n",
      "Epoch 91/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1333 - accuracy: 0.3290 - val_loss: 2.1887 - val_accuracy: 0.4034\n",
      "Epoch 92/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1604 - accuracy: 0.3205 - val_loss: 2.1932 - val_accuracy: 0.3908\n",
      "Epoch 93/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1069 - accuracy: 0.3326 - val_loss: 2.2076 - val_accuracy: 0.3934\n",
      "Epoch 94/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.1217 - accuracy: 0.3295 - val_loss: 2.1680 - val_accuracy: 0.4137\n",
      "Epoch 95/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1202 - accuracy: 0.3206 - val_loss: 2.2311 - val_accuracy: 0.3860\n",
      "Epoch 96/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1252 - accuracy: 0.3373 - val_loss: 2.2160 - val_accuracy: 0.3901\n",
      "Epoch 97/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1365 - accuracy: 0.3234 - val_loss: 2.2210 - val_accuracy: 0.3895\n",
      "Epoch 98/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 2.1146 - accuracy: 0.3235 - val_loss: 2.1788 - val_accuracy: 0.4101\n",
      "Epoch 99/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1280 - accuracy: 0.3265 - val_loss: 2.2172 - val_accuracy: 0.3856\n",
      "Epoch 100/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0947 - accuracy: 0.3317 - val_loss: 2.1807 - val_accuracy: 0.4088\n",
      "Epoch 101/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.1199 - accuracy: 0.3356 - val_loss: 2.2138 - val_accuracy: 0.3889\n",
      "Epoch 102/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.1123 - accuracy: 0.3359 - val_loss: 2.1650 - val_accuracy: 0.4130\n",
      "Epoch 103/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.1151 - accuracy: 0.3320 - val_loss: 2.1748 - val_accuracy: 0.3972\n",
      "Epoch 104/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1195 - accuracy: 0.3269 - val_loss: 2.1915 - val_accuracy: 0.4037\n",
      "Epoch 105/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1097 - accuracy: 0.3299 - val_loss: 2.2165 - val_accuracy: 0.3892\n",
      "Epoch 106/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1069 - accuracy: 0.3362 - val_loss: 2.2414 - val_accuracy: 0.3895\n",
      "Epoch 107/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0873 - accuracy: 0.3357 - val_loss: 2.1770 - val_accuracy: 0.4075\n",
      "Epoch 108/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0843 - accuracy: 0.3368 - val_loss: 2.1999 - val_accuracy: 0.3930\n",
      "Epoch 109/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0774 - accuracy: 0.3462 - val_loss: 2.2062 - val_accuracy: 0.3950\n",
      "Epoch 110/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0975 - accuracy: 0.3367 - val_loss: 2.1467 - val_accuracy: 0.4253\n",
      "Epoch 111/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0715 - accuracy: 0.3357 - val_loss: 2.1824 - val_accuracy: 0.4098\n",
      "Epoch 112/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0912 - accuracy: 0.3383 - val_loss: 2.1994 - val_accuracy: 0.3969\n",
      "Epoch 113/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0831 - accuracy: 0.3341 - val_loss: 2.1422 - val_accuracy: 0.4172\n",
      "Epoch 114/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0711 - accuracy: 0.3408 - val_loss: 2.1405 - val_accuracy: 0.4188\n",
      "Epoch 115/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0880 - accuracy: 0.3302 - val_loss: 2.1760 - val_accuracy: 0.3940\n",
      "Epoch 116/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0864 - accuracy: 0.3311 - val_loss: 2.1860 - val_accuracy: 0.3918\n",
      "Epoch 117/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1055 - accuracy: 0.3259 - val_loss: 2.1612 - val_accuracy: 0.4024\n",
      "Epoch 118/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0778 - accuracy: 0.3357 - val_loss: 2.1845 - val_accuracy: 0.3947\n",
      "Epoch 119/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0788 - accuracy: 0.3441 - val_loss: 2.1779 - val_accuracy: 0.4104\n",
      "Epoch 120/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0691 - accuracy: 0.3416 - val_loss: 2.1850 - val_accuracy: 0.3840\n",
      "Epoch 121/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0751 - accuracy: 0.3421 - val_loss: 2.1658 - val_accuracy: 0.4062\n",
      "Epoch 122/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0711 - accuracy: 0.3418 - val_loss: 2.1836 - val_accuracy: 0.3934\n",
      "Epoch 123/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0487 - accuracy: 0.3553 - val_loss: 2.1687 - val_accuracy: 0.3995\n",
      "Epoch 124/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0587 - accuracy: 0.3411 - val_loss: 2.1703 - val_accuracy: 0.3892\n",
      "Epoch 125/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0655 - accuracy: 0.3367 - val_loss: 2.1643 - val_accuracy: 0.4027\n",
      "Epoch 126/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0816 - accuracy: 0.3362 - val_loss: 2.1725 - val_accuracy: 0.3972\n",
      "Epoch 127/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0498 - accuracy: 0.3469 - val_loss: 2.1826 - val_accuracy: 0.3953\n",
      "Epoch 128/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0651 - accuracy: 0.3371 - val_loss: 2.1824 - val_accuracy: 0.3940\n",
      "Epoch 129/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0634 - accuracy: 0.3364 - val_loss: 2.1437 - val_accuracy: 0.3985\n",
      "Epoch 130/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0633 - accuracy: 0.3395 - val_loss: 2.2164 - val_accuracy: 0.3840\n",
      "Epoch 131/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0577 - accuracy: 0.3516 - val_loss: 2.1967 - val_accuracy: 0.3901\n",
      "Epoch 132/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0667 - accuracy: 0.3398 - val_loss: 2.1665 - val_accuracy: 0.3982\n",
      "Epoch 133/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0627 - accuracy: 0.3418 - val_loss: 2.1885 - val_accuracy: 0.3940\n",
      "Epoch 134/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0322 - accuracy: 0.3437 - val_loss: 2.1774 - val_accuracy: 0.3966\n",
      "Epoch 135/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0380 - accuracy: 0.3524 - val_loss: 2.2065 - val_accuracy: 0.3889\n",
      "Epoch 136/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0493 - accuracy: 0.3421 - val_loss: 2.2068 - val_accuracy: 0.3995\n",
      "Epoch 137/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0586 - accuracy: 0.3429 - val_loss: 2.1929 - val_accuracy: 0.4014\n",
      "Epoch 138/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0375 - accuracy: 0.3567 - val_loss: 2.2010 - val_accuracy: 0.3979\n",
      "Epoch 139/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0354 - accuracy: 0.3522 - val_loss: 2.1788 - val_accuracy: 0.3924\n",
      "Epoch 140/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0384 - accuracy: 0.3498 - val_loss: 2.1588 - val_accuracy: 0.4069\n",
      "Epoch 141/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0355 - accuracy: 0.3481 - val_loss: 2.1919 - val_accuracy: 0.3934\n",
      "Epoch 142/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0494 - accuracy: 0.3426 - val_loss: 2.1582 - val_accuracy: 0.4127\n",
      "Epoch 143/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0379 - accuracy: 0.3488 - val_loss: 2.1508 - val_accuracy: 0.4082\n",
      "Epoch 144/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0380 - accuracy: 0.3507 - val_loss: 2.1671 - val_accuracy: 0.4011\n",
      "Epoch 145/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0393 - accuracy: 0.3469 - val_loss: 2.1749 - val_accuracy: 0.3988\n",
      "Epoch 146/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0338 - accuracy: 0.3511 - val_loss: 2.1796 - val_accuracy: 0.4008\n",
      "Epoch 147/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0139 - accuracy: 0.3550 - val_loss: 2.1789 - val_accuracy: 0.3972\n",
      "Epoch 148/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0202 - accuracy: 0.3505 - val_loss: 2.1643 - val_accuracy: 0.3930\n",
      "Epoch 149/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0204 - accuracy: 0.3495 - val_loss: 2.1371 - val_accuracy: 0.4133\n",
      "Epoch 150/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0227 - accuracy: 0.3502 - val_loss: 2.1310 - val_accuracy: 0.4172\n",
      "Epoch 151/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0397 - accuracy: 0.3526 - val_loss: 2.1802 - val_accuracy: 0.3937\n",
      "Epoch 152/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0189 - accuracy: 0.3521 - val_loss: 2.1772 - val_accuracy: 0.3982\n",
      "Epoch 153/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0091 - accuracy: 0.3549 - val_loss: 2.1688 - val_accuracy: 0.3924\n",
      "Epoch 154/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0420 - accuracy: 0.3464 - val_loss: 2.1338 - val_accuracy: 0.4114\n",
      "Epoch 155/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0290 - accuracy: 0.3513 - val_loss: 2.1706 - val_accuracy: 0.3937\n",
      "Epoch 156/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0459 - accuracy: 0.3427 - val_loss: 2.1604 - val_accuracy: 0.3908\n",
      "Epoch 157/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0281 - accuracy: 0.3457 - val_loss: 2.1396 - val_accuracy: 0.4053\n",
      "Epoch 158/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0358 - accuracy: 0.3463 - val_loss: 2.1756 - val_accuracy: 0.3811\n",
      "Epoch 159/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0349 - accuracy: 0.3426 - val_loss: 2.1534 - val_accuracy: 0.4079\n",
      "Epoch 160/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0134 - accuracy: 0.3522 - val_loss: 2.1481 - val_accuracy: 0.4133\n",
      "Epoch 161/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0335 - accuracy: 0.3497 - val_loss: 2.1644 - val_accuracy: 0.3853\n",
      "Epoch 162/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0266 - accuracy: 0.3572 - val_loss: 2.1562 - val_accuracy: 0.3966\n",
      "Epoch 163/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9966 - accuracy: 0.3600 - val_loss: 2.1764 - val_accuracy: 0.3947\n",
      "Epoch 164/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0075 - accuracy: 0.3494 - val_loss: 2.1846 - val_accuracy: 0.3924\n",
      "Epoch 165/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0368 - accuracy: 0.3452 - val_loss: 2.1885 - val_accuracy: 0.3792\n",
      "Epoch 166/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0094 - accuracy: 0.3519 - val_loss: 2.1358 - val_accuracy: 0.4056\n",
      "Epoch 167/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0369 - accuracy: 0.3423 - val_loss: 2.1827 - val_accuracy: 0.3876\n",
      "Epoch 168/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0286 - accuracy: 0.3432 - val_loss: 2.1641 - val_accuracy: 0.3956\n",
      "Epoch 169/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0156 - accuracy: 0.3588 - val_loss: 2.1828 - val_accuracy: 0.3924\n",
      "Epoch 170/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0277 - accuracy: 0.3434 - val_loss: 2.1622 - val_accuracy: 0.3914\n",
      "Epoch 171/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0227 - accuracy: 0.3557 - val_loss: 2.1768 - val_accuracy: 0.3805\n",
      "Epoch 172/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9978 - accuracy: 0.3547 - val_loss: 2.1481 - val_accuracy: 0.4114\n",
      "Epoch 173/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0128 - accuracy: 0.3580 - val_loss: 2.1540 - val_accuracy: 0.4095\n",
      "Epoch 174/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9925 - accuracy: 0.3574 - val_loss: 2.1508 - val_accuracy: 0.4172\n",
      "Epoch 175/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.9924 - accuracy: 0.3547 - val_loss: 2.1510 - val_accuracy: 0.4021\n",
      "Epoch 176/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9975 - accuracy: 0.3584 - val_loss: 2.1704 - val_accuracy: 0.3895\n",
      "Epoch 177/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0206 - accuracy: 0.3531 - val_loss: 2.1834 - val_accuracy: 0.3918\n",
      "Epoch 178/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9958 - accuracy: 0.3583 - val_loss: 2.2144 - val_accuracy: 0.3879\n",
      "Epoch 179/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0178 - accuracy: 0.3529 - val_loss: 2.1815 - val_accuracy: 0.3853\n",
      "Epoch 180/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0082 - accuracy: 0.3466 - val_loss: 2.2059 - val_accuracy: 0.3853\n",
      "Epoch 181/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0080 - accuracy: 0.3520 - val_loss: 2.1926 - val_accuracy: 0.3885\n",
      "Epoch 182/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9967 - accuracy: 0.3610 - val_loss: 2.1707 - val_accuracy: 0.3879\n",
      "Epoch 183/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9925 - accuracy: 0.3620 - val_loss: 2.2101 - val_accuracy: 0.3766\n",
      "Epoch 184/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9977 - accuracy: 0.3599 - val_loss: 2.1837 - val_accuracy: 0.3914\n",
      "Epoch 185/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9912 - accuracy: 0.3529 - val_loss: 2.1545 - val_accuracy: 0.3943\n",
      "Epoch 186/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9900 - accuracy: 0.3619 - val_loss: 2.1650 - val_accuracy: 0.3937\n",
      "Epoch 187/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9941 - accuracy: 0.3583 - val_loss: 2.1502 - val_accuracy: 0.3953\n",
      "Epoch 188/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0114 - accuracy: 0.3441 - val_loss: 2.1714 - val_accuracy: 0.3895\n",
      "Epoch 189/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.0097 - accuracy: 0.3575 - val_loss: 2.2062 - val_accuracy: 0.3541\n",
      "Epoch 190/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9837 - accuracy: 0.3479 - val_loss: 2.1703 - val_accuracy: 0.3953\n",
      "Epoch 191/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9849 - accuracy: 0.3559 - val_loss: 2.2011 - val_accuracy: 0.3879\n",
      "Epoch 192/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9808 - accuracy: 0.3632 - val_loss: 2.1738 - val_accuracy: 0.3847\n",
      "Epoch 193/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9896 - accuracy: 0.3570 - val_loss: 2.2039 - val_accuracy: 0.3863\n",
      "Epoch 194/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9825 - accuracy: 0.3595 - val_loss: 2.1506 - val_accuracy: 0.3995\n",
      "Epoch 195/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9953 - accuracy: 0.3580 - val_loss: 2.1848 - val_accuracy: 0.3860\n",
      "Epoch 196/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9824 - accuracy: 0.3592 - val_loss: 2.1726 - val_accuracy: 0.3956\n",
      "Epoch 197/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9941 - accuracy: 0.3524 - val_loss: 2.1893 - val_accuracy: 0.3882\n",
      "Epoch 198/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9889 - accuracy: 0.3588 - val_loss: 2.1929 - val_accuracy: 0.3856\n",
      "Epoch 199/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9868 - accuracy: 0.3590 - val_loss: 2.1508 - val_accuracy: 0.3979\n",
      "Epoch 200/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9715 - accuracy: 0.3627 - val_loss: 2.1834 - val_accuracy: 0.4001\n",
      "Epoch 201/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9841 - accuracy: 0.3587 - val_loss: 2.1526 - val_accuracy: 0.4101\n",
      "Epoch 202/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9725 - accuracy: 0.3578 - val_loss: 2.1925 - val_accuracy: 0.3689\n",
      "Epoch 203/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9796 - accuracy: 0.3606 - val_loss: 2.1608 - val_accuracy: 0.3876\n",
      "Epoch 204/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9812 - accuracy: 0.3697 - val_loss: 2.1584 - val_accuracy: 0.3918\n",
      "Epoch 205/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9881 - accuracy: 0.3533 - val_loss: 2.1482 - val_accuracy: 0.3940\n",
      "Epoch 206/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9919 - accuracy: 0.3495 - val_loss: 2.1767 - val_accuracy: 0.3998\n",
      "Epoch 207/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9832 - accuracy: 0.3508 - val_loss: 2.1681 - val_accuracy: 0.3876\n",
      "Epoch 208/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9928 - accuracy: 0.3587 - val_loss: 2.1928 - val_accuracy: 0.3898\n",
      "Epoch 209/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9769 - accuracy: 0.3578 - val_loss: 2.1592 - val_accuracy: 0.3937\n",
      "Epoch 210/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9745 - accuracy: 0.3618 - val_loss: 2.1975 - val_accuracy: 0.3776\n",
      "Epoch 211/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9670 - accuracy: 0.3634 - val_loss: 2.1432 - val_accuracy: 0.4034\n",
      "Epoch 212/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9704 - accuracy: 0.3677 - val_loss: 2.1918 - val_accuracy: 0.4021\n",
      "Epoch 213/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9389 - accuracy: 0.3654 - val_loss: 2.1828 - val_accuracy: 0.3850\n",
      "Epoch 214/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9696 - accuracy: 0.3573 - val_loss: 2.1497 - val_accuracy: 0.4088\n",
      "Epoch 215/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9502 - accuracy: 0.3728 - val_loss: 2.1599 - val_accuracy: 0.3831\n",
      "Epoch 216/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9601 - accuracy: 0.3653 - val_loss: 2.1636 - val_accuracy: 0.3943\n",
      "Epoch 217/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9637 - accuracy: 0.3572 - val_loss: 2.1748 - val_accuracy: 0.3866\n",
      "Epoch 218/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9542 - accuracy: 0.3635 - val_loss: 2.1945 - val_accuracy: 0.3811\n",
      "Epoch 219/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9744 - accuracy: 0.3575 - val_loss: 2.1984 - val_accuracy: 0.3934\n",
      "Epoch 220/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9726 - accuracy: 0.3591 - val_loss: 2.1823 - val_accuracy: 0.3934\n",
      "Epoch 221/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9713 - accuracy: 0.3643 - val_loss: 2.1962 - val_accuracy: 0.3843\n",
      "Epoch 222/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9754 - accuracy: 0.3613 - val_loss: 2.1391 - val_accuracy: 0.3953\n",
      "Epoch 223/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9649 - accuracy: 0.3656 - val_loss: 2.1371 - val_accuracy: 0.4117\n",
      "Epoch 224/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9781 - accuracy: 0.3528 - val_loss: 2.1676 - val_accuracy: 0.3937\n",
      "Epoch 225/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9652 - accuracy: 0.3537 - val_loss: 2.1432 - val_accuracy: 0.3914\n",
      "Epoch 226/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9809 - accuracy: 0.3550 - val_loss: 2.1685 - val_accuracy: 0.3940\n",
      "Epoch 227/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9576 - accuracy: 0.3713 - val_loss: 2.1442 - val_accuracy: 0.4117\n",
      "Epoch 228/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9545 - accuracy: 0.3695 - val_loss: 2.2243 - val_accuracy: 0.3705\n",
      "Epoch 229/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9450 - accuracy: 0.3678 - val_loss: 2.1845 - val_accuracy: 0.3879\n",
      "Epoch 230/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9604 - accuracy: 0.3579 - val_loss: 2.1676 - val_accuracy: 0.3947\n",
      "Epoch 231/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9725 - accuracy: 0.3643 - val_loss: 2.1565 - val_accuracy: 0.4059\n",
      "Epoch 232/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9610 - accuracy: 0.3564 - val_loss: 2.1746 - val_accuracy: 0.3843\n",
      "Epoch 233/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9484 - accuracy: 0.3658 - val_loss: 2.1881 - val_accuracy: 0.3776\n",
      "Epoch 234/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9678 - accuracy: 0.3545 - val_loss: 2.1824 - val_accuracy: 0.3872\n",
      "Epoch 235/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9308 - accuracy: 0.3783 - val_loss: 2.2059 - val_accuracy: 0.3782\n",
      "Epoch 236/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9714 - accuracy: 0.3495 - val_loss: 2.1525 - val_accuracy: 0.4124\n",
      "Epoch 237/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9495 - accuracy: 0.3636 - val_loss: 2.1831 - val_accuracy: 0.3834\n",
      "Epoch 238/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9398 - accuracy: 0.3727 - val_loss: 2.1847 - val_accuracy: 0.3789\n",
      "Epoch 239/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9627 - accuracy: 0.3633 - val_loss: 2.1626 - val_accuracy: 0.4005\n",
      "Epoch 240/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9500 - accuracy: 0.3583 - val_loss: 2.1761 - val_accuracy: 0.3950\n",
      "Epoch 241/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9568 - accuracy: 0.3658 - val_loss: 2.1472 - val_accuracy: 0.4021\n",
      "Epoch 242/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9543 - accuracy: 0.3586 - val_loss: 2.1738 - val_accuracy: 0.3827\n",
      "Epoch 243/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9721 - accuracy: 0.3576 - val_loss: 2.1584 - val_accuracy: 0.3918\n",
      "Epoch 244/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9332 - accuracy: 0.3753 - val_loss: 2.1815 - val_accuracy: 0.3930\n",
      "Epoch 245/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9595 - accuracy: 0.3587 - val_loss: 2.1833 - val_accuracy: 0.3918\n",
      "Epoch 246/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9802 - accuracy: 0.3603 - val_loss: 2.1769 - val_accuracy: 0.3863\n",
      "Epoch 247/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9548 - accuracy: 0.3609 - val_loss: 2.1552 - val_accuracy: 0.4053\n",
      "Epoch 248/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9560 - accuracy: 0.3609 - val_loss: 2.1965 - val_accuracy: 0.3773\n",
      "Epoch 249/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9652 - accuracy: 0.3621 - val_loss: 2.1863 - val_accuracy: 0.3827\n",
      "Epoch 250/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9493 - accuracy: 0.3653 - val_loss: 2.1953 - val_accuracy: 0.3882\n",
      "Epoch 251/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9638 - accuracy: 0.3586 - val_loss: 2.1986 - val_accuracy: 0.3808\n",
      "Epoch 252/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9342 - accuracy: 0.3673 - val_loss: 2.2036 - val_accuracy: 0.3889\n",
      "Epoch 253/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9353 - accuracy: 0.3733 - val_loss: 2.1779 - val_accuracy: 0.3847\n",
      "Epoch 254/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9816 - accuracy: 0.3578 - val_loss: 2.1722 - val_accuracy: 0.3840\n",
      "Epoch 255/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9328 - accuracy: 0.3699 - val_loss: 2.1638 - val_accuracy: 0.3847\n",
      "Epoch 256/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9491 - accuracy: 0.3621 - val_loss: 2.1528 - val_accuracy: 0.3856\n",
      "Epoch 257/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9535 - accuracy: 0.3740 - val_loss: 2.1637 - val_accuracy: 0.3934\n",
      "Epoch 258/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9372 - accuracy: 0.3631 - val_loss: 2.1871 - val_accuracy: 0.3773\n",
      "Epoch 259/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9377 - accuracy: 0.3634 - val_loss: 2.1746 - val_accuracy: 0.3785\n",
      "Epoch 260/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9152 - accuracy: 0.3732 - val_loss: 2.1759 - val_accuracy: 0.3773\n",
      "Epoch 261/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9472 - accuracy: 0.3681 - val_loss: 2.1613 - val_accuracy: 0.3979\n",
      "Epoch 262/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9123 - accuracy: 0.3714 - val_loss: 2.1718 - val_accuracy: 0.3731\n",
      "Epoch 263/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9457 - accuracy: 0.3574 - val_loss: 2.2084 - val_accuracy: 0.3740\n",
      "Epoch 264/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9364 - accuracy: 0.3670 - val_loss: 2.2047 - val_accuracy: 0.3853\n",
      "Epoch 265/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9360 - accuracy: 0.3651 - val_loss: 2.1355 - val_accuracy: 0.4082\n",
      "Epoch 266/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9417 - accuracy: 0.3688 - val_loss: 2.1880 - val_accuracy: 0.3782\n",
      "Epoch 267/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9541 - accuracy: 0.3689 - val_loss: 2.2084 - val_accuracy: 0.3724\n",
      "Epoch 268/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9270 - accuracy: 0.3738 - val_loss: 2.1688 - val_accuracy: 0.3866\n",
      "Epoch 269/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9468 - accuracy: 0.3643 - val_loss: 2.1598 - val_accuracy: 0.3882\n",
      "Epoch 270/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9484 - accuracy: 0.3661 - val_loss: 2.1836 - val_accuracy: 0.3843\n",
      "Epoch 271/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9396 - accuracy: 0.3691 - val_loss: 2.1531 - val_accuracy: 0.4114\n",
      "Epoch 272/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9351 - accuracy: 0.3698 - val_loss: 2.1304 - val_accuracy: 0.3898\n",
      "Epoch 273/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9261 - accuracy: 0.3746 - val_loss: 2.1800 - val_accuracy: 0.3837\n",
      "Epoch 274/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9212 - accuracy: 0.3747 - val_loss: 2.1469 - val_accuracy: 0.3972\n",
      "Epoch 275/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9180 - accuracy: 0.3746 - val_loss: 2.1543 - val_accuracy: 0.3937\n",
      "Epoch 276/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9420 - accuracy: 0.3652 - val_loss: 2.1731 - val_accuracy: 0.3947\n",
      "Epoch 277/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9165 - accuracy: 0.3767 - val_loss: 2.1832 - val_accuracy: 0.3879\n",
      "Epoch 278/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9600 - accuracy: 0.3627 - val_loss: 2.1676 - val_accuracy: 0.3927\n",
      "Epoch 279/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9422 - accuracy: 0.3662 - val_loss: 2.1544 - val_accuracy: 0.4046\n",
      "Epoch 280/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9140 - accuracy: 0.3718 - val_loss: 2.1716 - val_accuracy: 0.3769\n",
      "Epoch 281/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9491 - accuracy: 0.3679 - val_loss: 2.1746 - val_accuracy: 0.3769\n",
      "Epoch 282/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9151 - accuracy: 0.3791 - val_loss: 2.2104 - val_accuracy: 0.3695\n",
      "Epoch 283/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9256 - accuracy: 0.3691 - val_loss: 2.1440 - val_accuracy: 0.3943\n",
      "Epoch 284/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9236 - accuracy: 0.3798 - val_loss: 2.1490 - val_accuracy: 0.3937\n",
      "Epoch 285/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9316 - accuracy: 0.3675 - val_loss: 2.1756 - val_accuracy: 0.3927\n",
      "Epoch 286/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9367 - accuracy: 0.3620 - val_loss: 2.1820 - val_accuracy: 0.3892\n",
      "Epoch 287/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9214 - accuracy: 0.3714 - val_loss: 2.2099 - val_accuracy: 0.3789\n",
      "Epoch 288/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9254 - accuracy: 0.3714 - val_loss: 2.1707 - val_accuracy: 0.3847\n",
      "Epoch 289/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9140 - accuracy: 0.3785 - val_loss: 2.1817 - val_accuracy: 0.3860\n",
      "Epoch 290/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9093 - accuracy: 0.3736 - val_loss: 2.1656 - val_accuracy: 0.3956\n",
      "Epoch 291/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9376 - accuracy: 0.3702 - val_loss: 2.1777 - val_accuracy: 0.3818\n",
      "Epoch 292/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9297 - accuracy: 0.3696 - val_loss: 2.1999 - val_accuracy: 0.3808\n",
      "Epoch 293/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9302 - accuracy: 0.3645 - val_loss: 2.1905 - val_accuracy: 0.3943\n",
      "Epoch 294/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9297 - accuracy: 0.3610 - val_loss: 2.1994 - val_accuracy: 0.3821\n",
      "Epoch 295/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9266 - accuracy: 0.3749 - val_loss: 2.1928 - val_accuracy: 0.3695\n",
      "Epoch 296/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9128 - accuracy: 0.3761 - val_loss: 2.1656 - val_accuracy: 0.3827\n",
      "Epoch 297/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9158 - accuracy: 0.3740 - val_loss: 2.1879 - val_accuracy: 0.3850\n",
      "Epoch 298/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9292 - accuracy: 0.3716 - val_loss: 2.1442 - val_accuracy: 0.4017\n",
      "Epoch 299/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9059 - accuracy: 0.3711 - val_loss: 2.1503 - val_accuracy: 0.3927\n",
      "Epoch 300/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9238 - accuracy: 0.3741 - val_loss: 2.2015 - val_accuracy: 0.3650\n",
      "Epoch 301/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9201 - accuracy: 0.3766 - val_loss: 2.1592 - val_accuracy: 0.3876\n",
      "Epoch 302/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9299 - accuracy: 0.3703 - val_loss: 2.1826 - val_accuracy: 0.3889\n",
      "Epoch 303/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9353 - accuracy: 0.3673 - val_loss: 2.1935 - val_accuracy: 0.3872\n",
      "Epoch 304/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9045 - accuracy: 0.3745 - val_loss: 2.1790 - val_accuracy: 0.3827\n",
      "Epoch 305/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9131 - accuracy: 0.3798 - val_loss: 2.1760 - val_accuracy: 0.3818\n",
      "Epoch 306/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9067 - accuracy: 0.3754 - val_loss: 2.1750 - val_accuracy: 0.3843\n",
      "Epoch 307/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9292 - accuracy: 0.3756 - val_loss: 2.1670 - val_accuracy: 0.3840\n",
      "Epoch 308/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9146 - accuracy: 0.3743 - val_loss: 2.1837 - val_accuracy: 0.3847\n",
      "Epoch 309/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9051 - accuracy: 0.3793 - val_loss: 2.1608 - val_accuracy: 0.3882\n",
      "Epoch 310/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9198 - accuracy: 0.3753 - val_loss: 2.1621 - val_accuracy: 0.3853\n",
      "Epoch 311/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9258 - accuracy: 0.3688 - val_loss: 2.1762 - val_accuracy: 0.3882\n",
      "Epoch 312/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9153 - accuracy: 0.3770 - val_loss: 2.2266 - val_accuracy: 0.3628\n",
      "Epoch 313/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9186 - accuracy: 0.3667 - val_loss: 2.1618 - val_accuracy: 0.3953\n",
      "Epoch 314/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9108 - accuracy: 0.3742 - val_loss: 2.1901 - val_accuracy: 0.3876\n",
      "Epoch 315/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9049 - accuracy: 0.3773 - val_loss: 2.1633 - val_accuracy: 0.4011\n",
      "Epoch 316/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.9220 - accuracy: 0.3793 - val_loss: 2.1903 - val_accuracy: 0.3863\n",
      "Epoch 317/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9292 - accuracy: 0.3732 - val_loss: 2.2105 - val_accuracy: 0.3782\n",
      "Epoch 318/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9170 - accuracy: 0.3667 - val_loss: 2.1969 - val_accuracy: 0.3811\n",
      "Epoch 319/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9229 - accuracy: 0.3699 - val_loss: 2.2088 - val_accuracy: 0.3718\n",
      "Epoch 320/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9119 - accuracy: 0.3799 - val_loss: 2.1836 - val_accuracy: 0.3863\n",
      "Epoch 321/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9047 - accuracy: 0.3774 - val_loss: 2.1628 - val_accuracy: 0.4050\n",
      "Epoch 322/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9134 - accuracy: 0.3688 - val_loss: 2.1827 - val_accuracy: 0.3889\n",
      "Epoch 323/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9100 - accuracy: 0.3774 - val_loss: 2.1960 - val_accuracy: 0.3863\n",
      "Epoch 324/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9166 - accuracy: 0.3671 - val_loss: 2.1730 - val_accuracy: 0.3818\n",
      "Epoch 325/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9170 - accuracy: 0.3728 - val_loss: 2.1739 - val_accuracy: 0.3750\n",
      "Epoch 326/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8909 - accuracy: 0.3803 - val_loss: 2.1910 - val_accuracy: 0.3737\n",
      "Epoch 327/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9037 - accuracy: 0.3773 - val_loss: 2.1797 - val_accuracy: 0.3734\n",
      "Epoch 328/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8958 - accuracy: 0.3854 - val_loss: 2.2061 - val_accuracy: 0.3708\n",
      "Epoch 329/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8834 - accuracy: 0.3906 - val_loss: 2.1962 - val_accuracy: 0.3666\n",
      "Epoch 330/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9030 - accuracy: 0.3780 - val_loss: 2.2000 - val_accuracy: 0.3708\n",
      "Epoch 331/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9314 - accuracy: 0.3823 - val_loss: 2.1842 - val_accuracy: 0.3821\n",
      "Epoch 332/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9131 - accuracy: 0.3749 - val_loss: 2.1891 - val_accuracy: 0.3756\n",
      "Epoch 333/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8887 - accuracy: 0.3841 - val_loss: 2.1919 - val_accuracy: 0.3721\n",
      "Epoch 334/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9164 - accuracy: 0.3664 - val_loss: 2.1495 - val_accuracy: 0.4005\n",
      "Epoch 335/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8958 - accuracy: 0.3809 - val_loss: 2.1552 - val_accuracy: 0.3988\n",
      "Epoch 336/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9015 - accuracy: 0.3763 - val_loss: 2.1980 - val_accuracy: 0.3914\n",
      "Epoch 337/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9211 - accuracy: 0.3687 - val_loss: 2.1914 - val_accuracy: 0.3963\n",
      "Epoch 338/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9013 - accuracy: 0.3734 - val_loss: 2.1914 - val_accuracy: 0.3798\n",
      "Epoch 339/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8922 - accuracy: 0.3786 - val_loss: 2.1945 - val_accuracy: 0.3756\n",
      "Epoch 340/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8943 - accuracy: 0.3781 - val_loss: 2.1869 - val_accuracy: 0.3715\n",
      "Epoch 341/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9055 - accuracy: 0.3787 - val_loss: 2.1914 - val_accuracy: 0.3724\n",
      "Epoch 342/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9087 - accuracy: 0.3684 - val_loss: 2.1899 - val_accuracy: 0.3779\n",
      "Epoch 343/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9303 - accuracy: 0.3692 - val_loss: 2.1880 - val_accuracy: 0.3882\n",
      "Epoch 344/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8960 - accuracy: 0.3705 - val_loss: 2.1670 - val_accuracy: 0.3853\n",
      "Epoch 345/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9098 - accuracy: 0.3764 - val_loss: 2.1753 - val_accuracy: 0.3911\n",
      "Epoch 346/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8987 - accuracy: 0.3770 - val_loss: 2.1634 - val_accuracy: 0.3863\n",
      "Epoch 347/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8778 - accuracy: 0.3835 - val_loss: 2.1951 - val_accuracy: 0.3782\n",
      "Epoch 348/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8834 - accuracy: 0.3690 - val_loss: 2.1632 - val_accuracy: 0.3789\n",
      "Epoch 349/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9058 - accuracy: 0.3679 - val_loss: 2.1731 - val_accuracy: 0.3876\n",
      "Epoch 350/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9154 - accuracy: 0.3666 - val_loss: 2.1850 - val_accuracy: 0.3821\n",
      "Epoch 351/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8817 - accuracy: 0.3799 - val_loss: 2.1884 - val_accuracy: 0.3885\n",
      "Epoch 352/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8999 - accuracy: 0.3746 - val_loss: 2.1981 - val_accuracy: 0.3866\n",
      "Epoch 353/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9140 - accuracy: 0.3706 - val_loss: 2.1479 - val_accuracy: 0.3963\n",
      "Epoch 354/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8982 - accuracy: 0.3790 - val_loss: 2.1813 - val_accuracy: 0.3856\n",
      "Epoch 355/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8821 - accuracy: 0.3834 - val_loss: 2.1818 - val_accuracy: 0.3792\n",
      "Epoch 356/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8949 - accuracy: 0.3853 - val_loss: 2.2016 - val_accuracy: 0.3769\n",
      "Epoch 357/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9205 - accuracy: 0.3722 - val_loss: 2.1831 - val_accuracy: 0.3860\n",
      "Epoch 358/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9020 - accuracy: 0.3671 - val_loss: 2.1888 - val_accuracy: 0.3782\n",
      "Epoch 359/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9142 - accuracy: 0.3737 - val_loss: 2.1808 - val_accuracy: 0.3789\n",
      "Epoch 360/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8854 - accuracy: 0.3778 - val_loss: 2.2006 - val_accuracy: 0.3747\n",
      "Epoch 361/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8784 - accuracy: 0.3797 - val_loss: 2.1836 - val_accuracy: 0.3863\n",
      "Epoch 362/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9040 - accuracy: 0.3725 - val_loss: 2.1943 - val_accuracy: 0.3789\n",
      "Epoch 363/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9170 - accuracy: 0.3668 - val_loss: 2.1565 - val_accuracy: 0.3930\n",
      "Epoch 364/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8904 - accuracy: 0.3912 - val_loss: 2.1906 - val_accuracy: 0.3882\n",
      "Epoch 365/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9079 - accuracy: 0.3718 - val_loss: 2.1795 - val_accuracy: 0.3763\n",
      "Epoch 366/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8963 - accuracy: 0.3722 - val_loss: 2.1801 - val_accuracy: 0.3798\n",
      "Epoch 367/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8887 - accuracy: 0.3801 - val_loss: 2.1602 - val_accuracy: 0.3908\n",
      "Epoch 368/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9040 - accuracy: 0.3777 - val_loss: 2.2071 - val_accuracy: 0.3669\n",
      "Epoch 369/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9082 - accuracy: 0.3713 - val_loss: 2.1864 - val_accuracy: 0.3721\n",
      "Epoch 370/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8976 - accuracy: 0.3771 - val_loss: 2.1996 - val_accuracy: 0.3734\n",
      "Epoch 371/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8934 - accuracy: 0.3748 - val_loss: 2.1660 - val_accuracy: 0.3892\n",
      "Epoch 372/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8870 - accuracy: 0.3801 - val_loss: 2.2031 - val_accuracy: 0.3753\n",
      "Epoch 373/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8880 - accuracy: 0.3766 - val_loss: 2.1829 - val_accuracy: 0.3718\n",
      "Epoch 374/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8831 - accuracy: 0.3813 - val_loss: 2.1886 - val_accuracy: 0.3805\n",
      "Epoch 375/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8908 - accuracy: 0.3812 - val_loss: 2.1994 - val_accuracy: 0.3805\n",
      "Epoch 376/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8654 - accuracy: 0.3769 - val_loss: 2.1614 - val_accuracy: 0.3879\n",
      "Epoch 377/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9004 - accuracy: 0.3712 - val_loss: 2.1770 - val_accuracy: 0.3959\n",
      "Epoch 378/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8915 - accuracy: 0.3749 - val_loss: 2.1706 - val_accuracy: 0.3837\n",
      "Epoch 379/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8876 - accuracy: 0.3788 - val_loss: 2.1729 - val_accuracy: 0.3798\n",
      "Epoch 380/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8818 - accuracy: 0.3874 - val_loss: 2.1831 - val_accuracy: 0.3702\n",
      "Epoch 381/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8958 - accuracy: 0.3778 - val_loss: 2.1869 - val_accuracy: 0.3802\n",
      "Epoch 382/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9022 - accuracy: 0.3776 - val_loss: 2.1903 - val_accuracy: 0.3769\n",
      "Epoch 383/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8890 - accuracy: 0.3718 - val_loss: 2.1797 - val_accuracy: 0.3698\n",
      "Epoch 384/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8824 - accuracy: 0.3836 - val_loss: 2.1937 - val_accuracy: 0.3695\n",
      "Epoch 385/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8733 - accuracy: 0.3698 - val_loss: 2.1798 - val_accuracy: 0.3850\n",
      "Epoch 386/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8722 - accuracy: 0.3828 - val_loss: 2.1972 - val_accuracy: 0.3834\n",
      "Epoch 387/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8995 - accuracy: 0.3737 - val_loss: 2.1907 - val_accuracy: 0.3731\n",
      "Epoch 388/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8985 - accuracy: 0.3716 - val_loss: 2.1975 - val_accuracy: 0.3708\n",
      "Epoch 389/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8953 - accuracy: 0.3761 - val_loss: 2.2130 - val_accuracy: 0.3795\n",
      "Epoch 390/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8740 - accuracy: 0.3864 - val_loss: 2.1785 - val_accuracy: 0.3911\n",
      "Epoch 391/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8699 - accuracy: 0.3830 - val_loss: 2.1879 - val_accuracy: 0.3676\n",
      "Epoch 392/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8916 - accuracy: 0.3772 - val_loss: 2.2097 - val_accuracy: 0.3676\n",
      "Epoch 393/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8774 - accuracy: 0.3957 - val_loss: 2.1746 - val_accuracy: 0.3808\n",
      "Epoch 394/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8848 - accuracy: 0.3813 - val_loss: 2.1848 - val_accuracy: 0.3740\n",
      "Epoch 395/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8733 - accuracy: 0.3844 - val_loss: 2.2117 - val_accuracy: 0.3708\n",
      "Epoch 396/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8635 - accuracy: 0.3787 - val_loss: 2.1965 - val_accuracy: 0.3750\n",
      "Epoch 397/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8823 - accuracy: 0.3828 - val_loss: 2.2127 - val_accuracy: 0.3624\n",
      "Epoch 398/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8924 - accuracy: 0.3755 - val_loss: 2.1906 - val_accuracy: 0.3708\n",
      "Epoch 399/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8885 - accuracy: 0.3815 - val_loss: 2.1824 - val_accuracy: 0.3930\n",
      "Epoch 400/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8620 - accuracy: 0.3870 - val_loss: 2.1889 - val_accuracy: 0.3847\n",
      "Epoch 401/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8793 - accuracy: 0.3770 - val_loss: 2.1595 - val_accuracy: 0.3943\n",
      "Epoch 402/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8791 - accuracy: 0.3760 - val_loss: 2.1956 - val_accuracy: 0.3827\n",
      "Epoch 403/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8637 - accuracy: 0.3829 - val_loss: 2.2497 - val_accuracy: 0.3702\n",
      "Epoch 404/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9066 - accuracy: 0.3742 - val_loss: 2.1620 - val_accuracy: 0.3901\n",
      "Epoch 405/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8891 - accuracy: 0.3851 - val_loss: 2.1978 - val_accuracy: 0.3744\n",
      "Epoch 406/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8741 - accuracy: 0.3733 - val_loss: 2.1911 - val_accuracy: 0.3805\n",
      "Epoch 407/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8739 - accuracy: 0.3865 - val_loss: 2.1889 - val_accuracy: 0.3918\n",
      "Epoch 408/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8923 - accuracy: 0.3736 - val_loss: 2.1757 - val_accuracy: 0.3905\n",
      "Epoch 409/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8826 - accuracy: 0.3859 - val_loss: 2.1624 - val_accuracy: 0.3885\n",
      "Epoch 410/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8723 - accuracy: 0.3790 - val_loss: 2.1568 - val_accuracy: 0.3866\n",
      "Epoch 411/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9037 - accuracy: 0.3676 - val_loss: 2.2286 - val_accuracy: 0.3524\n",
      "Epoch 412/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8886 - accuracy: 0.3744 - val_loss: 2.2143 - val_accuracy: 0.3692\n",
      "Epoch 413/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8818 - accuracy: 0.3815 - val_loss: 2.1716 - val_accuracy: 0.3885\n",
      "Epoch 414/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8627 - accuracy: 0.3899 - val_loss: 2.1780 - val_accuracy: 0.3824\n",
      "Epoch 415/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8888 - accuracy: 0.3879 - val_loss: 2.2088 - val_accuracy: 0.3747\n",
      "Epoch 416/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8781 - accuracy: 0.3810 - val_loss: 2.1917 - val_accuracy: 0.3782\n",
      "Epoch 417/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.9020 - accuracy: 0.3798 - val_loss: 2.1803 - val_accuracy: 0.3908\n",
      "Epoch 418/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8582 - accuracy: 0.3882 - val_loss: 2.1837 - val_accuracy: 0.3695\n",
      "Epoch 419/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8767 - accuracy: 0.3797 - val_loss: 2.1713 - val_accuracy: 0.3818\n",
      "Epoch 420/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8871 - accuracy: 0.3842 - val_loss: 2.1992 - val_accuracy: 0.3721\n",
      "Epoch 421/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8709 - accuracy: 0.3816 - val_loss: 2.1921 - val_accuracy: 0.3711\n",
      "Epoch 422/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8604 - accuracy: 0.3846 - val_loss: 2.2369 - val_accuracy: 0.3640\n",
      "Epoch 423/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8789 - accuracy: 0.3766 - val_loss: 2.2128 - val_accuracy: 0.3676\n",
      "Epoch 424/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8544 - accuracy: 0.3885 - val_loss: 2.1903 - val_accuracy: 0.3847\n",
      "Epoch 425/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8808 - accuracy: 0.3742 - val_loss: 2.1795 - val_accuracy: 0.3805\n",
      "Epoch 426/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8646 - accuracy: 0.3918 - val_loss: 2.1834 - val_accuracy: 0.3776\n",
      "Epoch 427/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8740 - accuracy: 0.3840 - val_loss: 2.1985 - val_accuracy: 0.3747\n",
      "Epoch 428/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8926 - accuracy: 0.3726 - val_loss: 2.2152 - val_accuracy: 0.3708\n",
      "Epoch 429/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8960 - accuracy: 0.3679 - val_loss: 2.1956 - val_accuracy: 0.3795\n",
      "Epoch 430/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8680 - accuracy: 0.3807 - val_loss: 2.2098 - val_accuracy: 0.3702\n",
      "Epoch 431/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9117 - accuracy: 0.3787 - val_loss: 2.1737 - val_accuracy: 0.3882\n",
      "Epoch 432/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8842 - accuracy: 0.3774 - val_loss: 2.2268 - val_accuracy: 0.3550\n",
      "Epoch 433/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8527 - accuracy: 0.3928 - val_loss: 2.1790 - val_accuracy: 0.3860\n",
      "Epoch 434/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8621 - accuracy: 0.3881 - val_loss: 2.1935 - val_accuracy: 0.3737\n",
      "Epoch 435/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8687 - accuracy: 0.3791 - val_loss: 2.1615 - val_accuracy: 0.3856\n",
      "Epoch 436/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8826 - accuracy: 0.3778 - val_loss: 2.1923 - val_accuracy: 0.3808\n",
      "Epoch 437/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8628 - accuracy: 0.3789 - val_loss: 2.1970 - val_accuracy: 0.3872\n",
      "Epoch 438/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8715 - accuracy: 0.3860 - val_loss: 2.1984 - val_accuracy: 0.3808\n",
      "Epoch 439/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8811 - accuracy: 0.3785 - val_loss: 2.1902 - val_accuracy: 0.3814\n",
      "Epoch 440/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8667 - accuracy: 0.3881 - val_loss: 2.1989 - val_accuracy: 0.3747\n",
      "Epoch 441/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8820 - accuracy: 0.3707 - val_loss: 2.1909 - val_accuracy: 0.3885\n",
      "Epoch 442/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8868 - accuracy: 0.3740 - val_loss: 2.1940 - val_accuracy: 0.3763\n",
      "Epoch 443/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8767 - accuracy: 0.3815 - val_loss: 2.2078 - val_accuracy: 0.3695\n",
      "Epoch 444/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8564 - accuracy: 0.3850 - val_loss: 2.2056 - val_accuracy: 0.3653\n",
      "Epoch 445/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8572 - accuracy: 0.3888 - val_loss: 2.1760 - val_accuracy: 0.3763\n",
      "Epoch 446/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8607 - accuracy: 0.3903 - val_loss: 2.2315 - val_accuracy: 0.3599\n",
      "Epoch 447/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8679 - accuracy: 0.3837 - val_loss: 2.2214 - val_accuracy: 0.3702\n",
      "Epoch 448/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8830 - accuracy: 0.3779 - val_loss: 2.2266 - val_accuracy: 0.3753\n",
      "Epoch 449/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8615 - accuracy: 0.3838 - val_loss: 2.1991 - val_accuracy: 0.3798\n",
      "Epoch 450/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8738 - accuracy: 0.3778 - val_loss: 2.2142 - val_accuracy: 0.3705\n",
      "Epoch 451/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8601 - accuracy: 0.3848 - val_loss: 2.2028 - val_accuracy: 0.3811\n",
      "Epoch 452/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8660 - accuracy: 0.3886 - val_loss: 2.1991 - val_accuracy: 0.3802\n",
      "Epoch 453/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8485 - accuracy: 0.3882 - val_loss: 2.2086 - val_accuracy: 0.3621\n",
      "Epoch 454/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8730 - accuracy: 0.3878 - val_loss: 2.2120 - val_accuracy: 0.3557\n",
      "Epoch 455/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8777 - accuracy: 0.3881 - val_loss: 2.1913 - val_accuracy: 0.3686\n",
      "Epoch 456/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8601 - accuracy: 0.3843 - val_loss: 2.2010 - val_accuracy: 0.3766\n",
      "Epoch 457/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8806 - accuracy: 0.3791 - val_loss: 2.1800 - val_accuracy: 0.3930\n",
      "Epoch 458/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8561 - accuracy: 0.3826 - val_loss: 2.2121 - val_accuracy: 0.3686\n",
      "Epoch 459/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8492 - accuracy: 0.3933 - val_loss: 2.2263 - val_accuracy: 0.3711\n",
      "Epoch 460/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8722 - accuracy: 0.3708 - val_loss: 2.2075 - val_accuracy: 0.3708\n",
      "Epoch 461/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8896 - accuracy: 0.3820 - val_loss: 2.2078 - val_accuracy: 0.3773\n",
      "Epoch 462/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8758 - accuracy: 0.3804 - val_loss: 2.2178 - val_accuracy: 0.3740\n",
      "Epoch 463/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8797 - accuracy: 0.3859 - val_loss: 2.2267 - val_accuracy: 0.3695\n",
      "Epoch 464/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8594 - accuracy: 0.3838 - val_loss: 2.1828 - val_accuracy: 0.3814\n",
      "Epoch 465/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8762 - accuracy: 0.3795 - val_loss: 2.1965 - val_accuracy: 0.3811\n",
      "Epoch 466/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8364 - accuracy: 0.3867 - val_loss: 2.1958 - val_accuracy: 0.3750\n",
      "Epoch 467/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8627 - accuracy: 0.3934 - val_loss: 2.1968 - val_accuracy: 0.3740\n",
      "Epoch 468/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8770 - accuracy: 0.3820 - val_loss: 2.2087 - val_accuracy: 0.3715\n",
      "Epoch 469/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8672 - accuracy: 0.3798 - val_loss: 2.1711 - val_accuracy: 0.3847\n",
      "Epoch 470/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8581 - accuracy: 0.3899 - val_loss: 2.2062 - val_accuracy: 0.3763\n",
      "Epoch 471/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8618 - accuracy: 0.3858 - val_loss: 2.1604 - val_accuracy: 0.3808\n",
      "Epoch 472/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8483 - accuracy: 0.3820 - val_loss: 2.2506 - val_accuracy: 0.3602\n",
      "Epoch 473/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8517 - accuracy: 0.3923 - val_loss: 2.1936 - val_accuracy: 0.3686\n",
      "Epoch 474/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8662 - accuracy: 0.3893 - val_loss: 2.2032 - val_accuracy: 0.3721\n",
      "Epoch 475/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8529 - accuracy: 0.3859 - val_loss: 2.2310 - val_accuracy: 0.3570\n",
      "Epoch 476/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8662 - accuracy: 0.3840 - val_loss: 2.1890 - val_accuracy: 0.3702\n",
      "Epoch 477/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8778 - accuracy: 0.3834 - val_loss: 2.1807 - val_accuracy: 0.3808\n",
      "Epoch 478/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8715 - accuracy: 0.3883 - val_loss: 2.1748 - val_accuracy: 0.3814\n",
      "Epoch 479/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8501 - accuracy: 0.3896 - val_loss: 2.1837 - val_accuracy: 0.3702\n",
      "Epoch 480/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8617 - accuracy: 0.3840 - val_loss: 2.1880 - val_accuracy: 0.3663\n",
      "Epoch 481/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8776 - accuracy: 0.3813 - val_loss: 2.1693 - val_accuracy: 0.3847\n",
      "Epoch 482/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8625 - accuracy: 0.3885 - val_loss: 2.1902 - val_accuracy: 0.3814\n",
      "Epoch 483/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8892 - accuracy: 0.3810 - val_loss: 2.2066 - val_accuracy: 0.3766\n",
      "Epoch 484/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8692 - accuracy: 0.3858 - val_loss: 2.2091 - val_accuracy: 0.3711\n",
      "Epoch 485/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8667 - accuracy: 0.3790 - val_loss: 2.1849 - val_accuracy: 0.3811\n",
      "Epoch 486/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8619 - accuracy: 0.3861 - val_loss: 2.2145 - val_accuracy: 0.3773\n",
      "Epoch 487/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8724 - accuracy: 0.3805 - val_loss: 2.2103 - val_accuracy: 0.3750\n",
      "Epoch 488/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8576 - accuracy: 0.3882 - val_loss: 2.2160 - val_accuracy: 0.3695\n",
      "Epoch 489/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8649 - accuracy: 0.3923 - val_loss: 2.2000 - val_accuracy: 0.3763\n",
      "Epoch 490/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8674 - accuracy: 0.3853 - val_loss: 2.1773 - val_accuracy: 0.3663\n",
      "Epoch 491/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8649 - accuracy: 0.3905 - val_loss: 2.2479 - val_accuracy: 0.3460\n",
      "Epoch 492/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8667 - accuracy: 0.3853 - val_loss: 2.1980 - val_accuracy: 0.3773\n",
      "Epoch 493/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8580 - accuracy: 0.3877 - val_loss: 2.1731 - val_accuracy: 0.3869\n",
      "Epoch 494/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8716 - accuracy: 0.3876 - val_loss: 2.1856 - val_accuracy: 0.3872\n",
      "Epoch 495/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8938 - accuracy: 0.3742 - val_loss: 2.1772 - val_accuracy: 0.3744\n",
      "Epoch 496/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8410 - accuracy: 0.3997 - val_loss: 2.1870 - val_accuracy: 0.3782\n",
      "Epoch 497/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8624 - accuracy: 0.3889 - val_loss: 2.2028 - val_accuracy: 0.3824\n",
      "Epoch 498/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8555 - accuracy: 0.3962 - val_loss: 2.2106 - val_accuracy: 0.3808\n",
      "Epoch 499/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8459 - accuracy: 0.3951 - val_loss: 2.2090 - val_accuracy: 0.3660\n",
      "Epoch 500/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8421 - accuracy: 0.3918 - val_loss: 2.2643 - val_accuracy: 0.3463\n",
      "Epoch 501/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8435 - accuracy: 0.3892 - val_loss: 2.1858 - val_accuracy: 0.3689\n",
      "Epoch 502/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8618 - accuracy: 0.3846 - val_loss: 2.1998 - val_accuracy: 0.3744\n",
      "Epoch 503/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8607 - accuracy: 0.3822 - val_loss: 2.1882 - val_accuracy: 0.3734\n",
      "Epoch 504/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8765 - accuracy: 0.3864 - val_loss: 2.1812 - val_accuracy: 0.3808\n",
      "Epoch 505/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8575 - accuracy: 0.3969 - val_loss: 2.2068 - val_accuracy: 0.3769\n",
      "Epoch 506/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8666 - accuracy: 0.3811 - val_loss: 2.2190 - val_accuracy: 0.3808\n",
      "Epoch 507/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8480 - accuracy: 0.3850 - val_loss: 2.1880 - val_accuracy: 0.3747\n",
      "Epoch 508/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8657 - accuracy: 0.3912 - val_loss: 2.1842 - val_accuracy: 0.3821\n",
      "Epoch 509/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8489 - accuracy: 0.3875 - val_loss: 2.1962 - val_accuracy: 0.3711\n",
      "Epoch 510/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8719 - accuracy: 0.3827 - val_loss: 2.1822 - val_accuracy: 0.3737\n",
      "Epoch 511/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8568 - accuracy: 0.3899 - val_loss: 2.1679 - val_accuracy: 0.3734\n",
      "Epoch 512/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8611 - accuracy: 0.3840 - val_loss: 2.1863 - val_accuracy: 0.3814\n",
      "Epoch 513/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8328 - accuracy: 0.3843 - val_loss: 2.1996 - val_accuracy: 0.3773\n",
      "Epoch 514/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8439 - accuracy: 0.3924 - val_loss: 2.1906 - val_accuracy: 0.3682\n",
      "Epoch 515/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8637 - accuracy: 0.3776 - val_loss: 2.2168 - val_accuracy: 0.3763\n",
      "Epoch 516/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8571 - accuracy: 0.3849 - val_loss: 2.1768 - val_accuracy: 0.3782\n",
      "Epoch 517/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8422 - accuracy: 0.3983 - val_loss: 2.1718 - val_accuracy: 0.3866\n",
      "Epoch 518/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8538 - accuracy: 0.3860 - val_loss: 2.1946 - val_accuracy: 0.3834\n",
      "Epoch 519/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8571 - accuracy: 0.3808 - val_loss: 2.1920 - val_accuracy: 0.3837\n",
      "Epoch 520/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8644 - accuracy: 0.3861 - val_loss: 2.2116 - val_accuracy: 0.3595\n",
      "Epoch 521/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8617 - accuracy: 0.3888 - val_loss: 2.2054 - val_accuracy: 0.3618\n",
      "Epoch 522/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8350 - accuracy: 0.3956 - val_loss: 2.2054 - val_accuracy: 0.3666\n",
      "Epoch 523/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8581 - accuracy: 0.3925 - val_loss: 2.1886 - val_accuracy: 0.3756\n",
      "Epoch 524/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8500 - accuracy: 0.3827 - val_loss: 2.1613 - val_accuracy: 0.3911\n",
      "Epoch 525/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8563 - accuracy: 0.3863 - val_loss: 2.2153 - val_accuracy: 0.3657\n",
      "Epoch 526/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8536 - accuracy: 0.3872 - val_loss: 2.1971 - val_accuracy: 0.3744\n",
      "Epoch 527/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8399 - accuracy: 0.3918 - val_loss: 2.2164 - val_accuracy: 0.3737\n",
      "Epoch 528/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8510 - accuracy: 0.3919 - val_loss: 2.1926 - val_accuracy: 0.3708\n",
      "Epoch 529/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8526 - accuracy: 0.3814 - val_loss: 2.2016 - val_accuracy: 0.3686\n",
      "Epoch 530/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8327 - accuracy: 0.3953 - val_loss: 2.1914 - val_accuracy: 0.3744\n",
      "Epoch 531/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8506 - accuracy: 0.3826 - val_loss: 2.1861 - val_accuracy: 0.3776\n",
      "Epoch 532/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8199 - accuracy: 0.3881 - val_loss: 2.1789 - val_accuracy: 0.3856\n",
      "Epoch 533/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8594 - accuracy: 0.3856 - val_loss: 2.2281 - val_accuracy: 0.3666\n",
      "Epoch 534/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8408 - accuracy: 0.3887 - val_loss: 2.1805 - val_accuracy: 0.3795\n",
      "Epoch 535/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8576 - accuracy: 0.3819 - val_loss: 2.1798 - val_accuracy: 0.3679\n",
      "Epoch 536/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8427 - accuracy: 0.3909 - val_loss: 2.2329 - val_accuracy: 0.3595\n",
      "Epoch 537/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8260 - accuracy: 0.3963 - val_loss: 2.2186 - val_accuracy: 0.3644\n",
      "Epoch 538/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8544 - accuracy: 0.3935 - val_loss: 2.1882 - val_accuracy: 0.3653\n",
      "Epoch 539/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8521 - accuracy: 0.3847 - val_loss: 2.2204 - val_accuracy: 0.3702\n",
      "Epoch 540/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8634 - accuracy: 0.3825 - val_loss: 2.2079 - val_accuracy: 0.3669\n",
      "Epoch 541/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8522 - accuracy: 0.3836 - val_loss: 2.1822 - val_accuracy: 0.3734\n",
      "Epoch 542/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8596 - accuracy: 0.3898 - val_loss: 2.2258 - val_accuracy: 0.3582\n",
      "Epoch 543/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8475 - accuracy: 0.3855 - val_loss: 2.1925 - val_accuracy: 0.3557\n",
      "Epoch 544/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8526 - accuracy: 0.3908 - val_loss: 2.2019 - val_accuracy: 0.3792\n",
      "Epoch 545/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8469 - accuracy: 0.3915 - val_loss: 2.2164 - val_accuracy: 0.3715\n",
      "Epoch 546/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8542 - accuracy: 0.3869 - val_loss: 2.2002 - val_accuracy: 0.3673\n",
      "Epoch 547/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8438 - accuracy: 0.3831 - val_loss: 2.2141 - val_accuracy: 0.3544\n",
      "Epoch 548/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8229 - accuracy: 0.4036 - val_loss: 2.1847 - val_accuracy: 0.3785\n",
      "Epoch 549/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8474 - accuracy: 0.3947 - val_loss: 2.2133 - val_accuracy: 0.3721\n",
      "Epoch 550/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8275 - accuracy: 0.4012 - val_loss: 2.1919 - val_accuracy: 0.3744\n",
      "Epoch 551/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8499 - accuracy: 0.3876 - val_loss: 2.2140 - val_accuracy: 0.3666\n",
      "Epoch 552/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8553 - accuracy: 0.3887 - val_loss: 2.2400 - val_accuracy: 0.3640\n",
      "Epoch 553/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8448 - accuracy: 0.3890 - val_loss: 2.2071 - val_accuracy: 0.3698\n",
      "Epoch 554/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8344 - accuracy: 0.3959 - val_loss: 2.1825 - val_accuracy: 0.3808\n",
      "Epoch 555/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8469 - accuracy: 0.3832 - val_loss: 2.1942 - val_accuracy: 0.3798\n",
      "Epoch 556/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8434 - accuracy: 0.3828 - val_loss: 2.2046 - val_accuracy: 0.3756\n",
      "Epoch 557/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8402 - accuracy: 0.3888 - val_loss: 2.2084 - val_accuracy: 0.3727\n",
      "Epoch 558/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8586 - accuracy: 0.3904 - val_loss: 2.2210 - val_accuracy: 0.3592\n",
      "Epoch 559/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8190 - accuracy: 0.3919 - val_loss: 2.2043 - val_accuracy: 0.3666\n",
      "Epoch 560/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8151 - accuracy: 0.4073 - val_loss: 2.2019 - val_accuracy: 0.3631\n",
      "Epoch 561/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8250 - accuracy: 0.3925 - val_loss: 2.1710 - val_accuracy: 0.3840\n",
      "Epoch 562/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8386 - accuracy: 0.3880 - val_loss: 2.2015 - val_accuracy: 0.3676\n",
      "Epoch 563/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8323 - accuracy: 0.3939 - val_loss: 2.1989 - val_accuracy: 0.3692\n",
      "Epoch 564/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8335 - accuracy: 0.3906 - val_loss: 2.2171 - val_accuracy: 0.3602\n",
      "Epoch 565/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8528 - accuracy: 0.3861 - val_loss: 2.2057 - val_accuracy: 0.3705\n",
      "Epoch 566/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8397 - accuracy: 0.3868 - val_loss: 2.2014 - val_accuracy: 0.3766\n",
      "Epoch 567/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8558 - accuracy: 0.3877 - val_loss: 2.2142 - val_accuracy: 0.3618\n",
      "Epoch 568/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8544 - accuracy: 0.3835 - val_loss: 2.2091 - val_accuracy: 0.3676\n",
      "Epoch 569/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8472 - accuracy: 0.3912 - val_loss: 2.2068 - val_accuracy: 0.3773\n",
      "Epoch 570/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8381 - accuracy: 0.3837 - val_loss: 2.2019 - val_accuracy: 0.3673\n",
      "Epoch 571/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8501 - accuracy: 0.3810 - val_loss: 2.2105 - val_accuracy: 0.3734\n",
      "Epoch 572/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8275 - accuracy: 0.3929 - val_loss: 2.2271 - val_accuracy: 0.3650\n",
      "Epoch 573/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8376 - accuracy: 0.3919 - val_loss: 2.1849 - val_accuracy: 0.3866\n",
      "Epoch 574/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8297 - accuracy: 0.3958 - val_loss: 2.1810 - val_accuracy: 0.3747\n",
      "Epoch 575/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8308 - accuracy: 0.3947 - val_loss: 2.1950 - val_accuracy: 0.3821\n",
      "Epoch 576/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8530 - accuracy: 0.3899 - val_loss: 2.1867 - val_accuracy: 0.3769\n",
      "Epoch 577/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8488 - accuracy: 0.3849 - val_loss: 2.2144 - val_accuracy: 0.3592\n",
      "Epoch 578/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8287 - accuracy: 0.4000 - val_loss: 2.1911 - val_accuracy: 0.3740\n",
      "Epoch 579/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8458 - accuracy: 0.3919 - val_loss: 2.1981 - val_accuracy: 0.3834\n",
      "Epoch 580/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8303 - accuracy: 0.3911 - val_loss: 2.1833 - val_accuracy: 0.3734\n",
      "Epoch 581/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8564 - accuracy: 0.3828 - val_loss: 2.2101 - val_accuracy: 0.3930\n",
      "Epoch 582/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8283 - accuracy: 0.3901 - val_loss: 2.1982 - val_accuracy: 0.3740\n",
      "Epoch 583/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8453 - accuracy: 0.3939 - val_loss: 2.2075 - val_accuracy: 0.3721\n",
      "Epoch 584/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8293 - accuracy: 0.3902 - val_loss: 2.2055 - val_accuracy: 0.3705\n",
      "Epoch 585/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8333 - accuracy: 0.3919 - val_loss: 2.2219 - val_accuracy: 0.3624\n",
      "Epoch 586/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8357 - accuracy: 0.3896 - val_loss: 2.2164 - val_accuracy: 0.3789\n",
      "Epoch 587/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8460 - accuracy: 0.3889 - val_loss: 2.2071 - val_accuracy: 0.3611\n",
      "Epoch 588/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8573 - accuracy: 0.3858 - val_loss: 2.2073 - val_accuracy: 0.3785\n",
      "Epoch 589/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8499 - accuracy: 0.3906 - val_loss: 2.2082 - val_accuracy: 0.3628\n",
      "Epoch 590/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8408 - accuracy: 0.3950 - val_loss: 2.2122 - val_accuracy: 0.3676\n",
      "Epoch 591/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8221 - accuracy: 0.4036 - val_loss: 2.2074 - val_accuracy: 0.3686\n",
      "Epoch 592/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8517 - accuracy: 0.3796 - val_loss: 2.2109 - val_accuracy: 0.3737\n",
      "Epoch 593/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8200 - accuracy: 0.3980 - val_loss: 2.2195 - val_accuracy: 0.3592\n",
      "Epoch 594/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8316 - accuracy: 0.3882 - val_loss: 2.1906 - val_accuracy: 0.3792\n",
      "Epoch 595/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8390 - accuracy: 0.3890 - val_loss: 2.2258 - val_accuracy: 0.3608\n",
      "Epoch 596/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8270 - accuracy: 0.4017 - val_loss: 2.2099 - val_accuracy: 0.3628\n",
      "Epoch 597/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8374 - accuracy: 0.3947 - val_loss: 2.2195 - val_accuracy: 0.3695\n",
      "Epoch 598/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8467 - accuracy: 0.3756 - val_loss: 2.2370 - val_accuracy: 0.3566\n",
      "Epoch 599/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8354 - accuracy: 0.3947 - val_loss: 2.2066 - val_accuracy: 0.3698\n",
      "Epoch 600/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8419 - accuracy: 0.3894 - val_loss: 2.2160 - val_accuracy: 0.3547\n",
      "Epoch 601/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8520 - accuracy: 0.3906 - val_loss: 2.2236 - val_accuracy: 0.3628\n",
      "Epoch 602/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8371 - accuracy: 0.3963 - val_loss: 2.1936 - val_accuracy: 0.3692\n",
      "Epoch 603/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8507 - accuracy: 0.3896 - val_loss: 2.2160 - val_accuracy: 0.3715\n",
      "Epoch 604/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8140 - accuracy: 0.3960 - val_loss: 2.2039 - val_accuracy: 0.3753\n",
      "Epoch 605/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8374 - accuracy: 0.3907 - val_loss: 2.2252 - val_accuracy: 0.3421\n",
      "Epoch 606/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8327 - accuracy: 0.3915 - val_loss: 2.2080 - val_accuracy: 0.3692\n",
      "Epoch 607/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8447 - accuracy: 0.3902 - val_loss: 2.2121 - val_accuracy: 0.3611\n",
      "Epoch 608/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8268 - accuracy: 0.3934 - val_loss: 2.2088 - val_accuracy: 0.3698\n",
      "Epoch 609/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8409 - accuracy: 0.3875 - val_loss: 2.2069 - val_accuracy: 0.3711\n",
      "Epoch 610/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8347 - accuracy: 0.3901 - val_loss: 2.2214 - val_accuracy: 0.3647\n",
      "Epoch 611/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8206 - accuracy: 0.3953 - val_loss: 2.2281 - val_accuracy: 0.3657\n",
      "Epoch 612/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8195 - accuracy: 0.3947 - val_loss: 2.2272 - val_accuracy: 0.3673\n",
      "Epoch 613/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8180 - accuracy: 0.4028 - val_loss: 2.2308 - val_accuracy: 0.3563\n",
      "Epoch 614/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8000 - accuracy: 0.4071 - val_loss: 2.2452 - val_accuracy: 0.3660\n",
      "Epoch 615/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8354 - accuracy: 0.3935 - val_loss: 2.2041 - val_accuracy: 0.3698\n",
      "Epoch 616/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8345 - accuracy: 0.3890 - val_loss: 2.2051 - val_accuracy: 0.3734\n",
      "Epoch 617/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8147 - accuracy: 0.3983 - val_loss: 2.1974 - val_accuracy: 0.3692\n",
      "Epoch 618/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8537 - accuracy: 0.3870 - val_loss: 2.1976 - val_accuracy: 0.3660\n",
      "Epoch 619/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8460 - accuracy: 0.3931 - val_loss: 2.2010 - val_accuracy: 0.3702\n",
      "Epoch 620/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8187 - accuracy: 0.3944 - val_loss: 2.2008 - val_accuracy: 0.3637\n",
      "Epoch 621/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8525 - accuracy: 0.3836 - val_loss: 2.2244 - val_accuracy: 0.3689\n",
      "Epoch 622/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8396 - accuracy: 0.3889 - val_loss: 2.2145 - val_accuracy: 0.3795\n",
      "Epoch 623/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8530 - accuracy: 0.3832 - val_loss: 2.2328 - val_accuracy: 0.3798\n",
      "Epoch 624/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8340 - accuracy: 0.3826 - val_loss: 2.2182 - val_accuracy: 0.3753\n",
      "Epoch 625/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8159 - accuracy: 0.3928 - val_loss: 2.1984 - val_accuracy: 0.3724\n",
      "Epoch 626/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8240 - accuracy: 0.3936 - val_loss: 2.2221 - val_accuracy: 0.3785\n",
      "Epoch 627/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8399 - accuracy: 0.3933 - val_loss: 2.2043 - val_accuracy: 0.3769\n",
      "Epoch 628/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8042 - accuracy: 0.4031 - val_loss: 2.2360 - val_accuracy: 0.3589\n",
      "Epoch 629/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8095 - accuracy: 0.4094 - val_loss: 2.2290 - val_accuracy: 0.3582\n",
      "Epoch 630/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8256 - accuracy: 0.3927 - val_loss: 2.2356 - val_accuracy: 0.3528\n",
      "Epoch 631/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8163 - accuracy: 0.4023 - val_loss: 2.2471 - val_accuracy: 0.3557\n",
      "Epoch 632/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8446 - accuracy: 0.3819 - val_loss: 2.2146 - val_accuracy: 0.3611\n",
      "Epoch 633/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8426 - accuracy: 0.3893 - val_loss: 2.1978 - val_accuracy: 0.3737\n",
      "Epoch 634/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8084 - accuracy: 0.3983 - val_loss: 2.2074 - val_accuracy: 0.3673\n",
      "Epoch 635/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8360 - accuracy: 0.3943 - val_loss: 2.1891 - val_accuracy: 0.3660\n",
      "Epoch 636/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8573 - accuracy: 0.3824 - val_loss: 2.1938 - val_accuracy: 0.3663\n",
      "Epoch 637/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8281 - accuracy: 0.3950 - val_loss: 2.1895 - val_accuracy: 0.3763\n",
      "Epoch 638/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8239 - accuracy: 0.3935 - val_loss: 2.2002 - val_accuracy: 0.3702\n",
      "Epoch 639/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8118 - accuracy: 0.4028 - val_loss: 2.2022 - val_accuracy: 0.3615\n",
      "Epoch 640/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8290 - accuracy: 0.3954 - val_loss: 2.2007 - val_accuracy: 0.3763\n",
      "Epoch 641/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8372 - accuracy: 0.3878 - val_loss: 2.2151 - val_accuracy: 0.3718\n",
      "Epoch 642/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8509 - accuracy: 0.3903 - val_loss: 2.1916 - val_accuracy: 0.3698\n",
      "Epoch 643/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8280 - accuracy: 0.3897 - val_loss: 2.2160 - val_accuracy: 0.3708\n",
      "Epoch 644/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8267 - accuracy: 0.3921 - val_loss: 2.2030 - val_accuracy: 0.3811\n",
      "Epoch 645/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8422 - accuracy: 0.4021 - val_loss: 2.2324 - val_accuracy: 0.3666\n",
      "Epoch 646/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8088 - accuracy: 0.4016 - val_loss: 2.2187 - val_accuracy: 0.3689\n",
      "Epoch 647/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8291 - accuracy: 0.3858 - val_loss: 2.1684 - val_accuracy: 0.3895\n",
      "Epoch 648/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8376 - accuracy: 0.3864 - val_loss: 2.2383 - val_accuracy: 0.3608\n",
      "Epoch 649/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8258 - accuracy: 0.3984 - val_loss: 2.2145 - val_accuracy: 0.3727\n",
      "Epoch 650/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8476 - accuracy: 0.3810 - val_loss: 2.2061 - val_accuracy: 0.3763\n",
      "Epoch 651/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8399 - accuracy: 0.3855 - val_loss: 2.2030 - val_accuracy: 0.3682\n",
      "Epoch 652/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8321 - accuracy: 0.3902 - val_loss: 2.2105 - val_accuracy: 0.3760\n",
      "Epoch 653/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8487 - accuracy: 0.3928 - val_loss: 2.2167 - val_accuracy: 0.3621\n",
      "Epoch 654/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8362 - accuracy: 0.3870 - val_loss: 2.2021 - val_accuracy: 0.3750\n",
      "Epoch 655/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8272 - accuracy: 0.3990 - val_loss: 2.1929 - val_accuracy: 0.3657\n",
      "Epoch 656/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8328 - accuracy: 0.3895 - val_loss: 2.2065 - val_accuracy: 0.3560\n",
      "Epoch 657/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8483 - accuracy: 0.3785 - val_loss: 2.2057 - val_accuracy: 0.3692\n",
      "Epoch 658/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8215 - accuracy: 0.3941 - val_loss: 2.2156 - val_accuracy: 0.3657\n",
      "Epoch 659/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8387 - accuracy: 0.3932 - val_loss: 2.1918 - val_accuracy: 0.3740\n",
      "Epoch 660/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8064 - accuracy: 0.3967 - val_loss: 2.2035 - val_accuracy: 0.3727\n",
      "Epoch 661/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8080 - accuracy: 0.3981 - val_loss: 2.2375 - val_accuracy: 0.3695\n",
      "Epoch 662/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8298 - accuracy: 0.3917 - val_loss: 2.1966 - val_accuracy: 0.3718\n",
      "Epoch 663/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8275 - accuracy: 0.3930 - val_loss: 2.2021 - val_accuracy: 0.3676\n",
      "Epoch 664/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8158 - accuracy: 0.3951 - val_loss: 2.1627 - val_accuracy: 0.3914\n",
      "Epoch 665/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8016 - accuracy: 0.3924 - val_loss: 2.2228 - val_accuracy: 0.3586\n",
      "Epoch 666/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8254 - accuracy: 0.3937 - val_loss: 2.2326 - val_accuracy: 0.3650\n",
      "Epoch 667/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7929 - accuracy: 0.4019 - val_loss: 2.2350 - val_accuracy: 0.3698\n",
      "Epoch 668/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8390 - accuracy: 0.3902 - val_loss: 2.2110 - val_accuracy: 0.3698\n",
      "Epoch 669/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8272 - accuracy: 0.3913 - val_loss: 2.2185 - val_accuracy: 0.3653\n",
      "Epoch 670/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8247 - accuracy: 0.3964 - val_loss: 2.2360 - val_accuracy: 0.3553\n",
      "Epoch 671/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8183 - accuracy: 0.3977 - val_loss: 2.2058 - val_accuracy: 0.3650\n",
      "Epoch 672/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8348 - accuracy: 0.3863 - val_loss: 2.2145 - val_accuracy: 0.3650\n",
      "Epoch 673/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8260 - accuracy: 0.3930 - val_loss: 2.2127 - val_accuracy: 0.3647\n",
      "Epoch 674/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8059 - accuracy: 0.4011 - val_loss: 2.2287 - val_accuracy: 0.3531\n",
      "Epoch 675/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8097 - accuracy: 0.3949 - val_loss: 2.2010 - val_accuracy: 0.3666\n",
      "Epoch 676/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8141 - accuracy: 0.3977 - val_loss: 2.1915 - val_accuracy: 0.3814\n",
      "Epoch 677/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8246 - accuracy: 0.3877 - val_loss: 2.2411 - val_accuracy: 0.3698\n",
      "Epoch 678/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8143 - accuracy: 0.3958 - val_loss: 2.2196 - val_accuracy: 0.3731\n",
      "Epoch 679/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8208 - accuracy: 0.3857 - val_loss: 2.2046 - val_accuracy: 0.3734\n",
      "Epoch 680/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8238 - accuracy: 0.3968 - val_loss: 2.2015 - val_accuracy: 0.3840\n",
      "Epoch 681/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8309 - accuracy: 0.3851 - val_loss: 2.2331 - val_accuracy: 0.3727\n",
      "Epoch 682/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8334 - accuracy: 0.3900 - val_loss: 2.2132 - val_accuracy: 0.3740\n",
      "Epoch 683/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8628 - accuracy: 0.3801 - val_loss: 2.2133 - val_accuracy: 0.3740\n",
      "Epoch 684/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8182 - accuracy: 0.3998 - val_loss: 2.2089 - val_accuracy: 0.3705\n",
      "Epoch 685/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8246 - accuracy: 0.4012 - val_loss: 2.2110 - val_accuracy: 0.3637\n",
      "Epoch 686/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8297 - accuracy: 0.3987 - val_loss: 2.1856 - val_accuracy: 0.3837\n",
      "Epoch 687/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8162 - accuracy: 0.4047 - val_loss: 2.2320 - val_accuracy: 0.3586\n",
      "Epoch 688/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8135 - accuracy: 0.4037 - val_loss: 2.2080 - val_accuracy: 0.3621\n",
      "Epoch 689/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8060 - accuracy: 0.3968 - val_loss: 2.2008 - val_accuracy: 0.3618\n",
      "Epoch 690/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8161 - accuracy: 0.3970 - val_loss: 2.2165 - val_accuracy: 0.3595\n",
      "Epoch 691/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8226 - accuracy: 0.3940 - val_loss: 2.2219 - val_accuracy: 0.3644\n",
      "Epoch 692/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8103 - accuracy: 0.4016 - val_loss: 2.2447 - val_accuracy: 0.3531\n",
      "Epoch 693/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8271 - accuracy: 0.3954 - val_loss: 2.1995 - val_accuracy: 0.3669\n",
      "Epoch 694/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8087 - accuracy: 0.4011 - val_loss: 2.2229 - val_accuracy: 0.3640\n",
      "Epoch 695/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8155 - accuracy: 0.3919 - val_loss: 2.2147 - val_accuracy: 0.3727\n",
      "Epoch 696/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8185 - accuracy: 0.3927 - val_loss: 2.2186 - val_accuracy: 0.3660\n",
      "Epoch 697/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8183 - accuracy: 0.3991 - val_loss: 2.2267 - val_accuracy: 0.3563\n",
      "Epoch 698/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8256 - accuracy: 0.3905 - val_loss: 2.2328 - val_accuracy: 0.3666\n",
      "Epoch 699/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8306 - accuracy: 0.3904 - val_loss: 2.2116 - val_accuracy: 0.3792\n",
      "Epoch 700/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8408 - accuracy: 0.3854 - val_loss: 2.1876 - val_accuracy: 0.3834\n",
      "Epoch 701/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8054 - accuracy: 0.4029 - val_loss: 2.1957 - val_accuracy: 0.3789\n",
      "Epoch 702/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8164 - accuracy: 0.3933 - val_loss: 2.2426 - val_accuracy: 0.3579\n",
      "Epoch 703/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8276 - accuracy: 0.3889 - val_loss: 2.1979 - val_accuracy: 0.3760\n",
      "Epoch 704/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8264 - accuracy: 0.3861 - val_loss: 2.2307 - val_accuracy: 0.3776\n",
      "Epoch 705/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8156 - accuracy: 0.3964 - val_loss: 2.2436 - val_accuracy: 0.3547\n",
      "Epoch 706/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8170 - accuracy: 0.3925 - val_loss: 2.2662 - val_accuracy: 0.3415\n",
      "Epoch 707/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8104 - accuracy: 0.4054 - val_loss: 2.2191 - val_accuracy: 0.3615\n",
      "Epoch 708/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8038 - accuracy: 0.4061 - val_loss: 2.1977 - val_accuracy: 0.3731\n",
      "Epoch 709/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8237 - accuracy: 0.3839 - val_loss: 2.1979 - val_accuracy: 0.3692\n",
      "Epoch 710/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8167 - accuracy: 0.4025 - val_loss: 2.2413 - val_accuracy: 0.3640\n",
      "Epoch 711/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8130 - accuracy: 0.3933 - val_loss: 2.2236 - val_accuracy: 0.3653\n",
      "Epoch 712/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8290 - accuracy: 0.3922 - val_loss: 2.2154 - val_accuracy: 0.3644\n",
      "Epoch 713/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8303 - accuracy: 0.3906 - val_loss: 2.2137 - val_accuracy: 0.3731\n",
      "Epoch 714/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8500 - accuracy: 0.3770 - val_loss: 2.2206 - val_accuracy: 0.3679\n",
      "Epoch 715/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8048 - accuracy: 0.3978 - val_loss: 2.2155 - val_accuracy: 0.3631\n",
      "Epoch 716/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8327 - accuracy: 0.3935 - val_loss: 2.2114 - val_accuracy: 0.3640\n",
      "Epoch 717/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8097 - accuracy: 0.3983 - val_loss: 2.2123 - val_accuracy: 0.3789\n",
      "Epoch 718/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8224 - accuracy: 0.3850 - val_loss: 2.1989 - val_accuracy: 0.3853\n",
      "Epoch 719/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8090 - accuracy: 0.4004 - val_loss: 2.2160 - val_accuracy: 0.3660\n",
      "Epoch 720/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8334 - accuracy: 0.3902 - val_loss: 2.1997 - val_accuracy: 0.3798\n",
      "Epoch 721/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8162 - accuracy: 0.3927 - val_loss: 2.2371 - val_accuracy: 0.3589\n",
      "Epoch 722/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8220 - accuracy: 0.3926 - val_loss: 2.2098 - val_accuracy: 0.3756\n",
      "Epoch 723/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8266 - accuracy: 0.3942 - val_loss: 2.2105 - val_accuracy: 0.3679\n",
      "Epoch 724/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8218 - accuracy: 0.3951 - val_loss: 2.2059 - val_accuracy: 0.3737\n",
      "Epoch 725/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8025 - accuracy: 0.4007 - val_loss: 2.2257 - val_accuracy: 0.3618\n",
      "Epoch 726/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8298 - accuracy: 0.3923 - val_loss: 2.2062 - val_accuracy: 0.3673\n",
      "Epoch 727/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7869 - accuracy: 0.4037 - val_loss: 2.2210 - val_accuracy: 0.3808\n",
      "Epoch 728/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8209 - accuracy: 0.3962 - val_loss: 2.2050 - val_accuracy: 0.3766\n",
      "Epoch 729/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8273 - accuracy: 0.3930 - val_loss: 2.2232 - val_accuracy: 0.3679\n",
      "Epoch 730/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8229 - accuracy: 0.3895 - val_loss: 2.2248 - val_accuracy: 0.3702\n",
      "Epoch 731/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8106 - accuracy: 0.3953 - val_loss: 2.1875 - val_accuracy: 0.3760\n",
      "Epoch 732/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8443 - accuracy: 0.3790 - val_loss: 2.2199 - val_accuracy: 0.3695\n",
      "Epoch 733/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8186 - accuracy: 0.3920 - val_loss: 2.1933 - val_accuracy: 0.3792\n",
      "Epoch 734/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8335 - accuracy: 0.3953 - val_loss: 2.2310 - val_accuracy: 0.3734\n",
      "Epoch 735/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8159 - accuracy: 0.3973 - val_loss: 2.2344 - val_accuracy: 0.3592\n",
      "Epoch 736/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8260 - accuracy: 0.3875 - val_loss: 2.2616 - val_accuracy: 0.3673\n",
      "Epoch 737/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8055 - accuracy: 0.3963 - val_loss: 2.2299 - val_accuracy: 0.3698\n",
      "Epoch 738/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8257 - accuracy: 0.3905 - val_loss: 2.2331 - val_accuracy: 0.3582\n",
      "Epoch 739/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8128 - accuracy: 0.3932 - val_loss: 2.2229 - val_accuracy: 0.3731\n",
      "Epoch 740/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8262 - accuracy: 0.3901 - val_loss: 2.2029 - val_accuracy: 0.3695\n",
      "Epoch 741/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7911 - accuracy: 0.4097 - val_loss: 2.2825 - val_accuracy: 0.3421\n",
      "Epoch 742/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8379 - accuracy: 0.3940 - val_loss: 2.2358 - val_accuracy: 0.3740\n",
      "Epoch 743/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8382 - accuracy: 0.3935 - val_loss: 2.2078 - val_accuracy: 0.3737\n",
      "Epoch 744/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8102 - accuracy: 0.4010 - val_loss: 2.2412 - val_accuracy: 0.3579\n",
      "Epoch 745/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8269 - accuracy: 0.3961 - val_loss: 2.2004 - val_accuracy: 0.3779\n",
      "Epoch 746/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8182 - accuracy: 0.3962 - val_loss: 2.1950 - val_accuracy: 0.3782\n",
      "Epoch 747/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8201 - accuracy: 0.3928 - val_loss: 2.2288 - val_accuracy: 0.3676\n",
      "Epoch 748/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7978 - accuracy: 0.4028 - val_loss: 2.2219 - val_accuracy: 0.3647\n",
      "Epoch 749/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8203 - accuracy: 0.4003 - val_loss: 2.2173 - val_accuracy: 0.3692\n",
      "Epoch 750/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8344 - accuracy: 0.3918 - val_loss: 2.2276 - val_accuracy: 0.3711\n",
      "Epoch 751/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8110 - accuracy: 0.3928 - val_loss: 2.2280 - val_accuracy: 0.3673\n",
      "Epoch 752/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8075 - accuracy: 0.4018 - val_loss: 2.2019 - val_accuracy: 0.3721\n",
      "Epoch 753/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8044 - accuracy: 0.3952 - val_loss: 2.2285 - val_accuracy: 0.3731\n",
      "Epoch 754/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8111 - accuracy: 0.4037 - val_loss: 2.2212 - val_accuracy: 0.3682\n",
      "Epoch 755/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7908 - accuracy: 0.3969 - val_loss: 2.2133 - val_accuracy: 0.3734\n",
      "Epoch 756/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8419 - accuracy: 0.3836 - val_loss: 2.2268 - val_accuracy: 0.3673\n",
      "Epoch 757/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8274 - accuracy: 0.3885 - val_loss: 2.2246 - val_accuracy: 0.3576\n",
      "Epoch 758/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8260 - accuracy: 0.3983 - val_loss: 2.1841 - val_accuracy: 0.3753\n",
      "Epoch 759/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8063 - accuracy: 0.4019 - val_loss: 2.2141 - val_accuracy: 0.3673\n",
      "Epoch 760/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8156 - accuracy: 0.3939 - val_loss: 2.2254 - val_accuracy: 0.3644\n",
      "Epoch 761/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7974 - accuracy: 0.3996 - val_loss: 2.2293 - val_accuracy: 0.3611\n",
      "Epoch 762/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8262 - accuracy: 0.3838 - val_loss: 2.2151 - val_accuracy: 0.3718\n",
      "Epoch 763/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8164 - accuracy: 0.3967 - val_loss: 2.2024 - val_accuracy: 0.3715\n",
      "Epoch 764/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7970 - accuracy: 0.4020 - val_loss: 2.2038 - val_accuracy: 0.3776\n",
      "Epoch 765/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7996 - accuracy: 0.4028 - val_loss: 2.2261 - val_accuracy: 0.3766\n",
      "Epoch 766/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8034 - accuracy: 0.4031 - val_loss: 2.1919 - val_accuracy: 0.3727\n",
      "Epoch 767/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8219 - accuracy: 0.3933 - val_loss: 2.1982 - val_accuracy: 0.3756\n",
      "Epoch 768/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8194 - accuracy: 0.4010 - val_loss: 2.2121 - val_accuracy: 0.3624\n",
      "Epoch 769/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8063 - accuracy: 0.3895 - val_loss: 2.2157 - val_accuracy: 0.3727\n",
      "Epoch 770/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8185 - accuracy: 0.4045 - val_loss: 2.2217 - val_accuracy: 0.3731\n",
      "Epoch 771/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8101 - accuracy: 0.3949 - val_loss: 2.2439 - val_accuracy: 0.3563\n",
      "Epoch 772/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8287 - accuracy: 0.3845 - val_loss: 2.2239 - val_accuracy: 0.3605\n",
      "Epoch 773/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8181 - accuracy: 0.3889 - val_loss: 2.2237 - val_accuracy: 0.3779\n",
      "Epoch 774/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8112 - accuracy: 0.3853 - val_loss: 2.2366 - val_accuracy: 0.3618\n",
      "Epoch 775/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8223 - accuracy: 0.3952 - val_loss: 2.1967 - val_accuracy: 0.3686\n",
      "Epoch 776/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8153 - accuracy: 0.3924 - val_loss: 2.2149 - val_accuracy: 0.3676\n",
      "Epoch 777/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8062 - accuracy: 0.3985 - val_loss: 2.2219 - val_accuracy: 0.3624\n",
      "Epoch 778/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8050 - accuracy: 0.4101 - val_loss: 2.2285 - val_accuracy: 0.3669\n",
      "Epoch 779/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8158 - accuracy: 0.3886 - val_loss: 2.2468 - val_accuracy: 0.3534\n",
      "Epoch 780/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8052 - accuracy: 0.4063 - val_loss: 2.2408 - val_accuracy: 0.3692\n",
      "Epoch 781/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8140 - accuracy: 0.4011 - val_loss: 2.2446 - val_accuracy: 0.3508\n",
      "Epoch 782/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8374 - accuracy: 0.3866 - val_loss: 2.2354 - val_accuracy: 0.3647\n",
      "Epoch 783/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8084 - accuracy: 0.3942 - val_loss: 2.1908 - val_accuracy: 0.3682\n",
      "Epoch 784/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8217 - accuracy: 0.4040 - val_loss: 2.2149 - val_accuracy: 0.3721\n",
      "Epoch 785/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8257 - accuracy: 0.3966 - val_loss: 2.2004 - val_accuracy: 0.3618\n",
      "Epoch 786/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8081 - accuracy: 0.3997 - val_loss: 2.2379 - val_accuracy: 0.3686\n",
      "Epoch 787/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8131 - accuracy: 0.3987 - val_loss: 2.2311 - val_accuracy: 0.3634\n",
      "Epoch 788/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8242 - accuracy: 0.4035 - val_loss: 2.2233 - val_accuracy: 0.3660\n",
      "Epoch 789/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8189 - accuracy: 0.4023 - val_loss: 2.2374 - val_accuracy: 0.3615\n",
      "Epoch 790/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8012 - accuracy: 0.3968 - val_loss: 2.2040 - val_accuracy: 0.3753\n",
      "Epoch 791/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8030 - accuracy: 0.4053 - val_loss: 2.2169 - val_accuracy: 0.3695\n",
      "Epoch 792/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8179 - accuracy: 0.3933 - val_loss: 2.2403 - val_accuracy: 0.3721\n",
      "Epoch 793/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8005 - accuracy: 0.4000 - val_loss: 2.2009 - val_accuracy: 0.3669\n",
      "Epoch 794/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8044 - accuracy: 0.4009 - val_loss: 2.2199 - val_accuracy: 0.3785\n",
      "Epoch 795/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8127 - accuracy: 0.3963 - val_loss: 2.2336 - val_accuracy: 0.3724\n",
      "Epoch 796/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8051 - accuracy: 0.4000 - val_loss: 2.2581 - val_accuracy: 0.3676\n",
      "Epoch 797/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8063 - accuracy: 0.3974 - val_loss: 2.2437 - val_accuracy: 0.3611\n",
      "Epoch 798/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7986 - accuracy: 0.4045 - val_loss: 2.2256 - val_accuracy: 0.3541\n",
      "Epoch 799/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8123 - accuracy: 0.3935 - val_loss: 2.2126 - val_accuracy: 0.3860\n",
      "Epoch 800/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8211 - accuracy: 0.3889 - val_loss: 2.2083 - val_accuracy: 0.3769\n",
      "Epoch 801/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8181 - accuracy: 0.3830 - val_loss: 2.2232 - val_accuracy: 0.3734\n",
      "Epoch 802/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7886 - accuracy: 0.3998 - val_loss: 2.2520 - val_accuracy: 0.3582\n",
      "Epoch 803/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.7883 - accuracy: 0.3983 - val_loss: 2.2309 - val_accuracy: 0.3628\n",
      "Epoch 804/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8235 - accuracy: 0.3903 - val_loss: 2.2116 - val_accuracy: 0.3705\n",
      "Epoch 805/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8023 - accuracy: 0.4047 - val_loss: 2.2204 - val_accuracy: 0.3708\n",
      "Epoch 806/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8008 - accuracy: 0.3944 - val_loss: 2.2093 - val_accuracy: 0.3673\n",
      "Epoch 807/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8067 - accuracy: 0.4010 - val_loss: 2.2168 - val_accuracy: 0.3818\n",
      "Epoch 808/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8002 - accuracy: 0.4050 - val_loss: 2.2064 - val_accuracy: 0.3686\n",
      "Epoch 809/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8074 - accuracy: 0.4006 - val_loss: 2.2302 - val_accuracy: 0.3669\n",
      "Epoch 810/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8036 - accuracy: 0.4000 - val_loss: 2.2311 - val_accuracy: 0.3592\n",
      "Epoch 811/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8254 - accuracy: 0.3919 - val_loss: 2.2520 - val_accuracy: 0.3673\n",
      "Epoch 812/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8121 - accuracy: 0.3938 - val_loss: 2.2165 - val_accuracy: 0.3785\n",
      "Epoch 813/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7960 - accuracy: 0.3951 - val_loss: 2.2115 - val_accuracy: 0.3727\n",
      "Epoch 814/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7862 - accuracy: 0.4091 - val_loss: 2.2589 - val_accuracy: 0.3579\n",
      "Epoch 815/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8170 - accuracy: 0.3869 - val_loss: 2.1938 - val_accuracy: 0.3821\n",
      "Epoch 816/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8256 - accuracy: 0.3924 - val_loss: 2.1901 - val_accuracy: 0.3814\n",
      "Epoch 817/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8021 - accuracy: 0.4055 - val_loss: 2.2389 - val_accuracy: 0.3669\n",
      "Epoch 818/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7875 - accuracy: 0.4109 - val_loss: 2.2123 - val_accuracy: 0.3737\n",
      "Epoch 819/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8069 - accuracy: 0.3977 - val_loss: 2.2390 - val_accuracy: 0.3531\n",
      "Epoch 820/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8071 - accuracy: 0.3985 - val_loss: 2.2283 - val_accuracy: 0.3611\n",
      "Epoch 821/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7967 - accuracy: 0.4032 - val_loss: 2.2246 - val_accuracy: 0.3669\n",
      "Epoch 822/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8077 - accuracy: 0.3969 - val_loss: 2.2426 - val_accuracy: 0.3676\n",
      "Epoch 823/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8214 - accuracy: 0.3913 - val_loss: 2.2420 - val_accuracy: 0.3708\n",
      "Epoch 824/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8097 - accuracy: 0.3928 - val_loss: 2.2325 - val_accuracy: 0.3666\n",
      "Epoch 825/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7790 - accuracy: 0.4020 - val_loss: 2.2270 - val_accuracy: 0.3705\n",
      "Epoch 826/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7986 - accuracy: 0.3940 - val_loss: 2.2379 - val_accuracy: 0.3682\n",
      "Epoch 827/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8100 - accuracy: 0.3962 - val_loss: 2.2338 - val_accuracy: 0.3679\n",
      "Epoch 828/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8094 - accuracy: 0.4039 - val_loss: 2.2239 - val_accuracy: 0.3657\n",
      "Epoch 829/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8116 - accuracy: 0.3967 - val_loss: 2.2224 - val_accuracy: 0.3689\n",
      "Epoch 830/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7986 - accuracy: 0.4022 - val_loss: 2.2443 - val_accuracy: 0.3657\n",
      "Epoch 831/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7937 - accuracy: 0.3996 - val_loss: 2.2418 - val_accuracy: 0.3689\n",
      "Epoch 832/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8165 - accuracy: 0.3858 - val_loss: 2.2067 - val_accuracy: 0.3814\n",
      "Epoch 833/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8043 - accuracy: 0.3977 - val_loss: 2.2393 - val_accuracy: 0.3599\n",
      "Epoch 834/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7914 - accuracy: 0.4033 - val_loss: 2.2030 - val_accuracy: 0.3795\n",
      "Epoch 835/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8168 - accuracy: 0.3925 - val_loss: 2.1982 - val_accuracy: 0.3818\n",
      "Epoch 836/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8012 - accuracy: 0.4070 - val_loss: 2.2390 - val_accuracy: 0.3605\n",
      "Epoch 837/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8376 - accuracy: 0.3887 - val_loss: 2.2381 - val_accuracy: 0.3599\n",
      "Epoch 838/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8093 - accuracy: 0.3990 - val_loss: 2.1939 - val_accuracy: 0.3834\n",
      "Epoch 839/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7989 - accuracy: 0.3975 - val_loss: 2.2231 - val_accuracy: 0.3634\n",
      "Epoch 840/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8122 - accuracy: 0.3991 - val_loss: 2.2549 - val_accuracy: 0.3608\n",
      "Epoch 841/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7972 - accuracy: 0.3959 - val_loss: 2.2111 - val_accuracy: 0.3718\n",
      "Epoch 842/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8138 - accuracy: 0.3930 - val_loss: 2.2384 - val_accuracy: 0.3621\n",
      "Epoch 843/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8006 - accuracy: 0.4051 - val_loss: 2.2109 - val_accuracy: 0.3663\n",
      "Epoch 844/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7986 - accuracy: 0.4064 - val_loss: 2.2325 - val_accuracy: 0.3560\n",
      "Epoch 845/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8300 - accuracy: 0.3905 - val_loss: 2.2367 - val_accuracy: 0.3608\n",
      "Epoch 846/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8204 - accuracy: 0.3949 - val_loss: 2.1970 - val_accuracy: 0.3618\n",
      "Epoch 847/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8089 - accuracy: 0.3978 - val_loss: 2.2298 - val_accuracy: 0.3653\n",
      "Epoch 848/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8052 - accuracy: 0.4037 - val_loss: 2.1896 - val_accuracy: 0.3789\n",
      "Epoch 849/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8036 - accuracy: 0.3903 - val_loss: 2.2097 - val_accuracy: 0.3708\n",
      "Epoch 850/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7921 - accuracy: 0.4047 - val_loss: 2.2380 - val_accuracy: 0.3611\n",
      "Epoch 851/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8178 - accuracy: 0.3925 - val_loss: 2.2125 - val_accuracy: 0.3763\n",
      "Epoch 852/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8111 - accuracy: 0.3908 - val_loss: 2.2289 - val_accuracy: 0.3702\n",
      "Epoch 853/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8040 - accuracy: 0.3962 - val_loss: 2.2391 - val_accuracy: 0.3766\n",
      "Epoch 854/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8004 - accuracy: 0.3991 - val_loss: 2.2663 - val_accuracy: 0.3573\n",
      "Epoch 855/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8059 - accuracy: 0.4035 - val_loss: 2.2313 - val_accuracy: 0.3818\n",
      "Epoch 856/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7842 - accuracy: 0.3992 - val_loss: 2.2234 - val_accuracy: 0.3698\n",
      "Epoch 857/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8128 - accuracy: 0.3992 - val_loss: 2.2816 - val_accuracy: 0.3373\n",
      "Epoch 858/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8009 - accuracy: 0.3936 - val_loss: 2.2828 - val_accuracy: 0.3537\n",
      "Epoch 859/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8001 - accuracy: 0.3988 - val_loss: 2.2301 - val_accuracy: 0.3576\n",
      "Epoch 860/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8104 - accuracy: 0.3922 - val_loss: 2.2307 - val_accuracy: 0.3747\n",
      "Epoch 861/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7944 - accuracy: 0.4006 - val_loss: 2.2478 - val_accuracy: 0.3657\n",
      "Epoch 862/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7911 - accuracy: 0.4067 - val_loss: 2.2402 - val_accuracy: 0.3653\n",
      "Epoch 863/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7992 - accuracy: 0.3899 - val_loss: 2.2318 - val_accuracy: 0.3599\n",
      "Epoch 864/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7925 - accuracy: 0.4059 - val_loss: 2.2495 - val_accuracy: 0.3560\n",
      "Epoch 865/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8083 - accuracy: 0.4061 - val_loss: 2.2417 - val_accuracy: 0.3753\n",
      "Epoch 866/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8100 - accuracy: 0.3901 - val_loss: 2.2384 - val_accuracy: 0.3602\n",
      "Epoch 867/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8013 - accuracy: 0.4049 - val_loss: 2.2563 - val_accuracy: 0.3586\n",
      "Epoch 868/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7984 - accuracy: 0.3944 - val_loss: 2.2499 - val_accuracy: 0.3721\n",
      "Epoch 869/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7957 - accuracy: 0.3904 - val_loss: 2.2264 - val_accuracy: 0.3628\n",
      "Epoch 870/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7918 - accuracy: 0.4059 - val_loss: 2.2365 - val_accuracy: 0.3805\n",
      "Epoch 871/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7997 - accuracy: 0.3993 - val_loss: 2.2439 - val_accuracy: 0.3624\n",
      "Epoch 872/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7953 - accuracy: 0.4012 - val_loss: 2.2254 - val_accuracy: 0.3666\n",
      "Epoch 873/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7863 - accuracy: 0.4020 - val_loss: 2.2523 - val_accuracy: 0.3560\n",
      "Epoch 874/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8027 - accuracy: 0.4001 - val_loss: 2.2344 - val_accuracy: 0.3634\n",
      "Epoch 875/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8068 - accuracy: 0.3956 - val_loss: 2.2395 - val_accuracy: 0.3553\n",
      "Epoch 876/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8055 - accuracy: 0.4014 - val_loss: 2.2643 - val_accuracy: 0.3618\n",
      "Epoch 877/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7828 - accuracy: 0.4047 - val_loss: 2.2510 - val_accuracy: 0.3582\n",
      "Epoch 878/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7851 - accuracy: 0.4054 - val_loss: 2.2566 - val_accuracy: 0.3566\n",
      "Epoch 879/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8050 - accuracy: 0.3964 - val_loss: 2.2505 - val_accuracy: 0.3534\n",
      "Epoch 880/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.7968 - accuracy: 0.3980 - val_loss: 2.2843 - val_accuracy: 0.3534\n",
      "Epoch 881/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7939 - accuracy: 0.4057 - val_loss: 2.2252 - val_accuracy: 0.3599\n",
      "Epoch 882/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7992 - accuracy: 0.4043 - val_loss: 2.2581 - val_accuracy: 0.3624\n",
      "Epoch 883/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8097 - accuracy: 0.4036 - val_loss: 2.2303 - val_accuracy: 0.3621\n",
      "Epoch 884/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8060 - accuracy: 0.3926 - val_loss: 2.2524 - val_accuracy: 0.3689\n",
      "Epoch 885/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8072 - accuracy: 0.3933 - val_loss: 2.2153 - val_accuracy: 0.3798\n",
      "Epoch 886/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8068 - accuracy: 0.3927 - val_loss: 2.2412 - val_accuracy: 0.3679\n",
      "Epoch 887/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7980 - accuracy: 0.4037 - val_loss: 2.2133 - val_accuracy: 0.3773\n",
      "Epoch 888/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8089 - accuracy: 0.3955 - val_loss: 2.2264 - val_accuracy: 0.3592\n",
      "Epoch 889/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7921 - accuracy: 0.4057 - val_loss: 2.2463 - val_accuracy: 0.3524\n",
      "Epoch 890/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7970 - accuracy: 0.3971 - val_loss: 2.2331 - val_accuracy: 0.3628\n",
      "Epoch 891/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7984 - accuracy: 0.3917 - val_loss: 2.2429 - val_accuracy: 0.3637\n",
      "Epoch 892/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8028 - accuracy: 0.4001 - val_loss: 2.1964 - val_accuracy: 0.3792\n",
      "Epoch 893/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7957 - accuracy: 0.3939 - val_loss: 2.2263 - val_accuracy: 0.3763\n",
      "Epoch 894/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7867 - accuracy: 0.4050 - val_loss: 2.2398 - val_accuracy: 0.3698\n",
      "Epoch 895/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7908 - accuracy: 0.4030 - val_loss: 2.2256 - val_accuracy: 0.3631\n",
      "Epoch 896/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7988 - accuracy: 0.3951 - val_loss: 2.2227 - val_accuracy: 0.3750\n",
      "Epoch 897/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7821 - accuracy: 0.4053 - val_loss: 2.2394 - val_accuracy: 0.3640\n",
      "Epoch 898/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7962 - accuracy: 0.4040 - val_loss: 2.2394 - val_accuracy: 0.3573\n",
      "Epoch 899/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7839 - accuracy: 0.4049 - val_loss: 2.2488 - val_accuracy: 0.3518\n",
      "Epoch 900/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7610 - accuracy: 0.4139 - val_loss: 2.2318 - val_accuracy: 0.3715\n",
      "Epoch 901/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8041 - accuracy: 0.3983 - val_loss: 2.2160 - val_accuracy: 0.3702\n",
      "Epoch 902/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8135 - accuracy: 0.3955 - val_loss: 2.2261 - val_accuracy: 0.3521\n",
      "Epoch 903/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7983 - accuracy: 0.4002 - val_loss: 2.2391 - val_accuracy: 0.3611\n",
      "Epoch 904/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7850 - accuracy: 0.3988 - val_loss: 2.2441 - val_accuracy: 0.3637\n",
      "Epoch 905/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7929 - accuracy: 0.4060 - val_loss: 2.2216 - val_accuracy: 0.3731\n",
      "Epoch 906/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8053 - accuracy: 0.3942 - val_loss: 2.2448 - val_accuracy: 0.3653\n",
      "Epoch 907/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7674 - accuracy: 0.4004 - val_loss: 2.2196 - val_accuracy: 0.3702\n",
      "Epoch 908/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7885 - accuracy: 0.4068 - val_loss: 2.2150 - val_accuracy: 0.3621\n",
      "Epoch 909/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7830 - accuracy: 0.4029 - val_loss: 2.2369 - val_accuracy: 0.3715\n",
      "Epoch 910/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.3947 - val_loss: 2.2334 - val_accuracy: 0.3573\n",
      "Epoch 911/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7629 - accuracy: 0.4106 - val_loss: 2.2550 - val_accuracy: 0.3466\n",
      "Epoch 912/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7974 - accuracy: 0.3998 - val_loss: 2.2219 - val_accuracy: 0.3814\n",
      "Epoch 913/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7930 - accuracy: 0.4024 - val_loss: 2.2504 - val_accuracy: 0.3563\n",
      "Epoch 914/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7885 - accuracy: 0.3975 - val_loss: 2.1966 - val_accuracy: 0.3805\n",
      "Epoch 915/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7910 - accuracy: 0.4003 - val_loss: 2.2324 - val_accuracy: 0.3708\n",
      "Epoch 916/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8070 - accuracy: 0.3957 - val_loss: 2.2244 - val_accuracy: 0.3676\n",
      "Epoch 917/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7950 - accuracy: 0.4071 - val_loss: 2.2346 - val_accuracy: 0.3634\n",
      "Epoch 918/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7988 - accuracy: 0.3973 - val_loss: 2.2406 - val_accuracy: 0.3686\n",
      "Epoch 919/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.3959 - val_loss: 2.2574 - val_accuracy: 0.3640\n",
      "Epoch 920/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7914 - accuracy: 0.3990 - val_loss: 2.2470 - val_accuracy: 0.3647\n",
      "Epoch 921/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8076 - accuracy: 0.4024 - val_loss: 2.2506 - val_accuracy: 0.3628\n",
      "Epoch 922/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8021 - accuracy: 0.3995 - val_loss: 2.2279 - val_accuracy: 0.3679\n",
      "Epoch 923/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8101 - accuracy: 0.3924 - val_loss: 2.2420 - val_accuracy: 0.3615\n",
      "Epoch 924/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7961 - accuracy: 0.3985 - val_loss: 2.2497 - val_accuracy: 0.3618\n",
      "Epoch 925/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8112 - accuracy: 0.4105 - val_loss: 2.2559 - val_accuracy: 0.3650\n",
      "Epoch 926/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8045 - accuracy: 0.3954 - val_loss: 2.2321 - val_accuracy: 0.3782\n",
      "Epoch 927/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7977 - accuracy: 0.3955 - val_loss: 2.2273 - val_accuracy: 0.3592\n",
      "Epoch 928/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.4044 - val_loss: 2.2357 - val_accuracy: 0.3608\n",
      "Epoch 929/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7907 - accuracy: 0.4034 - val_loss: 2.2611 - val_accuracy: 0.3515\n",
      "Epoch 930/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7813 - accuracy: 0.3962 - val_loss: 2.2663 - val_accuracy: 0.3502\n",
      "Epoch 931/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7818 - accuracy: 0.4119 - val_loss: 2.2469 - val_accuracy: 0.3724\n",
      "Epoch 932/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7821 - accuracy: 0.4161 - val_loss: 2.2749 - val_accuracy: 0.3428\n",
      "Epoch 933/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7895 - accuracy: 0.4072 - val_loss: 2.2188 - val_accuracy: 0.3763\n",
      "Epoch 934/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7831 - accuracy: 0.3957 - val_loss: 2.2817 - val_accuracy: 0.3492\n",
      "Epoch 935/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8036 - accuracy: 0.3927 - val_loss: 2.2562 - val_accuracy: 0.3537\n",
      "Epoch 936/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7993 - accuracy: 0.4077 - val_loss: 2.2558 - val_accuracy: 0.3573\n",
      "Epoch 937/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7959 - accuracy: 0.4048 - val_loss: 2.2735 - val_accuracy: 0.3608\n",
      "Epoch 938/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8045 - accuracy: 0.4020 - val_loss: 2.2551 - val_accuracy: 0.3560\n",
      "Epoch 939/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8005 - accuracy: 0.3970 - val_loss: 2.2195 - val_accuracy: 0.3679\n",
      "Epoch 940/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7815 - accuracy: 0.4108 - val_loss: 2.2218 - val_accuracy: 0.3702\n",
      "Epoch 941/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8007 - accuracy: 0.4048 - val_loss: 2.2270 - val_accuracy: 0.3711\n",
      "Epoch 942/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7893 - accuracy: 0.4016 - val_loss: 2.2630 - val_accuracy: 0.3573\n",
      "Epoch 943/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8164 - accuracy: 0.3942 - val_loss: 2.2617 - val_accuracy: 0.3657\n",
      "Epoch 944/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8015 - accuracy: 0.3990 - val_loss: 2.2418 - val_accuracy: 0.3579\n",
      "Epoch 945/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7795 - accuracy: 0.4080 - val_loss: 2.2364 - val_accuracy: 0.3508\n",
      "Epoch 946/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7971 - accuracy: 0.4050 - val_loss: 2.2649 - val_accuracy: 0.3557\n",
      "Epoch 947/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7874 - accuracy: 0.3976 - val_loss: 2.2445 - val_accuracy: 0.3698\n",
      "Epoch 948/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7863 - accuracy: 0.3982 - val_loss: 2.2206 - val_accuracy: 0.3557\n",
      "Epoch 949/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8011 - accuracy: 0.4047 - val_loss: 2.2149 - val_accuracy: 0.3711\n",
      "Epoch 950/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8011 - accuracy: 0.3945 - val_loss: 2.1946 - val_accuracy: 0.3734\n",
      "Epoch 951/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7990 - accuracy: 0.3949 - val_loss: 2.2250 - val_accuracy: 0.3666\n",
      "Epoch 952/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7908 - accuracy: 0.4069 - val_loss: 2.2220 - val_accuracy: 0.3660\n",
      "Epoch 953/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8074 - accuracy: 0.3996 - val_loss: 2.2394 - val_accuracy: 0.3608\n",
      "Epoch 954/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7992 - accuracy: 0.4032 - val_loss: 2.2432 - val_accuracy: 0.3763\n",
      "Epoch 955/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8049 - accuracy: 0.3935 - val_loss: 2.2251 - val_accuracy: 0.3663\n",
      "Epoch 956/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8065 - accuracy: 0.3946 - val_loss: 2.2533 - val_accuracy: 0.3531\n",
      "Epoch 957/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7979 - accuracy: 0.4006 - val_loss: 2.2592 - val_accuracy: 0.3576\n",
      "Epoch 958/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8221 - accuracy: 0.3975 - val_loss: 2.2402 - val_accuracy: 0.3673\n",
      "Epoch 959/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8059 - accuracy: 0.3932 - val_loss: 2.2473 - val_accuracy: 0.3682\n",
      "Epoch 960/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7841 - accuracy: 0.3985 - val_loss: 2.2608 - val_accuracy: 0.3495\n",
      "Epoch 961/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7856 - accuracy: 0.4015 - val_loss: 2.2471 - val_accuracy: 0.3676\n",
      "Epoch 962/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7785 - accuracy: 0.4013 - val_loss: 2.2081 - val_accuracy: 0.3750\n",
      "Epoch 963/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7852 - accuracy: 0.4038 - val_loss: 2.2392 - val_accuracy: 0.3644\n",
      "Epoch 964/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7687 - accuracy: 0.4097 - val_loss: 2.2369 - val_accuracy: 0.3589\n",
      "Epoch 965/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7790 - accuracy: 0.4041 - val_loss: 2.2807 - val_accuracy: 0.3512\n",
      "Epoch 966/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7848 - accuracy: 0.4036 - val_loss: 2.2621 - val_accuracy: 0.3508\n",
      "Epoch 967/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.3988 - val_loss: 2.2463 - val_accuracy: 0.3595\n",
      "Epoch 968/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7939 - accuracy: 0.3987 - val_loss: 2.2560 - val_accuracy: 0.3602\n",
      "Epoch 969/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7813 - accuracy: 0.4010 - val_loss: 2.2585 - val_accuracy: 0.3673\n",
      "Epoch 970/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7993 - accuracy: 0.4059 - val_loss: 2.2208 - val_accuracy: 0.3740\n",
      "Epoch 971/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7783 - accuracy: 0.4100 - val_loss: 2.2589 - val_accuracy: 0.3582\n",
      "Epoch 972/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7969 - accuracy: 0.4019 - val_loss: 2.2426 - val_accuracy: 0.3679\n",
      "Epoch 973/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8067 - accuracy: 0.3993 - val_loss: 2.2474 - val_accuracy: 0.3602\n",
      "Epoch 974/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8048 - accuracy: 0.3992 - val_loss: 2.2350 - val_accuracy: 0.3644\n",
      "Epoch 975/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7927 - accuracy: 0.4050 - val_loss: 2.2186 - val_accuracy: 0.3776\n",
      "Epoch 976/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8045 - accuracy: 0.3904 - val_loss: 2.2199 - val_accuracy: 0.3650\n",
      "Epoch 977/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7868 - accuracy: 0.4030 - val_loss: 2.1951 - val_accuracy: 0.3750\n",
      "Epoch 978/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7932 - accuracy: 0.4054 - val_loss: 2.2369 - val_accuracy: 0.3666\n",
      "Epoch 979/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8024 - accuracy: 0.4013 - val_loss: 2.2398 - val_accuracy: 0.3705\n",
      "Epoch 980/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7969 - accuracy: 0.4006 - val_loss: 2.2205 - val_accuracy: 0.3692\n",
      "Epoch 981/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7830 - accuracy: 0.4079 - val_loss: 2.2500 - val_accuracy: 0.3602\n",
      "Epoch 982/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7858 - accuracy: 0.4046 - val_loss: 2.2267 - val_accuracy: 0.3682\n",
      "Epoch 983/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8110 - accuracy: 0.3900 - val_loss: 2.1680 - val_accuracy: 0.3856\n",
      "Epoch 984/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7926 - accuracy: 0.3972 - val_loss: 2.2328 - val_accuracy: 0.3692\n",
      "Epoch 985/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8006 - accuracy: 0.3921 - val_loss: 2.2287 - val_accuracy: 0.3702\n",
      "Epoch 986/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.8074 - accuracy: 0.3953 - val_loss: 2.2161 - val_accuracy: 0.3718\n",
      "Epoch 987/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7813 - accuracy: 0.4057 - val_loss: 2.2235 - val_accuracy: 0.3676\n",
      "Epoch 988/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7758 - accuracy: 0.3988 - val_loss: 2.2218 - val_accuracy: 0.3721\n",
      "Epoch 989/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7773 - accuracy: 0.4123 - val_loss: 2.2393 - val_accuracy: 0.3608\n",
      "Epoch 990/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7864 - accuracy: 0.4023 - val_loss: 2.2448 - val_accuracy: 0.3634\n",
      "Epoch 991/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7743 - accuracy: 0.4099 - val_loss: 2.2728 - val_accuracy: 0.3669\n",
      "Epoch 992/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7989 - accuracy: 0.4047 - val_loss: 2.2305 - val_accuracy: 0.3750\n",
      "Epoch 993/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7754 - accuracy: 0.4012 - val_loss: 2.2412 - val_accuracy: 0.3563\n",
      "Epoch 994/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7873 - accuracy: 0.3983 - val_loss: 2.2461 - val_accuracy: 0.3589\n",
      "Epoch 995/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7842 - accuracy: 0.4025 - val_loss: 2.2213 - val_accuracy: 0.3702\n",
      "Epoch 996/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7869 - accuracy: 0.3992 - val_loss: 2.2067 - val_accuracy: 0.3731\n",
      "Epoch 997/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7756 - accuracy: 0.3995 - val_loss: 2.2459 - val_accuracy: 0.3586\n",
      "Epoch 998/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7848 - accuracy: 0.4028 - val_loss: 2.2189 - val_accuracy: 0.3776\n",
      "Epoch 999/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7972 - accuracy: 0.3978 - val_loss: 2.2644 - val_accuracy: 0.3621\n",
      "Epoch 1000/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.7933 - accuracy: 0.4068 - val_loss: 2.2356 - val_accuracy: 0.3573\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_emb_aug_complex = Emb_model_aug_complex.fit(x_emb_aug_train, y_emb_aug_train_one_hot,\n",
    "                                 epochs=1000,\n",
    "                                 batch_size=16,\n",
    "                                 validation_data=(x_emb_aug_val, y_emb_aug_val_one_hot)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 57 (Val Accuracy: 0.42783504724502563)\n",
      "Best Epoch for Training Accuracy: 989 (Train Accuracy: 0.41010552644729614)\n",
      "Best Epoch for Training Loss: 997 (Train Loss: 1.7844914197921753)\n",
      "Best Epoch for Validation Loss: 272 (Val Loss: 2.1304123401641846)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.42783504724502563\n",
      "Maximum Training Accuracy: 0.41010552644729614\n",
      "Minimum Training Loss: 1.7844914197921753\n",
      "Minimum Validation Loss: 2.1304123401641846\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_emb_aug_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_emb_aug_complex, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file = \"many_to_many_emb_LSTM_complex_aug_model.h5\"  \n",
    "Emb_model_aug_complex.save(model_file)\n",
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_emb_LSTM_complex_aug_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_emb_aug_complex.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.35728092783505155\n",
      "Accuracy for Label barrel_turn: 0.1\n",
      "Accuracy for Label basic_charleston: nan\n",
      "Accuracy for Label basic_closed: 0.5737704918032787\n",
      "Accuracy for Label basic_open: 0.0\n",
      "Accuracy for Label break: 0.06132075471698113\n",
      "Accuracy for Label come_back: 0.02962962962962963\n",
      "Accuracy for Label corridor: 0.0\n",
      "Accuracy for Label frankie´s_points: nan\n",
      "Accuracy for Label frankie´s_sixes: 0.0\n",
      "Accuracy for Label groove_walk: 0.0\n",
      "Accuracy for Label hallelujah_rocks: 0.0\n",
      "Accuracy for Label hand_to_hand: 0.0\n",
      "Accuracy for Label hand_to_hand_charleston: nan\n",
      "Accuracy for Label inside_spin: 0.0\n",
      "Accuracy for Label inside_turn: 0.11627906976744186\n",
      "Accuracy for Label lindy_circle: 0.02857142857142857\n",
      "Accuracy for Label mini_dip: 0.0\n",
      "Accuracy for Label outside_spin: 0.01\n",
      "Accuracy for Label outside_turn: 0.027777777777777776\n",
      "Accuracy for Label pass_by: 0.6555819477434679\n",
      "Accuracy for Label pop_turn: 0.0\n",
      "Accuracy for Label promenade: 0.0\n",
      "Accuracy for Label s_turn: 0.0\n",
      "Accuracy for Label sailor_kicks: 0.0\n",
      "Accuracy for Label send_out: 0.23076923076923078\n",
      "Accuracy for Label sling_shot: 0.375\n",
      "Accuracy for Label sugar_push: 0.08333333333333333\n",
      "Accuracy for Label sweetheart: 0.011904761904761904\n",
      "Accuracy for Label swingout: 0.18711656441717792\n",
      "Accuracy for Label switches: 0.0\n",
      "Accuracy for Label tandem: 1.0\n",
      "Accuracy for Label tuck_turn: 0.2810810810810811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/cds-au605619/cds-language/lang101/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Predict labels on the test data\n",
    "predictions = Emb_model_aug_complex.predict(x_emb_aug_val)\n",
    "\n",
    "# Convert one-hot encoded predictions to single labels using TensorFlow's argmax\n",
    "predicted_labels_encoded = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Flatten the arrays for label-wise accuracy calculation\n",
    "predicted_labels_encoded = predicted_labels_encoded.flatten()\n",
    "\n",
    "# Convert one-hot encoded true labels to single labels using TensorFlow's argmax\n",
    "true_labels_encoded = tf.argmax(y_emb_aug_val_one_hot, axis=-1).numpy().flatten()\n",
    "\n",
    "# Map predicted labels to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "# Map true labels to original labels\n",
    "true_labels = label_encoder.inverse_transform(true_labels_encoded)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Display label-wise accuracy\n",
    "unique_labels = label_encoder.classes_\n",
    "for label in unique_labels:\n",
    "    label_indices = true_labels == label\n",
    "    label_accuracy = accuracy_score(true_labels[label_indices], predicted_labels[label_indices])\n",
    "    print(f'Accuracy for Label {label}: {label_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-Many LSTM model (one-hot encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the iput-output data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([28, 19,  5, 31, 17, 19,  3, 19,  4, 19, 19, 19, 15, 31, 19,  5, 24,\n",
       "         4, 19, 17, 19,  5, 28, 19, 26, 26, 19,  5,  4, 24, 19, 19, 19,  5,\n",
       "        24, 19, 15, 31,  4, 19, 27, 19,  5, 28, 19,  4, 19,  4, 19,  5,  6,\n",
       "        28,  4, 19, 19,  4, 29, 19,  5,  6]),\n",
       " array([ 2, 31, 19, 19, 27, 19, 17, 19, 28, 19, 19, 19, 26, 19, 19, 28, 19,\n",
       "        19,  8, 19, 28, 19, 19, 27, 19, 19, 19, 19, 15, 31, 19, 19, 23, 19,\n",
       "         8, 19, 19,  8,  4, 19, 28, 19, 19,  8, 19, 28, 19, 19, 19, 19, 28]),\n",
       " array([ 2, 31, 19, 19, 28, 19,  4, 17, 19,  5,  2,  2,  2, 31, 19, 19,  8,\n",
       "        19, 28, 19, 15, 31, 19,  5, 31, 19, 19, 19, 19,  8, 19, 17, 19, 28,\n",
       "        19, 15, 31,  4, 14,  5, 31, 19,  8, 19, 28, 19, 17, 19, 28, 19, 19,\n",
       "        28, 19, 19, 19, 23, 19, 27]),\n",
       " array([ 2, 31, 19, 27, 19, 19, 19, 28, 19, 23, 19,  8,  0, 28, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19,  8, 19, 28, 19, 15, 31, 17, 19, 19, 28, 19,\n",
       "        19, 19, 19, 28, 19, 19,  4, 19, 28, 19, 19, 19, 27, 19, 28, 19, 19,\n",
       "        27, 19]),\n",
       " array([ 9,  2,  2,  2, 24,  4, 19, 26, 19, 15, 24, 19, 19, 28, 28, 28,  4,\n",
       "         0, 27, 17, 19,  4, 28,  4, 19, 15, 24, 19, 17, 19, 26, 19, 15, 31,\n",
       "        17, 19,  4, 19,  0,  4, 19, 15, 31, 19, 29, 19, 15, 31, 19, 28, 19,\n",
       "         4, 19, 17, 19, 15,  2, 31, 19, 19, 15, 31]),\n",
       " array([ 9, 19, 15, 28, 26, 19, 28, 19, 19,  0, 19,  4, 15,  2, 31, 19,  4,\n",
       "        15, 21, 28, 28, 28,  4,  5,  2, 31, 17,  0,  4, 19, 26, 19, 15,  2,\n",
       "        15, 31, 19, 15, 24, 26, 23, 19, 28, 15, 31, 19, 15, 24, 19, 17, 19,\n",
       "        15, 31,  4, 15, 28, 28,  4, 15]),\n",
       " array([ 9, 19, 19, 19, 15, 28, 15, 24, 26, 19, 28,  5, 31, 19]),\n",
       " array([ 9,  2, 31, 19, 16,  5,  2, 31, 17, 19, 28, 15,  4, 31, 19, 19, 18,\n",
       "        19, 28, 19, 28, 19, 19,  0, 18, 26, 26, 27, 19, 28, 14, 28, 17, 18,\n",
       "        19, 19,  4,  5,  9,  2, 19, 27,  4,  0, 27,  0, 27, 14,  2, 28, 28,\n",
       "         2, 20]),\n",
       " array([ 9,  2, 31, 19, 19, 27,  4, 19, 19,  5,  9, 31, 19,  5,  4,  2, 24,\n",
       "        17, 19,  4, 19, 28, 28, 18, 19,  0,  4, 19, 27,  0,  5,  2,  4, 31,\n",
       "        19,  4, 19,  4, 21, 31, 19,  0, 19, 27, 19, 19,  0,  4, 31, 19, 26,\n",
       "        26, 22, 30, 30,  4]),\n",
       " array([ 9, 31, 19, 19,  0, 19, 19, 31, 19, 19, 27, 15,  4, 24, 19, 19, 28,\n",
       "        19, 27,  9, 19, 19, 19, 28,  4, 19, 28,  4, 19, 19,  4, 14, 28, 19,\n",
       "         4, 14, 31, 18, 19,  4, 17, 19, 10,  4, 18, 19, 19, 19, 27, 19, 19,\n",
       "        18, 19,  4, 28, 28, 19, 19, 19]),\n",
       " array([ 9,  2,  2,  2,  2, 31, 19, 19, 14, 14, 14,  0, 17, 27, 19, 19, 28,\n",
       "         5,  2,  2, 31, 19, 19, 19, 28, 28, 28, 19, 19, 19, 19,  5,  2, 24,\n",
       "        23,  0, 27, 19, 19,  5,  2,  2,  2, 31, 19, 19,  5,  2,  2, 31, 28,\n",
       "        28, 14, 14, 19, 19]),\n",
       " array([ 9, 19, 28, 19, 28,  5,  2,  2, 31, 19, 19,  5,  2,  2, 31, 19,  5,\n",
       "         2,  2,  2,  6, 31, 17, 19, 19,  5, 31, 19, 19,  5,  2,  2, 31, 19,\n",
       "        19,  3, 19, 19, 28, 28, 28, 19, 19, 19, 28,  5,  2, 21, 24, 28, 19,\n",
       "         5, 21,  2,  2, 31, 17, 19, 19, 19,  3, 19]),\n",
       " array([ 9,  2, 31, 19,  4, 19, 19,  4, 19, 19, 19,  4, 19,  5,  2,  2, 31,\n",
       "        19, 19,  3,  4, 19, 19, 19, 29, 19, 19, 19,  3,  4, 19,  5,  2,  2,\n",
       "         4,  2, 31, 19,  4, 19,  5,  2, 31,  4, 19, 19,  3, 28,  5, 31, 19,\n",
       "         4, 19, 19,  4]),\n",
       " array([ 9, 19, 27, 19, 26, 27, 19,  8, 19, 19, 19, 28, 19,  8, 19, 19, 11,\n",
       "        19,  5, 31, 19, 28, 28, 19, 28, 18, 19, 28, 14, 19, 19,  8, 19, 26,\n",
       "        19, 19, 26, 17, 19, 26, 28, 28, 19, 19, 19, 19, 19, 26, 28,  6, 19,\n",
       "         8]),\n",
       " array([ 9, 19, 19, 28, 19, 28, 19, 11, 19, 26, 19, 17, 19, 19, 26, 27, 19,\n",
       "        13, 19, 19, 28, 28, 18, 19, 26, 25, 25, 19, 26, 19, 26, 28, 19,  8,\n",
       "         6, 19,  8, 19, 19, 19,  8,  5,  2, 31,  2, 28,  2, 31]),\n",
       " array([ 9, 26, 19, 19, 19, 26,  8, 19, 19, 17, 19,  8, 19, 19,  8, 19, 28,\n",
       "        19, 19, 26, 19, 28, 19, 19, 17, 19, 17,  8, 19, 19, 19, 19, 19, 26,\n",
       "        19, 19, 28, 28, 19, 26, 19, 19])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode sequences to integers\n",
    "# Apply encoding to each sequence for train dataset\n",
    "encoded_sequences_augmented_train = [encode_sequence(sequence) for sequence in all_sequences_train]\n",
    "encoded_sequences_augmented_train\n",
    "\n",
    "# Apply encoding to each sequence for val dataset\n",
    "encoded_sequences_augmented_val = [encode_sequence(sequence) for sequence in original_sequences_val]\n",
    "encoded_sequences_augmented_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aug_train, y_aug_train = create_input_output_pairs_mtm(encoded_sequences_augmented_train, 4)\n",
    "x_aug_val, y_aug_val = create_input_output_pairs_mtm(encoded_sequences_augmented_val, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xx: (2464, 4, 32)\n",
      "Shape of yy: (2464, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convert x and y to one-hot encoding\n",
    "x_aug_train_one_hot = to_categorical(x_aug_train, num_classes=num_classes)\n",
    "y_aug_train_one_hot = to_categorical(y_aug_train, num_classes=num_classes)\n",
    "x_aug_val_one_hot = to_categorical(x_aug_val, num_classes=num_classes)\n",
    "y_aug_val_one_hot = to_categorical(y_aug_val, num_classes=num_classes)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of xx:\", x_aug_train_one_hot.shape)\n",
    "print(\"Shape of yy:\", y_aug_train_one_hot.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_aug_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xx: (2464, 4, 32)\n",
      "Shape of yy: (776, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convert to TensorFlow tensors\n",
    "x_aug_train_tensor = tf.convert_to_tensor(x_aug_train_one_hot)\n",
    "x_aug_val_tensor = tf.convert_to_tensor(x_aug_val_one_hot)\n",
    "y_aug_train_tensor = tf.convert_to_tensor(y_aug_train_one_hot)\n",
    "y_aug_val_tensor = tf.convert_to_tensor(y_aug_val_one_hot)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of xx:\", x_aug_train_tensor.shape)\n",
    "print(\"Shape of yy:\", x_aug_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A baseline Many-to-Many LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 4, 64)             24832     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 26,912\n",
      "Trainable params: 26,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, TimeDistributed\n",
    "import random\n",
    "\n",
    "\n",
    "# Set a new random seed\n",
    "new_seed = 33\n",
    "tf.random.set_seed(new_seed)\n",
    "np.random.seed(new_seed)\n",
    "random.seed(new_seed)\n",
    "\n",
    "# Define the LSTM model for many-to-many\n",
    "many_to_many_model_aug_baseline = Sequential([\n",
    "    LSTM(64, input_shape=(4, 32), return_sequences=True),  # 64 units, return full sequence\n",
    "    Dropout(0.2),                                         # Dropout for regularization\n",
    "    TimeDistributed(Dense(32, activation='softmax'))      # Apply Dense layer to each timestep\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "many_to_many_model_aug_baseline.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "many_to_many_model_aug_baseline.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "154/154 [==============================] - 2s 6ms/step - loss: 3.2991 - accuracy: 0.1475 - val_loss: 2.6155 - val_accuracy: 0.3882\n",
      "Epoch 2/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8063 - accuracy: 0.2137 - val_loss: 2.3412 - val_accuracy: 0.4217\n",
      "Epoch 3/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5422 - accuracy: 0.2885 - val_loss: 2.2509 - val_accuracy: 0.4082\n",
      "Epoch 4/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.3160 - accuracy: 0.3305 - val_loss: 2.2213 - val_accuracy: 0.3995\n",
      "Epoch 5/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1938 - accuracy: 0.3585 - val_loss: 2.2282 - val_accuracy: 0.3660\n",
      "Epoch 6/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.1211 - accuracy: 0.3587 - val_loss: 2.2074 - val_accuracy: 0.3744\n",
      "Epoch 7/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0527 - accuracy: 0.3688 - val_loss: 2.2024 - val_accuracy: 0.3727\n",
      "Epoch 8/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.0111 - accuracy: 0.3745 - val_loss: 2.2163 - val_accuracy: 0.3686\n",
      "Epoch 9/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9897 - accuracy: 0.3725 - val_loss: 2.2052 - val_accuracy: 0.3528\n",
      "Epoch 10/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9610 - accuracy: 0.3753 - val_loss: 2.1860 - val_accuracy: 0.3744\n",
      "Epoch 11/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9522 - accuracy: 0.3682 - val_loss: 2.2032 - val_accuracy: 0.3557\n",
      "Epoch 12/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.9156 - accuracy: 0.3811 - val_loss: 2.1955 - val_accuracy: 0.3592\n",
      "Epoch 13/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8803 - accuracy: 0.3895 - val_loss: 2.1695 - val_accuracy: 0.3802\n",
      "Epoch 14/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8743 - accuracy: 0.3889 - val_loss: 2.1808 - val_accuracy: 0.3727\n",
      "Epoch 15/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8628 - accuracy: 0.3865 - val_loss: 2.1905 - val_accuracy: 0.3579\n",
      "Epoch 16/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8608 - accuracy: 0.3874 - val_loss: 2.1557 - val_accuracy: 0.3763\n",
      "Epoch 17/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8446 - accuracy: 0.3892 - val_loss: 2.1657 - val_accuracy: 0.3769\n",
      "Epoch 18/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8204 - accuracy: 0.3963 - val_loss: 2.1850 - val_accuracy: 0.3715\n",
      "Epoch 19/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8422 - accuracy: 0.3865 - val_loss: 2.1788 - val_accuracy: 0.3734\n",
      "Epoch 20/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8105 - accuracy: 0.3990 - val_loss: 2.1585 - val_accuracy: 0.3834\n",
      "Epoch 21/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8173 - accuracy: 0.3974 - val_loss: 2.1910 - val_accuracy: 0.3657\n",
      "Epoch 22/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8280 - accuracy: 0.3940 - val_loss: 2.1786 - val_accuracy: 0.3718\n",
      "Epoch 23/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.8038 - accuracy: 0.3929 - val_loss: 2.1686 - val_accuracy: 0.3773\n",
      "Epoch 24/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7862 - accuracy: 0.4055 - val_loss: 2.1915 - val_accuracy: 0.3666\n",
      "Epoch 25/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7771 - accuracy: 0.4048 - val_loss: 2.1859 - val_accuracy: 0.3727\n",
      "Epoch 26/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7645 - accuracy: 0.4052 - val_loss: 2.1825 - val_accuracy: 0.3702\n",
      "Epoch 27/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7607 - accuracy: 0.4160 - val_loss: 2.1761 - val_accuracy: 0.3673\n",
      "Epoch 28/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7622 - accuracy: 0.4009 - val_loss: 2.1870 - val_accuracy: 0.3676\n",
      "Epoch 29/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7595 - accuracy: 0.4135 - val_loss: 2.1951 - val_accuracy: 0.3634\n",
      "Epoch 30/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7512 - accuracy: 0.4143 - val_loss: 2.1977 - val_accuracy: 0.3592\n",
      "Epoch 31/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7549 - accuracy: 0.4061 - val_loss: 2.1821 - val_accuracy: 0.3705\n",
      "Epoch 32/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7380 - accuracy: 0.4156 - val_loss: 2.1859 - val_accuracy: 0.3698\n",
      "Epoch 33/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7404 - accuracy: 0.4092 - val_loss: 2.1859 - val_accuracy: 0.3747\n",
      "Epoch 34/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7391 - accuracy: 0.4087 - val_loss: 2.1925 - val_accuracy: 0.3589\n",
      "Epoch 35/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7221 - accuracy: 0.4244 - val_loss: 2.1959 - val_accuracy: 0.3586\n",
      "Epoch 36/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7497 - accuracy: 0.4113 - val_loss: 2.2010 - val_accuracy: 0.3640\n",
      "Epoch 37/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7133 - accuracy: 0.4155 - val_loss: 2.2032 - val_accuracy: 0.3589\n",
      "Epoch 38/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7054 - accuracy: 0.4167 - val_loss: 2.2245 - val_accuracy: 0.3524\n",
      "Epoch 39/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6896 - accuracy: 0.4292 - val_loss: 2.1980 - val_accuracy: 0.3692\n",
      "Epoch 40/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7087 - accuracy: 0.4216 - val_loss: 2.2091 - val_accuracy: 0.3550\n",
      "Epoch 41/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.7044 - accuracy: 0.4197 - val_loss: 2.1915 - val_accuracy: 0.3698\n",
      "Epoch 42/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6840 - accuracy: 0.4284 - val_loss: 2.2237 - val_accuracy: 0.3515\n",
      "Epoch 43/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6795 - accuracy: 0.4274 - val_loss: 2.2342 - val_accuracy: 0.3499\n",
      "Epoch 44/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6935 - accuracy: 0.4227 - val_loss: 2.2095 - val_accuracy: 0.3576\n",
      "Epoch 45/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6650 - accuracy: 0.4318 - val_loss: 2.2199 - val_accuracy: 0.3502\n",
      "Epoch 46/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6728 - accuracy: 0.4325 - val_loss: 2.2284 - val_accuracy: 0.3495\n",
      "Epoch 47/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6604 - accuracy: 0.4332 - val_loss: 2.2280 - val_accuracy: 0.3537\n",
      "Epoch 48/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6587 - accuracy: 0.4306 - val_loss: 2.2144 - val_accuracy: 0.3599\n",
      "Epoch 49/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6529 - accuracy: 0.4354 - val_loss: 2.2363 - val_accuracy: 0.3534\n",
      "Epoch 50/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6460 - accuracy: 0.4349 - val_loss: 2.2394 - val_accuracy: 0.3470\n",
      "Epoch 51/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.6497 - accuracy: 0.4379 - val_loss: 2.2241 - val_accuracy: 0.3595\n",
      "Epoch 52/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6424 - accuracy: 0.4426 - val_loss: 2.2247 - val_accuracy: 0.3553\n",
      "Epoch 53/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6285 - accuracy: 0.4440 - val_loss: 2.2420 - val_accuracy: 0.3460\n",
      "Epoch 54/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6500 - accuracy: 0.4372 - val_loss: 2.2316 - val_accuracy: 0.3499\n",
      "Epoch 55/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6509 - accuracy: 0.4375 - val_loss: 2.2434 - val_accuracy: 0.3505\n",
      "Epoch 56/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6384 - accuracy: 0.4355 - val_loss: 2.2446 - val_accuracy: 0.3505\n",
      "Epoch 57/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6273 - accuracy: 0.4482 - val_loss: 2.2360 - val_accuracy: 0.3534\n",
      "Epoch 58/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6343 - accuracy: 0.4365 - val_loss: 2.2518 - val_accuracy: 0.3441\n",
      "Epoch 59/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6206 - accuracy: 0.4491 - val_loss: 2.2721 - val_accuracy: 0.3441\n",
      "Epoch 60/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6093 - accuracy: 0.4493 - val_loss: 2.2518 - val_accuracy: 0.3483\n",
      "Epoch 61/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6172 - accuracy: 0.4500 - val_loss: 2.2571 - val_accuracy: 0.3415\n",
      "Epoch 62/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6045 - accuracy: 0.4442 - val_loss: 2.2582 - val_accuracy: 0.3473\n",
      "Epoch 63/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6044 - accuracy: 0.4531 - val_loss: 2.2510 - val_accuracy: 0.3524\n",
      "Epoch 64/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6208 - accuracy: 0.4502 - val_loss: 2.2548 - val_accuracy: 0.3531\n",
      "Epoch 65/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6158 - accuracy: 0.4444 - val_loss: 2.2649 - val_accuracy: 0.3454\n",
      "Epoch 66/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5992 - accuracy: 0.4509 - val_loss: 2.2757 - val_accuracy: 0.3357\n",
      "Epoch 67/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6232 - accuracy: 0.4434 - val_loss: 2.2807 - val_accuracy: 0.3383\n",
      "Epoch 68/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5939 - accuracy: 0.4497 - val_loss: 2.2684 - val_accuracy: 0.3515\n",
      "Epoch 69/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.6036 - accuracy: 0.4536 - val_loss: 2.2759 - val_accuracy: 0.3447\n",
      "Epoch 70/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5804 - accuracy: 0.4584 - val_loss: 2.2593 - val_accuracy: 0.3521\n",
      "Epoch 71/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5937 - accuracy: 0.4599 - val_loss: 2.2748 - val_accuracy: 0.3476\n",
      "Epoch 72/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5873 - accuracy: 0.4600 - val_loss: 2.2851 - val_accuracy: 0.3505\n",
      "Epoch 73/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5885 - accuracy: 0.4560 - val_loss: 2.2909 - val_accuracy: 0.3418\n",
      "Epoch 74/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5777 - accuracy: 0.4570 - val_loss: 2.2928 - val_accuracy: 0.3409\n",
      "Epoch 75/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5765 - accuracy: 0.4568 - val_loss: 2.2947 - val_accuracy: 0.3373\n",
      "Epoch 76/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5681 - accuracy: 0.4668 - val_loss: 2.2968 - val_accuracy: 0.3370\n",
      "Epoch 77/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5829 - accuracy: 0.4548 - val_loss: 2.2784 - val_accuracy: 0.3557\n",
      "Epoch 78/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5642 - accuracy: 0.4675 - val_loss: 2.2944 - val_accuracy: 0.3489\n",
      "Epoch 79/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5462 - accuracy: 0.4611 - val_loss: 2.2936 - val_accuracy: 0.3415\n",
      "Epoch 80/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5745 - accuracy: 0.4601 - val_loss: 2.2931 - val_accuracy: 0.3447\n",
      "Epoch 81/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5665 - accuracy: 0.4671 - val_loss: 2.3099 - val_accuracy: 0.3341\n",
      "Epoch 82/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5520 - accuracy: 0.4634 - val_loss: 2.2894 - val_accuracy: 0.3537\n",
      "Epoch 83/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5585 - accuracy: 0.4703 - val_loss: 2.3179 - val_accuracy: 0.3354\n",
      "Epoch 84/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5600 - accuracy: 0.4659 - val_loss: 2.3119 - val_accuracy: 0.3415\n",
      "Epoch 85/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5492 - accuracy: 0.4660 - val_loss: 2.3018 - val_accuracy: 0.3444\n",
      "Epoch 86/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5389 - accuracy: 0.4668 - val_loss: 2.2968 - val_accuracy: 0.3466\n",
      "Epoch 87/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5461 - accuracy: 0.4674 - val_loss: 2.3032 - val_accuracy: 0.3473\n",
      "Epoch 88/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5537 - accuracy: 0.4581 - val_loss: 2.3216 - val_accuracy: 0.3425\n",
      "Epoch 89/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5423 - accuracy: 0.4690 - val_loss: 2.3244 - val_accuracy: 0.3312\n",
      "Epoch 90/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5453 - accuracy: 0.4718 - val_loss: 2.3301 - val_accuracy: 0.3328\n",
      "Epoch 91/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5408 - accuracy: 0.4729 - val_loss: 2.3391 - val_accuracy: 0.3325\n",
      "Epoch 92/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5388 - accuracy: 0.4733 - val_loss: 2.3408 - val_accuracy: 0.3286\n",
      "Epoch 93/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5439 - accuracy: 0.4698 - val_loss: 2.3227 - val_accuracy: 0.3438\n",
      "Epoch 94/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5271 - accuracy: 0.4729 - val_loss: 2.3243 - val_accuracy: 0.3431\n",
      "Epoch 95/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5354 - accuracy: 0.4722 - val_loss: 2.3244 - val_accuracy: 0.3505\n",
      "Epoch 96/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5385 - accuracy: 0.4799 - val_loss: 2.3349 - val_accuracy: 0.3360\n",
      "Epoch 97/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5255 - accuracy: 0.4780 - val_loss: 2.3468 - val_accuracy: 0.3373\n",
      "Epoch 98/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5416 - accuracy: 0.4697 - val_loss: 2.3266 - val_accuracy: 0.3524\n",
      "Epoch 99/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5232 - accuracy: 0.4704 - val_loss: 2.3307 - val_accuracy: 0.3483\n",
      "Epoch 100/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5178 - accuracy: 0.4830 - val_loss: 2.3294 - val_accuracy: 0.3450\n",
      "Epoch 101/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5223 - accuracy: 0.4741 - val_loss: 2.3424 - val_accuracy: 0.3444\n",
      "Epoch 102/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5178 - accuracy: 0.4765 - val_loss: 2.3456 - val_accuracy: 0.3383\n",
      "Epoch 103/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5012 - accuracy: 0.4874 - val_loss: 2.3592 - val_accuracy: 0.3344\n",
      "Epoch 104/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5252 - accuracy: 0.4660 - val_loss: 2.3291 - val_accuracy: 0.3528\n",
      "Epoch 105/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5024 - accuracy: 0.4726 - val_loss: 2.3487 - val_accuracy: 0.3409\n",
      "Epoch 106/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5128 - accuracy: 0.4780 - val_loss: 2.3457 - val_accuracy: 0.3450\n",
      "Epoch 107/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4901 - accuracy: 0.4847 - val_loss: 2.3496 - val_accuracy: 0.3457\n",
      "Epoch 108/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4925 - accuracy: 0.4872 - val_loss: 2.3888 - val_accuracy: 0.3238\n",
      "Epoch 109/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.4803 - val_loss: 2.3550 - val_accuracy: 0.3322\n",
      "Epoch 110/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5016 - accuracy: 0.4834 - val_loss: 2.3360 - val_accuracy: 0.3473\n",
      "Epoch 111/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4973 - accuracy: 0.4903 - val_loss: 2.3592 - val_accuracy: 0.3383\n",
      "Epoch 112/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5118 - accuracy: 0.4752 - val_loss: 2.3597 - val_accuracy: 0.3505\n",
      "Epoch 113/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5214 - accuracy: 0.4740 - val_loss: 2.3566 - val_accuracy: 0.3415\n",
      "Epoch 114/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4904 - accuracy: 0.4914 - val_loss: 2.3669 - val_accuracy: 0.3396\n",
      "Epoch 115/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5041 - accuracy: 0.4812 - val_loss: 2.3721 - val_accuracy: 0.3367\n",
      "Epoch 116/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5059 - accuracy: 0.4798 - val_loss: 2.3730 - val_accuracy: 0.3383\n",
      "Epoch 117/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4898 - accuracy: 0.4758 - val_loss: 2.3660 - val_accuracy: 0.3325\n",
      "Epoch 118/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.4847 - val_loss: 2.3770 - val_accuracy: 0.3325\n",
      "Epoch 119/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4852 - accuracy: 0.4836 - val_loss: 2.3695 - val_accuracy: 0.3425\n",
      "Epoch 120/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4907 - accuracy: 0.4920 - val_loss: 2.3645 - val_accuracy: 0.3515\n",
      "Epoch 121/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.5037 - accuracy: 0.4865 - val_loss: 2.3784 - val_accuracy: 0.3331\n",
      "Epoch 122/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4928 - accuracy: 0.4885 - val_loss: 2.3854 - val_accuracy: 0.3318\n",
      "Epoch 123/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4701 - accuracy: 0.4989 - val_loss: 2.4011 - val_accuracy: 0.3241\n",
      "Epoch 124/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4783 - accuracy: 0.4842 - val_loss: 2.3835 - val_accuracy: 0.3341\n",
      "Epoch 125/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4704 - accuracy: 0.4911 - val_loss: 2.3789 - val_accuracy: 0.3367\n",
      "Epoch 126/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4731 - accuracy: 0.4921 - val_loss: 2.3878 - val_accuracy: 0.3264\n",
      "Epoch 127/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4874 - accuracy: 0.4920 - val_loss: 2.3966 - val_accuracy: 0.3341\n",
      "Epoch 128/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4732 - accuracy: 0.4877 - val_loss: 2.3884 - val_accuracy: 0.3376\n",
      "Epoch 129/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4855 - accuracy: 0.4887 - val_loss: 2.3965 - val_accuracy: 0.3325\n",
      "Epoch 130/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4708 - accuracy: 0.4823 - val_loss: 2.3868 - val_accuracy: 0.3367\n",
      "Epoch 131/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4646 - accuracy: 0.4894 - val_loss: 2.3946 - val_accuracy: 0.3338\n",
      "Epoch 132/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4798 - accuracy: 0.4923 - val_loss: 2.3921 - val_accuracy: 0.3344\n",
      "Epoch 133/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4712 - accuracy: 0.4914 - val_loss: 2.3981 - val_accuracy: 0.3318\n",
      "Epoch 134/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4760 - accuracy: 0.4912 - val_loss: 2.3942 - val_accuracy: 0.3415\n",
      "Epoch 135/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4829 - accuracy: 0.4794 - val_loss: 2.4011 - val_accuracy: 0.3238\n",
      "Epoch 136/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4849 - accuracy: 0.4800 - val_loss: 2.4048 - val_accuracy: 0.3305\n",
      "Epoch 137/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.4629 - accuracy: 0.4970 - val_loss: 2.3981 - val_accuracy: 0.3392\n",
      "Epoch 138/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4663 - accuracy: 0.4921 - val_loss: 2.4091 - val_accuracy: 0.3389\n",
      "Epoch 139/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4647 - accuracy: 0.4915 - val_loss: 2.4106 - val_accuracy: 0.3257\n",
      "Epoch 140/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4650 - accuracy: 0.4957 - val_loss: 2.4127 - val_accuracy: 0.3286\n",
      "Epoch 141/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4645 - accuracy: 0.4941 - val_loss: 2.3916 - val_accuracy: 0.3293\n",
      "Epoch 142/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4699 - accuracy: 0.4943 - val_loss: 2.4000 - val_accuracy: 0.3270\n",
      "Epoch 143/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4732 - accuracy: 0.4893 - val_loss: 2.4167 - val_accuracy: 0.3247\n",
      "Epoch 144/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4672 - accuracy: 0.4927 - val_loss: 2.4113 - val_accuracy: 0.3231\n",
      "Epoch 145/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4687 - accuracy: 0.4902 - val_loss: 2.4185 - val_accuracy: 0.3386\n",
      "Epoch 146/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4598 - accuracy: 0.4997 - val_loss: 2.4232 - val_accuracy: 0.3228\n",
      "Epoch 147/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4465 - accuracy: 0.5002 - val_loss: 2.4275 - val_accuracy: 0.3315\n",
      "Epoch 148/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4633 - accuracy: 0.4902 - val_loss: 2.4373 - val_accuracy: 0.3157\n",
      "Epoch 149/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4446 - accuracy: 0.4946 - val_loss: 2.4343 - val_accuracy: 0.3247\n",
      "Epoch 150/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4497 - accuracy: 0.4944 - val_loss: 2.4256 - val_accuracy: 0.3244\n",
      "Epoch 151/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4455 - accuracy: 0.4933 - val_loss: 2.4308 - val_accuracy: 0.3309\n",
      "Epoch 152/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4426 - accuracy: 0.5023 - val_loss: 2.4365 - val_accuracy: 0.3257\n",
      "Epoch 153/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4502 - accuracy: 0.4985 - val_loss: 2.4430 - val_accuracy: 0.3247\n",
      "Epoch 154/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4473 - accuracy: 0.4948 - val_loss: 2.4331 - val_accuracy: 0.3173\n",
      "Epoch 155/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4535 - accuracy: 0.4923 - val_loss: 2.4183 - val_accuracy: 0.3376\n",
      "Epoch 156/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4619 - accuracy: 0.4955 - val_loss: 2.4318 - val_accuracy: 0.3325\n",
      "Epoch 157/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4452 - accuracy: 0.4954 - val_loss: 2.4308 - val_accuracy: 0.3270\n",
      "Epoch 158/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4450 - accuracy: 0.4926 - val_loss: 2.4218 - val_accuracy: 0.3357\n",
      "Epoch 159/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4384 - accuracy: 0.4972 - val_loss: 2.4312 - val_accuracy: 0.3373\n",
      "Epoch 160/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4370 - accuracy: 0.4990 - val_loss: 2.4405 - val_accuracy: 0.3305\n",
      "Epoch 161/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4493 - accuracy: 0.4998 - val_loss: 2.4561 - val_accuracy: 0.3244\n",
      "Epoch 162/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4378 - accuracy: 0.4992 - val_loss: 2.4413 - val_accuracy: 0.3302\n",
      "Epoch 163/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4284 - accuracy: 0.4974 - val_loss: 2.4524 - val_accuracy: 0.3212\n",
      "Epoch 164/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4492 - accuracy: 0.4995 - val_loss: 2.4393 - val_accuracy: 0.3270\n",
      "Epoch 165/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4342 - accuracy: 0.5029 - val_loss: 2.4375 - val_accuracy: 0.3286\n",
      "Epoch 166/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4483 - accuracy: 0.5011 - val_loss: 2.4542 - val_accuracy: 0.3164\n",
      "Epoch 167/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4391 - accuracy: 0.4983 - val_loss: 2.4505 - val_accuracy: 0.3276\n",
      "Epoch 168/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4365 - accuracy: 0.4979 - val_loss: 2.4381 - val_accuracy: 0.3276\n",
      "Epoch 169/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4541 - accuracy: 0.4826 - val_loss: 2.4399 - val_accuracy: 0.3383\n",
      "Epoch 170/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4410 - accuracy: 0.4968 - val_loss: 2.4625 - val_accuracy: 0.3264\n",
      "Epoch 171/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4368 - accuracy: 0.4957 - val_loss: 2.4559 - val_accuracy: 0.3231\n",
      "Epoch 172/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4172 - accuracy: 0.5043 - val_loss: 2.4578 - val_accuracy: 0.3299\n",
      "Epoch 173/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4213 - accuracy: 0.4982 - val_loss: 2.4690 - val_accuracy: 0.3231\n",
      "Epoch 174/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4346 - accuracy: 0.4969 - val_loss: 2.4549 - val_accuracy: 0.3380\n",
      "Epoch 175/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4364 - accuracy: 0.5020 - val_loss: 2.4600 - val_accuracy: 0.3247\n",
      "Epoch 176/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4452 - accuracy: 0.4929 - val_loss: 2.4674 - val_accuracy: 0.3244\n",
      "Epoch 177/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4432 - accuracy: 0.4901 - val_loss: 2.4464 - val_accuracy: 0.3383\n",
      "Epoch 178/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4275 - accuracy: 0.4917 - val_loss: 2.4676 - val_accuracy: 0.3286\n",
      "Epoch 179/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4095 - accuracy: 0.5069 - val_loss: 2.4755 - val_accuracy: 0.3222\n",
      "Epoch 180/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4413 - accuracy: 0.5019 - val_loss: 2.4655 - val_accuracy: 0.3267\n",
      "Epoch 181/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4137 - accuracy: 0.5071 - val_loss: 2.4616 - val_accuracy: 0.3334\n",
      "Epoch 182/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4141 - accuracy: 0.5007 - val_loss: 2.4658 - val_accuracy: 0.3260\n",
      "Epoch 183/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4297 - accuracy: 0.4992 - val_loss: 2.4519 - val_accuracy: 0.3344\n",
      "Epoch 184/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4348 - accuracy: 0.4962 - val_loss: 2.4754 - val_accuracy: 0.3328\n",
      "Epoch 185/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4174 - accuracy: 0.5100 - val_loss: 2.4717 - val_accuracy: 0.3264\n",
      "Epoch 186/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4300 - accuracy: 0.5012 - val_loss: 2.4711 - val_accuracy: 0.3331\n",
      "Epoch 187/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4179 - accuracy: 0.5051 - val_loss: 2.4884 - val_accuracy: 0.3183\n",
      "Epoch 188/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4274 - accuracy: 0.4993 - val_loss: 2.4690 - val_accuracy: 0.3309\n",
      "Epoch 189/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4239 - accuracy: 0.5000 - val_loss: 2.4825 - val_accuracy: 0.3238\n",
      "Epoch 190/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4144 - accuracy: 0.5081 - val_loss: 2.4848 - val_accuracy: 0.3270\n",
      "Epoch 191/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4153 - accuracy: 0.4946 - val_loss: 2.4763 - val_accuracy: 0.3276\n",
      "Epoch 192/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4294 - accuracy: 0.5011 - val_loss: 2.4704 - val_accuracy: 0.3322\n",
      "Epoch 193/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4137 - accuracy: 0.5050 - val_loss: 2.4855 - val_accuracy: 0.3193\n",
      "Epoch 194/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4256 - accuracy: 0.5005 - val_loss: 2.4799 - val_accuracy: 0.3309\n",
      "Epoch 195/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.5061 - val_loss: 2.4678 - val_accuracy: 0.3280\n",
      "Epoch 196/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4163 - accuracy: 0.5018 - val_loss: 2.4793 - val_accuracy: 0.3247\n",
      "Epoch 197/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4180 - accuracy: 0.4987 - val_loss: 2.4891 - val_accuracy: 0.3231\n",
      "Epoch 198/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4171 - accuracy: 0.5102 - val_loss: 2.4882 - val_accuracy: 0.3218\n",
      "Epoch 199/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4201 - accuracy: 0.4989 - val_loss: 2.4740 - val_accuracy: 0.3354\n",
      "Epoch 200/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3868 - accuracy: 0.5140 - val_loss: 2.4957 - val_accuracy: 0.3189\n",
      "Epoch 201/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4099 - accuracy: 0.5034 - val_loss: 2.4829 - val_accuracy: 0.3241\n",
      "Epoch 202/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4108 - accuracy: 0.4954 - val_loss: 2.4920 - val_accuracy: 0.3238\n",
      "Epoch 203/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4217 - accuracy: 0.4988 - val_loss: 2.4850 - val_accuracy: 0.3251\n",
      "Epoch 204/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.4073 - accuracy: 0.5075 - val_loss: 2.4907 - val_accuracy: 0.3257\n",
      "Epoch 205/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4052 - accuracy: 0.5065 - val_loss: 2.4922 - val_accuracy: 0.3264\n",
      "Epoch 206/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4043 - accuracy: 0.5082 - val_loss: 2.4887 - val_accuracy: 0.3264\n",
      "Epoch 207/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4090 - accuracy: 0.5038 - val_loss: 2.4960 - val_accuracy: 0.3257\n",
      "Epoch 208/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4073 - accuracy: 0.5025 - val_loss: 2.5082 - val_accuracy: 0.3222\n",
      "Epoch 209/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.5077 - val_loss: 2.5032 - val_accuracy: 0.3199\n",
      "Epoch 210/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4083 - accuracy: 0.5045 - val_loss: 2.5075 - val_accuracy: 0.3135\n",
      "Epoch 211/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3919 - accuracy: 0.5032 - val_loss: 2.5045 - val_accuracy: 0.3183\n",
      "Epoch 212/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4069 - accuracy: 0.5012 - val_loss: 2.4989 - val_accuracy: 0.3173\n",
      "Epoch 213/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4158 - accuracy: 0.5052 - val_loss: 2.5054 - val_accuracy: 0.3202\n",
      "Epoch 214/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.5062 - val_loss: 2.5021 - val_accuracy: 0.3222\n",
      "Epoch 215/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4107 - accuracy: 0.4970 - val_loss: 2.5035 - val_accuracy: 0.3235\n",
      "Epoch 216/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3973 - accuracy: 0.5104 - val_loss: 2.5086 - val_accuracy: 0.3241\n",
      "Epoch 217/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4067 - accuracy: 0.5048 - val_loss: 2.5023 - val_accuracy: 0.3222\n",
      "Epoch 218/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4104 - accuracy: 0.4931 - val_loss: 2.5013 - val_accuracy: 0.3302\n",
      "Epoch 219/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4055 - accuracy: 0.5097 - val_loss: 2.5141 - val_accuracy: 0.3222\n",
      "Epoch 220/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4139 - accuracy: 0.5068 - val_loss: 2.5153 - val_accuracy: 0.3199\n",
      "Epoch 221/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.5031 - val_loss: 2.5052 - val_accuracy: 0.3222\n",
      "Epoch 222/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3960 - accuracy: 0.5114 - val_loss: 2.5076 - val_accuracy: 0.3189\n",
      "Epoch 223/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4021 - accuracy: 0.5042 - val_loss: 2.4967 - val_accuracy: 0.3228\n",
      "Epoch 224/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3886 - accuracy: 0.5102 - val_loss: 2.4989 - val_accuracy: 0.3235\n",
      "Epoch 225/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3900 - accuracy: 0.5094 - val_loss: 2.5142 - val_accuracy: 0.3231\n",
      "Epoch 226/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.5077 - val_loss: 2.5086 - val_accuracy: 0.3244\n",
      "Epoch 227/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3973 - accuracy: 0.5002 - val_loss: 2.5011 - val_accuracy: 0.3325\n",
      "Epoch 228/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3916 - accuracy: 0.5109 - val_loss: 2.5034 - val_accuracy: 0.3212\n",
      "Epoch 229/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3917 - accuracy: 0.5065 - val_loss: 2.5133 - val_accuracy: 0.3206\n",
      "Epoch 230/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.5014 - val_loss: 2.5142 - val_accuracy: 0.3251\n",
      "Epoch 231/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3903 - accuracy: 0.5052 - val_loss: 2.5303 - val_accuracy: 0.3196\n",
      "Epoch 232/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3887 - accuracy: 0.5004 - val_loss: 2.5093 - val_accuracy: 0.3267\n",
      "Epoch 233/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3901 - accuracy: 0.5081 - val_loss: 2.5225 - val_accuracy: 0.3231\n",
      "Epoch 234/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4092 - accuracy: 0.5045 - val_loss: 2.5101 - val_accuracy: 0.3247\n",
      "Epoch 235/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3984 - accuracy: 0.5071 - val_loss: 2.5176 - val_accuracy: 0.3206\n",
      "Epoch 236/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3861 - accuracy: 0.5129 - val_loss: 2.5257 - val_accuracy: 0.3151\n",
      "Epoch 237/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3877 - accuracy: 0.5066 - val_loss: 2.5099 - val_accuracy: 0.3225\n",
      "Epoch 238/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3935 - accuracy: 0.5043 - val_loss: 2.5297 - val_accuracy: 0.3164\n",
      "Epoch 239/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3891 - accuracy: 0.5006 - val_loss: 2.5269 - val_accuracy: 0.3180\n",
      "Epoch 240/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3828 - accuracy: 0.5134 - val_loss: 2.5201 - val_accuracy: 0.3202\n",
      "Epoch 241/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4042 - accuracy: 0.4989 - val_loss: 2.5240 - val_accuracy: 0.3199\n",
      "Epoch 242/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3858 - accuracy: 0.5091 - val_loss: 2.5320 - val_accuracy: 0.3189\n",
      "Epoch 243/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.5067 - val_loss: 2.5148 - val_accuracy: 0.3273\n",
      "Epoch 244/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3893 - accuracy: 0.5056 - val_loss: 2.5252 - val_accuracy: 0.3238\n",
      "Epoch 245/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.5060 - val_loss: 2.5222 - val_accuracy: 0.3244\n",
      "Epoch 246/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3771 - accuracy: 0.5194 - val_loss: 2.5290 - val_accuracy: 0.3244\n",
      "Epoch 247/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3819 - accuracy: 0.5081 - val_loss: 2.5433 - val_accuracy: 0.3148\n",
      "Epoch 248/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3769 - accuracy: 0.5119 - val_loss: 2.5450 - val_accuracy: 0.3109\n",
      "Epoch 249/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3901 - accuracy: 0.5017 - val_loss: 2.5416 - val_accuracy: 0.3154\n",
      "Epoch 250/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3903 - accuracy: 0.5051 - val_loss: 2.5462 - val_accuracy: 0.3148\n",
      "Epoch 251/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3859 - accuracy: 0.5096 - val_loss: 2.5500 - val_accuracy: 0.3173\n",
      "Epoch 252/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3857 - accuracy: 0.5070 - val_loss: 2.5328 - val_accuracy: 0.3225\n",
      "Epoch 253/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3987 - accuracy: 0.4984 - val_loss: 2.5403 - val_accuracy: 0.3177\n",
      "Epoch 254/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3817 - accuracy: 0.5089 - val_loss: 2.5312 - val_accuracy: 0.3228\n",
      "Epoch 255/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3861 - accuracy: 0.5161 - val_loss: 2.5405 - val_accuracy: 0.3180\n",
      "Epoch 256/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3789 - accuracy: 0.5129 - val_loss: 2.5280 - val_accuracy: 0.3215\n",
      "Epoch 257/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3896 - accuracy: 0.5118 - val_loss: 2.5421 - val_accuracy: 0.3218\n",
      "Epoch 258/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3740 - accuracy: 0.5091 - val_loss: 2.5349 - val_accuracy: 0.3241\n",
      "Epoch 259/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3769 - accuracy: 0.5136 - val_loss: 2.5436 - val_accuracy: 0.3244\n",
      "Epoch 260/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3976 - accuracy: 0.5049 - val_loss: 2.5452 - val_accuracy: 0.3154\n",
      "Epoch 261/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3864 - accuracy: 0.5141 - val_loss: 2.5468 - val_accuracy: 0.3215\n",
      "Epoch 262/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3792 - accuracy: 0.5097 - val_loss: 2.5332 - val_accuracy: 0.3244\n",
      "Epoch 263/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3914 - accuracy: 0.5008 - val_loss: 2.5454 - val_accuracy: 0.3196\n",
      "Epoch 264/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3756 - accuracy: 0.5165 - val_loss: 2.5282 - val_accuracy: 0.3273\n",
      "Epoch 265/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3786 - accuracy: 0.5156 - val_loss: 2.5521 - val_accuracy: 0.3202\n",
      "Epoch 266/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3824 - accuracy: 0.5176 - val_loss: 2.5409 - val_accuracy: 0.3173\n",
      "Epoch 267/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3645 - accuracy: 0.5226 - val_loss: 2.5572 - val_accuracy: 0.3144\n",
      "Epoch 268/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3743 - accuracy: 0.5116 - val_loss: 2.5461 - val_accuracy: 0.3228\n",
      "Epoch 269/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3858 - accuracy: 0.5084 - val_loss: 2.5489 - val_accuracy: 0.3299\n",
      "Epoch 270/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3803 - accuracy: 0.5101 - val_loss: 2.5491 - val_accuracy: 0.3247\n",
      "Epoch 271/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3804 - accuracy: 0.5078 - val_loss: 2.5530 - val_accuracy: 0.3180\n",
      "Epoch 272/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3963 - accuracy: 0.5113 - val_loss: 2.5400 - val_accuracy: 0.3218\n",
      "Epoch 273/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3891 - accuracy: 0.5113 - val_loss: 2.5482 - val_accuracy: 0.3202\n",
      "Epoch 274/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3579 - accuracy: 0.5204 - val_loss: 2.5484 - val_accuracy: 0.3218\n",
      "Epoch 275/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3824 - accuracy: 0.5129 - val_loss: 2.5479 - val_accuracy: 0.3160\n",
      "Epoch 276/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3799 - accuracy: 0.5072 - val_loss: 2.5483 - val_accuracy: 0.3212\n",
      "Epoch 277/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3759 - accuracy: 0.5138 - val_loss: 2.5506 - val_accuracy: 0.3209\n",
      "Epoch 278/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3683 - accuracy: 0.5191 - val_loss: 2.5460 - val_accuracy: 0.3218\n",
      "Epoch 279/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3772 - accuracy: 0.5131 - val_loss: 2.5633 - val_accuracy: 0.3138\n",
      "Epoch 280/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3749 - accuracy: 0.5095 - val_loss: 2.5431 - val_accuracy: 0.3273\n",
      "Epoch 281/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3734 - accuracy: 0.5087 - val_loss: 2.5366 - val_accuracy: 0.3273\n",
      "Epoch 282/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3646 - accuracy: 0.5126 - val_loss: 2.5528 - val_accuracy: 0.3177\n",
      "Epoch 283/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3810 - accuracy: 0.5080 - val_loss: 2.5552 - val_accuracy: 0.3193\n",
      "Epoch 284/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3870 - accuracy: 0.5102 - val_loss: 2.5463 - val_accuracy: 0.3209\n",
      "Epoch 285/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.5161 - val_loss: 2.5630 - val_accuracy: 0.3189\n",
      "Epoch 286/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3720 - accuracy: 0.5031 - val_loss: 2.5478 - val_accuracy: 0.3215\n",
      "Epoch 287/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3771 - accuracy: 0.5118 - val_loss: 2.5532 - val_accuracy: 0.3206\n",
      "Epoch 288/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3753 - accuracy: 0.5152 - val_loss: 2.5555 - val_accuracy: 0.3160\n",
      "Epoch 289/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3731 - accuracy: 0.5106 - val_loss: 2.5531 - val_accuracy: 0.3144\n",
      "Epoch 290/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3761 - accuracy: 0.5061 - val_loss: 2.5593 - val_accuracy: 0.3164\n",
      "Epoch 291/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3850 - accuracy: 0.5066 - val_loss: 2.5525 - val_accuracy: 0.3264\n",
      "Epoch 292/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3810 - accuracy: 0.5111 - val_loss: 2.5813 - val_accuracy: 0.3096\n",
      "Epoch 293/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3599 - accuracy: 0.5152 - val_loss: 2.5588 - val_accuracy: 0.3154\n",
      "Epoch 294/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3565 - accuracy: 0.5217 - val_loss: 2.5672 - val_accuracy: 0.3164\n",
      "Epoch 295/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3735 - accuracy: 0.5076 - val_loss: 2.5501 - val_accuracy: 0.3235\n",
      "Epoch 296/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3754 - accuracy: 0.5054 - val_loss: 2.5569 - val_accuracy: 0.3131\n",
      "Epoch 297/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3815 - accuracy: 0.5101 - val_loss: 2.5628 - val_accuracy: 0.3125\n",
      "Epoch 298/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3794 - accuracy: 0.5084 - val_loss: 2.5591 - val_accuracy: 0.3160\n",
      "Epoch 299/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3624 - accuracy: 0.5213 - val_loss: 2.5532 - val_accuracy: 0.3186\n",
      "Epoch 300/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3766 - accuracy: 0.4993 - val_loss: 2.5560 - val_accuracy: 0.3215\n",
      "Epoch 301/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3743 - accuracy: 0.5124 - val_loss: 2.5635 - val_accuracy: 0.3167\n",
      "Epoch 302/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3708 - accuracy: 0.5152 - val_loss: 2.5639 - val_accuracy: 0.3189\n",
      "Epoch 303/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3866 - accuracy: 0.5037 - val_loss: 2.5684 - val_accuracy: 0.3193\n",
      "Epoch 304/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3776 - accuracy: 0.5101 - val_loss: 2.5457 - val_accuracy: 0.3293\n",
      "Epoch 305/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3926 - accuracy: 0.5019 - val_loss: 2.5570 - val_accuracy: 0.3193\n",
      "Epoch 306/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3673 - accuracy: 0.5127 - val_loss: 2.5583 - val_accuracy: 0.3189\n",
      "Epoch 307/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.5061 - val_loss: 2.5676 - val_accuracy: 0.3160\n",
      "Epoch 308/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3689 - accuracy: 0.5077 - val_loss: 2.5595 - val_accuracy: 0.3106\n",
      "Epoch 309/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3602 - accuracy: 0.5187 - val_loss: 2.5709 - val_accuracy: 0.3154\n",
      "Epoch 310/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3710 - accuracy: 0.5096 - val_loss: 2.5668 - val_accuracy: 0.3115\n",
      "Epoch 311/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3590 - accuracy: 0.5202 - val_loss: 2.5730 - val_accuracy: 0.3206\n",
      "Epoch 312/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3706 - accuracy: 0.5148 - val_loss: 2.5757 - val_accuracy: 0.3180\n",
      "Epoch 313/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3760 - accuracy: 0.5084 - val_loss: 2.5641 - val_accuracy: 0.3193\n",
      "Epoch 314/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3566 - accuracy: 0.5110 - val_loss: 2.5669 - val_accuracy: 0.3238\n",
      "Epoch 315/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3604 - accuracy: 0.5165 - val_loss: 2.5708 - val_accuracy: 0.3218\n",
      "Epoch 316/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3734 - accuracy: 0.5143 - val_loss: 2.5758 - val_accuracy: 0.3131\n",
      "Epoch 317/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3740 - accuracy: 0.5167 - val_loss: 2.5713 - val_accuracy: 0.3138\n",
      "Epoch 318/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3861 - accuracy: 0.5018 - val_loss: 2.5688 - val_accuracy: 0.3106\n",
      "Epoch 319/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3713 - accuracy: 0.5184 - val_loss: 2.5604 - val_accuracy: 0.3218\n",
      "Epoch 320/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3673 - accuracy: 0.5135 - val_loss: 2.5794 - val_accuracy: 0.3148\n",
      "Epoch 321/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3615 - accuracy: 0.5128 - val_loss: 2.5670 - val_accuracy: 0.3196\n",
      "Epoch 322/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3587 - accuracy: 0.5174 - val_loss: 2.5888 - val_accuracy: 0.3148\n",
      "Epoch 323/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3739 - accuracy: 0.5144 - val_loss: 2.5828 - val_accuracy: 0.3151\n",
      "Epoch 324/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3578 - accuracy: 0.5093 - val_loss: 2.5782 - val_accuracy: 0.3170\n",
      "Epoch 325/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3640 - accuracy: 0.5192 - val_loss: 2.5855 - val_accuracy: 0.3170\n",
      "Epoch 326/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3750 - accuracy: 0.5090 - val_loss: 2.5723 - val_accuracy: 0.3177\n",
      "Epoch 327/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3640 - accuracy: 0.5093 - val_loss: 2.5861 - val_accuracy: 0.3119\n",
      "Epoch 328/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3690 - accuracy: 0.5157 - val_loss: 2.5759 - val_accuracy: 0.3235\n",
      "Epoch 329/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3598 - accuracy: 0.5143 - val_loss: 2.5899 - val_accuracy: 0.3177\n",
      "Epoch 330/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3658 - accuracy: 0.5148 - val_loss: 2.5856 - val_accuracy: 0.3148\n",
      "Epoch 331/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3635 - accuracy: 0.5142 - val_loss: 2.5816 - val_accuracy: 0.3180\n",
      "Epoch 332/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3613 - accuracy: 0.5128 - val_loss: 2.5805 - val_accuracy: 0.3148\n",
      "Epoch 333/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.5152 - val_loss: 2.5759 - val_accuracy: 0.3144\n",
      "Epoch 334/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3561 - accuracy: 0.5186 - val_loss: 2.5801 - val_accuracy: 0.3148\n",
      "Epoch 335/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3455 - accuracy: 0.5272 - val_loss: 2.5851 - val_accuracy: 0.3173\n",
      "Epoch 336/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3548 - accuracy: 0.5200 - val_loss: 2.5840 - val_accuracy: 0.3144\n",
      "Epoch 337/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3683 - accuracy: 0.5117 - val_loss: 2.5825 - val_accuracy: 0.3215\n",
      "Epoch 338/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5173 - val_loss: 2.5814 - val_accuracy: 0.3164\n",
      "Epoch 339/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3623 - accuracy: 0.5149 - val_loss: 2.5902 - val_accuracy: 0.3164\n",
      "Epoch 340/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3362 - accuracy: 0.5229 - val_loss: 2.5825 - val_accuracy: 0.3186\n",
      "Epoch 341/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3590 - accuracy: 0.5141 - val_loss: 2.5933 - val_accuracy: 0.3073\n",
      "Epoch 342/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.5224 - val_loss: 2.5819 - val_accuracy: 0.3196\n",
      "Epoch 343/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3583 - accuracy: 0.5178 - val_loss: 2.5897 - val_accuracy: 0.3167\n",
      "Epoch 344/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3647 - accuracy: 0.5127 - val_loss: 2.5799 - val_accuracy: 0.3148\n",
      "Epoch 345/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3521 - accuracy: 0.5158 - val_loss: 2.5862 - val_accuracy: 0.3183\n",
      "Epoch 346/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3507 - accuracy: 0.5201 - val_loss: 2.5830 - val_accuracy: 0.3157\n",
      "Epoch 347/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3609 - accuracy: 0.5081 - val_loss: 2.5872 - val_accuracy: 0.3202\n",
      "Epoch 348/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3486 - accuracy: 0.5254 - val_loss: 2.5857 - val_accuracy: 0.3215\n",
      "Epoch 349/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3742 - accuracy: 0.5074 - val_loss: 2.5960 - val_accuracy: 0.3099\n",
      "Epoch 350/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3588 - accuracy: 0.5096 - val_loss: 2.5989 - val_accuracy: 0.3112\n",
      "Epoch 351/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3503 - accuracy: 0.5159 - val_loss: 2.5972 - val_accuracy: 0.3119\n",
      "Epoch 352/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3623 - accuracy: 0.5205 - val_loss: 2.6089 - val_accuracy: 0.3125\n",
      "Epoch 353/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3577 - accuracy: 0.5200 - val_loss: 2.5950 - val_accuracy: 0.3154\n",
      "Epoch 354/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.5080 - val_loss: 2.5891 - val_accuracy: 0.3141\n",
      "Epoch 355/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.5176 - val_loss: 2.5866 - val_accuracy: 0.3144\n",
      "Epoch 356/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3440 - accuracy: 0.5185 - val_loss: 2.5882 - val_accuracy: 0.3173\n",
      "Epoch 357/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3573 - accuracy: 0.5143 - val_loss: 2.5752 - val_accuracy: 0.3209\n",
      "Epoch 358/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3577 - accuracy: 0.5132 - val_loss: 2.6003 - val_accuracy: 0.3128\n",
      "Epoch 359/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3462 - accuracy: 0.5231 - val_loss: 2.5889 - val_accuracy: 0.3154\n",
      "Epoch 360/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3510 - accuracy: 0.5112 - val_loss: 2.6008 - val_accuracy: 0.3148\n",
      "Epoch 361/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3480 - accuracy: 0.5147 - val_loss: 2.5872 - val_accuracy: 0.3151\n",
      "Epoch 362/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3545 - accuracy: 0.5209 - val_loss: 2.5888 - val_accuracy: 0.3164\n",
      "Epoch 363/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3439 - accuracy: 0.5255 - val_loss: 2.5990 - val_accuracy: 0.3180\n",
      "Epoch 364/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3579 - accuracy: 0.5082 - val_loss: 2.6057 - val_accuracy: 0.3151\n",
      "Epoch 365/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.5166 - val_loss: 2.5906 - val_accuracy: 0.3202\n",
      "Epoch 366/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3442 - accuracy: 0.5184 - val_loss: 2.6102 - val_accuracy: 0.3128\n",
      "Epoch 367/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5176 - val_loss: 2.6028 - val_accuracy: 0.3138\n",
      "Epoch 368/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3475 - accuracy: 0.5242 - val_loss: 2.6008 - val_accuracy: 0.3144\n",
      "Epoch 369/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3516 - accuracy: 0.5220 - val_loss: 2.6041 - val_accuracy: 0.3141\n",
      "Epoch 370/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3521 - accuracy: 0.5166 - val_loss: 2.6024 - val_accuracy: 0.3189\n",
      "Epoch 371/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3512 - accuracy: 0.5129 - val_loss: 2.6016 - val_accuracy: 0.3115\n",
      "Epoch 372/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3514 - accuracy: 0.5201 - val_loss: 2.5982 - val_accuracy: 0.3186\n",
      "Epoch 373/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3464 - accuracy: 0.5181 - val_loss: 2.5901 - val_accuracy: 0.3189\n",
      "Epoch 374/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3604 - accuracy: 0.5170 - val_loss: 2.6091 - val_accuracy: 0.3138\n",
      "Epoch 375/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3562 - accuracy: 0.5118 - val_loss: 2.5973 - val_accuracy: 0.3122\n",
      "Epoch 376/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3388 - accuracy: 0.5262 - val_loss: 2.6018 - val_accuracy: 0.3109\n",
      "Epoch 377/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.5155 - val_loss: 2.6099 - val_accuracy: 0.3151\n",
      "Epoch 378/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3420 - accuracy: 0.5200 - val_loss: 2.6003 - val_accuracy: 0.3157\n",
      "Epoch 379/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3487 - accuracy: 0.5230 - val_loss: 2.6018 - val_accuracy: 0.3125\n",
      "Epoch 380/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3395 - accuracy: 0.5156 - val_loss: 2.6056 - val_accuracy: 0.3128\n",
      "Epoch 381/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3334 - accuracy: 0.5177 - val_loss: 2.5936 - val_accuracy: 0.3125\n",
      "Epoch 382/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3480 - accuracy: 0.5149 - val_loss: 2.6056 - val_accuracy: 0.3148\n",
      "Epoch 383/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3467 - accuracy: 0.5236 - val_loss: 2.6140 - val_accuracy: 0.3144\n",
      "Epoch 384/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3449 - accuracy: 0.5157 - val_loss: 2.6124 - val_accuracy: 0.3112\n",
      "Epoch 385/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3470 - accuracy: 0.5198 - val_loss: 2.6029 - val_accuracy: 0.3173\n",
      "Epoch 386/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3652 - accuracy: 0.5080 - val_loss: 2.6016 - val_accuracy: 0.3206\n",
      "Epoch 387/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3520 - accuracy: 0.5120 - val_loss: 2.5916 - val_accuracy: 0.3173\n",
      "Epoch 388/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3670 - accuracy: 0.5101 - val_loss: 2.6119 - val_accuracy: 0.3193\n",
      "Epoch 389/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3556 - accuracy: 0.5167 - val_loss: 2.6049 - val_accuracy: 0.3151\n",
      "Epoch 390/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3519 - accuracy: 0.5222 - val_loss: 2.6136 - val_accuracy: 0.3102\n",
      "Epoch 391/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3643 - accuracy: 0.5170 - val_loss: 2.6002 - val_accuracy: 0.3154\n",
      "Epoch 392/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3441 - accuracy: 0.5199 - val_loss: 2.6114 - val_accuracy: 0.3128\n",
      "Epoch 393/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3321 - accuracy: 0.5257 - val_loss: 2.5948 - val_accuracy: 0.3112\n",
      "Epoch 394/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3436 - accuracy: 0.5164 - val_loss: 2.6164 - val_accuracy: 0.3135\n",
      "Epoch 395/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.5226 - val_loss: 2.6227 - val_accuracy: 0.3138\n",
      "Epoch 396/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3449 - accuracy: 0.5151 - val_loss: 2.6149 - val_accuracy: 0.3080\n",
      "Epoch 397/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3398 - accuracy: 0.5201 - val_loss: 2.6146 - val_accuracy: 0.3160\n",
      "Epoch 398/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3325 - accuracy: 0.5191 - val_loss: 2.6172 - val_accuracy: 0.3119\n",
      "Epoch 399/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3503 - accuracy: 0.5213 - val_loss: 2.6140 - val_accuracy: 0.3170\n",
      "Epoch 400/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3566 - accuracy: 0.5089 - val_loss: 2.6181 - val_accuracy: 0.3112\n",
      "Epoch 401/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3495 - accuracy: 0.5165 - val_loss: 2.6060 - val_accuracy: 0.3167\n",
      "Epoch 402/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3352 - accuracy: 0.5207 - val_loss: 2.6306 - val_accuracy: 0.3057\n",
      "Epoch 403/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3367 - accuracy: 0.5199 - val_loss: 2.6266 - val_accuracy: 0.3122\n",
      "Epoch 404/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.5101 - val_loss: 2.6137 - val_accuracy: 0.3196\n",
      "Epoch 405/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3497 - accuracy: 0.5200 - val_loss: 2.6158 - val_accuracy: 0.3151\n",
      "Epoch 406/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3431 - accuracy: 0.5195 - val_loss: 2.6255 - val_accuracy: 0.3173\n",
      "Epoch 407/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3342 - accuracy: 0.5202 - val_loss: 2.6188 - val_accuracy: 0.3102\n",
      "Epoch 408/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3422 - accuracy: 0.5262 - val_loss: 2.6320 - val_accuracy: 0.3096\n",
      "Epoch 409/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3482 - accuracy: 0.5200 - val_loss: 2.6221 - val_accuracy: 0.3080\n",
      "Epoch 410/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3253 - accuracy: 0.5276 - val_loss: 2.6129 - val_accuracy: 0.3160\n",
      "Epoch 411/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3446 - accuracy: 0.5215 - val_loss: 2.6149 - val_accuracy: 0.3164\n",
      "Epoch 412/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3483 - accuracy: 0.5153 - val_loss: 2.6125 - val_accuracy: 0.3151\n",
      "Epoch 413/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3458 - accuracy: 0.5215 - val_loss: 2.6152 - val_accuracy: 0.3151\n",
      "Epoch 414/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3235 - accuracy: 0.5232 - val_loss: 2.6244 - val_accuracy: 0.3135\n",
      "Epoch 415/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3432 - accuracy: 0.5154 - val_loss: 2.6214 - val_accuracy: 0.3141\n",
      "Epoch 416/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3401 - accuracy: 0.5226 - val_loss: 2.6147 - val_accuracy: 0.3170\n",
      "Epoch 417/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3476 - accuracy: 0.5123 - val_loss: 2.6193 - val_accuracy: 0.3122\n",
      "Epoch 418/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3500 - accuracy: 0.5193 - val_loss: 2.6331 - val_accuracy: 0.3102\n",
      "Epoch 419/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3435 - accuracy: 0.5173 - val_loss: 2.6312 - val_accuracy: 0.3157\n",
      "Epoch 420/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3504 - accuracy: 0.5184 - val_loss: 2.6144 - val_accuracy: 0.3180\n",
      "Epoch 421/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3448 - accuracy: 0.5161 - val_loss: 2.6214 - val_accuracy: 0.3138\n",
      "Epoch 422/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.5185 - val_loss: 2.6208 - val_accuracy: 0.3131\n",
      "Epoch 423/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3470 - accuracy: 0.5171 - val_loss: 2.6425 - val_accuracy: 0.3112\n",
      "Epoch 424/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3286 - accuracy: 0.5210 - val_loss: 2.6352 - val_accuracy: 0.3177\n",
      "Epoch 425/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3436 - accuracy: 0.5174 - val_loss: 2.6272 - val_accuracy: 0.3144\n",
      "Epoch 426/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.5265 - val_loss: 2.6293 - val_accuracy: 0.3148\n",
      "Epoch 427/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3359 - accuracy: 0.5130 - val_loss: 2.6351 - val_accuracy: 0.3109\n",
      "Epoch 428/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3404 - accuracy: 0.5214 - val_loss: 2.6352 - val_accuracy: 0.3115\n",
      "Epoch 429/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3308 - accuracy: 0.5246 - val_loss: 2.6304 - val_accuracy: 0.3128\n",
      "Epoch 430/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.5292 - val_loss: 2.6267 - val_accuracy: 0.3157\n",
      "Epoch 431/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3352 - accuracy: 0.5218 - val_loss: 2.6292 - val_accuracy: 0.3167\n",
      "Epoch 432/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3502 - accuracy: 0.5195 - val_loss: 2.6220 - val_accuracy: 0.3157\n",
      "Epoch 433/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3357 - accuracy: 0.5147 - val_loss: 2.6219 - val_accuracy: 0.3164\n",
      "Epoch 434/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3400 - accuracy: 0.5250 - val_loss: 2.6268 - val_accuracy: 0.3154\n",
      "Epoch 435/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3301 - accuracy: 0.5206 - val_loss: 2.6336 - val_accuracy: 0.3112\n",
      "Epoch 436/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3296 - accuracy: 0.5293 - val_loss: 2.6309 - val_accuracy: 0.3083\n",
      "Epoch 437/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3411 - accuracy: 0.5194 - val_loss: 2.6327 - val_accuracy: 0.3122\n",
      "Epoch 438/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3330 - accuracy: 0.5135 - val_loss: 2.6228 - val_accuracy: 0.3131\n",
      "Epoch 439/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3360 - accuracy: 0.5163 - val_loss: 2.6256 - val_accuracy: 0.3151\n",
      "Epoch 440/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3398 - accuracy: 0.5084 - val_loss: 2.6331 - val_accuracy: 0.3112\n",
      "Epoch 441/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3187 - accuracy: 0.5295 - val_loss: 2.6405 - val_accuracy: 0.3112\n",
      "Epoch 442/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3321 - accuracy: 0.5232 - val_loss: 2.6360 - val_accuracy: 0.3138\n",
      "Epoch 443/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3407 - accuracy: 0.5194 - val_loss: 2.6396 - val_accuracy: 0.3177\n",
      "Epoch 444/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3347 - accuracy: 0.5138 - val_loss: 2.6223 - val_accuracy: 0.3202\n",
      "Epoch 445/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3425 - accuracy: 0.5204 - val_loss: 2.6359 - val_accuracy: 0.3154\n",
      "Epoch 446/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.5123 - val_loss: 2.6312 - val_accuracy: 0.3177\n",
      "Epoch 447/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3369 - accuracy: 0.5202 - val_loss: 2.6394 - val_accuracy: 0.3099\n",
      "Epoch 448/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3379 - accuracy: 0.5181 - val_loss: 2.6280 - val_accuracy: 0.3154\n",
      "Epoch 449/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3342 - accuracy: 0.5190 - val_loss: 2.6456 - val_accuracy: 0.3112\n",
      "Epoch 450/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3434 - accuracy: 0.5199 - val_loss: 2.6386 - val_accuracy: 0.3164\n",
      "Epoch 451/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3507 - accuracy: 0.5094 - val_loss: 2.6388 - val_accuracy: 0.3167\n",
      "Epoch 452/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3328 - accuracy: 0.5246 - val_loss: 2.6342 - val_accuracy: 0.3151\n",
      "Epoch 453/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3212 - accuracy: 0.5262 - val_loss: 2.6412 - val_accuracy: 0.3131\n",
      "Epoch 454/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3385 - accuracy: 0.5186 - val_loss: 2.6392 - val_accuracy: 0.3154\n",
      "Epoch 455/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3335 - accuracy: 0.5218 - val_loss: 2.6424 - val_accuracy: 0.3177\n",
      "Epoch 456/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3376 - accuracy: 0.5260 - val_loss: 2.6424 - val_accuracy: 0.3196\n",
      "Epoch 457/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5254 - val_loss: 2.6410 - val_accuracy: 0.3106\n",
      "Epoch 458/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.5222 - val_loss: 2.6436 - val_accuracy: 0.3189\n",
      "Epoch 459/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3393 - accuracy: 0.5133 - val_loss: 2.6404 - val_accuracy: 0.3119\n",
      "Epoch 460/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3419 - accuracy: 0.5181 - val_loss: 2.6362 - val_accuracy: 0.3125\n",
      "Epoch 461/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.5256 - val_loss: 2.6426 - val_accuracy: 0.3119\n",
      "Epoch 462/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3470 - accuracy: 0.5150 - val_loss: 2.6476 - val_accuracy: 0.3109\n",
      "Epoch 463/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3395 - accuracy: 0.5137 - val_loss: 2.6325 - val_accuracy: 0.3099\n",
      "Epoch 464/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3302 - accuracy: 0.5205 - val_loss: 2.6300 - val_accuracy: 0.3122\n",
      "Epoch 465/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3404 - accuracy: 0.5262 - val_loss: 2.6306 - val_accuracy: 0.3138\n",
      "Epoch 466/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3190 - accuracy: 0.5240 - val_loss: 2.6385 - val_accuracy: 0.3167\n",
      "Epoch 467/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3428 - accuracy: 0.5172 - val_loss: 2.6436 - val_accuracy: 0.3131\n",
      "Epoch 468/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3409 - accuracy: 0.5234 - val_loss: 2.6415 - val_accuracy: 0.3135\n",
      "Epoch 469/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3378 - accuracy: 0.5190 - val_loss: 2.6462 - val_accuracy: 0.3154\n",
      "Epoch 470/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3350 - accuracy: 0.5202 - val_loss: 2.6386 - val_accuracy: 0.3148\n",
      "Epoch 471/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3474 - accuracy: 0.5179 - val_loss: 2.6459 - val_accuracy: 0.3154\n",
      "Epoch 472/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3331 - accuracy: 0.5143 - val_loss: 2.6644 - val_accuracy: 0.3048\n",
      "Epoch 473/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3407 - accuracy: 0.5222 - val_loss: 2.6391 - val_accuracy: 0.3083\n",
      "Epoch 474/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3299 - accuracy: 0.5249 - val_loss: 2.6445 - val_accuracy: 0.3170\n",
      "Epoch 475/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3310 - accuracy: 0.5193 - val_loss: 2.6423 - val_accuracy: 0.3112\n",
      "Epoch 476/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3412 - accuracy: 0.5210 - val_loss: 2.6495 - val_accuracy: 0.3083\n",
      "Epoch 477/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3234 - accuracy: 0.5215 - val_loss: 2.6404 - val_accuracy: 0.3154\n",
      "Epoch 478/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3268 - accuracy: 0.5235 - val_loss: 2.6346 - val_accuracy: 0.3177\n",
      "Epoch 479/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3272 - accuracy: 0.5241 - val_loss: 2.6467 - val_accuracy: 0.3090\n",
      "Epoch 480/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3492 - accuracy: 0.5136 - val_loss: 2.6479 - val_accuracy: 0.3125\n",
      "Epoch 481/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3258 - accuracy: 0.5204 - val_loss: 2.6484 - val_accuracy: 0.3099\n",
      "Epoch 482/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3312 - accuracy: 0.5247 - val_loss: 2.6479 - val_accuracy: 0.3115\n",
      "Epoch 483/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3217 - accuracy: 0.5220 - val_loss: 2.6576 - val_accuracy: 0.3090\n",
      "Epoch 484/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3416 - accuracy: 0.5160 - val_loss: 2.6464 - val_accuracy: 0.3141\n",
      "Epoch 485/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3204 - accuracy: 0.5235 - val_loss: 2.6498 - val_accuracy: 0.3131\n",
      "Epoch 486/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3279 - accuracy: 0.5247 - val_loss: 2.6573 - val_accuracy: 0.3115\n",
      "Epoch 487/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3337 - accuracy: 0.5153 - val_loss: 2.6530 - val_accuracy: 0.3193\n",
      "Epoch 488/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3394 - accuracy: 0.5221 - val_loss: 2.6590 - val_accuracy: 0.3125\n",
      "Epoch 489/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3424 - accuracy: 0.5166 - val_loss: 2.6614 - val_accuracy: 0.3125\n",
      "Epoch 490/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3283 - accuracy: 0.5205 - val_loss: 2.6647 - val_accuracy: 0.3099\n",
      "Epoch 491/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3296 - accuracy: 0.5269 - val_loss: 2.6631 - val_accuracy: 0.3077\n",
      "Epoch 492/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3191 - accuracy: 0.5173 - val_loss: 2.6502 - val_accuracy: 0.3141\n",
      "Epoch 493/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3334 - accuracy: 0.5237 - val_loss: 2.6483 - val_accuracy: 0.3128\n",
      "Epoch 494/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3303 - accuracy: 0.5226 - val_loss: 2.6470 - val_accuracy: 0.3115\n",
      "Epoch 495/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3160 - accuracy: 0.5137 - val_loss: 2.6425 - val_accuracy: 0.3106\n",
      "Epoch 496/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3381 - accuracy: 0.5132 - val_loss: 2.6398 - val_accuracy: 0.3131\n",
      "Epoch 497/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3325 - accuracy: 0.5207 - val_loss: 2.6430 - val_accuracy: 0.3180\n",
      "Epoch 498/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3362 - accuracy: 0.5193 - val_loss: 2.6417 - val_accuracy: 0.3154\n",
      "Epoch 499/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3165 - accuracy: 0.5257 - val_loss: 2.6738 - val_accuracy: 0.3106\n",
      "Epoch 500/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3281 - accuracy: 0.5222 - val_loss: 2.6536 - val_accuracy: 0.3135\n",
      "Epoch 501/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3310 - accuracy: 0.5161 - val_loss: 2.6583 - val_accuracy: 0.3177\n",
      "Epoch 502/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3218 - accuracy: 0.5221 - val_loss: 2.6556 - val_accuracy: 0.3157\n",
      "Epoch 503/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3248 - accuracy: 0.5208 - val_loss: 2.6580 - val_accuracy: 0.3106\n",
      "Epoch 504/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3182 - accuracy: 0.5205 - val_loss: 2.6661 - val_accuracy: 0.3109\n",
      "Epoch 505/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3334 - accuracy: 0.5221 - val_loss: 2.6559 - val_accuracy: 0.3128\n",
      "Epoch 506/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3258 - accuracy: 0.5229 - val_loss: 2.6705 - val_accuracy: 0.3122\n",
      "Epoch 507/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.5286 - val_loss: 2.6713 - val_accuracy: 0.3112\n",
      "Epoch 508/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3470 - accuracy: 0.5050 - val_loss: 2.6591 - val_accuracy: 0.3141\n",
      "Epoch 509/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3154 - accuracy: 0.5259 - val_loss: 2.6615 - val_accuracy: 0.3122\n",
      "Epoch 510/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3211 - accuracy: 0.5221 - val_loss: 2.6541 - val_accuracy: 0.3160\n",
      "Epoch 511/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3310 - accuracy: 0.5150 - val_loss: 2.6533 - val_accuracy: 0.3096\n",
      "Epoch 512/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3262 - accuracy: 0.5184 - val_loss: 2.6644 - val_accuracy: 0.3090\n",
      "Epoch 513/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3331 - accuracy: 0.5174 - val_loss: 2.6526 - val_accuracy: 0.3151\n",
      "Epoch 514/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3279 - accuracy: 0.5251 - val_loss: 2.6551 - val_accuracy: 0.3109\n",
      "Epoch 515/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3368 - accuracy: 0.5180 - val_loss: 2.6557 - val_accuracy: 0.3141\n",
      "Epoch 516/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3278 - accuracy: 0.5107 - val_loss: 2.6610 - val_accuracy: 0.3102\n",
      "Epoch 517/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3381 - accuracy: 0.5175 - val_loss: 2.6626 - val_accuracy: 0.3109\n",
      "Epoch 518/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3213 - accuracy: 0.5248 - val_loss: 2.6671 - val_accuracy: 0.3090\n",
      "Epoch 519/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3262 - accuracy: 0.5194 - val_loss: 2.6636 - val_accuracy: 0.3125\n",
      "Epoch 520/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3310 - accuracy: 0.5152 - val_loss: 2.6589 - val_accuracy: 0.3151\n",
      "Epoch 521/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3353 - accuracy: 0.5151 - val_loss: 2.6689 - val_accuracy: 0.3090\n",
      "Epoch 522/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3283 - accuracy: 0.5223 - val_loss: 2.6712 - val_accuracy: 0.3102\n",
      "Epoch 523/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3180 - accuracy: 0.5299 - val_loss: 2.6675 - val_accuracy: 0.3106\n",
      "Epoch 524/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3187 - accuracy: 0.5250 - val_loss: 2.6662 - val_accuracy: 0.3148\n",
      "Epoch 525/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3245 - accuracy: 0.5149 - val_loss: 2.6756 - val_accuracy: 0.3122\n",
      "Epoch 526/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3271 - accuracy: 0.5202 - val_loss: 2.6680 - val_accuracy: 0.3180\n",
      "Epoch 527/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3413 - accuracy: 0.5137 - val_loss: 2.6762 - val_accuracy: 0.3154\n",
      "Epoch 528/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3299 - accuracy: 0.5199 - val_loss: 2.6668 - val_accuracy: 0.3180\n",
      "Epoch 529/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3261 - accuracy: 0.5135 - val_loss: 2.6708 - val_accuracy: 0.3131\n",
      "Epoch 530/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3305 - accuracy: 0.5223 - val_loss: 2.6692 - val_accuracy: 0.3206\n",
      "Epoch 531/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3217 - accuracy: 0.5213 - val_loss: 2.6740 - val_accuracy: 0.3119\n",
      "Epoch 532/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3421 - accuracy: 0.5076 - val_loss: 2.6763 - val_accuracy: 0.3157\n",
      "Epoch 533/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3264 - accuracy: 0.5221 - val_loss: 2.6741 - val_accuracy: 0.3025\n",
      "Epoch 534/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3344 - accuracy: 0.5145 - val_loss: 2.6682 - val_accuracy: 0.3119\n",
      "Epoch 535/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3260 - accuracy: 0.5163 - val_loss: 2.6723 - val_accuracy: 0.3096\n",
      "Epoch 536/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3246 - accuracy: 0.5241 - val_loss: 2.6719 - val_accuracy: 0.3131\n",
      "Epoch 537/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3202 - accuracy: 0.5242 - val_loss: 2.6724 - val_accuracy: 0.3151\n",
      "Epoch 538/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3378 - accuracy: 0.5209 - val_loss: 2.6860 - val_accuracy: 0.3138\n",
      "Epoch 539/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3235 - accuracy: 0.5195 - val_loss: 2.6866 - val_accuracy: 0.3048\n",
      "Epoch 540/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3073 - accuracy: 0.5285 - val_loss: 2.6793 - val_accuracy: 0.3096\n",
      "Epoch 541/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.5134 - val_loss: 2.6742 - val_accuracy: 0.3154\n",
      "Epoch 542/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3112 - accuracy: 0.5217 - val_loss: 2.6707 - val_accuracy: 0.3067\n",
      "Epoch 543/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3229 - accuracy: 0.5202 - val_loss: 2.6684 - val_accuracy: 0.3151\n",
      "Epoch 544/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3213 - accuracy: 0.5216 - val_loss: 2.6696 - val_accuracy: 0.3173\n",
      "Epoch 545/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3221 - accuracy: 0.5221 - val_loss: 2.6704 - val_accuracy: 0.3144\n",
      "Epoch 546/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3286 - accuracy: 0.5101 - val_loss: 2.6727 - val_accuracy: 0.3122\n",
      "Epoch 547/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3344 - accuracy: 0.5254 - val_loss: 2.6730 - val_accuracy: 0.3125\n",
      "Epoch 548/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3208 - accuracy: 0.5302 - val_loss: 2.6950 - val_accuracy: 0.3093\n",
      "Epoch 549/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3432 - accuracy: 0.5128 - val_loss: 2.6691 - val_accuracy: 0.3164\n",
      "Epoch 550/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3219 - accuracy: 0.5171 - val_loss: 2.6860 - val_accuracy: 0.3144\n",
      "Epoch 551/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3131 - accuracy: 0.5269 - val_loss: 2.6795 - val_accuracy: 0.3125\n",
      "Epoch 552/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3258 - accuracy: 0.5287 - val_loss: 2.6813 - val_accuracy: 0.3128\n",
      "Epoch 553/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3235 - accuracy: 0.5240 - val_loss: 2.6815 - val_accuracy: 0.3183\n",
      "Epoch 554/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3242 - accuracy: 0.5225 - val_loss: 2.6866 - val_accuracy: 0.3106\n",
      "Epoch 555/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3222 - accuracy: 0.5178 - val_loss: 2.6762 - val_accuracy: 0.3183\n",
      "Epoch 556/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3302 - accuracy: 0.5161 - val_loss: 2.6755 - val_accuracy: 0.3077\n",
      "Epoch 557/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3143 - accuracy: 0.5325 - val_loss: 2.6759 - val_accuracy: 0.3141\n",
      "Epoch 558/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3241 - accuracy: 0.5199 - val_loss: 2.6860 - val_accuracy: 0.3080\n",
      "Epoch 559/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3272 - accuracy: 0.5239 - val_loss: 2.6811 - val_accuracy: 0.3138\n",
      "Epoch 560/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3158 - accuracy: 0.5217 - val_loss: 2.6834 - val_accuracy: 0.3164\n",
      "Epoch 561/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3303 - accuracy: 0.5216 - val_loss: 2.6731 - val_accuracy: 0.3141\n",
      "Epoch 562/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5277 - val_loss: 2.6697 - val_accuracy: 0.3151\n",
      "Epoch 563/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3191 - accuracy: 0.5258 - val_loss: 2.6755 - val_accuracy: 0.3141\n",
      "Epoch 564/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3222 - accuracy: 0.5217 - val_loss: 2.6787 - val_accuracy: 0.3080\n",
      "Epoch 565/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3206 - accuracy: 0.5218 - val_loss: 2.6746 - val_accuracy: 0.3141\n",
      "Epoch 566/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3143 - accuracy: 0.5259 - val_loss: 2.6646 - val_accuracy: 0.3202\n",
      "Epoch 567/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3195 - accuracy: 0.5228 - val_loss: 2.6808 - val_accuracy: 0.3099\n",
      "Epoch 568/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3374 - accuracy: 0.5139 - val_loss: 2.6802 - val_accuracy: 0.3144\n",
      "Epoch 569/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3123 - accuracy: 0.5258 - val_loss: 2.6741 - val_accuracy: 0.3164\n",
      "Epoch 570/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3091 - accuracy: 0.5237 - val_loss: 2.6879 - val_accuracy: 0.3096\n",
      "Epoch 571/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3130 - accuracy: 0.5283 - val_loss: 2.6848 - val_accuracy: 0.3180\n",
      "Epoch 572/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3231 - accuracy: 0.5168 - val_loss: 2.6772 - val_accuracy: 0.3141\n",
      "Epoch 573/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3332 - accuracy: 0.5156 - val_loss: 2.6770 - val_accuracy: 0.3119\n",
      "Epoch 574/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3198 - accuracy: 0.5210 - val_loss: 2.6796 - val_accuracy: 0.3090\n",
      "Epoch 575/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5197 - val_loss: 2.6819 - val_accuracy: 0.3144\n",
      "Epoch 576/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3180 - accuracy: 0.5265 - val_loss: 2.6876 - val_accuracy: 0.3128\n",
      "Epoch 577/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3175 - accuracy: 0.5145 - val_loss: 2.6833 - val_accuracy: 0.3090\n",
      "Epoch 578/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3225 - accuracy: 0.5212 - val_loss: 2.6885 - val_accuracy: 0.3093\n",
      "Epoch 579/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5294 - val_loss: 2.6849 - val_accuracy: 0.3102\n",
      "Epoch 580/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3112 - accuracy: 0.5267 - val_loss: 2.6884 - val_accuracy: 0.3083\n",
      "Epoch 581/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.5144 - val_loss: 2.6835 - val_accuracy: 0.3138\n",
      "Epoch 582/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3248 - accuracy: 0.5151 - val_loss: 2.6923 - val_accuracy: 0.3106\n",
      "Epoch 583/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3188 - accuracy: 0.5275 - val_loss: 2.6989 - val_accuracy: 0.3109\n",
      "Epoch 584/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3362 - accuracy: 0.5140 - val_loss: 2.6929 - val_accuracy: 0.3148\n",
      "Epoch 585/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3268 - accuracy: 0.5162 - val_loss: 2.6801 - val_accuracy: 0.3141\n",
      "Epoch 586/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3336 - accuracy: 0.5170 - val_loss: 2.6900 - val_accuracy: 0.3080\n",
      "Epoch 587/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3317 - accuracy: 0.5255 - val_loss: 2.6712 - val_accuracy: 0.3199\n",
      "Epoch 588/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3209 - accuracy: 0.5223 - val_loss: 2.6948 - val_accuracy: 0.3083\n",
      "Epoch 589/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3171 - accuracy: 0.5165 - val_loss: 2.6751 - val_accuracy: 0.3144\n",
      "Epoch 590/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.5213 - val_loss: 2.6940 - val_accuracy: 0.3093\n",
      "Epoch 591/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3215 - accuracy: 0.5189 - val_loss: 2.6854 - val_accuracy: 0.3115\n",
      "Epoch 592/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3097 - accuracy: 0.5264 - val_loss: 2.6767 - val_accuracy: 0.3141\n",
      "Epoch 593/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5203 - val_loss: 2.6884 - val_accuracy: 0.3106\n",
      "Epoch 594/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.5216 - val_loss: 2.6850 - val_accuracy: 0.3102\n",
      "Epoch 595/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3203 - accuracy: 0.5231 - val_loss: 2.6885 - val_accuracy: 0.3119\n",
      "Epoch 596/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3243 - accuracy: 0.5166 - val_loss: 2.6849 - val_accuracy: 0.3141\n",
      "Epoch 597/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3133 - accuracy: 0.5226 - val_loss: 2.6844 - val_accuracy: 0.3093\n",
      "Epoch 598/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3323 - accuracy: 0.5214 - val_loss: 2.6946 - val_accuracy: 0.3128\n",
      "Epoch 599/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3360 - accuracy: 0.5167 - val_loss: 2.6788 - val_accuracy: 0.3222\n",
      "Epoch 600/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3124 - accuracy: 0.5202 - val_loss: 2.6832 - val_accuracy: 0.3160\n",
      "Epoch 601/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3251 - accuracy: 0.5188 - val_loss: 2.6817 - val_accuracy: 0.3170\n",
      "Epoch 602/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3121 - accuracy: 0.5316 - val_loss: 2.6938 - val_accuracy: 0.3109\n",
      "Epoch 603/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3107 - accuracy: 0.5295 - val_loss: 2.6912 - val_accuracy: 0.3109\n",
      "Epoch 604/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3111 - accuracy: 0.5251 - val_loss: 2.6995 - val_accuracy: 0.3086\n",
      "Epoch 605/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3160 - accuracy: 0.5272 - val_loss: 2.6977 - val_accuracy: 0.3128\n",
      "Epoch 606/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3317 - accuracy: 0.5233 - val_loss: 2.6940 - val_accuracy: 0.3067\n",
      "Epoch 607/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3249 - accuracy: 0.5198 - val_loss: 2.6937 - val_accuracy: 0.3131\n",
      "Epoch 608/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.5153 - val_loss: 2.6816 - val_accuracy: 0.3141\n",
      "Epoch 609/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3286 - accuracy: 0.5195 - val_loss: 2.6805 - val_accuracy: 0.3115\n",
      "Epoch 610/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5234 - val_loss: 2.6847 - val_accuracy: 0.3167\n",
      "Epoch 611/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3215 - accuracy: 0.5224 - val_loss: 2.6902 - val_accuracy: 0.3131\n",
      "Epoch 612/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3275 - accuracy: 0.5240 - val_loss: 2.6910 - val_accuracy: 0.3148\n",
      "Epoch 613/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3159 - accuracy: 0.5265 - val_loss: 2.6938 - val_accuracy: 0.3128\n",
      "Epoch 614/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3209 - accuracy: 0.5145 - val_loss: 2.7012 - val_accuracy: 0.3077\n",
      "Epoch 615/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3056 - accuracy: 0.5214 - val_loss: 2.6927 - val_accuracy: 0.3160\n",
      "Epoch 616/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3269 - accuracy: 0.5196 - val_loss: 2.6893 - val_accuracy: 0.3164\n",
      "Epoch 617/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5291 - val_loss: 2.6960 - val_accuracy: 0.3144\n",
      "Epoch 618/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3070 - accuracy: 0.5314 - val_loss: 2.7011 - val_accuracy: 0.3125\n",
      "Epoch 619/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3044 - accuracy: 0.5192 - val_loss: 2.6885 - val_accuracy: 0.3128\n",
      "Epoch 620/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3133 - accuracy: 0.5273 - val_loss: 2.6952 - val_accuracy: 0.3067\n",
      "Epoch 621/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3108 - accuracy: 0.5243 - val_loss: 2.7084 - val_accuracy: 0.3041\n",
      "Epoch 622/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3208 - accuracy: 0.5221 - val_loss: 2.7075 - val_accuracy: 0.3099\n",
      "Epoch 623/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3276 - accuracy: 0.5168 - val_loss: 2.6994 - val_accuracy: 0.3090\n",
      "Epoch 624/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.5148 - val_loss: 2.6989 - val_accuracy: 0.3112\n",
      "Epoch 625/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3207 - accuracy: 0.5180 - val_loss: 2.7209 - val_accuracy: 0.3077\n",
      "Epoch 626/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3201 - accuracy: 0.5192 - val_loss: 2.7017 - val_accuracy: 0.3090\n",
      "Epoch 627/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3149 - accuracy: 0.5238 - val_loss: 2.7082 - val_accuracy: 0.3119\n",
      "Epoch 628/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.5284 - val_loss: 2.6928 - val_accuracy: 0.3109\n",
      "Epoch 629/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3206 - accuracy: 0.5249 - val_loss: 2.6990 - val_accuracy: 0.3167\n",
      "Epoch 630/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3189 - accuracy: 0.5230 - val_loss: 2.7082 - val_accuracy: 0.3090\n",
      "Epoch 631/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5250 - val_loss: 2.7236 - val_accuracy: 0.3093\n",
      "Epoch 632/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.5199 - val_loss: 2.7110 - val_accuracy: 0.3170\n",
      "Epoch 633/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3110 - accuracy: 0.5222 - val_loss: 2.7072 - val_accuracy: 0.3057\n",
      "Epoch 634/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3160 - accuracy: 0.5171 - val_loss: 2.6977 - val_accuracy: 0.3144\n",
      "Epoch 635/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3093 - accuracy: 0.5246 - val_loss: 2.7103 - val_accuracy: 0.3128\n",
      "Epoch 636/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3233 - accuracy: 0.5127 - val_loss: 2.7048 - val_accuracy: 0.3125\n",
      "Epoch 637/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3160 - accuracy: 0.5153 - val_loss: 2.7051 - val_accuracy: 0.3102\n",
      "Epoch 638/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3217 - accuracy: 0.5156 - val_loss: 2.7028 - val_accuracy: 0.3109\n",
      "Epoch 639/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3322 - accuracy: 0.5144 - val_loss: 2.6939 - val_accuracy: 0.3164\n",
      "Epoch 640/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3124 - accuracy: 0.5195 - val_loss: 2.7043 - val_accuracy: 0.3067\n",
      "Epoch 641/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5247 - val_loss: 2.7083 - val_accuracy: 0.3148\n",
      "Epoch 642/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.5210 - val_loss: 2.7024 - val_accuracy: 0.3154\n",
      "Epoch 643/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3248 - accuracy: 0.5203 - val_loss: 2.7055 - val_accuracy: 0.3119\n",
      "Epoch 644/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2984 - accuracy: 0.5286 - val_loss: 2.7042 - val_accuracy: 0.3119\n",
      "Epoch 645/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3190 - accuracy: 0.5144 - val_loss: 2.6985 - val_accuracy: 0.3115\n",
      "Epoch 646/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3085 - accuracy: 0.5265 - val_loss: 2.7198 - val_accuracy: 0.3106\n",
      "Epoch 647/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3309 - accuracy: 0.5242 - val_loss: 2.7023 - val_accuracy: 0.3112\n",
      "Epoch 648/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3378 - accuracy: 0.5124 - val_loss: 2.6968 - val_accuracy: 0.3180\n",
      "Epoch 649/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3269 - accuracy: 0.5223 - val_loss: 2.7056 - val_accuracy: 0.3131\n",
      "Epoch 650/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3212 - accuracy: 0.5165 - val_loss: 2.6960 - val_accuracy: 0.3115\n",
      "Epoch 651/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3183 - accuracy: 0.5146 - val_loss: 2.7012 - val_accuracy: 0.3061\n",
      "Epoch 652/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3123 - accuracy: 0.5247 - val_loss: 2.7047 - val_accuracy: 0.3119\n",
      "Epoch 653/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3148 - accuracy: 0.5208 - val_loss: 2.7052 - val_accuracy: 0.3122\n",
      "Epoch 654/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3225 - accuracy: 0.5149 - val_loss: 2.7156 - val_accuracy: 0.3090\n",
      "Epoch 655/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3067 - accuracy: 0.5263 - val_loss: 2.6979 - val_accuracy: 0.3177\n",
      "Epoch 656/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3092 - accuracy: 0.5197 - val_loss: 2.6939 - val_accuracy: 0.3164\n",
      "Epoch 657/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3301 - accuracy: 0.5151 - val_loss: 2.7065 - val_accuracy: 0.3199\n",
      "Epoch 658/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3124 - accuracy: 0.5249 - val_loss: 2.6939 - val_accuracy: 0.3144\n",
      "Epoch 659/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3027 - accuracy: 0.5203 - val_loss: 2.6990 - val_accuracy: 0.3151\n",
      "Epoch 660/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3005 - accuracy: 0.5296 - val_loss: 2.7009 - val_accuracy: 0.3083\n",
      "Epoch 661/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3178 - accuracy: 0.5216 - val_loss: 2.7081 - val_accuracy: 0.3122\n",
      "Epoch 662/1000\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 1.3146 - accuracy: 0.5253 - val_loss: 2.7105 - val_accuracy: 0.3080\n",
      "Epoch 663/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3241 - accuracy: 0.5225 - val_loss: 2.7228 - val_accuracy: 0.3112\n",
      "Epoch 664/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3181 - accuracy: 0.5254 - val_loss: 2.7177 - val_accuracy: 0.3109\n",
      "Epoch 665/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3260 - accuracy: 0.5194 - val_loss: 2.7156 - val_accuracy: 0.3096\n",
      "Epoch 666/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3234 - accuracy: 0.5173 - val_loss: 2.6977 - val_accuracy: 0.3144\n",
      "Epoch 667/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3146 - accuracy: 0.5250 - val_loss: 2.7147 - val_accuracy: 0.3141\n",
      "Epoch 668/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3159 - accuracy: 0.5175 - val_loss: 2.7109 - val_accuracy: 0.3112\n",
      "Epoch 669/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3066 - accuracy: 0.5250 - val_loss: 2.7083 - val_accuracy: 0.3135\n",
      "Epoch 670/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3106 - accuracy: 0.5195 - val_loss: 2.7112 - val_accuracy: 0.3131\n",
      "Epoch 671/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3100 - accuracy: 0.5249 - val_loss: 2.7048 - val_accuracy: 0.3112\n",
      "Epoch 672/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3005 - accuracy: 0.5295 - val_loss: 2.7239 - val_accuracy: 0.3073\n",
      "Epoch 673/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.5183 - val_loss: 2.7047 - val_accuracy: 0.3135\n",
      "Epoch 674/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3159 - accuracy: 0.5228 - val_loss: 2.7206 - val_accuracy: 0.3093\n",
      "Epoch 675/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5284 - val_loss: 2.7307 - val_accuracy: 0.3112\n",
      "Epoch 676/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3201 - accuracy: 0.5190 - val_loss: 2.7102 - val_accuracy: 0.3090\n",
      "Epoch 677/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3206 - accuracy: 0.5174 - val_loss: 2.7279 - val_accuracy: 0.3109\n",
      "Epoch 678/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3100 - accuracy: 0.5210 - val_loss: 2.7092 - val_accuracy: 0.3064\n",
      "Epoch 679/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3202 - accuracy: 0.5232 - val_loss: 2.7119 - val_accuracy: 0.3119\n",
      "Epoch 680/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3114 - accuracy: 0.5285 - val_loss: 2.7214 - val_accuracy: 0.3086\n",
      "Epoch 681/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3118 - accuracy: 0.5260 - val_loss: 2.7183 - val_accuracy: 0.3131\n",
      "Epoch 682/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3167 - accuracy: 0.5238 - val_loss: 2.7160 - val_accuracy: 0.3144\n",
      "Epoch 683/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5212 - val_loss: 2.7138 - val_accuracy: 0.3122\n",
      "Epoch 684/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3109 - accuracy: 0.5225 - val_loss: 2.7102 - val_accuracy: 0.3177\n",
      "Epoch 685/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3259 - accuracy: 0.5257 - val_loss: 2.7265 - val_accuracy: 0.3106\n",
      "Epoch 686/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3201 - accuracy: 0.5223 - val_loss: 2.7189 - val_accuracy: 0.3115\n",
      "Epoch 687/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3020 - accuracy: 0.5241 - val_loss: 2.7244 - val_accuracy: 0.3173\n",
      "Epoch 688/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3133 - accuracy: 0.5260 - val_loss: 2.7194 - val_accuracy: 0.3073\n",
      "Epoch 689/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3157 - accuracy: 0.5189 - val_loss: 2.7184 - val_accuracy: 0.3090\n",
      "Epoch 690/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3119 - accuracy: 0.5199 - val_loss: 2.7158 - val_accuracy: 0.3128\n",
      "Epoch 691/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3321 - accuracy: 0.5244 - val_loss: 2.7145 - val_accuracy: 0.3128\n",
      "Epoch 692/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3115 - accuracy: 0.5175 - val_loss: 2.7127 - val_accuracy: 0.3125\n",
      "Epoch 693/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3128 - accuracy: 0.5200 - val_loss: 2.7356 - val_accuracy: 0.3080\n",
      "Epoch 694/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3112 - accuracy: 0.5239 - val_loss: 2.7163 - val_accuracy: 0.3144\n",
      "Epoch 695/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3233 - accuracy: 0.5219 - val_loss: 2.7155 - val_accuracy: 0.3122\n",
      "Epoch 696/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3098 - accuracy: 0.5283 - val_loss: 2.7217 - val_accuracy: 0.3141\n",
      "Epoch 697/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2952 - accuracy: 0.5317 - val_loss: 2.7255 - val_accuracy: 0.3131\n",
      "Epoch 698/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3028 - accuracy: 0.5218 - val_loss: 2.7249 - val_accuracy: 0.3096\n",
      "Epoch 699/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3143 - accuracy: 0.5235 - val_loss: 2.7270 - val_accuracy: 0.3090\n",
      "Epoch 700/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3084 - accuracy: 0.5230 - val_loss: 2.7377 - val_accuracy: 0.3057\n",
      "Epoch 701/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3065 - accuracy: 0.5298 - val_loss: 2.7227 - val_accuracy: 0.3131\n",
      "Epoch 702/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3158 - accuracy: 0.5212 - val_loss: 2.7157 - val_accuracy: 0.3115\n",
      "Epoch 703/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3104 - accuracy: 0.5216 - val_loss: 2.7275 - val_accuracy: 0.3083\n",
      "Epoch 704/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.5145 - val_loss: 2.7140 - val_accuracy: 0.3115\n",
      "Epoch 705/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5171 - val_loss: 2.7210 - val_accuracy: 0.3090\n",
      "Epoch 706/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3079 - accuracy: 0.5232 - val_loss: 2.7204 - val_accuracy: 0.3135\n",
      "Epoch 707/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3076 - accuracy: 0.5284 - val_loss: 2.7197 - val_accuracy: 0.3128\n",
      "Epoch 708/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5248 - val_loss: 2.7269 - val_accuracy: 0.3112\n",
      "Epoch 709/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3010 - accuracy: 0.5216 - val_loss: 2.7364 - val_accuracy: 0.3064\n",
      "Epoch 710/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3085 - accuracy: 0.5240 - val_loss: 2.7249 - val_accuracy: 0.3073\n",
      "Epoch 711/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5199 - val_loss: 2.7169 - val_accuracy: 0.3144\n",
      "Epoch 712/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.5224 - val_loss: 2.7182 - val_accuracy: 0.3106\n",
      "Epoch 713/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3055 - accuracy: 0.5250 - val_loss: 2.7276 - val_accuracy: 0.3090\n",
      "Epoch 714/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3077 - accuracy: 0.5286 - val_loss: 2.7158 - val_accuracy: 0.3112\n",
      "Epoch 715/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.5167 - val_loss: 2.7272 - val_accuracy: 0.3077\n",
      "Epoch 716/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3068 - accuracy: 0.5264 - val_loss: 2.7086 - val_accuracy: 0.3212\n",
      "Epoch 717/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3086 - accuracy: 0.5265 - val_loss: 2.7128 - val_accuracy: 0.3106\n",
      "Epoch 718/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5285 - val_loss: 2.7169 - val_accuracy: 0.3102\n",
      "Epoch 719/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3021 - accuracy: 0.5261 - val_loss: 2.7242 - val_accuracy: 0.3073\n",
      "Epoch 720/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3107 - accuracy: 0.5225 - val_loss: 2.7196 - val_accuracy: 0.3106\n",
      "Epoch 721/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2973 - accuracy: 0.5307 - val_loss: 2.7096 - val_accuracy: 0.3167\n",
      "Epoch 722/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3079 - accuracy: 0.5234 - val_loss: 2.7101 - val_accuracy: 0.3048\n",
      "Epoch 723/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5223 - val_loss: 2.7079 - val_accuracy: 0.3148\n",
      "Epoch 724/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.5275 - val_loss: 2.7153 - val_accuracy: 0.3128\n",
      "Epoch 725/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3061 - accuracy: 0.5259 - val_loss: 2.7345 - val_accuracy: 0.3096\n",
      "Epoch 726/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2972 - accuracy: 0.5277 - val_loss: 2.7173 - val_accuracy: 0.3119\n",
      "Epoch 727/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3109 - accuracy: 0.5242 - val_loss: 2.7265 - val_accuracy: 0.3180\n",
      "Epoch 728/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3027 - accuracy: 0.5233 - val_loss: 2.7312 - val_accuracy: 0.3067\n",
      "Epoch 729/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3058 - accuracy: 0.5181 - val_loss: 2.7127 - val_accuracy: 0.3125\n",
      "Epoch 730/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2991 - accuracy: 0.5213 - val_loss: 2.7284 - val_accuracy: 0.3096\n",
      "Epoch 731/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5253 - val_loss: 2.7273 - val_accuracy: 0.3099\n",
      "Epoch 732/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3154 - accuracy: 0.5218 - val_loss: 2.7193 - val_accuracy: 0.3090\n",
      "Epoch 733/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3042 - accuracy: 0.5230 - val_loss: 2.7179 - val_accuracy: 0.3122\n",
      "Epoch 734/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3093 - accuracy: 0.5190 - val_loss: 2.7110 - val_accuracy: 0.3157\n",
      "Epoch 735/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3069 - accuracy: 0.5251 - val_loss: 2.7124 - val_accuracy: 0.3115\n",
      "Epoch 736/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3126 - accuracy: 0.5278 - val_loss: 2.7276 - val_accuracy: 0.3096\n",
      "Epoch 737/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3075 - accuracy: 0.5301 - val_loss: 2.7360 - val_accuracy: 0.3099\n",
      "Epoch 738/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3174 - accuracy: 0.5190 - val_loss: 2.7146 - val_accuracy: 0.3164\n",
      "Epoch 739/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3245 - accuracy: 0.5224 - val_loss: 2.7384 - val_accuracy: 0.3083\n",
      "Epoch 740/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3073 - accuracy: 0.5220 - val_loss: 2.7399 - val_accuracy: 0.3061\n",
      "Epoch 741/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3065 - accuracy: 0.5223 - val_loss: 2.7302 - val_accuracy: 0.3115\n",
      "Epoch 742/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3005 - accuracy: 0.5297 - val_loss: 2.7265 - val_accuracy: 0.3138\n",
      "Epoch 743/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3155 - accuracy: 0.5119 - val_loss: 2.7208 - val_accuracy: 0.3090\n",
      "Epoch 744/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5264 - val_loss: 2.7248 - val_accuracy: 0.3157\n",
      "Epoch 745/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3131 - accuracy: 0.5332 - val_loss: 2.7328 - val_accuracy: 0.3073\n",
      "Epoch 746/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3017 - accuracy: 0.5190 - val_loss: 2.7289 - val_accuracy: 0.3067\n",
      "Epoch 747/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2945 - accuracy: 0.5312 - val_loss: 2.7389 - val_accuracy: 0.3106\n",
      "Epoch 748/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2970 - accuracy: 0.5202 - val_loss: 2.7317 - val_accuracy: 0.3109\n",
      "Epoch 749/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3076 - accuracy: 0.5321 - val_loss: 2.7404 - val_accuracy: 0.3173\n",
      "Epoch 750/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5192 - val_loss: 2.7245 - val_accuracy: 0.3122\n",
      "Epoch 751/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.5316 - val_loss: 2.7191 - val_accuracy: 0.3173\n",
      "Epoch 752/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2925 - accuracy: 0.5377 - val_loss: 2.7265 - val_accuracy: 0.3102\n",
      "Epoch 753/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.5209 - val_loss: 2.7327 - val_accuracy: 0.3148\n",
      "Epoch 754/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3045 - accuracy: 0.5227 - val_loss: 2.7224 - val_accuracy: 0.3099\n",
      "Epoch 755/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3038 - accuracy: 0.5247 - val_loss: 2.7308 - val_accuracy: 0.3125\n",
      "Epoch 756/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3043 - accuracy: 0.5277 - val_loss: 2.7461 - val_accuracy: 0.3096\n",
      "Epoch 757/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3124 - accuracy: 0.5116 - val_loss: 2.7332 - val_accuracy: 0.3125\n",
      "Epoch 758/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.5246 - val_loss: 2.7261 - val_accuracy: 0.3157\n",
      "Epoch 759/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3053 - accuracy: 0.5222 - val_loss: 2.7230 - val_accuracy: 0.3154\n",
      "Epoch 760/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3247 - accuracy: 0.5191 - val_loss: 2.7337 - val_accuracy: 0.3102\n",
      "Epoch 761/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3163 - accuracy: 0.5194 - val_loss: 2.7246 - val_accuracy: 0.3128\n",
      "Epoch 762/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3159 - accuracy: 0.5189 - val_loss: 2.7338 - val_accuracy: 0.3077\n",
      "Epoch 763/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3070 - accuracy: 0.5253 - val_loss: 2.7337 - val_accuracy: 0.3077\n",
      "Epoch 764/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3074 - accuracy: 0.5236 - val_loss: 2.7300 - val_accuracy: 0.3135\n",
      "Epoch 765/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.5217 - val_loss: 2.7264 - val_accuracy: 0.3125\n",
      "Epoch 766/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3137 - accuracy: 0.5204 - val_loss: 2.7317 - val_accuracy: 0.3093\n",
      "Epoch 767/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3166 - accuracy: 0.5132 - val_loss: 2.7269 - val_accuracy: 0.3086\n",
      "Epoch 768/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3128 - accuracy: 0.5269 - val_loss: 2.7331 - val_accuracy: 0.3160\n",
      "Epoch 769/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2983 - accuracy: 0.5285 - val_loss: 2.7494 - val_accuracy: 0.3125\n",
      "Epoch 770/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3007 - accuracy: 0.5236 - val_loss: 2.7380 - val_accuracy: 0.3138\n",
      "Epoch 771/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2976 - accuracy: 0.5237 - val_loss: 2.7298 - val_accuracy: 0.3170\n",
      "Epoch 772/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3066 - accuracy: 0.5212 - val_loss: 2.7343 - val_accuracy: 0.3125\n",
      "Epoch 773/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3014 - accuracy: 0.5263 - val_loss: 2.7344 - val_accuracy: 0.3160\n",
      "Epoch 774/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3042 - accuracy: 0.5245 - val_loss: 2.7342 - val_accuracy: 0.3119\n",
      "Epoch 775/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3097 - accuracy: 0.5219 - val_loss: 2.7381 - val_accuracy: 0.3160\n",
      "Epoch 776/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3071 - accuracy: 0.5293 - val_loss: 2.7380 - val_accuracy: 0.3170\n",
      "Epoch 777/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3072 - accuracy: 0.5263 - val_loss: 2.7392 - val_accuracy: 0.3086\n",
      "Epoch 778/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3067 - accuracy: 0.5293 - val_loss: 2.7400 - val_accuracy: 0.3106\n",
      "Epoch 779/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3091 - accuracy: 0.5256 - val_loss: 2.7318 - val_accuracy: 0.3125\n",
      "Epoch 780/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3164 - accuracy: 0.5206 - val_loss: 2.7335 - val_accuracy: 0.3164\n",
      "Epoch 781/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3016 - accuracy: 0.5202 - val_loss: 2.7281 - val_accuracy: 0.3206\n",
      "Epoch 782/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2884 - accuracy: 0.5303 - val_loss: 2.7341 - val_accuracy: 0.3138\n",
      "Epoch 783/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3048 - accuracy: 0.5219 - val_loss: 2.7406 - val_accuracy: 0.3231\n",
      "Epoch 784/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3070 - accuracy: 0.5238 - val_loss: 2.7397 - val_accuracy: 0.3170\n",
      "Epoch 785/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3025 - accuracy: 0.5215 - val_loss: 2.7398 - val_accuracy: 0.3115\n",
      "Epoch 786/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3154 - accuracy: 0.5246 - val_loss: 2.7486 - val_accuracy: 0.3099\n",
      "Epoch 787/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2980 - accuracy: 0.5235 - val_loss: 2.7244 - val_accuracy: 0.3193\n",
      "Epoch 788/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3110 - accuracy: 0.5199 - val_loss: 2.7296 - val_accuracy: 0.3209\n",
      "Epoch 789/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3049 - accuracy: 0.5217 - val_loss: 2.7271 - val_accuracy: 0.3096\n",
      "Epoch 790/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3020 - accuracy: 0.5282 - val_loss: 2.7460 - val_accuracy: 0.3083\n",
      "Epoch 791/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5275 - val_loss: 2.7453 - val_accuracy: 0.3067\n",
      "Epoch 792/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3019 - accuracy: 0.5225 - val_loss: 2.7525 - val_accuracy: 0.3102\n",
      "Epoch 793/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2983 - accuracy: 0.5251 - val_loss: 2.7358 - val_accuracy: 0.3115\n",
      "Epoch 794/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3111 - accuracy: 0.5261 - val_loss: 2.7525 - val_accuracy: 0.3106\n",
      "Epoch 795/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.5177 - val_loss: 2.7486 - val_accuracy: 0.3093\n",
      "Epoch 796/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2916 - accuracy: 0.5293 - val_loss: 2.7360 - val_accuracy: 0.3138\n",
      "Epoch 797/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3081 - accuracy: 0.5179 - val_loss: 2.7364 - val_accuracy: 0.3077\n",
      "Epoch 798/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2966 - accuracy: 0.5280 - val_loss: 2.7370 - val_accuracy: 0.3186\n",
      "Epoch 799/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2987 - accuracy: 0.5353 - val_loss: 2.7251 - val_accuracy: 0.3109\n",
      "Epoch 800/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3159 - accuracy: 0.5266 - val_loss: 2.7356 - val_accuracy: 0.3109\n",
      "Epoch 801/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3173 - accuracy: 0.5188 - val_loss: 2.7342 - val_accuracy: 0.3119\n",
      "Epoch 802/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2999 - accuracy: 0.5247 - val_loss: 2.7353 - val_accuracy: 0.3070\n",
      "Epoch 803/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3059 - accuracy: 0.5229 - val_loss: 2.7514 - val_accuracy: 0.3125\n",
      "Epoch 804/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3032 - accuracy: 0.5263 - val_loss: 2.7376 - val_accuracy: 0.3164\n",
      "Epoch 805/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2976 - accuracy: 0.5345 - val_loss: 2.7392 - val_accuracy: 0.3154\n",
      "Epoch 806/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3041 - accuracy: 0.5133 - val_loss: 2.7367 - val_accuracy: 0.3128\n",
      "Epoch 807/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2981 - accuracy: 0.5267 - val_loss: 2.7455 - val_accuracy: 0.3144\n",
      "Epoch 808/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2994 - accuracy: 0.5216 - val_loss: 2.7410 - val_accuracy: 0.3122\n",
      "Epoch 809/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3004 - accuracy: 0.5217 - val_loss: 2.7419 - val_accuracy: 0.3212\n",
      "Epoch 810/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3046 - accuracy: 0.5242 - val_loss: 2.7390 - val_accuracy: 0.3189\n",
      "Epoch 811/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3081 - accuracy: 0.5140 - val_loss: 2.7416 - val_accuracy: 0.3115\n",
      "Epoch 812/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2942 - accuracy: 0.5282 - val_loss: 2.7531 - val_accuracy: 0.3119\n",
      "Epoch 813/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5177 - val_loss: 2.7516 - val_accuracy: 0.3102\n",
      "Epoch 814/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2935 - accuracy: 0.5244 - val_loss: 2.7471 - val_accuracy: 0.3119\n",
      "Epoch 815/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3147 - accuracy: 0.5210 - val_loss: 2.7568 - val_accuracy: 0.3070\n",
      "Epoch 816/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3076 - accuracy: 0.5231 - val_loss: 2.7529 - val_accuracy: 0.3112\n",
      "Epoch 817/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2996 - accuracy: 0.5252 - val_loss: 2.7509 - val_accuracy: 0.3170\n",
      "Epoch 818/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3057 - accuracy: 0.5302 - val_loss: 2.7664 - val_accuracy: 0.3099\n",
      "Epoch 819/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3048 - accuracy: 0.5268 - val_loss: 2.7585 - val_accuracy: 0.3157\n",
      "Epoch 820/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5141 - val_loss: 2.7357 - val_accuracy: 0.3148\n",
      "Epoch 821/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3050 - accuracy: 0.5191 - val_loss: 2.7632 - val_accuracy: 0.3167\n",
      "Epoch 822/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3012 - accuracy: 0.5253 - val_loss: 2.7558 - val_accuracy: 0.3119\n",
      "Epoch 823/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3009 - accuracy: 0.5292 - val_loss: 2.7500 - val_accuracy: 0.3160\n",
      "Epoch 824/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3007 - accuracy: 0.5258 - val_loss: 2.7417 - val_accuracy: 0.3212\n",
      "Epoch 825/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3078 - accuracy: 0.5272 - val_loss: 2.7526 - val_accuracy: 0.3135\n",
      "Epoch 826/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2975 - accuracy: 0.5313 - val_loss: 2.7500 - val_accuracy: 0.3128\n",
      "Epoch 827/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2950 - accuracy: 0.5323 - val_loss: 2.7444 - val_accuracy: 0.3206\n",
      "Epoch 828/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3107 - accuracy: 0.5203 - val_loss: 2.7398 - val_accuracy: 0.3148\n",
      "Epoch 829/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3024 - accuracy: 0.5213 - val_loss: 2.7532 - val_accuracy: 0.3173\n",
      "Epoch 830/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.5259 - val_loss: 2.7615 - val_accuracy: 0.3073\n",
      "Epoch 831/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5209 - val_loss: 2.7395 - val_accuracy: 0.3138\n",
      "Epoch 832/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2983 - accuracy: 0.5245 - val_loss: 2.7694 - val_accuracy: 0.3112\n",
      "Epoch 833/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2995 - accuracy: 0.5215 - val_loss: 2.7468 - val_accuracy: 0.3102\n",
      "Epoch 834/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2916 - accuracy: 0.5273 - val_loss: 2.7562 - val_accuracy: 0.3070\n",
      "Epoch 835/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2931 - accuracy: 0.5246 - val_loss: 2.7463 - val_accuracy: 0.3077\n",
      "Epoch 836/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2946 - accuracy: 0.5261 - val_loss: 2.7386 - val_accuracy: 0.3115\n",
      "Epoch 837/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3036 - accuracy: 0.5201 - val_loss: 2.7399 - val_accuracy: 0.3177\n",
      "Epoch 838/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3102 - accuracy: 0.5221 - val_loss: 2.7590 - val_accuracy: 0.3128\n",
      "Epoch 839/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3032 - accuracy: 0.5265 - val_loss: 2.7434 - val_accuracy: 0.3138\n",
      "Epoch 840/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2982 - accuracy: 0.5313 - val_loss: 2.7552 - val_accuracy: 0.3061\n",
      "Epoch 841/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3096 - accuracy: 0.5218 - val_loss: 2.7391 - val_accuracy: 0.3128\n",
      "Epoch 842/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3041 - accuracy: 0.5240 - val_loss: 2.7623 - val_accuracy: 0.3061\n",
      "Epoch 843/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2989 - accuracy: 0.5280 - val_loss: 2.7528 - val_accuracy: 0.3151\n",
      "Epoch 844/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2989 - accuracy: 0.5187 - val_loss: 2.7430 - val_accuracy: 0.3141\n",
      "Epoch 845/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2915 - accuracy: 0.5295 - val_loss: 2.7466 - val_accuracy: 0.3128\n",
      "Epoch 846/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3017 - accuracy: 0.5252 - val_loss: 2.7536 - val_accuracy: 0.3080\n",
      "Epoch 847/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2925 - accuracy: 0.5234 - val_loss: 2.7534 - val_accuracy: 0.3119\n",
      "Epoch 848/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2880 - accuracy: 0.5309 - val_loss: 2.7519 - val_accuracy: 0.3109\n",
      "Epoch 849/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3007 - accuracy: 0.5238 - val_loss: 2.7527 - val_accuracy: 0.3112\n",
      "Epoch 850/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3051 - accuracy: 0.5224 - val_loss: 2.7523 - val_accuracy: 0.3061\n",
      "Epoch 851/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2935 - accuracy: 0.5189 - val_loss: 2.7407 - val_accuracy: 0.3128\n",
      "Epoch 852/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3030 - accuracy: 0.5241 - val_loss: 2.7550 - val_accuracy: 0.3193\n",
      "Epoch 853/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2950 - accuracy: 0.5264 - val_loss: 2.7522 - val_accuracy: 0.3115\n",
      "Epoch 854/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3073 - accuracy: 0.5271 - val_loss: 2.7531 - val_accuracy: 0.3115\n",
      "Epoch 855/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3049 - accuracy: 0.5229 - val_loss: 2.7480 - val_accuracy: 0.3135\n",
      "Epoch 856/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.5240 - val_loss: 2.7498 - val_accuracy: 0.3122\n",
      "Epoch 857/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3098 - accuracy: 0.5210 - val_loss: 2.7532 - val_accuracy: 0.3064\n",
      "Epoch 858/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3034 - accuracy: 0.5196 - val_loss: 2.7554 - val_accuracy: 0.3090\n",
      "Epoch 859/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3021 - accuracy: 0.5203 - val_loss: 2.7477 - val_accuracy: 0.3128\n",
      "Epoch 860/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3057 - accuracy: 0.5295 - val_loss: 2.7515 - val_accuracy: 0.3086\n",
      "Epoch 861/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3025 - accuracy: 0.5220 - val_loss: 2.7367 - val_accuracy: 0.3077\n",
      "Epoch 862/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2933 - accuracy: 0.5266 - val_loss: 2.7466 - val_accuracy: 0.3096\n",
      "Epoch 863/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2910 - accuracy: 0.5253 - val_loss: 2.7481 - val_accuracy: 0.3090\n",
      "Epoch 864/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3029 - accuracy: 0.5256 - val_loss: 2.7678 - val_accuracy: 0.3064\n",
      "Epoch 865/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3140 - accuracy: 0.5228 - val_loss: 2.7398 - val_accuracy: 0.3177\n",
      "Epoch 866/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3038 - accuracy: 0.5247 - val_loss: 2.7461 - val_accuracy: 0.3122\n",
      "Epoch 867/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2968 - accuracy: 0.5245 - val_loss: 2.7569 - val_accuracy: 0.3077\n",
      "Epoch 868/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3110 - accuracy: 0.5124 - val_loss: 2.7501 - val_accuracy: 0.3115\n",
      "Epoch 869/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2989 - accuracy: 0.5296 - val_loss: 2.7647 - val_accuracy: 0.3112\n",
      "Epoch 870/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2878 - accuracy: 0.5228 - val_loss: 2.7498 - val_accuracy: 0.3096\n",
      "Epoch 871/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3074 - accuracy: 0.5303 - val_loss: 2.7649 - val_accuracy: 0.3073\n",
      "Epoch 872/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3011 - accuracy: 0.5248 - val_loss: 2.7539 - val_accuracy: 0.3102\n",
      "Epoch 873/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3082 - accuracy: 0.5246 - val_loss: 2.7479 - val_accuracy: 0.3096\n",
      "Epoch 874/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3076 - accuracy: 0.5200 - val_loss: 2.7620 - val_accuracy: 0.3138\n",
      "Epoch 875/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3057 - accuracy: 0.5240 - val_loss: 2.7616 - val_accuracy: 0.3057\n",
      "Epoch 876/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2945 - accuracy: 0.5300 - val_loss: 2.7608 - val_accuracy: 0.3073\n",
      "Epoch 877/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2991 - accuracy: 0.5207 - val_loss: 2.7503 - val_accuracy: 0.3135\n",
      "Epoch 878/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2960 - accuracy: 0.5251 - val_loss: 2.7591 - val_accuracy: 0.3119\n",
      "Epoch 879/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2975 - accuracy: 0.5263 - val_loss: 2.7534 - val_accuracy: 0.3083\n",
      "Epoch 880/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3010 - accuracy: 0.5312 - val_loss: 2.7724 - val_accuracy: 0.3135\n",
      "Epoch 881/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3069 - accuracy: 0.5190 - val_loss: 2.7508 - val_accuracy: 0.3157\n",
      "Epoch 882/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.5244 - val_loss: 2.7527 - val_accuracy: 0.3209\n",
      "Epoch 883/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5264 - val_loss: 2.7678 - val_accuracy: 0.3135\n",
      "Epoch 884/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2904 - accuracy: 0.5283 - val_loss: 2.7604 - val_accuracy: 0.3093\n",
      "Epoch 885/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.5306 - val_loss: 2.7632 - val_accuracy: 0.3141\n",
      "Epoch 886/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3028 - accuracy: 0.5192 - val_loss: 2.7541 - val_accuracy: 0.3189\n",
      "Epoch 887/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.5198 - val_loss: 2.7559 - val_accuracy: 0.3128\n",
      "Epoch 888/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2886 - accuracy: 0.5289 - val_loss: 2.7640 - val_accuracy: 0.3167\n",
      "Epoch 889/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3192 - accuracy: 0.5186 - val_loss: 2.7622 - val_accuracy: 0.3151\n",
      "Epoch 890/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2933 - accuracy: 0.5325 - val_loss: 2.7774 - val_accuracy: 0.3112\n",
      "Epoch 891/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2983 - accuracy: 0.5263 - val_loss: 2.7700 - val_accuracy: 0.3119\n",
      "Epoch 892/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3064 - accuracy: 0.5219 - val_loss: 2.7631 - val_accuracy: 0.3164\n",
      "Epoch 893/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2972 - accuracy: 0.5284 - val_loss: 2.7548 - val_accuracy: 0.3096\n",
      "Epoch 894/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2969 - accuracy: 0.5258 - val_loss: 2.7494 - val_accuracy: 0.3196\n",
      "Epoch 895/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2968 - accuracy: 0.5235 - val_loss: 2.7631 - val_accuracy: 0.3099\n",
      "Epoch 896/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2999 - accuracy: 0.5251 - val_loss: 2.7646 - val_accuracy: 0.3183\n",
      "Epoch 897/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3033 - accuracy: 0.5249 - val_loss: 2.7620 - val_accuracy: 0.3173\n",
      "Epoch 898/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3012 - accuracy: 0.5214 - val_loss: 2.7639 - val_accuracy: 0.3131\n",
      "Epoch 899/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2912 - accuracy: 0.5324 - val_loss: 2.7628 - val_accuracy: 0.3093\n",
      "Epoch 900/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2990 - accuracy: 0.5198 - val_loss: 2.7705 - val_accuracy: 0.3115\n",
      "Epoch 901/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2914 - accuracy: 0.5243 - val_loss: 2.7625 - val_accuracy: 0.3160\n",
      "Epoch 902/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.3018 - accuracy: 0.5207 - val_loss: 2.7504 - val_accuracy: 0.3173\n",
      "Epoch 903/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3020 - accuracy: 0.5314 - val_loss: 2.7581 - val_accuracy: 0.3086\n",
      "Epoch 904/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2849 - accuracy: 0.5382 - val_loss: 2.7551 - val_accuracy: 0.3157\n",
      "Epoch 905/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3080 - accuracy: 0.5264 - val_loss: 2.7628 - val_accuracy: 0.3122\n",
      "Epoch 906/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2946 - accuracy: 0.5302 - val_loss: 2.7635 - val_accuracy: 0.3189\n",
      "Epoch 907/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2933 - accuracy: 0.5232 - val_loss: 2.7689 - val_accuracy: 0.3157\n",
      "Epoch 908/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3052 - accuracy: 0.5270 - val_loss: 2.7638 - val_accuracy: 0.3238\n",
      "Epoch 909/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2896 - accuracy: 0.5305 - val_loss: 2.7699 - val_accuracy: 0.3128\n",
      "Epoch 910/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3112 - accuracy: 0.5260 - val_loss: 2.7539 - val_accuracy: 0.3144\n",
      "Epoch 911/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2899 - accuracy: 0.5308 - val_loss: 2.7634 - val_accuracy: 0.3144\n",
      "Epoch 912/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2991 - accuracy: 0.5276 - val_loss: 2.7557 - val_accuracy: 0.3138\n",
      "Epoch 913/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2897 - accuracy: 0.5291 - val_loss: 2.7582 - val_accuracy: 0.3070\n",
      "Epoch 914/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2867 - accuracy: 0.5179 - val_loss: 2.7655 - val_accuracy: 0.3102\n",
      "Epoch 915/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2994 - accuracy: 0.5344 - val_loss: 2.7591 - val_accuracy: 0.3119\n",
      "Epoch 916/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2981 - accuracy: 0.5215 - val_loss: 2.7740 - val_accuracy: 0.3093\n",
      "Epoch 917/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.5188 - val_loss: 2.7724 - val_accuracy: 0.3064\n",
      "Epoch 918/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2957 - accuracy: 0.5255 - val_loss: 2.7683 - val_accuracy: 0.3119\n",
      "Epoch 919/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3048 - accuracy: 0.5297 - val_loss: 2.7753 - val_accuracy: 0.3067\n",
      "Epoch 920/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2923 - accuracy: 0.5318 - val_loss: 2.7644 - val_accuracy: 0.3151\n",
      "Epoch 921/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3003 - accuracy: 0.5238 - val_loss: 2.7749 - val_accuracy: 0.3115\n",
      "Epoch 922/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2932 - accuracy: 0.5226 - val_loss: 2.7758 - val_accuracy: 0.3106\n",
      "Epoch 923/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3074 - accuracy: 0.5233 - val_loss: 2.7787 - val_accuracy: 0.3083\n",
      "Epoch 924/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3042 - accuracy: 0.5218 - val_loss: 2.7717 - val_accuracy: 0.3131\n",
      "Epoch 925/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2924 - accuracy: 0.5229 - val_loss: 2.7711 - val_accuracy: 0.3135\n",
      "Epoch 926/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2866 - accuracy: 0.5310 - val_loss: 2.7761 - val_accuracy: 0.3061\n",
      "Epoch 927/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2991 - accuracy: 0.5266 - val_loss: 2.7768 - val_accuracy: 0.3183\n",
      "Epoch 928/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2990 - accuracy: 0.5227 - val_loss: 2.7615 - val_accuracy: 0.3157\n",
      "Epoch 929/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3017 - accuracy: 0.5330 - val_loss: 2.7807 - val_accuracy: 0.3099\n",
      "Epoch 930/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2872 - accuracy: 0.5278 - val_loss: 2.7734 - val_accuracy: 0.3157\n",
      "Epoch 931/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2927 - accuracy: 0.5326 - val_loss: 2.7671 - val_accuracy: 0.3189\n",
      "Epoch 932/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2919 - accuracy: 0.5301 - val_loss: 2.7721 - val_accuracy: 0.3102\n",
      "Epoch 933/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2949 - accuracy: 0.5255 - val_loss: 2.7613 - val_accuracy: 0.3106\n",
      "Epoch 934/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3036 - accuracy: 0.5247 - val_loss: 2.7618 - val_accuracy: 0.3122\n",
      "Epoch 935/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2927 - accuracy: 0.5346 - val_loss: 2.7834 - val_accuracy: 0.3051\n",
      "Epoch 936/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3042 - accuracy: 0.5255 - val_loss: 2.7826 - val_accuracy: 0.3064\n",
      "Epoch 937/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2970 - accuracy: 0.5140 - val_loss: 2.7804 - val_accuracy: 0.3112\n",
      "Epoch 938/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2948 - accuracy: 0.5311 - val_loss: 2.7797 - val_accuracy: 0.3138\n",
      "Epoch 939/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2955 - accuracy: 0.5226 - val_loss: 2.7709 - val_accuracy: 0.3160\n",
      "Epoch 940/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3009 - accuracy: 0.5231 - val_loss: 2.7717 - val_accuracy: 0.3157\n",
      "Epoch 941/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3027 - accuracy: 0.5244 - val_loss: 2.7753 - val_accuracy: 0.3183\n",
      "Epoch 942/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2922 - accuracy: 0.5197 - val_loss: 2.7743 - val_accuracy: 0.3099\n",
      "Epoch 943/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2966 - accuracy: 0.5254 - val_loss: 2.7800 - val_accuracy: 0.3102\n",
      "Epoch 944/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2977 - accuracy: 0.5272 - val_loss: 2.7749 - val_accuracy: 0.3135\n",
      "Epoch 945/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2891 - accuracy: 0.5263 - val_loss: 2.7727 - val_accuracy: 0.3054\n",
      "Epoch 946/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3047 - accuracy: 0.5302 - val_loss: 2.7840 - val_accuracy: 0.3109\n",
      "Epoch 947/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2934 - accuracy: 0.5352 - val_loss: 2.7802 - val_accuracy: 0.3151\n",
      "Epoch 948/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2996 - accuracy: 0.5271 - val_loss: 2.7893 - val_accuracy: 0.3077\n",
      "Epoch 949/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2833 - accuracy: 0.5304 - val_loss: 2.7736 - val_accuracy: 0.3122\n",
      "Epoch 950/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.5186 - val_loss: 2.7745 - val_accuracy: 0.3135\n",
      "Epoch 951/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3104 - accuracy: 0.5253 - val_loss: 2.7757 - val_accuracy: 0.3106\n",
      "Epoch 952/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2940 - accuracy: 0.5275 - val_loss: 2.7703 - val_accuracy: 0.3154\n",
      "Epoch 953/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2998 - accuracy: 0.5263 - val_loss: 2.7667 - val_accuracy: 0.3125\n",
      "Epoch 954/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2981 - accuracy: 0.5254 - val_loss: 2.7791 - val_accuracy: 0.3083\n",
      "Epoch 955/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2882 - accuracy: 0.5252 - val_loss: 2.7824 - val_accuracy: 0.3154\n",
      "Epoch 956/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3024 - accuracy: 0.5156 - val_loss: 2.7805 - val_accuracy: 0.3119\n",
      "Epoch 957/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2752 - accuracy: 0.5336 - val_loss: 2.7659 - val_accuracy: 0.3083\n",
      "Epoch 958/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3034 - accuracy: 0.5241 - val_loss: 2.7772 - val_accuracy: 0.3109\n",
      "Epoch 959/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2950 - accuracy: 0.5282 - val_loss: 2.7819 - val_accuracy: 0.3093\n",
      "Epoch 960/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2967 - accuracy: 0.5284 - val_loss: 2.7726 - val_accuracy: 0.3083\n",
      "Epoch 961/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2837 - accuracy: 0.5319 - val_loss: 2.7665 - val_accuracy: 0.3096\n",
      "Epoch 962/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3004 - accuracy: 0.5270 - val_loss: 2.7657 - val_accuracy: 0.3135\n",
      "Epoch 963/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2941 - accuracy: 0.5275 - val_loss: 2.7641 - val_accuracy: 0.3119\n",
      "Epoch 964/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2965 - accuracy: 0.5294 - val_loss: 2.7702 - val_accuracy: 0.3131\n",
      "Epoch 965/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2925 - accuracy: 0.5255 - val_loss: 2.7756 - val_accuracy: 0.3077\n",
      "Epoch 966/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2900 - accuracy: 0.5264 - val_loss: 2.7651 - val_accuracy: 0.3125\n",
      "Epoch 967/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2857 - accuracy: 0.5208 - val_loss: 2.7862 - val_accuracy: 0.3106\n",
      "Epoch 968/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2853 - accuracy: 0.5269 - val_loss: 2.7763 - val_accuracy: 0.3102\n",
      "Epoch 969/1000\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.2939 - accuracy: 0.5283 - val_loss: 2.7811 - val_accuracy: 0.3122\n",
      "Epoch 970/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2910 - accuracy: 0.5235 - val_loss: 2.7705 - val_accuracy: 0.3122\n",
      "Epoch 971/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3092 - accuracy: 0.5337 - val_loss: 2.7737 - val_accuracy: 0.3106\n",
      "Epoch 972/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2947 - accuracy: 0.5366 - val_loss: 2.7870 - val_accuracy: 0.3077\n",
      "Epoch 973/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.5223 - val_loss: 2.7806 - val_accuracy: 0.3115\n",
      "Epoch 974/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2971 - accuracy: 0.5267 - val_loss: 2.7789 - val_accuracy: 0.3106\n",
      "Epoch 975/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2967 - accuracy: 0.5226 - val_loss: 2.7881 - val_accuracy: 0.3083\n",
      "Epoch 976/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3076 - accuracy: 0.5232 - val_loss: 2.7857 - val_accuracy: 0.3122\n",
      "Epoch 977/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5260 - val_loss: 2.7984 - val_accuracy: 0.3102\n",
      "Epoch 978/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2925 - accuracy: 0.5248 - val_loss: 2.7840 - val_accuracy: 0.3106\n",
      "Epoch 979/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.5156 - val_loss: 2.7735 - val_accuracy: 0.3106\n",
      "Epoch 980/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5227 - val_loss: 2.7795 - val_accuracy: 0.3109\n",
      "Epoch 981/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2941 - accuracy: 0.5215 - val_loss: 2.7714 - val_accuracy: 0.3106\n",
      "Epoch 982/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3008 - accuracy: 0.5139 - val_loss: 2.7704 - val_accuracy: 0.3077\n",
      "Epoch 983/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5172 - val_loss: 2.7787 - val_accuracy: 0.3138\n",
      "Epoch 984/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3056 - accuracy: 0.5223 - val_loss: 2.7754 - val_accuracy: 0.3122\n",
      "Epoch 985/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3062 - accuracy: 0.5241 - val_loss: 2.7861 - val_accuracy: 0.3109\n",
      "Epoch 986/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3015 - accuracy: 0.5202 - val_loss: 2.7861 - val_accuracy: 0.3109\n",
      "Epoch 987/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2902 - accuracy: 0.5210 - val_loss: 2.7868 - val_accuracy: 0.3154\n",
      "Epoch 988/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5222 - val_loss: 2.7657 - val_accuracy: 0.3189\n",
      "Epoch 989/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3117 - accuracy: 0.5178 - val_loss: 2.7654 - val_accuracy: 0.3093\n",
      "Epoch 990/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2951 - accuracy: 0.5243 - val_loss: 2.7730 - val_accuracy: 0.3160\n",
      "Epoch 991/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3046 - accuracy: 0.5211 - val_loss: 2.7830 - val_accuracy: 0.3070\n",
      "Epoch 992/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2804 - accuracy: 0.5346 - val_loss: 2.7784 - val_accuracy: 0.3083\n",
      "Epoch 993/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2909 - accuracy: 0.5300 - val_loss: 2.7918 - val_accuracy: 0.3070\n",
      "Epoch 994/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2972 - accuracy: 0.5299 - val_loss: 2.7794 - val_accuracy: 0.3083\n",
      "Epoch 995/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3112 - accuracy: 0.5252 - val_loss: 2.7703 - val_accuracy: 0.3128\n",
      "Epoch 996/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2971 - accuracy: 0.5157 - val_loss: 2.7806 - val_accuracy: 0.3106\n",
      "Epoch 997/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2960 - accuracy: 0.5242 - val_loss: 2.7736 - val_accuracy: 0.3106\n",
      "Epoch 998/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.5260 - val_loss: 2.7907 - val_accuracy: 0.3138\n",
      "Epoch 999/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2874 - accuracy: 0.5241 - val_loss: 2.7956 - val_accuracy: 0.3112\n",
      "Epoch 1000/1000\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 1.2920 - accuracy: 0.5279 - val_loss: 2.7819 - val_accuracy: 0.3070\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_many_to_many_aug_baseline = many_to_many_model_aug_baseline.fit(x_aug_train_tensor, y_aug_train_tensor, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=16,  # Batch size\n",
    "                                              validation_data=(x_aug_val_tensor, y_aug_val_tensor)  # Validation data\n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 2 (Val Accuracy: 0.4217139184474945)\n",
      "Best Epoch for Training Accuracy: 972 (Train Accuracy: 0.5283076167106628)\n",
      "Best Epoch for Training Loss: 913 (Train Loss: 1.2979365587234497)\n",
      "Best Epoch for Validation Loss: 16 (Val Loss: 2.1556556224823)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.4217139184474945\n",
      "Maximum Training Accuracy: 0.5283076167106628\n",
      "Minimum Training Loss: 1.2979365587234497\n",
      "Minimum Validation Loss: 2.1556556224823\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_many_to_many_aug_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_aug_baseline, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file = \"many_to_many_LSTM_baseline_aug_model.h5\"  \n",
    "many_to_many_model_aug_baseline.save(model_file)\n",
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_baseline_aug_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_aug_baseline.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more complex Many-to-Many LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 4, 64)             24832     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 4, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4, 64)             2112      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4, 32)             2080      \n",
      "=================================================================\n",
      "Total params: 41,440\n",
      "Trainable params: 41,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "import random\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set a new random seed\n",
    "new_seed = 27\n",
    "tf.random.set_seed(new_seed)\n",
    "np.random.seed(new_seed)\n",
    "random.seed(new_seed)\n",
    "\n",
    "# Define a simplified LSTM model\n",
    "many_to_many_model_aug_complex = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(4, 32)),  # Unidirectional LSTM\n",
    "    Dropout(0.4),\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    Dense(32, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the simplified model\n",
    "many_to_many_model_aug_complex.compile(optimizer='adam', \n",
    "                         loss='categorical_crossentropy', \n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Summary of the simplified model\n",
    "many_to_many_model_aug_complex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 2.3196 - accuracy: 0.2949 - val_loss: 2.2137 - val_accuracy: 0.3950\n",
      "Epoch 2/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2656 - accuracy: 0.3077 - val_loss: 2.2222 - val_accuracy: 0.4037\n",
      "Epoch 3/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2183 - accuracy: 0.3182 - val_loss: 2.2122 - val_accuracy: 0.3911\n",
      "Epoch 4/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1935 - accuracy: 0.3291 - val_loss: 2.2053 - val_accuracy: 0.3940\n",
      "Epoch 5/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1633 - accuracy: 0.3327 - val_loss: 2.2043 - val_accuracy: 0.3860\n",
      "Epoch 6/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1428 - accuracy: 0.3378 - val_loss: 2.2126 - val_accuracy: 0.3750\n",
      "Epoch 7/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1252 - accuracy: 0.3420 - val_loss: 2.1827 - val_accuracy: 0.3972\n",
      "Epoch 8/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.1114 - accuracy: 0.3453 - val_loss: 2.1991 - val_accuracy: 0.3792\n",
      "Epoch 9/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0940 - accuracy: 0.3484 - val_loss: 2.1780 - val_accuracy: 0.3750\n",
      "Epoch 10/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0833 - accuracy: 0.3530 - val_loss: 2.1792 - val_accuracy: 0.3918\n",
      "Epoch 11/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0661 - accuracy: 0.3616 - val_loss: 2.1771 - val_accuracy: 0.3847\n",
      "Epoch 12/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0566 - accuracy: 0.3514 - val_loss: 2.1590 - val_accuracy: 0.3827\n",
      "Epoch 13/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0458 - accuracy: 0.3613 - val_loss: 2.1867 - val_accuracy: 0.3818\n",
      "Epoch 14/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0363 - accuracy: 0.3581 - val_loss: 2.1583 - val_accuracy: 0.3918\n",
      "Epoch 15/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0249 - accuracy: 0.3614 - val_loss: 2.1505 - val_accuracy: 0.3837\n",
      "Epoch 16/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0188 - accuracy: 0.3603 - val_loss: 2.1629 - val_accuracy: 0.3918\n",
      "Epoch 17/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0112 - accuracy: 0.3649 - val_loss: 2.1615 - val_accuracy: 0.3837\n",
      "Epoch 18/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0031 - accuracy: 0.3594 - val_loss: 2.1582 - val_accuracy: 0.3918\n",
      "Epoch 19/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0019 - accuracy: 0.3676 - val_loss: 2.1681 - val_accuracy: 0.3889\n",
      "Epoch 20/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9927 - accuracy: 0.3605 - val_loss: 2.1503 - val_accuracy: 0.3914\n",
      "Epoch 21/1000\n",
      "154/154 [==============================] - ETA: 0s - loss: 1.9866 - accuracy: 0.36 - 1s 5ms/step - loss: 1.9865 - accuracy: 0.3664 - val_loss: 2.1468 - val_accuracy: 0.3872\n",
      "Epoch 22/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9798 - accuracy: 0.3656 - val_loss: 2.1535 - val_accuracy: 0.3866\n",
      "Epoch 23/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9714 - accuracy: 0.3702 - val_loss: 2.1926 - val_accuracy: 0.3711\n",
      "Epoch 24/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9689 - accuracy: 0.3693 - val_loss: 2.1593 - val_accuracy: 0.3840\n",
      "Epoch 25/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9655 - accuracy: 0.3657 - val_loss: 2.1433 - val_accuracy: 0.3898\n",
      "Epoch 26/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9627 - accuracy: 0.3654 - val_loss: 2.1349 - val_accuracy: 0.3924\n",
      "Epoch 27/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9563 - accuracy: 0.3687 - val_loss: 2.1705 - val_accuracy: 0.3779\n",
      "Epoch 28/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9453 - accuracy: 0.3714 - val_loss: 2.1445 - val_accuracy: 0.3892\n",
      "Epoch 29/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9481 - accuracy: 0.3701 - val_loss: 2.1922 - val_accuracy: 0.3792\n",
      "Epoch 30/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9372 - accuracy: 0.3788 - val_loss: 2.1703 - val_accuracy: 0.3827\n",
      "Epoch 31/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9391 - accuracy: 0.3759 - val_loss: 2.1534 - val_accuracy: 0.3934\n",
      "Epoch 32/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9395 - accuracy: 0.3730 - val_loss: 2.1565 - val_accuracy: 0.3834\n",
      "Epoch 33/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9349 - accuracy: 0.3692 - val_loss: 2.1948 - val_accuracy: 0.3814\n",
      "Epoch 34/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9256 - accuracy: 0.3774 - val_loss: 2.1665 - val_accuracy: 0.3818\n",
      "Epoch 35/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9252 - accuracy: 0.3728 - val_loss: 2.1936 - val_accuracy: 0.3798\n",
      "Epoch 36/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9267 - accuracy: 0.3775 - val_loss: 2.1563 - val_accuracy: 0.3934\n",
      "Epoch 37/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9169 - accuracy: 0.3766 - val_loss: 2.1498 - val_accuracy: 0.3892\n",
      "Epoch 38/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9136 - accuracy: 0.3786 - val_loss: 2.1649 - val_accuracy: 0.3908\n",
      "Epoch 39/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9205 - accuracy: 0.3756 - val_loss: 2.1525 - val_accuracy: 0.3969\n",
      "Epoch 40/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9142 - accuracy: 0.3738 - val_loss: 2.1792 - val_accuracy: 0.3914\n",
      "Epoch 41/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9041 - accuracy: 0.3770 - val_loss: 2.1770 - val_accuracy: 0.3863\n",
      "Epoch 42/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9052 - accuracy: 0.3825 - val_loss: 2.1761 - val_accuracy: 0.3808\n",
      "Epoch 43/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8945 - accuracy: 0.3815 - val_loss: 2.1639 - val_accuracy: 0.3908\n",
      "Epoch 44/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9085 - accuracy: 0.3757 - val_loss: 2.1481 - val_accuracy: 0.4024\n",
      "Epoch 45/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8969 - accuracy: 0.3770 - val_loss: 2.1730 - val_accuracy: 0.3840\n",
      "Epoch 46/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9023 - accuracy: 0.3802 - val_loss: 2.1644 - val_accuracy: 0.3940\n",
      "Epoch 47/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.9006 - accuracy: 0.3830 - val_loss: 2.1522 - val_accuracy: 0.4005\n",
      "Epoch 48/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8874 - accuracy: 0.3858 - val_loss: 2.1848 - val_accuracy: 0.3795\n",
      "Epoch 49/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8885 - accuracy: 0.3861 - val_loss: 2.1825 - val_accuracy: 0.3834\n",
      "Epoch 50/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8861 - accuracy: 0.3823 - val_loss: 2.1994 - val_accuracy: 0.3763\n",
      "Epoch 51/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8887 - accuracy: 0.3813 - val_loss: 2.1857 - val_accuracy: 0.3821\n",
      "Epoch 52/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8858 - accuracy: 0.3807 - val_loss: 2.1875 - val_accuracy: 0.3876\n",
      "Epoch 53/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8815 - accuracy: 0.3818 - val_loss: 2.2259 - val_accuracy: 0.3653\n",
      "Epoch 54/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8708 - accuracy: 0.3831 - val_loss: 2.1528 - val_accuracy: 0.3892\n",
      "Epoch 55/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8795 - accuracy: 0.3863 - val_loss: 2.1620 - val_accuracy: 0.3918\n",
      "Epoch 56/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8817 - accuracy: 0.3858 - val_loss: 2.1734 - val_accuracy: 0.3766\n",
      "Epoch 57/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8638 - accuracy: 0.3848 - val_loss: 2.2102 - val_accuracy: 0.3669\n",
      "Epoch 58/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8719 - accuracy: 0.3800 - val_loss: 2.1898 - val_accuracy: 0.3843\n",
      "Epoch 59/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8696 - accuracy: 0.3869 - val_loss: 2.1849 - val_accuracy: 0.3776\n",
      "Epoch 60/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8554 - accuracy: 0.3862 - val_loss: 2.2019 - val_accuracy: 0.3734\n",
      "Epoch 61/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.8647 - accuracy: 0.3871 - val_loss: 2.1816 - val_accuracy: 0.3860\n",
      "Epoch 62/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8627 - accuracy: 0.3879 - val_loss: 2.1759 - val_accuracy: 0.3914\n",
      "Epoch 63/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8640 - accuracy: 0.3909 - val_loss: 2.2171 - val_accuracy: 0.3740\n",
      "Epoch 64/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8603 - accuracy: 0.3939 - val_loss: 2.1769 - val_accuracy: 0.3795\n",
      "Epoch 65/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8520 - accuracy: 0.3896 - val_loss: 2.1781 - val_accuracy: 0.3802\n",
      "Epoch 66/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8492 - accuracy: 0.3926 - val_loss: 2.2296 - val_accuracy: 0.3737\n",
      "Epoch 67/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8595 - accuracy: 0.3909 - val_loss: 2.1930 - val_accuracy: 0.3805\n",
      "Epoch 68/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8529 - accuracy: 0.3890 - val_loss: 2.1902 - val_accuracy: 0.3860\n",
      "Epoch 69/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8516 - accuracy: 0.3892 - val_loss: 2.1863 - val_accuracy: 0.3837\n",
      "Epoch 70/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8484 - accuracy: 0.3944 - val_loss: 2.1877 - val_accuracy: 0.3814\n",
      "Epoch 71/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8381 - accuracy: 0.3934 - val_loss: 2.2000 - val_accuracy: 0.3750\n",
      "Epoch 72/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8365 - accuracy: 0.3935 - val_loss: 2.2200 - val_accuracy: 0.3669\n",
      "Epoch 73/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8366 - accuracy: 0.3914 - val_loss: 2.1986 - val_accuracy: 0.3779\n",
      "Epoch 74/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8410 - accuracy: 0.3918 - val_loss: 2.2211 - val_accuracy: 0.3673\n",
      "Epoch 75/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8353 - accuracy: 0.3935 - val_loss: 2.1978 - val_accuracy: 0.3731\n",
      "Epoch 76/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8384 - accuracy: 0.3946 - val_loss: 2.2301 - val_accuracy: 0.3660\n",
      "Epoch 77/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8334 - accuracy: 0.3907 - val_loss: 2.2301 - val_accuracy: 0.3602\n",
      "Epoch 78/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8397 - accuracy: 0.3957 - val_loss: 2.1804 - val_accuracy: 0.3789\n",
      "Epoch 79/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8300 - accuracy: 0.3929 - val_loss: 2.1949 - val_accuracy: 0.3760\n",
      "Epoch 80/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8227 - accuracy: 0.3964 - val_loss: 2.2126 - val_accuracy: 0.3692\n",
      "Epoch 81/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8253 - accuracy: 0.3979 - val_loss: 2.1957 - val_accuracy: 0.3895\n",
      "Epoch 82/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8285 - accuracy: 0.3910 - val_loss: 2.2084 - val_accuracy: 0.3785\n",
      "Epoch 83/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8314 - accuracy: 0.4002 - val_loss: 2.1826 - val_accuracy: 0.3892\n",
      "Epoch 84/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8269 - accuracy: 0.3955 - val_loss: 2.2208 - val_accuracy: 0.3637\n",
      "Epoch 85/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8198 - accuracy: 0.4004 - val_loss: 2.2137 - val_accuracy: 0.3811\n",
      "Epoch 86/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8195 - accuracy: 0.3998 - val_loss: 2.2229 - val_accuracy: 0.3731\n",
      "Epoch 87/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8251 - accuracy: 0.3992 - val_loss: 2.2067 - val_accuracy: 0.3708\n",
      "Epoch 88/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8200 - accuracy: 0.3963 - val_loss: 2.2095 - val_accuracy: 0.3740\n",
      "Epoch 89/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8102 - accuracy: 0.4012 - val_loss: 2.2327 - val_accuracy: 0.3695\n",
      "Epoch 90/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8019 - accuracy: 0.4024 - val_loss: 2.2121 - val_accuracy: 0.3821\n",
      "Epoch 91/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8108 - accuracy: 0.4005 - val_loss: 2.2057 - val_accuracy: 0.3853\n",
      "Epoch 92/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8154 - accuracy: 0.3981 - val_loss: 2.2332 - val_accuracy: 0.3653\n",
      "Epoch 93/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8070 - accuracy: 0.3997 - val_loss: 2.2299 - val_accuracy: 0.3721\n",
      "Epoch 94/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8151 - accuracy: 0.3994 - val_loss: 2.2093 - val_accuracy: 0.3763\n",
      "Epoch 95/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8058 - accuracy: 0.4007 - val_loss: 2.2345 - val_accuracy: 0.3650\n",
      "Epoch 96/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8157 - accuracy: 0.4013 - val_loss: 2.2158 - val_accuracy: 0.3773\n",
      "Epoch 97/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8004 - accuracy: 0.3983 - val_loss: 2.2461 - val_accuracy: 0.3624\n",
      "Epoch 98/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8115 - accuracy: 0.3987 - val_loss: 2.2276 - val_accuracy: 0.3785\n",
      "Epoch 99/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8033 - accuracy: 0.4022 - val_loss: 2.2152 - val_accuracy: 0.3721\n",
      "Epoch 100/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.8020 - accuracy: 0.3987 - val_loss: 2.2168 - val_accuracy: 0.3860\n",
      "Epoch 101/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7959 - accuracy: 0.3988 - val_loss: 2.2394 - val_accuracy: 0.3676\n",
      "Epoch 102/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7961 - accuracy: 0.4044 - val_loss: 2.2367 - val_accuracy: 0.3618\n",
      "Epoch 103/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7979 - accuracy: 0.4005 - val_loss: 2.2156 - val_accuracy: 0.3702\n",
      "Epoch 104/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7927 - accuracy: 0.4052 - val_loss: 2.1965 - val_accuracy: 0.3953\n",
      "Epoch 105/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7898 - accuracy: 0.4041 - val_loss: 2.2315 - val_accuracy: 0.3686\n",
      "Epoch 106/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7920 - accuracy: 0.4068 - val_loss: 2.2156 - val_accuracy: 0.3805\n",
      "Epoch 107/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7954 - accuracy: 0.4056 - val_loss: 2.2168 - val_accuracy: 0.3744\n",
      "Epoch 108/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7956 - accuracy: 0.4032 - val_loss: 2.2163 - val_accuracy: 0.3698\n",
      "Epoch 109/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7902 - accuracy: 0.4027 - val_loss: 2.2445 - val_accuracy: 0.3795\n",
      "Epoch 110/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7842 - accuracy: 0.4038 - val_loss: 2.2329 - val_accuracy: 0.3740\n",
      "Epoch 111/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7772 - accuracy: 0.4037 - val_loss: 2.2618 - val_accuracy: 0.3576\n",
      "Epoch 112/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7955 - accuracy: 0.4056 - val_loss: 2.2491 - val_accuracy: 0.3686\n",
      "Epoch 113/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7843 - accuracy: 0.4084 - val_loss: 2.2565 - val_accuracy: 0.3650\n",
      "Epoch 114/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7906 - accuracy: 0.4009 - val_loss: 2.2190 - val_accuracy: 0.3843\n",
      "Epoch 115/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7860 - accuracy: 0.4055 - val_loss: 2.2151 - val_accuracy: 0.3818\n",
      "Epoch 116/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.7754 - accuracy: 0.4071 - val_loss: 2.2710 - val_accuracy: 0.3711\n",
      "Epoch 117/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7788 - accuracy: 0.4056 - val_loss: 2.2679 - val_accuracy: 0.3708\n",
      "Epoch 118/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7829 - accuracy: 0.4053 - val_loss: 2.2269 - val_accuracy: 0.3718\n",
      "Epoch 119/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7764 - accuracy: 0.4117 - val_loss: 2.2152 - val_accuracy: 0.3802\n",
      "Epoch 120/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7790 - accuracy: 0.4079 - val_loss: 2.2387 - val_accuracy: 0.3782\n",
      "Epoch 121/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7824 - accuracy: 0.4149 - val_loss: 2.2667 - val_accuracy: 0.3582\n",
      "Epoch 122/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7760 - accuracy: 0.4099 - val_loss: 2.2525 - val_accuracy: 0.3640\n",
      "Epoch 123/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7697 - accuracy: 0.4115 - val_loss: 2.2463 - val_accuracy: 0.3731\n",
      "Epoch 124/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7716 - accuracy: 0.4087 - val_loss: 2.2626 - val_accuracy: 0.3595\n",
      "Epoch 125/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7705 - accuracy: 0.4084 - val_loss: 2.2541 - val_accuracy: 0.3634\n",
      "Epoch 126/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7728 - accuracy: 0.4081 - val_loss: 2.2354 - val_accuracy: 0.3818\n",
      "Epoch 127/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7781 - accuracy: 0.4067 - val_loss: 2.2873 - val_accuracy: 0.3544\n",
      "Epoch 128/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7664 - accuracy: 0.4106 - val_loss: 2.2325 - val_accuracy: 0.3756\n",
      "Epoch 129/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7685 - accuracy: 0.4100 - val_loss: 2.2650 - val_accuracy: 0.3611\n",
      "Epoch 130/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7628 - accuracy: 0.4134 - val_loss: 2.2554 - val_accuracy: 0.3708\n",
      "Epoch 131/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7691 - accuracy: 0.4131 - val_loss: 2.2662 - val_accuracy: 0.3589\n",
      "Epoch 132/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7643 - accuracy: 0.4066 - val_loss: 2.2549 - val_accuracy: 0.3711\n",
      "Epoch 133/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7688 - accuracy: 0.4089 - val_loss: 2.2625 - val_accuracy: 0.3553\n",
      "Epoch 134/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7668 - accuracy: 0.4103 - val_loss: 2.2650 - val_accuracy: 0.3682\n",
      "Epoch 135/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7679 - accuracy: 0.4133 - val_loss: 2.2682 - val_accuracy: 0.3644\n",
      "Epoch 136/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7680 - accuracy: 0.4116 - val_loss: 2.2572 - val_accuracy: 0.3750\n",
      "Epoch 137/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7722 - accuracy: 0.4072 - val_loss: 2.2514 - val_accuracy: 0.3740\n",
      "Epoch 138/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7589 - accuracy: 0.4150 - val_loss: 2.2691 - val_accuracy: 0.3602\n",
      "Epoch 139/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7736 - accuracy: 0.4040 - val_loss: 2.2909 - val_accuracy: 0.3518\n",
      "Epoch 140/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7655 - accuracy: 0.4126 - val_loss: 2.2542 - val_accuracy: 0.3682\n",
      "Epoch 141/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7546 - accuracy: 0.4182 - val_loss: 2.3005 - val_accuracy: 0.3586\n",
      "Epoch 142/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7527 - accuracy: 0.4118 - val_loss: 2.2991 - val_accuracy: 0.3628\n",
      "Epoch 143/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7517 - accuracy: 0.4123 - val_loss: 2.2615 - val_accuracy: 0.3744\n",
      "Epoch 144/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7468 - accuracy: 0.4174 - val_loss: 2.2734 - val_accuracy: 0.3702\n",
      "Epoch 145/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7404 - accuracy: 0.4163 - val_loss: 2.3091 - val_accuracy: 0.3605\n",
      "Epoch 146/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7506 - accuracy: 0.4122 - val_loss: 2.3169 - val_accuracy: 0.3537\n",
      "Epoch 147/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7440 - accuracy: 0.4150 - val_loss: 2.2693 - val_accuracy: 0.3689\n",
      "Epoch 148/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7577 - accuracy: 0.4136 - val_loss: 2.2570 - val_accuracy: 0.3763\n",
      "Epoch 149/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7484 - accuracy: 0.4185 - val_loss: 2.2938 - val_accuracy: 0.3628\n",
      "Epoch 150/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7557 - accuracy: 0.4166 - val_loss: 2.2774 - val_accuracy: 0.3734\n",
      "Epoch 151/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7502 - accuracy: 0.4157 - val_loss: 2.2668 - val_accuracy: 0.3734\n",
      "Epoch 152/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7484 - accuracy: 0.4175 - val_loss: 2.2660 - val_accuracy: 0.3682\n",
      "Epoch 153/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7489 - accuracy: 0.4146 - val_loss: 2.2779 - val_accuracy: 0.3708\n",
      "Epoch 154/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7416 - accuracy: 0.4182 - val_loss: 2.2825 - val_accuracy: 0.3727\n",
      "Epoch 155/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7388 - accuracy: 0.4159 - val_loss: 2.2709 - val_accuracy: 0.3708\n",
      "Epoch 156/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7369 - accuracy: 0.4203 - val_loss: 2.2825 - val_accuracy: 0.3634\n",
      "Epoch 157/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7431 - accuracy: 0.4165 - val_loss: 2.2839 - val_accuracy: 0.3676\n",
      "Epoch 158/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7487 - accuracy: 0.4115 - val_loss: 2.2759 - val_accuracy: 0.3599\n",
      "Epoch 159/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7460 - accuracy: 0.4173 - val_loss: 2.2922 - val_accuracy: 0.3650\n",
      "Epoch 160/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7396 - accuracy: 0.4182 - val_loss: 2.2927 - val_accuracy: 0.3647\n",
      "Epoch 161/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7389 - accuracy: 0.4161 - val_loss: 2.3141 - val_accuracy: 0.3553\n",
      "Epoch 162/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7295 - accuracy: 0.4214 - val_loss: 2.3145 - val_accuracy: 0.3512\n",
      "Epoch 163/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7321 - accuracy: 0.4197 - val_loss: 2.2955 - val_accuracy: 0.3653\n",
      "Epoch 164/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7364 - accuracy: 0.4169 - val_loss: 2.3039 - val_accuracy: 0.3653\n",
      "Epoch 165/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7343 - accuracy: 0.4151 - val_loss: 2.3159 - val_accuracy: 0.3599\n",
      "Epoch 166/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7325 - accuracy: 0.4173 - val_loss: 2.2956 - val_accuracy: 0.3676\n",
      "Epoch 167/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7320 - accuracy: 0.4184 - val_loss: 2.3062 - val_accuracy: 0.3634\n",
      "Epoch 168/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7393 - accuracy: 0.4104 - val_loss: 2.2974 - val_accuracy: 0.3650\n",
      "Epoch 169/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7314 - accuracy: 0.4238 - val_loss: 2.3212 - val_accuracy: 0.3602\n",
      "Epoch 170/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7338 - accuracy: 0.4212 - val_loss: 2.3071 - val_accuracy: 0.3676\n",
      "Epoch 171/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7247 - accuracy: 0.4214 - val_loss: 2.3608 - val_accuracy: 0.3450\n",
      "Epoch 172/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7255 - accuracy: 0.4205 - val_loss: 2.2872 - val_accuracy: 0.3599\n",
      "Epoch 173/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7271 - accuracy: 0.4273 - val_loss: 2.3031 - val_accuracy: 0.3669\n",
      "Epoch 174/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7348 - accuracy: 0.4186 - val_loss: 2.2876 - val_accuracy: 0.3673\n",
      "Epoch 175/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7224 - accuracy: 0.4249 - val_loss: 2.3347 - val_accuracy: 0.3557\n",
      "Epoch 176/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7276 - accuracy: 0.4209 - val_loss: 2.3142 - val_accuracy: 0.3602\n",
      "Epoch 177/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7308 - accuracy: 0.4215 - val_loss: 2.3118 - val_accuracy: 0.3576\n",
      "Epoch 178/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7320 - accuracy: 0.4204 - val_loss: 2.3415 - val_accuracy: 0.3531\n",
      "Epoch 179/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7222 - accuracy: 0.4219 - val_loss: 2.3162 - val_accuracy: 0.3544\n",
      "Epoch 180/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7223 - accuracy: 0.4199 - val_loss: 2.2927 - val_accuracy: 0.3650\n",
      "Epoch 181/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7282 - accuracy: 0.4173 - val_loss: 2.2873 - val_accuracy: 0.3669\n",
      "Epoch 182/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.7256 - accuracy: 0.4267 - val_loss: 2.3281 - val_accuracy: 0.3470\n",
      "Epoch 183/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7168 - accuracy: 0.4238 - val_loss: 2.3037 - val_accuracy: 0.3653\n",
      "Epoch 184/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7192 - accuracy: 0.4253 - val_loss: 2.3420 - val_accuracy: 0.3399\n",
      "Epoch 185/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7180 - accuracy: 0.4226 - val_loss: 2.2968 - val_accuracy: 0.3621\n",
      "Epoch 186/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7115 - accuracy: 0.4235 - val_loss: 2.3143 - val_accuracy: 0.3650\n",
      "Epoch 187/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7147 - accuracy: 0.4287 - val_loss: 2.3174 - val_accuracy: 0.3521\n",
      "Epoch 188/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7226 - accuracy: 0.4218 - val_loss: 2.3391 - val_accuracy: 0.3618\n",
      "Epoch 189/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7236 - accuracy: 0.4209 - val_loss: 2.3417 - val_accuracy: 0.3576\n",
      "Epoch 190/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7206 - accuracy: 0.4213 - val_loss: 2.3338 - val_accuracy: 0.3483\n",
      "Epoch 191/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7096 - accuracy: 0.4237 - val_loss: 2.3462 - val_accuracy: 0.3508\n",
      "Epoch 192/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7114 - accuracy: 0.4319 - val_loss: 2.3660 - val_accuracy: 0.3486\n",
      "Epoch 193/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7167 - accuracy: 0.4243 - val_loss: 2.3604 - val_accuracy: 0.3570\n",
      "Epoch 194/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7234 - accuracy: 0.4218 - val_loss: 2.3275 - val_accuracy: 0.3608\n",
      "Epoch 195/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7105 - accuracy: 0.4314 - val_loss: 2.3615 - val_accuracy: 0.3521\n",
      "Epoch 196/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7070 - accuracy: 0.4342 - val_loss: 2.3377 - val_accuracy: 0.3660\n",
      "Epoch 197/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7082 - accuracy: 0.4253 - val_loss: 2.3414 - val_accuracy: 0.3602\n",
      "Epoch 198/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7055 - accuracy: 0.4313 - val_loss: 2.3458 - val_accuracy: 0.3476\n",
      "Epoch 199/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7109 - accuracy: 0.4291 - val_loss: 2.3625 - val_accuracy: 0.3589\n",
      "Epoch 200/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7028 - accuracy: 0.4353 - val_loss: 2.3360 - val_accuracy: 0.3505\n",
      "Epoch 201/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7057 - accuracy: 0.4285 - val_loss: 2.3090 - val_accuracy: 0.3634\n",
      "Epoch 202/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7107 - accuracy: 0.4264 - val_loss: 2.3525 - val_accuracy: 0.3563\n",
      "Epoch 203/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7000 - accuracy: 0.4253 - val_loss: 2.3360 - val_accuracy: 0.3599\n",
      "Epoch 204/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7039 - accuracy: 0.4277 - val_loss: 2.3518 - val_accuracy: 0.3547\n",
      "Epoch 205/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7144 - accuracy: 0.4189 - val_loss: 2.3643 - val_accuracy: 0.3376\n",
      "Epoch 206/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6979 - accuracy: 0.4334 - val_loss: 2.3633 - val_accuracy: 0.3524\n",
      "Epoch 207/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6990 - accuracy: 0.4324 - val_loss: 2.3366 - val_accuracy: 0.3628\n",
      "Epoch 208/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7082 - accuracy: 0.4286 - val_loss: 2.3457 - val_accuracy: 0.3550\n",
      "Epoch 209/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6991 - accuracy: 0.4275 - val_loss: 2.3469 - val_accuracy: 0.3579\n",
      "Epoch 210/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6971 - accuracy: 0.4299 - val_loss: 2.3465 - val_accuracy: 0.3389\n",
      "Epoch 211/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7053 - accuracy: 0.4306 - val_loss: 2.3430 - val_accuracy: 0.3409\n",
      "Epoch 212/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7062 - accuracy: 0.4281 - val_loss: 2.3474 - val_accuracy: 0.3450\n",
      "Epoch 213/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6974 - accuracy: 0.4255 - val_loss: 2.3574 - val_accuracy: 0.3560\n",
      "Epoch 214/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6959 - accuracy: 0.4299 - val_loss: 2.3395 - val_accuracy: 0.3605\n",
      "Epoch 215/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6928 - accuracy: 0.4278 - val_loss: 2.3495 - val_accuracy: 0.3579\n",
      "Epoch 216/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6973 - accuracy: 0.4326 - val_loss: 2.3682 - val_accuracy: 0.3531\n",
      "Epoch 217/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6961 - accuracy: 0.4326 - val_loss: 2.3495 - val_accuracy: 0.3592\n",
      "Epoch 218/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6973 - accuracy: 0.4282 - val_loss: 2.3755 - val_accuracy: 0.3492\n",
      "Epoch 219/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7005 - accuracy: 0.4342 - val_loss: 2.3739 - val_accuracy: 0.3508\n",
      "Epoch 220/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7017 - accuracy: 0.4272 - val_loss: 2.3724 - val_accuracy: 0.3531\n",
      "Epoch 221/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6905 - accuracy: 0.4325 - val_loss: 2.3606 - val_accuracy: 0.3486\n",
      "Epoch 222/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6981 - accuracy: 0.4325 - val_loss: 2.3883 - val_accuracy: 0.3470\n",
      "Epoch 223/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.7042 - accuracy: 0.4293 - val_loss: 2.3458 - val_accuracy: 0.3599\n",
      "Epoch 224/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6940 - accuracy: 0.4327 - val_loss: 2.3729 - val_accuracy: 0.3521\n",
      "Epoch 225/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6956 - accuracy: 0.4294 - val_loss: 2.3640 - val_accuracy: 0.3541\n",
      "Epoch 226/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6955 - accuracy: 0.4296 - val_loss: 2.3513 - val_accuracy: 0.3605\n",
      "Epoch 227/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6898 - accuracy: 0.4296 - val_loss: 2.3777 - val_accuracy: 0.3499\n",
      "Epoch 228/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6829 - accuracy: 0.4363 - val_loss: 2.3581 - val_accuracy: 0.3550\n",
      "Epoch 229/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6934 - accuracy: 0.4368 - val_loss: 2.3716 - val_accuracy: 0.3495\n",
      "Epoch 230/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6844 - accuracy: 0.4353 - val_loss: 2.3713 - val_accuracy: 0.3483\n",
      "Epoch 231/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6938 - accuracy: 0.4289 - val_loss: 2.3933 - val_accuracy: 0.3489\n",
      "Epoch 232/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6905 - accuracy: 0.4357 - val_loss: 2.3777 - val_accuracy: 0.3505\n",
      "Epoch 233/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6852 - accuracy: 0.4359 - val_loss: 2.3700 - val_accuracy: 0.3479\n",
      "Epoch 234/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6895 - accuracy: 0.4364 - val_loss: 2.3635 - val_accuracy: 0.3425\n",
      "Epoch 235/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6914 - accuracy: 0.4321 - val_loss: 2.4062 - val_accuracy: 0.3415\n",
      "Epoch 236/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6950 - accuracy: 0.4264 - val_loss: 2.3867 - val_accuracy: 0.3486\n",
      "Epoch 237/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6849 - accuracy: 0.4341 - val_loss: 2.4060 - val_accuracy: 0.3396\n",
      "Epoch 238/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6896 - accuracy: 0.4296 - val_loss: 2.3666 - val_accuracy: 0.3463\n",
      "Epoch 239/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6853 - accuracy: 0.4318 - val_loss: 2.4000 - val_accuracy: 0.3373\n",
      "Epoch 240/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6931 - accuracy: 0.4320 - val_loss: 2.3420 - val_accuracy: 0.3415\n",
      "Epoch 241/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6850 - accuracy: 0.4316 - val_loss: 2.3682 - val_accuracy: 0.3505\n",
      "Epoch 242/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6870 - accuracy: 0.4275 - val_loss: 2.3312 - val_accuracy: 0.3640\n",
      "Epoch 243/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6880 - accuracy: 0.4376 - val_loss: 2.3784 - val_accuracy: 0.3428\n",
      "Epoch 244/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6856 - accuracy: 0.4305 - val_loss: 2.3694 - val_accuracy: 0.3466\n",
      "Epoch 245/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6823 - accuracy: 0.4345 - val_loss: 2.3944 - val_accuracy: 0.3566\n",
      "Epoch 246/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6784 - accuracy: 0.4401 - val_loss: 2.3916 - val_accuracy: 0.3515\n",
      "Epoch 247/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6801 - accuracy: 0.4361 - val_loss: 2.3919 - val_accuracy: 0.3463\n",
      "Epoch 248/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6846 - accuracy: 0.4334 - val_loss: 2.4034 - val_accuracy: 0.3331\n",
      "Epoch 249/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6700 - accuracy: 0.4390 - val_loss: 2.3940 - val_accuracy: 0.3396\n",
      "Epoch 250/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6836 - accuracy: 0.4358 - val_loss: 2.4190 - val_accuracy: 0.3425\n",
      "Epoch 251/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6832 - accuracy: 0.4361 - val_loss: 2.4156 - val_accuracy: 0.3331\n",
      "Epoch 252/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6789 - accuracy: 0.4331 - val_loss: 2.3871 - val_accuracy: 0.3473\n",
      "Epoch 253/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6828 - accuracy: 0.4345 - val_loss: 2.3964 - val_accuracy: 0.3515\n",
      "Epoch 254/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.6788 - accuracy: 0.4360 - val_loss: 2.4039 - val_accuracy: 0.3515\n",
      "Epoch 255/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6738 - accuracy: 0.4346 - val_loss: 2.3988 - val_accuracy: 0.3405\n",
      "Epoch 256/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6858 - accuracy: 0.4317 - val_loss: 2.4179 - val_accuracy: 0.3447\n",
      "Epoch 257/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6637 - accuracy: 0.4401 - val_loss: 2.4275 - val_accuracy: 0.3434\n",
      "Epoch 258/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6686 - accuracy: 0.4468 - val_loss: 2.4434 - val_accuracy: 0.3376\n",
      "Epoch 259/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6727 - accuracy: 0.4380 - val_loss: 2.4068 - val_accuracy: 0.3466\n",
      "Epoch 260/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6774 - accuracy: 0.4366 - val_loss: 2.3927 - val_accuracy: 0.3412\n",
      "Epoch 261/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6685 - accuracy: 0.4381 - val_loss: 2.3897 - val_accuracy: 0.3450\n",
      "Epoch 262/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6739 - accuracy: 0.4385 - val_loss: 2.4082 - val_accuracy: 0.3457\n",
      "Epoch 263/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6674 - accuracy: 0.4421 - val_loss: 2.4032 - val_accuracy: 0.3402\n",
      "Epoch 264/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6641 - accuracy: 0.4405 - val_loss: 2.4170 - val_accuracy: 0.3450\n",
      "Epoch 265/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6727 - accuracy: 0.4413 - val_loss: 2.4208 - val_accuracy: 0.3392\n",
      "Epoch 266/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6723 - accuracy: 0.4441 - val_loss: 2.3722 - val_accuracy: 0.3524\n",
      "Epoch 267/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6761 - accuracy: 0.4332 - val_loss: 2.4146 - val_accuracy: 0.3409\n",
      "Epoch 268/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6745 - accuracy: 0.4352 - val_loss: 2.4245 - val_accuracy: 0.3499\n",
      "Epoch 269/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6804 - accuracy: 0.4364 - val_loss: 2.4042 - val_accuracy: 0.3473\n",
      "Epoch 270/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6642 - accuracy: 0.4362 - val_loss: 2.4329 - val_accuracy: 0.3347\n",
      "Epoch 271/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6769 - accuracy: 0.4407 - val_loss: 2.4078 - val_accuracy: 0.3434\n",
      "Epoch 272/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6686 - accuracy: 0.4377 - val_loss: 2.3984 - val_accuracy: 0.3534\n",
      "Epoch 273/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6645 - accuracy: 0.4408 - val_loss: 2.4389 - val_accuracy: 0.3389\n",
      "Epoch 274/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6528 - accuracy: 0.4428 - val_loss: 2.4104 - val_accuracy: 0.3495\n",
      "Epoch 275/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6677 - accuracy: 0.4371 - val_loss: 2.4366 - val_accuracy: 0.3463\n",
      "Epoch 276/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6660 - accuracy: 0.4414 - val_loss: 2.4362 - val_accuracy: 0.3409\n",
      "Epoch 277/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6618 - accuracy: 0.4426 - val_loss: 2.4243 - val_accuracy: 0.3460\n",
      "Epoch 278/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6670 - accuracy: 0.4406 - val_loss: 2.4371 - val_accuracy: 0.3331\n",
      "Epoch 279/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6580 - accuracy: 0.4439 - val_loss: 2.4395 - val_accuracy: 0.3360\n",
      "Epoch 280/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6651 - accuracy: 0.4403 - val_loss: 2.4101 - val_accuracy: 0.3434\n",
      "Epoch 281/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6586 - accuracy: 0.4382 - val_loss: 2.4291 - val_accuracy: 0.3447\n",
      "Epoch 282/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6630 - accuracy: 0.4413 - val_loss: 2.4361 - val_accuracy: 0.3386\n",
      "Epoch 283/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6609 - accuracy: 0.4402 - val_loss: 2.4245 - val_accuracy: 0.3370\n",
      "Epoch 284/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6723 - accuracy: 0.4390 - val_loss: 2.4011 - val_accuracy: 0.3454\n",
      "Epoch 285/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6585 - accuracy: 0.4438 - val_loss: 2.4315 - val_accuracy: 0.3415\n",
      "Epoch 286/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6622 - accuracy: 0.4380 - val_loss: 2.4218 - val_accuracy: 0.3389\n",
      "Epoch 287/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6637 - accuracy: 0.4451 - val_loss: 2.4391 - val_accuracy: 0.3396\n",
      "Epoch 288/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6592 - accuracy: 0.4385 - val_loss: 2.4038 - val_accuracy: 0.3515\n",
      "Epoch 289/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6502 - accuracy: 0.4422 - val_loss: 2.4184 - val_accuracy: 0.3492\n",
      "Epoch 290/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6647 - accuracy: 0.4408 - val_loss: 2.4402 - val_accuracy: 0.3447\n",
      "Epoch 291/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6524 - accuracy: 0.4440 - val_loss: 2.4441 - val_accuracy: 0.3421\n",
      "Epoch 292/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6587 - accuracy: 0.4435 - val_loss: 2.4662 - val_accuracy: 0.3421\n",
      "Epoch 293/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6555 - accuracy: 0.4442 - val_loss: 2.4518 - val_accuracy: 0.3360\n",
      "Epoch 294/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6541 - accuracy: 0.4429 - val_loss: 2.4251 - val_accuracy: 0.3454\n",
      "Epoch 295/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6521 - accuracy: 0.4445 - val_loss: 2.4328 - val_accuracy: 0.3405\n",
      "Epoch 296/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6597 - accuracy: 0.4433 - val_loss: 2.4471 - val_accuracy: 0.3428\n",
      "Epoch 297/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6600 - accuracy: 0.4438 - val_loss: 2.4430 - val_accuracy: 0.3483\n",
      "Epoch 298/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6606 - accuracy: 0.4409 - val_loss: 2.4177 - val_accuracy: 0.3502\n",
      "Epoch 299/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6510 - accuracy: 0.4475 - val_loss: 2.4445 - val_accuracy: 0.3457\n",
      "Epoch 300/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6559 - accuracy: 0.4455 - val_loss: 2.4581 - val_accuracy: 0.3376\n",
      "Epoch 301/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6500 - accuracy: 0.4362 - val_loss: 2.4770 - val_accuracy: 0.3392\n",
      "Epoch 302/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6539 - accuracy: 0.4419 - val_loss: 2.4423 - val_accuracy: 0.3466\n",
      "Epoch 303/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6576 - accuracy: 0.4445 - val_loss: 2.4363 - val_accuracy: 0.3418\n",
      "Epoch 304/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6527 - accuracy: 0.4448 - val_loss: 2.4011 - val_accuracy: 0.3495\n",
      "Epoch 305/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6619 - accuracy: 0.4437 - val_loss: 2.4098 - val_accuracy: 0.3473\n",
      "Epoch 306/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6511 - accuracy: 0.4482 - val_loss: 2.4338 - val_accuracy: 0.3386\n",
      "Epoch 307/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6469 - accuracy: 0.4487 - val_loss: 2.3946 - val_accuracy: 0.3508\n",
      "Epoch 308/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6508 - accuracy: 0.4426 - val_loss: 2.4680 - val_accuracy: 0.3431\n",
      "Epoch 309/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.6592 - accuracy: 0.4374 - val_loss: 2.4709 - val_accuracy: 0.3383\n",
      "Epoch 310/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6482 - accuracy: 0.4453 - val_loss: 2.4489 - val_accuracy: 0.3444\n",
      "Epoch 311/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6538 - accuracy: 0.4405 - val_loss: 2.4627 - val_accuracy: 0.3383\n",
      "Epoch 312/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6460 - accuracy: 0.4485 - val_loss: 2.4729 - val_accuracy: 0.3354\n",
      "Epoch 313/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6480 - accuracy: 0.4457 - val_loss: 2.4690 - val_accuracy: 0.3396\n",
      "Epoch 314/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6520 - accuracy: 0.4426 - val_loss: 2.4936 - val_accuracy: 0.3322\n",
      "Epoch 315/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6506 - accuracy: 0.4386 - val_loss: 2.4413 - val_accuracy: 0.3431\n",
      "Epoch 316/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6523 - accuracy: 0.4457 - val_loss: 2.4489 - val_accuracy: 0.3473\n",
      "Epoch 317/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6395 - accuracy: 0.4438 - val_loss: 2.4681 - val_accuracy: 0.3450\n",
      "Epoch 318/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6469 - accuracy: 0.4451 - val_loss: 2.4563 - val_accuracy: 0.3351\n",
      "Epoch 319/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6456 - accuracy: 0.4480 - val_loss: 2.4352 - val_accuracy: 0.3438\n",
      "Epoch 320/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6520 - accuracy: 0.4449 - val_loss: 2.4547 - val_accuracy: 0.3399\n",
      "Epoch 321/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6375 - accuracy: 0.4406 - val_loss: 2.4644 - val_accuracy: 0.3409\n",
      "Epoch 322/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6439 - accuracy: 0.4420 - val_loss: 2.4736 - val_accuracy: 0.3399\n",
      "Epoch 323/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6405 - accuracy: 0.4508 - val_loss: 2.4959 - val_accuracy: 0.3425\n",
      "Epoch 324/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6588 - accuracy: 0.4433 - val_loss: 2.4840 - val_accuracy: 0.3354\n",
      "Epoch 325/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6402 - accuracy: 0.4446 - val_loss: 2.4476 - val_accuracy: 0.3454\n",
      "Epoch 326/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6494 - accuracy: 0.4441 - val_loss: 2.4387 - val_accuracy: 0.3489\n",
      "Epoch 327/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6400 - accuracy: 0.4482 - val_loss: 2.4841 - val_accuracy: 0.3409\n",
      "Epoch 328/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6333 - accuracy: 0.4518 - val_loss: 2.4413 - val_accuracy: 0.3454\n",
      "Epoch 329/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6370 - accuracy: 0.4474 - val_loss: 2.4514 - val_accuracy: 0.3454\n",
      "Epoch 330/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6442 - accuracy: 0.4419 - val_loss: 2.4510 - val_accuracy: 0.3450\n",
      "Epoch 331/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6396 - accuracy: 0.4511 - val_loss: 2.4608 - val_accuracy: 0.3454\n",
      "Epoch 332/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6394 - accuracy: 0.4442 - val_loss: 2.4618 - val_accuracy: 0.3441\n",
      "Epoch 333/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6439 - accuracy: 0.4531 - val_loss: 2.5006 - val_accuracy: 0.3396\n",
      "Epoch 334/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6451 - accuracy: 0.4495 - val_loss: 2.4080 - val_accuracy: 0.3495\n",
      "Epoch 335/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6305 - accuracy: 0.4472 - val_loss: 2.4558 - val_accuracy: 0.3454\n",
      "Epoch 336/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6342 - accuracy: 0.4449 - val_loss: 2.4911 - val_accuracy: 0.3457\n",
      "Epoch 337/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6340 - accuracy: 0.4424 - val_loss: 2.4823 - val_accuracy: 0.3392\n",
      "Epoch 338/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6365 - accuracy: 0.4495 - val_loss: 2.4781 - val_accuracy: 0.3373\n",
      "Epoch 339/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6452 - accuracy: 0.4477 - val_loss: 2.4430 - val_accuracy: 0.3425\n",
      "Epoch 340/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6505 - accuracy: 0.4519 - val_loss: 2.4646 - val_accuracy: 0.3438\n",
      "Epoch 341/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6417 - accuracy: 0.4518 - val_loss: 2.4802 - val_accuracy: 0.3428\n",
      "Epoch 342/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6400 - accuracy: 0.4418 - val_loss: 2.4739 - val_accuracy: 0.3409\n",
      "Epoch 343/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6438 - accuracy: 0.4458 - val_loss: 2.4804 - val_accuracy: 0.3309\n",
      "Epoch 344/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6392 - accuracy: 0.4461 - val_loss: 2.4929 - val_accuracy: 0.3386\n",
      "Epoch 345/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6449 - accuracy: 0.4420 - val_loss: 2.4923 - val_accuracy: 0.3438\n",
      "Epoch 346/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6301 - accuracy: 0.4537 - val_loss: 2.5013 - val_accuracy: 0.3392\n",
      "Epoch 347/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6377 - accuracy: 0.4527 - val_loss: 2.4686 - val_accuracy: 0.3479\n",
      "Epoch 348/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6390 - accuracy: 0.4485 - val_loss: 2.5101 - val_accuracy: 0.3357\n",
      "Epoch 349/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6319 - accuracy: 0.4454 - val_loss: 2.5196 - val_accuracy: 0.3351\n",
      "Epoch 350/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6444 - accuracy: 0.4443 - val_loss: 2.4982 - val_accuracy: 0.3396\n",
      "Epoch 351/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6335 - accuracy: 0.4513 - val_loss: 2.4614 - val_accuracy: 0.3479\n",
      "Epoch 352/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6399 - accuracy: 0.4412 - val_loss: 2.4842 - val_accuracy: 0.3421\n",
      "Epoch 353/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6422 - accuracy: 0.4480 - val_loss: 2.4927 - val_accuracy: 0.3383\n",
      "Epoch 354/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6198 - accuracy: 0.4539 - val_loss: 2.4869 - val_accuracy: 0.3380\n",
      "Epoch 355/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6287 - accuracy: 0.4516 - val_loss: 2.4961 - val_accuracy: 0.3409\n",
      "Epoch 356/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6377 - accuracy: 0.4511 - val_loss: 2.4706 - val_accuracy: 0.3466\n",
      "Epoch 357/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6471 - accuracy: 0.4447 - val_loss: 2.4813 - val_accuracy: 0.3380\n",
      "Epoch 358/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6197 - accuracy: 0.4508 - val_loss: 2.4863 - val_accuracy: 0.3457\n",
      "Epoch 359/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6248 - accuracy: 0.4554 - val_loss: 2.4981 - val_accuracy: 0.3463\n",
      "Epoch 360/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6321 - accuracy: 0.4471 - val_loss: 2.4910 - val_accuracy: 0.3463\n",
      "Epoch 361/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6253 - accuracy: 0.4519 - val_loss: 2.5144 - val_accuracy: 0.3392\n",
      "Epoch 362/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6360 - accuracy: 0.4497 - val_loss: 2.5268 - val_accuracy: 0.3357\n",
      "Epoch 363/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6330 - accuracy: 0.4484 - val_loss: 2.4922 - val_accuracy: 0.3399\n",
      "Epoch 364/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6244 - accuracy: 0.4551 - val_loss: 2.5057 - val_accuracy: 0.3412\n",
      "Epoch 365/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6209 - accuracy: 0.4491 - val_loss: 2.4699 - val_accuracy: 0.3483\n",
      "Epoch 366/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6365 - accuracy: 0.4447 - val_loss: 2.4829 - val_accuracy: 0.3428\n",
      "Epoch 367/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6290 - accuracy: 0.4527 - val_loss: 2.5177 - val_accuracy: 0.3405\n",
      "Epoch 368/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6324 - accuracy: 0.4487 - val_loss: 2.4862 - val_accuracy: 0.3463\n",
      "Epoch 369/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6309 - accuracy: 0.4451 - val_loss: 2.4823 - val_accuracy: 0.3305\n",
      "Epoch 370/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6338 - accuracy: 0.4523 - val_loss: 2.5283 - val_accuracy: 0.3283\n",
      "Epoch 371/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6284 - accuracy: 0.4522 - val_loss: 2.4744 - val_accuracy: 0.3418\n",
      "Epoch 372/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6254 - accuracy: 0.4505 - val_loss: 2.4995 - val_accuracy: 0.3434\n",
      "Epoch 373/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6227 - accuracy: 0.4531 - val_loss: 2.5491 - val_accuracy: 0.3357\n",
      "Epoch 374/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6301 - accuracy: 0.4470 - val_loss: 2.5097 - val_accuracy: 0.3415\n",
      "Epoch 375/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6234 - accuracy: 0.4532 - val_loss: 2.5298 - val_accuracy: 0.3302\n",
      "Epoch 376/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.6279 - accuracy: 0.4489 - val_loss: 2.4875 - val_accuracy: 0.3415\n",
      "Epoch 377/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6256 - accuracy: 0.4544 - val_loss: 2.4979 - val_accuracy: 0.3380\n",
      "Epoch 378/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6241 - accuracy: 0.4528 - val_loss: 2.5005 - val_accuracy: 0.3347\n",
      "Epoch 379/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6201 - accuracy: 0.4514 - val_loss: 2.5208 - val_accuracy: 0.3357\n",
      "Epoch 380/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6245 - accuracy: 0.4543 - val_loss: 2.5178 - val_accuracy: 0.3376\n",
      "Epoch 381/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6313 - accuracy: 0.4504 - val_loss: 2.5305 - val_accuracy: 0.3351\n",
      "Epoch 382/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6297 - accuracy: 0.4483 - val_loss: 2.4983 - val_accuracy: 0.3370\n",
      "Epoch 383/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6179 - accuracy: 0.4512 - val_loss: 2.5369 - val_accuracy: 0.3344\n",
      "Epoch 384/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6178 - accuracy: 0.4501 - val_loss: 2.4945 - val_accuracy: 0.3405\n",
      "Epoch 385/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6194 - accuracy: 0.4566 - val_loss: 2.4964 - val_accuracy: 0.3418\n",
      "Epoch 386/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6179 - accuracy: 0.4506 - val_loss: 2.5453 - val_accuracy: 0.3402\n",
      "Epoch 387/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6219 - accuracy: 0.4559 - val_loss: 2.5218 - val_accuracy: 0.3428\n",
      "Epoch 388/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6261 - accuracy: 0.4567 - val_loss: 2.5356 - val_accuracy: 0.3341\n",
      "Epoch 389/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6149 - accuracy: 0.4524 - val_loss: 2.5427 - val_accuracy: 0.3289\n",
      "Epoch 390/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6261 - accuracy: 0.4533 - val_loss: 2.5472 - val_accuracy: 0.3421\n",
      "Epoch 391/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6198 - accuracy: 0.4512 - val_loss: 2.5797 - val_accuracy: 0.3315\n",
      "Epoch 392/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6280 - accuracy: 0.4494 - val_loss: 2.5652 - val_accuracy: 0.3238\n",
      "Epoch 393/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6148 - accuracy: 0.4567 - val_loss: 2.5271 - val_accuracy: 0.3444\n",
      "Epoch 394/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6165 - accuracy: 0.4499 - val_loss: 2.5115 - val_accuracy: 0.3434\n",
      "Epoch 395/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6073 - accuracy: 0.4566 - val_loss: 2.5397 - val_accuracy: 0.3386\n",
      "Epoch 396/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6146 - accuracy: 0.4498 - val_loss: 2.4897 - val_accuracy: 0.3402\n",
      "Epoch 397/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6151 - accuracy: 0.4596 - val_loss: 2.5003 - val_accuracy: 0.3434\n",
      "Epoch 398/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6224 - accuracy: 0.4520 - val_loss: 2.5331 - val_accuracy: 0.3218\n",
      "Epoch 399/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6190 - accuracy: 0.4517 - val_loss: 2.5116 - val_accuracy: 0.3351\n",
      "Epoch 400/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6167 - accuracy: 0.4571 - val_loss: 2.4903 - val_accuracy: 0.3450\n",
      "Epoch 401/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6102 - accuracy: 0.4634 - val_loss: 2.5369 - val_accuracy: 0.3363\n",
      "Epoch 402/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6274 - accuracy: 0.4490 - val_loss: 2.5102 - val_accuracy: 0.3409\n",
      "Epoch 403/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6126 - accuracy: 0.4542 - val_loss: 2.5718 - val_accuracy: 0.3322\n",
      "Epoch 404/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6301 - accuracy: 0.4569 - val_loss: 2.5530 - val_accuracy: 0.3444\n",
      "Epoch 405/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6273 - accuracy: 0.4497 - val_loss: 2.4950 - val_accuracy: 0.3470\n",
      "Epoch 406/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6090 - accuracy: 0.4569 - val_loss: 2.5434 - val_accuracy: 0.3351\n",
      "Epoch 407/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6129 - accuracy: 0.4545 - val_loss: 2.5785 - val_accuracy: 0.3296\n",
      "Epoch 408/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6173 - accuracy: 0.4556 - val_loss: 2.5073 - val_accuracy: 0.3392\n",
      "Epoch 409/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6151 - accuracy: 0.4522 - val_loss: 2.5137 - val_accuracy: 0.3315\n",
      "Epoch 410/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6192 - accuracy: 0.4586 - val_loss: 2.5157 - val_accuracy: 0.3373\n",
      "Epoch 411/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6192 - accuracy: 0.4493 - val_loss: 2.5448 - val_accuracy: 0.3392\n",
      "Epoch 412/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6154 - accuracy: 0.4516 - val_loss: 2.5769 - val_accuracy: 0.3334\n",
      "Epoch 413/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6026 - accuracy: 0.4554 - val_loss: 2.5428 - val_accuracy: 0.3325\n",
      "Epoch 414/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6147 - accuracy: 0.4526 - val_loss: 2.5354 - val_accuracy: 0.3367\n",
      "Epoch 415/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6175 - accuracy: 0.4507 - val_loss: 2.5344 - val_accuracy: 0.3380\n",
      "Epoch 416/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6127 - accuracy: 0.4544 - val_loss: 2.5481 - val_accuracy: 0.3392\n",
      "Epoch 417/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6110 - accuracy: 0.4515 - val_loss: 2.5712 - val_accuracy: 0.3299\n",
      "Epoch 418/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6222 - accuracy: 0.4518 - val_loss: 2.5036 - val_accuracy: 0.3396\n",
      "Epoch 419/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6073 - accuracy: 0.4555 - val_loss: 2.5478 - val_accuracy: 0.3280\n",
      "Epoch 420/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6033 - accuracy: 0.4576 - val_loss: 2.5288 - val_accuracy: 0.3425\n",
      "Epoch 421/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6193 - accuracy: 0.4567 - val_loss: 2.5220 - val_accuracy: 0.3370\n",
      "Epoch 422/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6076 - accuracy: 0.4586 - val_loss: 2.5307 - val_accuracy: 0.3396\n",
      "Epoch 423/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6078 - accuracy: 0.4609 - val_loss: 2.5354 - val_accuracy: 0.3293\n",
      "Epoch 424/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6150 - accuracy: 0.4523 - val_loss: 2.5633 - val_accuracy: 0.3351\n",
      "Epoch 425/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6153 - accuracy: 0.4525 - val_loss: 2.5719 - val_accuracy: 0.3322\n",
      "Epoch 426/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6096 - accuracy: 0.4563 - val_loss: 2.5228 - val_accuracy: 0.3370\n",
      "Epoch 427/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6074 - accuracy: 0.4575 - val_loss: 2.5183 - val_accuracy: 0.3470\n",
      "Epoch 428/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6031 - accuracy: 0.4587 - val_loss: 2.5291 - val_accuracy: 0.3447\n",
      "Epoch 429/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6051 - accuracy: 0.4588 - val_loss: 2.5596 - val_accuracy: 0.3328\n",
      "Epoch 430/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6156 - accuracy: 0.4518 - val_loss: 2.5707 - val_accuracy: 0.3296\n",
      "Epoch 431/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.6009 - accuracy: 0.4607 - val_loss: 2.5610 - val_accuracy: 0.3415\n",
      "Epoch 432/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6064 - accuracy: 0.4614 - val_loss: 2.6047 - val_accuracy: 0.3251\n",
      "Epoch 433/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6077 - accuracy: 0.4567 - val_loss: 2.5466 - val_accuracy: 0.3360\n",
      "Epoch 434/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6050 - accuracy: 0.4530 - val_loss: 2.5742 - val_accuracy: 0.3357\n",
      "Epoch 435/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6035 - accuracy: 0.4579 - val_loss: 2.5309 - val_accuracy: 0.3293\n",
      "Epoch 436/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6076 - accuracy: 0.4560 - val_loss: 2.5490 - val_accuracy: 0.3409\n",
      "Epoch 437/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6084 - accuracy: 0.4555 - val_loss: 2.5394 - val_accuracy: 0.3354\n",
      "Epoch 438/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6092 - accuracy: 0.4572 - val_loss: 2.5675 - val_accuracy: 0.3302\n",
      "Epoch 439/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6091 - accuracy: 0.4571 - val_loss: 2.5628 - val_accuracy: 0.3351\n",
      "Epoch 440/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6052 - accuracy: 0.4531 - val_loss: 2.5660 - val_accuracy: 0.3351\n",
      "Epoch 441/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6016 - accuracy: 0.4541 - val_loss: 2.5426 - val_accuracy: 0.3434\n",
      "Epoch 442/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5956 - accuracy: 0.4604 - val_loss: 2.6090 - val_accuracy: 0.3360\n",
      "Epoch 443/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6062 - accuracy: 0.4629 - val_loss: 2.5484 - val_accuracy: 0.3402\n",
      "Epoch 444/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6058 - accuracy: 0.4550 - val_loss: 2.5562 - val_accuracy: 0.3389\n",
      "Epoch 445/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6156 - accuracy: 0.4509 - val_loss: 2.5944 - val_accuracy: 0.3238\n",
      "Epoch 446/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5938 - accuracy: 0.4589 - val_loss: 2.5844 - val_accuracy: 0.3380\n",
      "Epoch 447/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6064 - accuracy: 0.4542 - val_loss: 2.5404 - val_accuracy: 0.3283\n",
      "Epoch 448/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6032 - accuracy: 0.4567 - val_loss: 2.5621 - val_accuracy: 0.3257\n",
      "Epoch 449/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6012 - accuracy: 0.4613 - val_loss: 2.5517 - val_accuracy: 0.3347\n",
      "Epoch 450/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6053 - accuracy: 0.4578 - val_loss: 2.5555 - val_accuracy: 0.3402\n",
      "Epoch 451/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6099 - accuracy: 0.4529 - val_loss: 2.5889 - val_accuracy: 0.3289\n",
      "Epoch 452/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5971 - accuracy: 0.4662 - val_loss: 2.5844 - val_accuracy: 0.3347\n",
      "Epoch 453/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5946 - accuracy: 0.4617 - val_loss: 2.5753 - val_accuracy: 0.3341\n",
      "Epoch 454/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5982 - accuracy: 0.4648 - val_loss: 2.5530 - val_accuracy: 0.3334\n",
      "Epoch 455/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6001 - accuracy: 0.4599 - val_loss: 2.5711 - val_accuracy: 0.3347\n",
      "Epoch 456/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6012 - accuracy: 0.4613 - val_loss: 2.5470 - val_accuracy: 0.3447\n",
      "Epoch 457/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6010 - accuracy: 0.4568 - val_loss: 2.5745 - val_accuracy: 0.3260\n",
      "Epoch 458/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6028 - accuracy: 0.4561 - val_loss: 2.5522 - val_accuracy: 0.3373\n",
      "Epoch 459/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6069 - accuracy: 0.4565 - val_loss: 2.6176 - val_accuracy: 0.3315\n",
      "Epoch 460/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5969 - accuracy: 0.4617 - val_loss: 2.5786 - val_accuracy: 0.3351\n",
      "Epoch 461/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6003 - accuracy: 0.4625 - val_loss: 2.5667 - val_accuracy: 0.3331\n",
      "Epoch 462/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6006 - accuracy: 0.4563 - val_loss: 2.5568 - val_accuracy: 0.3386\n",
      "Epoch 463/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5992 - accuracy: 0.4600 - val_loss: 2.5289 - val_accuracy: 0.3421\n",
      "Epoch 464/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5999 - accuracy: 0.4554 - val_loss: 2.5789 - val_accuracy: 0.3338\n",
      "Epoch 465/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6114 - accuracy: 0.4591 - val_loss: 2.5552 - val_accuracy: 0.3386\n",
      "Epoch 466/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5998 - accuracy: 0.4605 - val_loss: 2.5692 - val_accuracy: 0.3351\n",
      "Epoch 467/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6070 - accuracy: 0.4594 - val_loss: 2.5334 - val_accuracy: 0.3450\n",
      "Epoch 468/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6049 - accuracy: 0.4606 - val_loss: 2.6046 - val_accuracy: 0.3376\n",
      "Epoch 469/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5936 - accuracy: 0.4584 - val_loss: 2.5809 - val_accuracy: 0.3380\n",
      "Epoch 470/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5929 - accuracy: 0.4600 - val_loss: 2.5449 - val_accuracy: 0.3473\n",
      "Epoch 471/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5834 - accuracy: 0.4637 - val_loss: 2.6467 - val_accuracy: 0.3267\n",
      "Epoch 472/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6017 - accuracy: 0.4573 - val_loss: 2.6098 - val_accuracy: 0.3354\n",
      "Epoch 473/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6003 - accuracy: 0.4603 - val_loss: 2.6146 - val_accuracy: 0.3373\n",
      "Epoch 474/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5927 - accuracy: 0.4627 - val_loss: 2.5954 - val_accuracy: 0.3312\n",
      "Epoch 475/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5857 - accuracy: 0.4586 - val_loss: 2.6047 - val_accuracy: 0.3363\n",
      "Epoch 476/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5922 - accuracy: 0.4635 - val_loss: 2.6003 - val_accuracy: 0.3312\n",
      "Epoch 477/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5972 - accuracy: 0.4620 - val_loss: 2.5857 - val_accuracy: 0.3357\n",
      "Epoch 478/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5972 - accuracy: 0.4620 - val_loss: 2.5683 - val_accuracy: 0.3473\n",
      "Epoch 479/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.6061 - accuracy: 0.4599 - val_loss: 2.6108 - val_accuracy: 0.3354\n",
      "Epoch 480/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5899 - accuracy: 0.4593 - val_loss: 2.6322 - val_accuracy: 0.3370\n",
      "Epoch 481/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5854 - accuracy: 0.4650 - val_loss: 2.6140 - val_accuracy: 0.3312\n",
      "Epoch 482/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5907 - accuracy: 0.4680 - val_loss: 2.6114 - val_accuracy: 0.3351\n",
      "Epoch 483/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5934 - accuracy: 0.4672 - val_loss: 2.6057 - val_accuracy: 0.3389\n",
      "Epoch 484/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5863 - accuracy: 0.4672 - val_loss: 2.6105 - val_accuracy: 0.3373\n",
      "Epoch 485/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5987 - accuracy: 0.4623 - val_loss: 2.6112 - val_accuracy: 0.3376\n",
      "Epoch 486/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5989 - accuracy: 0.4599 - val_loss: 2.5949 - val_accuracy: 0.3412\n",
      "Epoch 487/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5858 - accuracy: 0.4569 - val_loss: 2.5882 - val_accuracy: 0.3360\n",
      "Epoch 488/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5981 - accuracy: 0.4624 - val_loss: 2.5700 - val_accuracy: 0.3380\n",
      "Epoch 489/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5961 - accuracy: 0.4619 - val_loss: 2.5714 - val_accuracy: 0.3341\n",
      "Epoch 490/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5966 - accuracy: 0.4576 - val_loss: 2.6098 - val_accuracy: 0.3318\n",
      "Epoch 491/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5929 - accuracy: 0.4609 - val_loss: 2.5836 - val_accuracy: 0.3402\n",
      "Epoch 492/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5933 - accuracy: 0.4653 - val_loss: 2.5567 - val_accuracy: 0.3421\n",
      "Epoch 493/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5896 - accuracy: 0.4576 - val_loss: 2.6071 - val_accuracy: 0.3312\n",
      "Epoch 494/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5899 - accuracy: 0.4609 - val_loss: 2.6173 - val_accuracy: 0.3354\n",
      "Epoch 495/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5918 - accuracy: 0.4599 - val_loss: 2.6250 - val_accuracy: 0.3328\n",
      "Epoch 496/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5888 - accuracy: 0.4613 - val_loss: 2.5920 - val_accuracy: 0.3363\n",
      "Epoch 497/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5992 - accuracy: 0.4579 - val_loss: 2.5879 - val_accuracy: 0.3425\n",
      "Epoch 498/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5949 - accuracy: 0.4624 - val_loss: 2.6060 - val_accuracy: 0.3360\n",
      "Epoch 499/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5974 - accuracy: 0.4634 - val_loss: 2.5993 - val_accuracy: 0.3360\n",
      "Epoch 500/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5906 - accuracy: 0.4620 - val_loss: 2.5914 - val_accuracy: 0.3334\n",
      "Epoch 501/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5819 - accuracy: 0.4654 - val_loss: 2.6118 - val_accuracy: 0.3347\n",
      "Epoch 502/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5963 - accuracy: 0.4624 - val_loss: 2.6032 - val_accuracy: 0.3354\n",
      "Epoch 503/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5936 - accuracy: 0.4591 - val_loss: 2.5551 - val_accuracy: 0.3386\n",
      "Epoch 504/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5986 - accuracy: 0.4600 - val_loss: 2.5845 - val_accuracy: 0.3344\n",
      "Epoch 505/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5854 - accuracy: 0.4638 - val_loss: 2.6587 - val_accuracy: 0.3270\n",
      "Epoch 506/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5933 - accuracy: 0.4607 - val_loss: 2.6134 - val_accuracy: 0.3363\n",
      "Epoch 507/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5955 - accuracy: 0.4614 - val_loss: 2.6332 - val_accuracy: 0.3318\n",
      "Epoch 508/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5821 - accuracy: 0.4656 - val_loss: 2.6341 - val_accuracy: 0.3276\n",
      "Epoch 509/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5926 - accuracy: 0.4620 - val_loss: 2.6273 - val_accuracy: 0.3280\n",
      "Epoch 510/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5840 - accuracy: 0.4677 - val_loss: 2.5956 - val_accuracy: 0.3357\n",
      "Epoch 511/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5902 - accuracy: 0.4691 - val_loss: 2.6409 - val_accuracy: 0.3315\n",
      "Epoch 512/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5919 - accuracy: 0.4648 - val_loss: 2.6408 - val_accuracy: 0.3344\n",
      "Epoch 513/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5937 - accuracy: 0.4600 - val_loss: 2.6233 - val_accuracy: 0.3357\n",
      "Epoch 514/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5920 - accuracy: 0.4629 - val_loss: 2.5977 - val_accuracy: 0.3354\n",
      "Epoch 515/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5897 - accuracy: 0.4633 - val_loss: 2.6859 - val_accuracy: 0.3189\n",
      "Epoch 516/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5900 - accuracy: 0.4597 - val_loss: 2.5802 - val_accuracy: 0.3347\n",
      "Epoch 517/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5888 - accuracy: 0.4576 - val_loss: 2.6707 - val_accuracy: 0.3241\n",
      "Epoch 518/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5887 - accuracy: 0.4611 - val_loss: 2.5970 - val_accuracy: 0.3380\n",
      "Epoch 519/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5904 - accuracy: 0.4617 - val_loss: 2.6070 - val_accuracy: 0.3383\n",
      "Epoch 520/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5916 - accuracy: 0.4649 - val_loss: 2.5657 - val_accuracy: 0.3367\n",
      "Epoch 521/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5888 - accuracy: 0.4634 - val_loss: 2.5821 - val_accuracy: 0.3412\n",
      "Epoch 522/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5853 - accuracy: 0.4635 - val_loss: 2.6292 - val_accuracy: 0.3367\n",
      "Epoch 523/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5776 - accuracy: 0.4689 - val_loss: 2.6152 - val_accuracy: 0.3315\n",
      "Epoch 524/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5869 - accuracy: 0.4601 - val_loss: 2.6002 - val_accuracy: 0.3363\n",
      "Epoch 525/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5879 - accuracy: 0.4639 - val_loss: 2.6099 - val_accuracy: 0.3354\n",
      "Epoch 526/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5840 - accuracy: 0.4665 - val_loss: 2.6021 - val_accuracy: 0.3334\n",
      "Epoch 527/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5873 - accuracy: 0.4622 - val_loss: 2.6672 - val_accuracy: 0.3267\n",
      "Epoch 528/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5832 - accuracy: 0.4657 - val_loss: 2.6279 - val_accuracy: 0.3328\n",
      "Epoch 529/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5862 - accuracy: 0.4667 - val_loss: 2.6358 - val_accuracy: 0.3351\n",
      "Epoch 530/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5898 - accuracy: 0.4638 - val_loss: 2.6463 - val_accuracy: 0.3312\n",
      "Epoch 531/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5914 - accuracy: 0.4664 - val_loss: 2.6701 - val_accuracy: 0.3328\n",
      "Epoch 532/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5898 - accuracy: 0.4664 - val_loss: 2.6737 - val_accuracy: 0.3302\n",
      "Epoch 533/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5872 - accuracy: 0.4612 - val_loss: 2.6286 - val_accuracy: 0.3312\n",
      "Epoch 534/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5807 - accuracy: 0.4635 - val_loss: 2.6012 - val_accuracy: 0.3373\n",
      "Epoch 535/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5894 - accuracy: 0.4629 - val_loss: 2.6387 - val_accuracy: 0.3331\n",
      "Epoch 536/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5779 - accuracy: 0.4662 - val_loss: 2.6158 - val_accuracy: 0.3309\n",
      "Epoch 537/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5744 - accuracy: 0.4682 - val_loss: 2.6588 - val_accuracy: 0.3328\n",
      "Epoch 538/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5912 - accuracy: 0.4603 - val_loss: 2.6809 - val_accuracy: 0.3360\n",
      "Epoch 539/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5814 - accuracy: 0.4629 - val_loss: 2.6031 - val_accuracy: 0.3354\n",
      "Epoch 540/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5739 - accuracy: 0.4648 - val_loss: 2.6476 - val_accuracy: 0.3344\n",
      "Epoch 541/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5833 - accuracy: 0.4654 - val_loss: 2.6005 - val_accuracy: 0.3315\n",
      "Epoch 542/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5909 - accuracy: 0.4647 - val_loss: 2.6495 - val_accuracy: 0.3351\n",
      "Epoch 543/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5797 - accuracy: 0.4659 - val_loss: 2.6717 - val_accuracy: 0.3293\n",
      "Epoch 544/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5806 - accuracy: 0.4673 - val_loss: 2.6284 - val_accuracy: 0.3302\n",
      "Epoch 545/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5789 - accuracy: 0.4663 - val_loss: 2.6547 - val_accuracy: 0.3341\n",
      "Epoch 546/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5793 - accuracy: 0.4674 - val_loss: 2.6930 - val_accuracy: 0.3351\n",
      "Epoch 547/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5824 - accuracy: 0.4682 - val_loss: 2.6640 - val_accuracy: 0.3334\n",
      "Epoch 548/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5835 - accuracy: 0.4614 - val_loss: 2.6375 - val_accuracy: 0.3325\n",
      "Epoch 549/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5883 - accuracy: 0.4605 - val_loss: 2.6960 - val_accuracy: 0.3334\n",
      "Epoch 550/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5922 - accuracy: 0.4608 - val_loss: 2.6258 - val_accuracy: 0.3338\n",
      "Epoch 551/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5775 - accuracy: 0.4622 - val_loss: 2.6491 - val_accuracy: 0.3325\n",
      "Epoch 552/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5718 - accuracy: 0.4657 - val_loss: 2.6674 - val_accuracy: 0.3325\n",
      "Epoch 553/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5825 - accuracy: 0.4666 - val_loss: 2.6344 - val_accuracy: 0.3367\n",
      "Epoch 554/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5798 - accuracy: 0.4640 - val_loss: 2.6438 - val_accuracy: 0.3418\n",
      "Epoch 555/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5824 - accuracy: 0.4682 - val_loss: 2.6956 - val_accuracy: 0.3254\n",
      "Epoch 556/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5796 - accuracy: 0.4661 - val_loss: 2.6592 - val_accuracy: 0.3338\n",
      "Epoch 557/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5825 - accuracy: 0.4626 - val_loss: 2.6331 - val_accuracy: 0.3318\n",
      "Epoch 558/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5731 - accuracy: 0.4673 - val_loss: 2.6467 - val_accuracy: 0.3293\n",
      "Epoch 559/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5677 - accuracy: 0.4689 - val_loss: 2.6842 - val_accuracy: 0.3251\n",
      "Epoch 560/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5863 - accuracy: 0.4642 - val_loss: 2.6581 - val_accuracy: 0.3383\n",
      "Epoch 561/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5764 - accuracy: 0.4676 - val_loss: 2.6264 - val_accuracy: 0.3415\n",
      "Epoch 562/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5870 - accuracy: 0.4605 - val_loss: 2.6184 - val_accuracy: 0.3399\n",
      "Epoch 563/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5729 - accuracy: 0.4664 - val_loss: 2.6604 - val_accuracy: 0.3389\n",
      "Epoch 564/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5804 - accuracy: 0.4661 - val_loss: 2.6561 - val_accuracy: 0.3286\n",
      "Epoch 565/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5763 - accuracy: 0.4599 - val_loss: 2.6760 - val_accuracy: 0.3257\n",
      "Epoch 566/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5835 - accuracy: 0.4612 - val_loss: 2.7008 - val_accuracy: 0.3309\n",
      "Epoch 567/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5776 - accuracy: 0.4692 - val_loss: 2.6838 - val_accuracy: 0.3376\n",
      "Epoch 568/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5735 - accuracy: 0.4675 - val_loss: 2.6647 - val_accuracy: 0.3383\n",
      "Epoch 569/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5700 - accuracy: 0.4681 - val_loss: 2.6718 - val_accuracy: 0.3338\n",
      "Epoch 570/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5740 - accuracy: 0.4668 - val_loss: 2.6669 - val_accuracy: 0.3351\n",
      "Epoch 571/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5767 - accuracy: 0.4644 - val_loss: 2.6883 - val_accuracy: 0.3322\n",
      "Epoch 572/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5800 - accuracy: 0.4653 - val_loss: 2.6655 - val_accuracy: 0.3283\n",
      "Epoch 573/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5750 - accuracy: 0.4647 - val_loss: 2.6833 - val_accuracy: 0.3367\n",
      "Epoch 574/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5722 - accuracy: 0.4667 - val_loss: 2.6643 - val_accuracy: 0.3383\n",
      "Epoch 575/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5854 - accuracy: 0.4670 - val_loss: 2.6595 - val_accuracy: 0.3344\n",
      "Epoch 576/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5773 - accuracy: 0.4663 - val_loss: 2.6705 - val_accuracy: 0.3299\n",
      "Epoch 577/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5744 - accuracy: 0.4688 - val_loss: 2.6850 - val_accuracy: 0.3289\n",
      "Epoch 578/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5750 - accuracy: 0.4678 - val_loss: 2.7009 - val_accuracy: 0.3318\n",
      "Epoch 579/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5722 - accuracy: 0.4697 - val_loss: 2.6625 - val_accuracy: 0.3254\n",
      "Epoch 580/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5794 - accuracy: 0.4628 - val_loss: 2.6879 - val_accuracy: 0.3286\n",
      "Epoch 581/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5774 - accuracy: 0.4651 - val_loss: 2.6070 - val_accuracy: 0.3399\n",
      "Epoch 582/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5754 - accuracy: 0.4689 - val_loss: 2.6623 - val_accuracy: 0.3380\n",
      "Epoch 583/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5774 - accuracy: 0.4626 - val_loss: 2.7055 - val_accuracy: 0.3318\n",
      "Epoch 584/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5807 - accuracy: 0.4647 - val_loss: 2.6477 - val_accuracy: 0.3296\n",
      "Epoch 585/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5684 - accuracy: 0.4682 - val_loss: 2.6633 - val_accuracy: 0.3296\n",
      "Epoch 586/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5810 - accuracy: 0.4644 - val_loss: 2.6637 - val_accuracy: 0.3315\n",
      "Epoch 587/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5769 - accuracy: 0.4657 - val_loss: 2.6043 - val_accuracy: 0.3389\n",
      "Epoch 588/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5734 - accuracy: 0.4655 - val_loss: 2.6835 - val_accuracy: 0.3367\n",
      "Epoch 589/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5870 - accuracy: 0.4670 - val_loss: 2.6568 - val_accuracy: 0.3344\n",
      "Epoch 590/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5688 - accuracy: 0.4686 - val_loss: 2.6810 - val_accuracy: 0.3328\n",
      "Epoch 591/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5779 - accuracy: 0.4643 - val_loss: 2.6495 - val_accuracy: 0.3341\n",
      "Epoch 592/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5714 - accuracy: 0.4700 - val_loss: 2.6637 - val_accuracy: 0.3360\n",
      "Epoch 593/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5733 - accuracy: 0.4699 - val_loss: 2.6911 - val_accuracy: 0.3267\n",
      "Epoch 594/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5736 - accuracy: 0.4672 - val_loss: 2.7110 - val_accuracy: 0.3286\n",
      "Epoch 595/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5717 - accuracy: 0.4700 - val_loss: 2.6836 - val_accuracy: 0.3289\n",
      "Epoch 596/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5713 - accuracy: 0.4650 - val_loss: 2.6602 - val_accuracy: 0.3318\n",
      "Epoch 597/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5745 - accuracy: 0.4669 - val_loss: 2.6835 - val_accuracy: 0.3283\n",
      "Epoch 598/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5716 - accuracy: 0.4657 - val_loss: 2.6689 - val_accuracy: 0.3338\n",
      "Epoch 599/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5797 - accuracy: 0.4648 - val_loss: 2.6600 - val_accuracy: 0.3293\n",
      "Epoch 600/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5768 - accuracy: 0.4626 - val_loss: 2.6905 - val_accuracy: 0.3241\n",
      "Epoch 601/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5817 - accuracy: 0.4680 - val_loss: 2.6718 - val_accuracy: 0.3334\n",
      "Epoch 602/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5731 - accuracy: 0.4637 - val_loss: 2.6831 - val_accuracy: 0.3318\n",
      "Epoch 603/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5732 - accuracy: 0.4643 - val_loss: 2.6522 - val_accuracy: 0.3360\n",
      "Epoch 604/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5611 - accuracy: 0.4657 - val_loss: 2.6601 - val_accuracy: 0.3315\n",
      "Epoch 605/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5722 - accuracy: 0.4660 - val_loss: 2.7000 - val_accuracy: 0.3296\n",
      "Epoch 606/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5652 - accuracy: 0.4717 - val_loss: 2.6843 - val_accuracy: 0.3370\n",
      "Epoch 607/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5697 - accuracy: 0.4712 - val_loss: 2.6610 - val_accuracy: 0.3334\n",
      "Epoch 608/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5766 - accuracy: 0.4657 - val_loss: 2.7288 - val_accuracy: 0.3299\n",
      "Epoch 609/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5665 - accuracy: 0.4673 - val_loss: 2.6741 - val_accuracy: 0.3293\n",
      "Epoch 610/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5616 - accuracy: 0.4710 - val_loss: 2.7204 - val_accuracy: 0.3405\n",
      "Epoch 611/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5815 - accuracy: 0.4703 - val_loss: 2.6869 - val_accuracy: 0.3380\n",
      "Epoch 612/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5684 - accuracy: 0.4658 - val_loss: 2.6403 - val_accuracy: 0.3389\n",
      "Epoch 613/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5627 - accuracy: 0.4667 - val_loss: 2.6679 - val_accuracy: 0.3312\n",
      "Epoch 614/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5605 - accuracy: 0.4743 - val_loss: 2.7110 - val_accuracy: 0.3322\n",
      "Epoch 615/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5618 - accuracy: 0.4702 - val_loss: 2.7553 - val_accuracy: 0.3322\n",
      "Epoch 616/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5693 - accuracy: 0.4645 - val_loss: 2.6899 - val_accuracy: 0.3344\n",
      "Epoch 617/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5678 - accuracy: 0.4670 - val_loss: 2.7194 - val_accuracy: 0.3360\n",
      "Epoch 618/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5603 - accuracy: 0.4695 - val_loss: 2.7530 - val_accuracy: 0.3309\n",
      "Epoch 619/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5624 - accuracy: 0.4690 - val_loss: 2.7238 - val_accuracy: 0.3241\n",
      "Epoch 620/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5681 - accuracy: 0.4712 - val_loss: 2.7044 - val_accuracy: 0.3341\n",
      "Epoch 621/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5648 - accuracy: 0.4740 - val_loss: 2.6871 - val_accuracy: 0.3257\n",
      "Epoch 622/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5690 - accuracy: 0.4706 - val_loss: 2.6852 - val_accuracy: 0.3276\n",
      "Epoch 623/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5653 - accuracy: 0.4689 - val_loss: 2.6577 - val_accuracy: 0.3322\n",
      "Epoch 624/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5593 - accuracy: 0.4695 - val_loss: 2.6952 - val_accuracy: 0.3328\n",
      "Epoch 625/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5723 - accuracy: 0.4657 - val_loss: 2.6596 - val_accuracy: 0.3318\n",
      "Epoch 626/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5675 - accuracy: 0.4616 - val_loss: 2.6459 - val_accuracy: 0.3380\n",
      "Epoch 627/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5745 - accuracy: 0.4658 - val_loss: 2.7685 - val_accuracy: 0.3299\n",
      "Epoch 628/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5587 - accuracy: 0.4713 - val_loss: 2.7106 - val_accuracy: 0.3238\n",
      "Epoch 629/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5680 - accuracy: 0.4716 - val_loss: 2.7123 - val_accuracy: 0.3373\n",
      "Epoch 630/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5679 - accuracy: 0.4679 - val_loss: 2.7401 - val_accuracy: 0.3325\n",
      "Epoch 631/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5694 - accuracy: 0.4676 - val_loss: 2.7277 - val_accuracy: 0.3264\n",
      "Epoch 632/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5643 - accuracy: 0.4647 - val_loss: 2.6604 - val_accuracy: 0.3334\n",
      "Epoch 633/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5622 - accuracy: 0.4682 - val_loss: 2.7029 - val_accuracy: 0.3315\n",
      "Epoch 634/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5594 - accuracy: 0.4739 - val_loss: 2.6593 - val_accuracy: 0.3315\n",
      "Epoch 635/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5569 - accuracy: 0.4726 - val_loss: 2.7217 - val_accuracy: 0.3302\n",
      "Epoch 636/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5596 - accuracy: 0.4670 - val_loss: 2.6898 - val_accuracy: 0.3389\n",
      "Epoch 637/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5673 - accuracy: 0.4665 - val_loss: 2.7426 - val_accuracy: 0.3312\n",
      "Epoch 638/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5611 - accuracy: 0.4682 - val_loss: 2.7014 - val_accuracy: 0.3267\n",
      "Epoch 639/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5673 - accuracy: 0.4719 - val_loss: 2.7455 - val_accuracy: 0.3241\n",
      "Epoch 640/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5683 - accuracy: 0.4694 - val_loss: 2.7109 - val_accuracy: 0.3280\n",
      "Epoch 641/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5622 - accuracy: 0.4697 - val_loss: 2.7585 - val_accuracy: 0.3325\n",
      "Epoch 642/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5633 - accuracy: 0.4675 - val_loss: 2.7143 - val_accuracy: 0.3312\n",
      "Epoch 643/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5581 - accuracy: 0.4732 - val_loss: 2.7390 - val_accuracy: 0.3341\n",
      "Epoch 644/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5678 - accuracy: 0.4735 - val_loss: 2.7221 - val_accuracy: 0.3302\n",
      "Epoch 645/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5555 - accuracy: 0.4703 - val_loss: 2.7409 - val_accuracy: 0.3244\n",
      "Epoch 646/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5670 - accuracy: 0.4679 - val_loss: 2.7451 - val_accuracy: 0.3276\n",
      "Epoch 647/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5659 - accuracy: 0.4685 - val_loss: 2.6961 - val_accuracy: 0.3328\n",
      "Epoch 648/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5644 - accuracy: 0.4667 - val_loss: 2.6747 - val_accuracy: 0.3318\n",
      "Epoch 649/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5494 - accuracy: 0.4733 - val_loss: 2.7379 - val_accuracy: 0.3305\n",
      "Epoch 650/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5601 - accuracy: 0.4707 - val_loss: 2.7292 - val_accuracy: 0.3315\n",
      "Epoch 651/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5617 - accuracy: 0.4697 - val_loss: 2.7266 - val_accuracy: 0.3386\n",
      "Epoch 652/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5657 - accuracy: 0.4711 - val_loss: 2.7171 - val_accuracy: 0.3293\n",
      "Epoch 653/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5659 - accuracy: 0.4676 - val_loss: 2.6930 - val_accuracy: 0.3347\n",
      "Epoch 654/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5623 - accuracy: 0.4671 - val_loss: 2.7091 - val_accuracy: 0.3289\n",
      "Epoch 655/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5610 - accuracy: 0.4700 - val_loss: 2.7760 - val_accuracy: 0.3283\n",
      "Epoch 656/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5577 - accuracy: 0.4765 - val_loss: 2.6978 - val_accuracy: 0.3357\n",
      "Epoch 657/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5580 - accuracy: 0.4686 - val_loss: 2.7173 - val_accuracy: 0.3357\n",
      "Epoch 658/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5646 - accuracy: 0.4685 - val_loss: 2.7281 - val_accuracy: 0.3283\n",
      "Epoch 659/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5563 - accuracy: 0.4720 - val_loss: 2.7276 - val_accuracy: 0.3338\n",
      "Epoch 660/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5571 - accuracy: 0.4722 - val_loss: 2.7766 - val_accuracy: 0.3331\n",
      "Epoch 661/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5613 - accuracy: 0.4742 - val_loss: 2.6911 - val_accuracy: 0.3367\n",
      "Epoch 662/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5627 - accuracy: 0.4733 - val_loss: 2.7326 - val_accuracy: 0.3302\n",
      "Epoch 663/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5584 - accuracy: 0.4691 - val_loss: 2.7324 - val_accuracy: 0.3325\n",
      "Epoch 664/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5553 - accuracy: 0.4727 - val_loss: 2.7194 - val_accuracy: 0.3273\n",
      "Epoch 665/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5598 - accuracy: 0.4741 - val_loss: 2.7350 - val_accuracy: 0.3363\n",
      "Epoch 666/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5550 - accuracy: 0.4721 - val_loss: 2.6915 - val_accuracy: 0.3370\n",
      "Epoch 667/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5589 - accuracy: 0.4718 - val_loss: 2.7607 - val_accuracy: 0.3264\n",
      "Epoch 668/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5540 - accuracy: 0.4709 - val_loss: 2.7566 - val_accuracy: 0.3347\n",
      "Epoch 669/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5538 - accuracy: 0.4695 - val_loss: 2.7558 - val_accuracy: 0.3286\n",
      "Epoch 670/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5549 - accuracy: 0.4701 - val_loss: 2.7394 - val_accuracy: 0.3341\n",
      "Epoch 671/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5644 - accuracy: 0.4680 - val_loss: 2.7479 - val_accuracy: 0.3328\n",
      "Epoch 672/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5587 - accuracy: 0.4716 - val_loss: 2.7125 - val_accuracy: 0.3373\n",
      "Epoch 673/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5552 - accuracy: 0.4723 - val_loss: 2.7350 - val_accuracy: 0.3347\n",
      "Epoch 674/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5609 - accuracy: 0.4748 - val_loss: 2.7279 - val_accuracy: 0.3286\n",
      "Epoch 675/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5707 - accuracy: 0.4663 - val_loss: 2.6672 - val_accuracy: 0.3376\n",
      "Epoch 676/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5619 - accuracy: 0.4719 - val_loss: 2.6931 - val_accuracy: 0.3357\n",
      "Epoch 677/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5602 - accuracy: 0.4735 - val_loss: 2.7172 - val_accuracy: 0.3367\n",
      "Epoch 678/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5678 - accuracy: 0.4670 - val_loss: 2.6717 - val_accuracy: 0.3305\n",
      "Epoch 679/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5667 - accuracy: 0.4696 - val_loss: 2.7120 - val_accuracy: 0.3299\n",
      "Epoch 680/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5730 - accuracy: 0.4668 - val_loss: 2.7317 - val_accuracy: 0.3202\n",
      "Epoch 681/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5520 - accuracy: 0.4717 - val_loss: 2.6717 - val_accuracy: 0.3354\n",
      "Epoch 682/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5501 - accuracy: 0.4731 - val_loss: 2.7550 - val_accuracy: 0.3318\n",
      "Epoch 683/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5469 - accuracy: 0.4745 - val_loss: 2.7324 - val_accuracy: 0.3309\n",
      "Epoch 684/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5589 - accuracy: 0.4707 - val_loss: 2.7526 - val_accuracy: 0.3376\n",
      "Epoch 685/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5584 - accuracy: 0.4680 - val_loss: 2.7671 - val_accuracy: 0.3309\n",
      "Epoch 686/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5613 - accuracy: 0.4706 - val_loss: 2.7507 - val_accuracy: 0.3280\n",
      "Epoch 687/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5540 - accuracy: 0.4746 - val_loss: 2.7333 - val_accuracy: 0.3289\n",
      "Epoch 688/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5682 - accuracy: 0.4711 - val_loss: 2.7416 - val_accuracy: 0.3254\n",
      "Epoch 689/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5417 - accuracy: 0.4713 - val_loss: 2.7462 - val_accuracy: 0.3344\n",
      "Epoch 690/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5587 - accuracy: 0.4732 - val_loss: 2.7427 - val_accuracy: 0.3283\n",
      "Epoch 691/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5563 - accuracy: 0.4710 - val_loss: 2.7013 - val_accuracy: 0.3351\n",
      "Epoch 692/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5546 - accuracy: 0.4723 - val_loss: 2.7428 - val_accuracy: 0.3318\n",
      "Epoch 693/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5580 - accuracy: 0.4719 - val_loss: 2.7434 - val_accuracy: 0.3254\n",
      "Epoch 694/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5498 - accuracy: 0.4756 - val_loss: 2.6927 - val_accuracy: 0.3312\n",
      "Epoch 695/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5498 - accuracy: 0.4790 - val_loss: 2.7350 - val_accuracy: 0.3357\n",
      "Epoch 696/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5499 - accuracy: 0.4784 - val_loss: 2.7469 - val_accuracy: 0.3218\n",
      "Epoch 697/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5520 - accuracy: 0.4733 - val_loss: 2.7283 - val_accuracy: 0.3238\n",
      "Epoch 698/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5656 - accuracy: 0.4718 - val_loss: 2.7122 - val_accuracy: 0.3244\n",
      "Epoch 699/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5503 - accuracy: 0.4746 - val_loss: 2.7625 - val_accuracy: 0.3283\n",
      "Epoch 700/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5534 - accuracy: 0.4712 - val_loss: 2.7581 - val_accuracy: 0.3280\n",
      "Epoch 701/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5635 - accuracy: 0.4713 - val_loss: 2.7199 - val_accuracy: 0.3305\n",
      "Epoch 702/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5486 - accuracy: 0.4747 - val_loss: 2.7261 - val_accuracy: 0.3299\n",
      "Epoch 703/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5510 - accuracy: 0.4727 - val_loss: 2.7451 - val_accuracy: 0.3325\n",
      "Epoch 704/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5550 - accuracy: 0.4726 - val_loss: 2.7543 - val_accuracy: 0.3389\n",
      "Epoch 705/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5680 - accuracy: 0.4704 - val_loss: 2.7132 - val_accuracy: 0.3360\n",
      "Epoch 706/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5628 - accuracy: 0.4657 - val_loss: 2.7272 - val_accuracy: 0.3309\n",
      "Epoch 707/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5536 - accuracy: 0.4732 - val_loss: 2.7606 - val_accuracy: 0.3257\n",
      "Epoch 708/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5540 - accuracy: 0.4703 - val_loss: 2.7401 - val_accuracy: 0.3283\n",
      "Epoch 709/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5638 - accuracy: 0.4654 - val_loss: 2.6910 - val_accuracy: 0.3206\n",
      "Epoch 710/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5415 - accuracy: 0.4804 - val_loss: 2.7530 - val_accuracy: 0.3293\n",
      "Epoch 711/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5516 - accuracy: 0.4743 - val_loss: 2.6941 - val_accuracy: 0.3267\n",
      "Epoch 712/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5514 - accuracy: 0.4707 - val_loss: 2.6987 - val_accuracy: 0.3309\n",
      "Epoch 713/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5553 - accuracy: 0.4733 - val_loss: 2.7484 - val_accuracy: 0.3305\n",
      "Epoch 714/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5523 - accuracy: 0.4760 - val_loss: 2.7354 - val_accuracy: 0.3305\n",
      "Epoch 715/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5440 - accuracy: 0.4778 - val_loss: 2.7308 - val_accuracy: 0.3360\n",
      "Epoch 716/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5517 - accuracy: 0.4729 - val_loss: 2.7327 - val_accuracy: 0.3254\n",
      "Epoch 717/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5576 - accuracy: 0.4698 - val_loss: 2.7195 - val_accuracy: 0.3315\n",
      "Epoch 718/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5514 - accuracy: 0.4775 - val_loss: 2.7269 - val_accuracy: 0.3235\n",
      "Epoch 719/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5495 - accuracy: 0.4748 - val_loss: 2.7360 - val_accuracy: 0.3189\n",
      "Epoch 720/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5504 - accuracy: 0.4784 - val_loss: 2.7247 - val_accuracy: 0.3193\n",
      "Epoch 721/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5467 - accuracy: 0.4721 - val_loss: 2.7587 - val_accuracy: 0.3338\n",
      "Epoch 722/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5416 - accuracy: 0.4739 - val_loss: 2.7594 - val_accuracy: 0.3286\n",
      "Epoch 723/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5584 - accuracy: 0.4730 - val_loss: 2.7905 - val_accuracy: 0.3212\n",
      "Epoch 724/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5537 - accuracy: 0.4768 - val_loss: 2.7476 - val_accuracy: 0.3328\n",
      "Epoch 725/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5484 - accuracy: 0.4783 - val_loss: 2.7546 - val_accuracy: 0.3273\n",
      "Epoch 726/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5530 - accuracy: 0.4697 - val_loss: 2.7591 - val_accuracy: 0.3264\n",
      "Epoch 727/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5453 - accuracy: 0.4754 - val_loss: 2.7483 - val_accuracy: 0.3273\n",
      "Epoch 728/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5466 - accuracy: 0.4767 - val_loss: 2.8206 - val_accuracy: 0.3247\n",
      "Epoch 729/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5546 - accuracy: 0.4729 - val_loss: 2.7339 - val_accuracy: 0.3299\n",
      "Epoch 730/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5484 - accuracy: 0.4712 - val_loss: 2.7711 - val_accuracy: 0.3334\n",
      "Epoch 731/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5561 - accuracy: 0.4727 - val_loss: 2.7487 - val_accuracy: 0.3235\n",
      "Epoch 732/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5571 - accuracy: 0.4720 - val_loss: 2.8003 - val_accuracy: 0.3202\n",
      "Epoch 733/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5515 - accuracy: 0.4755 - val_loss: 2.7256 - val_accuracy: 0.3280\n",
      "Epoch 734/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5500 - accuracy: 0.4683 - val_loss: 2.7589 - val_accuracy: 0.3302\n",
      "Epoch 735/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5448 - accuracy: 0.4709 - val_loss: 2.7518 - val_accuracy: 0.3325\n",
      "Epoch 736/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5523 - accuracy: 0.4708 - val_loss: 2.7382 - val_accuracy: 0.3305\n",
      "Epoch 737/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4740 - val_loss: 2.7472 - val_accuracy: 0.3347\n",
      "Epoch 738/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5516 - accuracy: 0.4766 - val_loss: 2.6919 - val_accuracy: 0.3280\n",
      "Epoch 739/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5422 - accuracy: 0.4761 - val_loss: 2.7720 - val_accuracy: 0.3225\n",
      "Epoch 740/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5471 - accuracy: 0.4759 - val_loss: 2.7414 - val_accuracy: 0.3296\n",
      "Epoch 741/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5463 - accuracy: 0.4782 - val_loss: 2.7219 - val_accuracy: 0.3318\n",
      "Epoch 742/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5419 - accuracy: 0.4733 - val_loss: 2.7521 - val_accuracy: 0.3344\n",
      "Epoch 743/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5509 - accuracy: 0.4734 - val_loss: 2.6980 - val_accuracy: 0.3302\n",
      "Epoch 744/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5488 - accuracy: 0.4722 - val_loss: 2.7578 - val_accuracy: 0.3299\n",
      "Epoch 745/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5524 - accuracy: 0.4778 - val_loss: 2.7375 - val_accuracy: 0.3286\n",
      "Epoch 746/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5368 - accuracy: 0.4803 - val_loss: 2.7739 - val_accuracy: 0.3302\n",
      "Epoch 747/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5464 - accuracy: 0.4754 - val_loss: 2.7508 - val_accuracy: 0.3296\n",
      "Epoch 748/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5473 - accuracy: 0.4729 - val_loss: 2.7175 - val_accuracy: 0.3296\n",
      "Epoch 749/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5581 - accuracy: 0.4714 - val_loss: 2.7048 - val_accuracy: 0.3238\n",
      "Epoch 750/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5421 - accuracy: 0.4738 - val_loss: 2.7993 - val_accuracy: 0.3280\n",
      "Epoch 751/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5468 - accuracy: 0.4727 - val_loss: 2.7391 - val_accuracy: 0.3328\n",
      "Epoch 752/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5498 - accuracy: 0.4710 - val_loss: 2.7732 - val_accuracy: 0.3309\n",
      "Epoch 753/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5497 - accuracy: 0.4702 - val_loss: 2.7715 - val_accuracy: 0.3312\n",
      "Epoch 754/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5496 - accuracy: 0.4725 - val_loss: 2.7221 - val_accuracy: 0.3354\n",
      "Epoch 755/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5475 - accuracy: 0.4753 - val_loss: 2.7498 - val_accuracy: 0.3312\n",
      "Epoch 756/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5525 - accuracy: 0.4742 - val_loss: 2.7950 - val_accuracy: 0.3312\n",
      "Epoch 757/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5553 - accuracy: 0.4746 - val_loss: 2.7527 - val_accuracy: 0.3302\n",
      "Epoch 758/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5492 - accuracy: 0.4728 - val_loss: 2.7397 - val_accuracy: 0.3376\n",
      "Epoch 759/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4753 - val_loss: 2.7629 - val_accuracy: 0.3331\n",
      "Epoch 760/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5380 - accuracy: 0.4797 - val_loss: 2.7787 - val_accuracy: 0.3331\n",
      "Epoch 761/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5509 - accuracy: 0.4742 - val_loss: 2.7129 - val_accuracy: 0.3312\n",
      "Epoch 762/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5404 - accuracy: 0.4772 - val_loss: 2.7830 - val_accuracy: 0.3231\n",
      "Epoch 763/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5399 - accuracy: 0.4794 - val_loss: 2.8037 - val_accuracy: 0.3331\n",
      "Epoch 764/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5467 - accuracy: 0.4725 - val_loss: 2.7884 - val_accuracy: 0.3315\n",
      "Epoch 765/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5480 - accuracy: 0.4775 - val_loss: 2.7418 - val_accuracy: 0.3305\n",
      "Epoch 766/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5475 - accuracy: 0.4769 - val_loss: 2.7766 - val_accuracy: 0.3251\n",
      "Epoch 767/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5434 - accuracy: 0.4763 - val_loss: 2.8475 - val_accuracy: 0.3276\n",
      "Epoch 768/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5304 - accuracy: 0.4782 - val_loss: 2.7437 - val_accuracy: 0.3299\n",
      "Epoch 769/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5379 - accuracy: 0.4783 - val_loss: 2.8103 - val_accuracy: 0.3260\n",
      "Epoch 770/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5546 - accuracy: 0.4761 - val_loss: 2.7872 - val_accuracy: 0.3302\n",
      "Epoch 771/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5450 - accuracy: 0.4714 - val_loss: 2.7707 - val_accuracy: 0.3286\n",
      "Epoch 772/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5374 - accuracy: 0.4776 - val_loss: 2.8462 - val_accuracy: 0.3318\n",
      "Epoch 773/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5351 - accuracy: 0.4769 - val_loss: 2.7473 - val_accuracy: 0.3280\n",
      "Epoch 774/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5535 - accuracy: 0.4699 - val_loss: 2.7682 - val_accuracy: 0.3341\n",
      "Epoch 775/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5513 - accuracy: 0.4756 - val_loss: 2.7903 - val_accuracy: 0.3305\n",
      "Epoch 776/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5558 - accuracy: 0.4755 - val_loss: 2.8056 - val_accuracy: 0.3286\n",
      "Epoch 777/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5507 - accuracy: 0.4746 - val_loss: 2.7669 - val_accuracy: 0.3354\n",
      "Epoch 778/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5466 - accuracy: 0.4761 - val_loss: 2.7544 - val_accuracy: 0.3360\n",
      "Epoch 779/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5432 - accuracy: 0.4752 - val_loss: 2.7339 - val_accuracy: 0.3199\n",
      "Epoch 780/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5429 - accuracy: 0.4785 - val_loss: 2.7902 - val_accuracy: 0.3189\n",
      "Epoch 781/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5426 - accuracy: 0.4738 - val_loss: 2.7208 - val_accuracy: 0.3286\n",
      "Epoch 782/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5461 - accuracy: 0.4758 - val_loss: 2.7610 - val_accuracy: 0.3276\n",
      "Epoch 783/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5382 - accuracy: 0.4768 - val_loss: 2.7449 - val_accuracy: 0.3267\n",
      "Epoch 784/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5457 - accuracy: 0.4744 - val_loss: 2.8100 - val_accuracy: 0.3354\n",
      "Epoch 785/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5323 - accuracy: 0.4766 - val_loss: 2.8003 - val_accuracy: 0.3293\n",
      "Epoch 786/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5524 - accuracy: 0.4692 - val_loss: 2.8190 - val_accuracy: 0.3286\n",
      "Epoch 787/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4751 - val_loss: 2.7706 - val_accuracy: 0.3302\n",
      "Epoch 788/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5440 - accuracy: 0.4723 - val_loss: 2.7866 - val_accuracy: 0.3235\n",
      "Epoch 789/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5388 - accuracy: 0.4823 - val_loss: 2.7690 - val_accuracy: 0.3309\n",
      "Epoch 790/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5349 - accuracy: 0.4769 - val_loss: 2.8127 - val_accuracy: 0.3160\n",
      "Epoch 791/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5374 - accuracy: 0.4817 - val_loss: 2.7819 - val_accuracy: 0.3305\n",
      "Epoch 792/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5431 - accuracy: 0.4775 - val_loss: 2.7966 - val_accuracy: 0.3325\n",
      "Epoch 793/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5422 - accuracy: 0.4740 - val_loss: 2.7973 - val_accuracy: 0.3231\n",
      "Epoch 794/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5537 - accuracy: 0.4710 - val_loss: 2.7457 - val_accuracy: 0.3270\n",
      "Epoch 795/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5519 - accuracy: 0.4727 - val_loss: 2.7688 - val_accuracy: 0.3315\n",
      "Epoch 796/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5526 - accuracy: 0.4747 - val_loss: 2.7675 - val_accuracy: 0.3254\n",
      "Epoch 797/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5415 - accuracy: 0.4743 - val_loss: 2.7405 - val_accuracy: 0.3334\n",
      "Epoch 798/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5417 - accuracy: 0.4698 - val_loss: 2.7636 - val_accuracy: 0.3270\n",
      "Epoch 799/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5403 - accuracy: 0.4762 - val_loss: 2.7900 - val_accuracy: 0.3302\n",
      "Epoch 800/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5410 - accuracy: 0.4748 - val_loss: 2.8129 - val_accuracy: 0.3257\n",
      "Epoch 801/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5463 - accuracy: 0.4744 - val_loss: 2.8073 - val_accuracy: 0.3154\n",
      "Epoch 802/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5337 - accuracy: 0.4811 - val_loss: 2.8025 - val_accuracy: 0.3289\n",
      "Epoch 803/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5451 - accuracy: 0.4778 - val_loss: 2.7238 - val_accuracy: 0.3280\n",
      "Epoch 804/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5479 - accuracy: 0.4727 - val_loss: 2.7690 - val_accuracy: 0.3373\n",
      "Epoch 805/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5444 - accuracy: 0.4732 - val_loss: 2.7511 - val_accuracy: 0.3363\n",
      "Epoch 806/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5445 - accuracy: 0.4781 - val_loss: 2.8122 - val_accuracy: 0.3106\n",
      "Epoch 807/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5389 - accuracy: 0.4778 - val_loss: 2.7326 - val_accuracy: 0.3273\n",
      "Epoch 808/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5322 - accuracy: 0.4748 - val_loss: 2.7985 - val_accuracy: 0.3347\n",
      "Epoch 809/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5438 - accuracy: 0.4732 - val_loss: 2.8115 - val_accuracy: 0.3218\n",
      "Epoch 810/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5541 - accuracy: 0.4691 - val_loss: 2.7360 - val_accuracy: 0.3293\n",
      "Epoch 811/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5404 - accuracy: 0.4770 - val_loss: 2.7233 - val_accuracy: 0.3299\n",
      "Epoch 812/1000\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 1.5339 - accuracy: 0.4809 - val_loss: 2.7550 - val_accuracy: 0.3276\n",
      "Epoch 813/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5423 - accuracy: 0.4730 - val_loss: 2.7697 - val_accuracy: 0.3196\n",
      "Epoch 814/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5310 - accuracy: 0.4807 - val_loss: 2.7601 - val_accuracy: 0.3341\n",
      "Epoch 815/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5377 - accuracy: 0.4759 - val_loss: 2.7970 - val_accuracy: 0.3264\n",
      "Epoch 816/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5428 - accuracy: 0.4739 - val_loss: 2.7912 - val_accuracy: 0.3299\n",
      "Epoch 817/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5404 - accuracy: 0.4753 - val_loss: 2.7787 - val_accuracy: 0.3293\n",
      "Epoch 818/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5577 - accuracy: 0.4730 - val_loss: 2.7972 - val_accuracy: 0.3235\n",
      "Epoch 819/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5506 - accuracy: 0.4758 - val_loss: 2.7310 - val_accuracy: 0.3206\n",
      "Epoch 820/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5466 - accuracy: 0.4700 - val_loss: 2.7628 - val_accuracy: 0.3267\n",
      "Epoch 821/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5371 - accuracy: 0.4778 - val_loss: 2.7841 - val_accuracy: 0.3315\n",
      "Epoch 822/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5529 - accuracy: 0.4719 - val_loss: 2.7975 - val_accuracy: 0.3299\n",
      "Epoch 823/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5360 - accuracy: 0.4779 - val_loss: 2.7924 - val_accuracy: 0.3270\n",
      "Epoch 824/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5407 - accuracy: 0.4751 - val_loss: 2.8279 - val_accuracy: 0.3218\n",
      "Epoch 825/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5409 - accuracy: 0.4803 - val_loss: 2.7324 - val_accuracy: 0.3305\n",
      "Epoch 826/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5416 - accuracy: 0.4756 - val_loss: 2.8268 - val_accuracy: 0.3193\n",
      "Epoch 827/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5413 - accuracy: 0.4740 - val_loss: 2.7910 - val_accuracy: 0.3228\n",
      "Epoch 828/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5404 - accuracy: 0.4778 - val_loss: 2.7887 - val_accuracy: 0.3315\n",
      "Epoch 829/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5346 - accuracy: 0.4781 - val_loss: 2.8185 - val_accuracy: 0.3264\n",
      "Epoch 830/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5275 - accuracy: 0.4789 - val_loss: 2.8544 - val_accuracy: 0.3218\n",
      "Epoch 831/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5282 - accuracy: 0.4840 - val_loss: 2.8360 - val_accuracy: 0.3215\n",
      "Epoch 832/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5332 - accuracy: 0.4785 - val_loss: 2.8673 - val_accuracy: 0.3273\n",
      "Epoch 833/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5380 - accuracy: 0.4800 - val_loss: 2.8193 - val_accuracy: 0.3254\n",
      "Epoch 834/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5306 - accuracy: 0.4791 - val_loss: 2.7957 - val_accuracy: 0.3254\n",
      "Epoch 835/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5350 - accuracy: 0.4764 - val_loss: 2.8830 - val_accuracy: 0.3173\n",
      "Epoch 836/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5337 - accuracy: 0.4723 - val_loss: 2.8215 - val_accuracy: 0.3299\n",
      "Epoch 837/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4752 - val_loss: 2.8330 - val_accuracy: 0.3264\n",
      "Epoch 838/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5444 - accuracy: 0.4817 - val_loss: 2.7866 - val_accuracy: 0.3273\n",
      "Epoch 839/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5293 - accuracy: 0.4797 - val_loss: 2.8428 - val_accuracy: 0.3273\n",
      "Epoch 840/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5265 - accuracy: 0.4843 - val_loss: 2.8254 - val_accuracy: 0.3283\n",
      "Epoch 841/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5299 - accuracy: 0.4765 - val_loss: 2.8093 - val_accuracy: 0.3283\n",
      "Epoch 842/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5280 - accuracy: 0.4755 - val_loss: 2.8506 - val_accuracy: 0.3289\n",
      "Epoch 843/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5321 - accuracy: 0.4782 - val_loss: 2.8480 - val_accuracy: 0.3264\n",
      "Epoch 844/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5320 - accuracy: 0.4821 - val_loss: 2.8606 - val_accuracy: 0.3225\n",
      "Epoch 845/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5410 - accuracy: 0.4748 - val_loss: 2.7571 - val_accuracy: 0.3354\n",
      "Epoch 846/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5378 - accuracy: 0.4774 - val_loss: 2.8455 - val_accuracy: 0.3280\n",
      "Epoch 847/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5410 - accuracy: 0.4787 - val_loss: 2.8113 - val_accuracy: 0.3196\n",
      "Epoch 848/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5300 - accuracy: 0.4782 - val_loss: 2.7862 - val_accuracy: 0.3235\n",
      "Epoch 849/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5387 - accuracy: 0.4756 - val_loss: 2.8399 - val_accuracy: 0.3202\n",
      "Epoch 850/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5349 - accuracy: 0.4744 - val_loss: 2.8417 - val_accuracy: 0.3260\n",
      "Epoch 851/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5435 - accuracy: 0.4754 - val_loss: 2.8944 - val_accuracy: 0.3257\n",
      "Epoch 852/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5366 - accuracy: 0.4744 - val_loss: 2.8338 - val_accuracy: 0.3231\n",
      "Epoch 853/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5385 - accuracy: 0.4747 - val_loss: 2.8230 - val_accuracy: 0.3270\n",
      "Epoch 854/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5263 - accuracy: 0.4835 - val_loss: 2.8622 - val_accuracy: 0.3183\n",
      "Epoch 855/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5534 - accuracy: 0.4728 - val_loss: 2.8104 - val_accuracy: 0.3267\n",
      "Epoch 856/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5378 - accuracy: 0.4747 - val_loss: 2.8100 - val_accuracy: 0.3241\n",
      "Epoch 857/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5311 - accuracy: 0.4775 - val_loss: 2.8374 - val_accuracy: 0.3215\n",
      "Epoch 858/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5395 - accuracy: 0.4801 - val_loss: 2.8031 - val_accuracy: 0.3315\n",
      "Epoch 859/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5418 - accuracy: 0.4818 - val_loss: 2.7607 - val_accuracy: 0.3312\n",
      "Epoch 860/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5366 - accuracy: 0.4811 - val_loss: 2.7493 - val_accuracy: 0.3325\n",
      "Epoch 861/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4773 - val_loss: 2.7616 - val_accuracy: 0.3276\n",
      "Epoch 862/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5310 - accuracy: 0.4745 - val_loss: 2.8303 - val_accuracy: 0.3238\n",
      "Epoch 863/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5372 - accuracy: 0.4758 - val_loss: 2.8234 - val_accuracy: 0.3206\n",
      "Epoch 864/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5283 - accuracy: 0.4760 - val_loss: 2.8458 - val_accuracy: 0.3251\n",
      "Epoch 865/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5350 - accuracy: 0.4788 - val_loss: 2.7846 - val_accuracy: 0.3312\n",
      "Epoch 866/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5287 - accuracy: 0.4790 - val_loss: 2.8459 - val_accuracy: 0.3299\n",
      "Epoch 867/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5366 - accuracy: 0.4781 - val_loss: 2.8814 - val_accuracy: 0.3228\n",
      "Epoch 868/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5310 - accuracy: 0.4779 - val_loss: 2.7868 - val_accuracy: 0.3296\n",
      "Epoch 869/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5308 - accuracy: 0.4785 - val_loss: 2.8114 - val_accuracy: 0.3267\n",
      "Epoch 870/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5320 - accuracy: 0.4805 - val_loss: 2.7849 - val_accuracy: 0.3264\n",
      "Epoch 871/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5376 - accuracy: 0.4764 - val_loss: 2.7603 - val_accuracy: 0.3286\n",
      "Epoch 872/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5327 - accuracy: 0.4762 - val_loss: 2.8308 - val_accuracy: 0.3264\n",
      "Epoch 873/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5362 - accuracy: 0.4729 - val_loss: 2.8153 - val_accuracy: 0.3305\n",
      "Epoch 874/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5412 - accuracy: 0.4760 - val_loss: 2.8279 - val_accuracy: 0.3273\n",
      "Epoch 875/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5351 - accuracy: 0.4759 - val_loss: 2.8120 - val_accuracy: 0.3241\n",
      "Epoch 876/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5419 - accuracy: 0.4734 - val_loss: 2.8117 - val_accuracy: 0.3247\n",
      "Epoch 877/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5335 - accuracy: 0.4788 - val_loss: 2.8243 - val_accuracy: 0.3244\n",
      "Epoch 878/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5292 - accuracy: 0.4804 - val_loss: 2.8418 - val_accuracy: 0.3241\n",
      "Epoch 879/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5334 - accuracy: 0.4821 - val_loss: 2.7598 - val_accuracy: 0.3276\n",
      "Epoch 880/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5304 - accuracy: 0.4792 - val_loss: 2.7701 - val_accuracy: 0.3309\n",
      "Epoch 881/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5408 - accuracy: 0.4784 - val_loss: 2.8240 - val_accuracy: 0.3244\n",
      "Epoch 882/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5299 - accuracy: 0.4782 - val_loss: 2.7957 - val_accuracy: 0.3231\n",
      "Epoch 883/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5295 - accuracy: 0.4798 - val_loss: 2.7922 - val_accuracy: 0.3280\n",
      "Epoch 884/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5288 - accuracy: 0.4775 - val_loss: 2.8849 - val_accuracy: 0.3247\n",
      "Epoch 885/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5409 - accuracy: 0.4790 - val_loss: 2.8210 - val_accuracy: 0.3289\n",
      "Epoch 886/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5342 - accuracy: 0.4761 - val_loss: 2.8592 - val_accuracy: 0.3260\n",
      "Epoch 887/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5331 - accuracy: 0.4788 - val_loss: 2.8212 - val_accuracy: 0.3260\n",
      "Epoch 888/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5310 - accuracy: 0.4744 - val_loss: 2.8641 - val_accuracy: 0.3186\n",
      "Epoch 889/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5321 - accuracy: 0.4774 - val_loss: 2.7903 - val_accuracy: 0.3354\n",
      "Epoch 890/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5297 - accuracy: 0.4764 - val_loss: 2.8259 - val_accuracy: 0.3283\n",
      "Epoch 891/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5290 - accuracy: 0.4830 - val_loss: 2.7894 - val_accuracy: 0.3267\n",
      "Epoch 892/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5342 - accuracy: 0.4786 - val_loss: 2.8069 - val_accuracy: 0.3199\n",
      "Epoch 893/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5271 - accuracy: 0.4803 - val_loss: 2.7811 - val_accuracy: 0.3247\n",
      "Epoch 894/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5374 - accuracy: 0.4809 - val_loss: 2.8310 - val_accuracy: 0.3186\n",
      "Epoch 895/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5313 - accuracy: 0.4714 - val_loss: 2.8395 - val_accuracy: 0.3251\n",
      "Epoch 896/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5288 - accuracy: 0.4812 - val_loss: 2.8224 - val_accuracy: 0.3254\n",
      "Epoch 897/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5244 - accuracy: 0.4827 - val_loss: 2.8403 - val_accuracy: 0.3241\n",
      "Epoch 898/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5313 - accuracy: 0.4797 - val_loss: 2.8384 - val_accuracy: 0.3247\n",
      "Epoch 899/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5212 - accuracy: 0.4818 - val_loss: 2.8254 - val_accuracy: 0.3338\n",
      "Epoch 900/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5262 - accuracy: 0.4795 - val_loss: 2.9072 - val_accuracy: 0.3206\n",
      "Epoch 901/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5300 - accuracy: 0.4796 - val_loss: 2.8252 - val_accuracy: 0.3238\n",
      "Epoch 902/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5318 - accuracy: 0.4769 - val_loss: 2.8550 - val_accuracy: 0.3241\n",
      "Epoch 903/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5261 - accuracy: 0.4802 - val_loss: 2.8584 - val_accuracy: 0.3231\n",
      "Epoch 904/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5299 - accuracy: 0.4797 - val_loss: 2.8738 - val_accuracy: 0.3189\n",
      "Epoch 905/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5268 - accuracy: 0.4781 - val_loss: 2.8421 - val_accuracy: 0.3138\n",
      "Epoch 906/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5322 - accuracy: 0.4803 - val_loss: 2.9089 - val_accuracy: 0.3267\n",
      "Epoch 907/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5257 - accuracy: 0.4809 - val_loss: 2.8623 - val_accuracy: 0.3276\n",
      "Epoch 908/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5357 - accuracy: 0.4738 - val_loss: 2.8752 - val_accuracy: 0.3309\n",
      "Epoch 909/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5236 - accuracy: 0.4786 - val_loss: 2.8138 - val_accuracy: 0.3357\n",
      "Epoch 910/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5352 - accuracy: 0.4749 - val_loss: 2.8615 - val_accuracy: 0.3318\n",
      "Epoch 911/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5294 - accuracy: 0.4812 - val_loss: 2.8533 - val_accuracy: 0.3260\n",
      "Epoch 912/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5307 - accuracy: 0.4804 - val_loss: 2.8433 - val_accuracy: 0.3376\n",
      "Epoch 913/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5340 - accuracy: 0.4770 - val_loss: 2.8414 - val_accuracy: 0.3264\n",
      "Epoch 914/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5312 - accuracy: 0.4780 - val_loss: 2.8008 - val_accuracy: 0.3338\n",
      "Epoch 915/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5242 - accuracy: 0.4847 - val_loss: 2.8347 - val_accuracy: 0.3293\n",
      "Epoch 916/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5203 - accuracy: 0.4794 - val_loss: 2.8602 - val_accuracy: 0.3331\n",
      "Epoch 917/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5390 - accuracy: 0.4764 - val_loss: 2.7754 - val_accuracy: 0.3354\n",
      "Epoch 918/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5303 - accuracy: 0.4771 - val_loss: 2.8169 - val_accuracy: 0.3238\n",
      "Epoch 919/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5308 - accuracy: 0.4780 - val_loss: 2.7997 - val_accuracy: 0.3289\n",
      "Epoch 920/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5245 - accuracy: 0.4832 - val_loss: 2.8160 - val_accuracy: 0.3309\n",
      "Epoch 921/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5311 - accuracy: 0.4752 - val_loss: 2.8502 - val_accuracy: 0.3247\n",
      "Epoch 922/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5346 - accuracy: 0.4754 - val_loss: 2.8762 - val_accuracy: 0.3218\n",
      "Epoch 923/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5261 - accuracy: 0.4763 - val_loss: 2.8260 - val_accuracy: 0.3251\n",
      "Epoch 924/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5253 - accuracy: 0.4819 - val_loss: 2.8055 - val_accuracy: 0.3363\n",
      "Epoch 925/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5232 - accuracy: 0.4812 - val_loss: 2.8613 - val_accuracy: 0.3309\n",
      "Epoch 926/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5363 - accuracy: 0.4768 - val_loss: 2.7997 - val_accuracy: 0.3270\n",
      "Epoch 927/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5327 - accuracy: 0.4784 - val_loss: 2.8524 - val_accuracy: 0.3241\n",
      "Epoch 928/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5300 - accuracy: 0.4769 - val_loss: 2.8289 - val_accuracy: 0.3293\n",
      "Epoch 929/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5239 - accuracy: 0.4847 - val_loss: 2.8302 - val_accuracy: 0.3370\n",
      "Epoch 930/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5277 - accuracy: 0.4836 - val_loss: 2.8147 - val_accuracy: 0.3260\n",
      "Epoch 931/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5245 - accuracy: 0.4795 - val_loss: 2.8385 - val_accuracy: 0.3315\n",
      "Epoch 932/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5292 - accuracy: 0.4776 - val_loss: 2.8238 - val_accuracy: 0.3267\n",
      "Epoch 933/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5274 - accuracy: 0.4820 - val_loss: 2.8219 - val_accuracy: 0.3309\n",
      "Epoch 934/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5166 - accuracy: 0.4801 - val_loss: 2.8896 - val_accuracy: 0.3296\n",
      "Epoch 935/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5291 - accuracy: 0.4804 - val_loss: 2.8934 - val_accuracy: 0.3344\n",
      "Epoch 936/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5359 - accuracy: 0.4752 - val_loss: 2.8365 - val_accuracy: 0.3309\n",
      "Epoch 937/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5249 - accuracy: 0.4783 - val_loss: 2.8428 - val_accuracy: 0.3299\n",
      "Epoch 938/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5247 - accuracy: 0.4813 - val_loss: 2.8383 - val_accuracy: 0.3231\n",
      "Epoch 939/1000\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 1.5204 - accuracy: 0.4807 - val_loss: 2.8477 - val_accuracy: 0.3341\n",
      "Epoch 940/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5191 - accuracy: 0.4840 - val_loss: 2.8387 - val_accuracy: 0.3322\n",
      "Epoch 941/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5291 - accuracy: 0.4800 - val_loss: 2.8528 - val_accuracy: 0.3238\n",
      "Epoch 942/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5194 - accuracy: 0.4819 - val_loss: 2.9031 - val_accuracy: 0.3244\n",
      "Epoch 943/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5287 - accuracy: 0.4751 - val_loss: 2.8343 - val_accuracy: 0.3267\n",
      "Epoch 944/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5200 - accuracy: 0.4812 - val_loss: 2.8489 - val_accuracy: 0.3293\n",
      "Epoch 945/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5234 - accuracy: 0.4783 - val_loss: 2.8478 - val_accuracy: 0.3257\n",
      "Epoch 946/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5233 - accuracy: 0.4842 - val_loss: 2.8346 - val_accuracy: 0.3276\n",
      "Epoch 947/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5292 - accuracy: 0.4777 - val_loss: 2.8680 - val_accuracy: 0.3309\n",
      "Epoch 948/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5334 - accuracy: 0.4764 - val_loss: 2.8568 - val_accuracy: 0.3241\n",
      "Epoch 949/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5233 - accuracy: 0.4796 - val_loss: 2.8520 - val_accuracy: 0.3193\n",
      "Epoch 950/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5260 - accuracy: 0.4812 - val_loss: 2.8280 - val_accuracy: 0.3318\n",
      "Epoch 951/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5279 - accuracy: 0.4761 - val_loss: 2.8867 - val_accuracy: 0.3286\n",
      "Epoch 952/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5201 - accuracy: 0.4852 - val_loss: 2.8518 - val_accuracy: 0.3325\n",
      "Epoch 953/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5278 - accuracy: 0.4773 - val_loss: 2.8288 - val_accuracy: 0.3222\n",
      "Epoch 954/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5172 - accuracy: 0.4811 - val_loss: 2.8691 - val_accuracy: 0.3276\n",
      "Epoch 955/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5212 - accuracy: 0.4813 - val_loss: 2.8594 - val_accuracy: 0.3235\n",
      "Epoch 956/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5219 - accuracy: 0.4783 - val_loss: 2.8087 - val_accuracy: 0.3186\n",
      "Epoch 957/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5295 - accuracy: 0.4786 - val_loss: 2.8551 - val_accuracy: 0.3228\n",
      "Epoch 958/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5208 - accuracy: 0.4832 - val_loss: 2.8525 - val_accuracy: 0.3218\n",
      "Epoch 959/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5208 - accuracy: 0.4824 - val_loss: 2.8308 - val_accuracy: 0.3264\n",
      "Epoch 960/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5305 - accuracy: 0.4789 - val_loss: 2.8769 - val_accuracy: 0.3141\n",
      "Epoch 961/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5265 - accuracy: 0.4792 - val_loss: 2.8357 - val_accuracy: 0.3244\n",
      "Epoch 962/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5330 - accuracy: 0.4749 - val_loss: 2.7990 - val_accuracy: 0.3264\n",
      "Epoch 963/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5309 - accuracy: 0.4769 - val_loss: 2.8362 - val_accuracy: 0.3186\n",
      "Epoch 964/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5140 - accuracy: 0.4867 - val_loss: 2.8555 - val_accuracy: 0.3228\n",
      "Epoch 965/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5240 - accuracy: 0.4792 - val_loss: 2.8547 - val_accuracy: 0.3302\n",
      "Epoch 966/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5303 - accuracy: 0.4749 - val_loss: 2.8392 - val_accuracy: 0.3283\n",
      "Epoch 967/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5307 - accuracy: 0.4799 - val_loss: 2.8481 - val_accuracy: 0.3293\n",
      "Epoch 968/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5148 - accuracy: 0.4847 - val_loss: 2.8552 - val_accuracy: 0.3257\n",
      "Epoch 969/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5187 - accuracy: 0.4871 - val_loss: 2.9067 - val_accuracy: 0.3270\n",
      "Epoch 970/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5158 - accuracy: 0.4820 - val_loss: 2.8443 - val_accuracy: 0.3286\n",
      "Epoch 971/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5290 - accuracy: 0.4777 - val_loss: 2.8494 - val_accuracy: 0.3231\n",
      "Epoch 972/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5256 - accuracy: 0.4834 - val_loss: 2.8210 - val_accuracy: 0.3170\n",
      "Epoch 973/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5310 - accuracy: 0.4781 - val_loss: 2.9313 - val_accuracy: 0.3209\n",
      "Epoch 974/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5177 - accuracy: 0.4860 - val_loss: 2.7826 - val_accuracy: 0.3228\n",
      "Epoch 975/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5219 - accuracy: 0.4841 - val_loss: 2.8776 - val_accuracy: 0.3322\n",
      "Epoch 976/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5175 - accuracy: 0.4824 - val_loss: 2.8873 - val_accuracy: 0.3173\n",
      "Epoch 977/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5170 - accuracy: 0.4848 - val_loss: 2.8897 - val_accuracy: 0.3334\n",
      "Epoch 978/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5180 - accuracy: 0.4848 - val_loss: 2.8434 - val_accuracy: 0.3276\n",
      "Epoch 979/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5292 - accuracy: 0.4819 - val_loss: 2.8258 - val_accuracy: 0.3276\n",
      "Epoch 980/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5192 - accuracy: 0.4824 - val_loss: 2.8515 - val_accuracy: 0.3254\n",
      "Epoch 981/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5088 - accuracy: 0.4816 - val_loss: 2.9220 - val_accuracy: 0.3225\n",
      "Epoch 982/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5246 - accuracy: 0.4794 - val_loss: 2.8980 - val_accuracy: 0.3209\n",
      "Epoch 983/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5299 - accuracy: 0.4766 - val_loss: 2.8414 - val_accuracy: 0.3247\n",
      "Epoch 984/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5306 - accuracy: 0.4798 - val_loss: 2.8104 - val_accuracy: 0.3338\n",
      "Epoch 985/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5218 - accuracy: 0.4776 - val_loss: 2.8299 - val_accuracy: 0.3318\n",
      "Epoch 986/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5161 - accuracy: 0.4796 - val_loss: 2.8966 - val_accuracy: 0.3235\n",
      "Epoch 987/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5298 - accuracy: 0.4766 - val_loss: 2.8651 - val_accuracy: 0.3241\n",
      "Epoch 988/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5186 - accuracy: 0.4824 - val_loss: 2.8510 - val_accuracy: 0.3228\n",
      "Epoch 989/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5208 - accuracy: 0.4863 - val_loss: 2.8820 - val_accuracy: 0.3254\n",
      "Epoch 990/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5274 - accuracy: 0.4785 - val_loss: 2.8843 - val_accuracy: 0.3254\n",
      "Epoch 991/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5268 - accuracy: 0.4799 - val_loss: 2.8907 - val_accuracy: 0.3238\n",
      "Epoch 992/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5231 - accuracy: 0.4798 - val_loss: 2.8812 - val_accuracy: 0.3289\n",
      "Epoch 993/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5213 - accuracy: 0.4851 - val_loss: 2.8710 - val_accuracy: 0.3270\n",
      "Epoch 994/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5228 - accuracy: 0.4808 - val_loss: 2.8981 - val_accuracy: 0.3247\n",
      "Epoch 995/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5221 - accuracy: 0.4774 - val_loss: 2.8524 - val_accuracy: 0.3199\n",
      "Epoch 996/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5175 - accuracy: 0.4823 - val_loss: 2.8063 - val_accuracy: 0.3244\n",
      "Epoch 997/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5281 - accuracy: 0.4814 - val_loss: 2.8732 - val_accuracy: 0.3215\n",
      "Epoch 998/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5168 - accuracy: 0.4837 - val_loss: 2.8375 - val_accuracy: 0.3209\n",
      "Epoch 999/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5184 - accuracy: 0.4796 - val_loss: 2.8391 - val_accuracy: 0.3257\n",
      "Epoch 1000/1000\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.5259 - accuracy: 0.4818 - val_loss: 2.8606 - val_accuracy: 0.3251\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_many_to_many_aug_complex = many_to_many_model_aug_complex.fit(x_aug_train_tensor, y_aug_train_tensor, \n",
    "                                              epochs=1000,  # Adjust the number of epochs based on training performance\n",
    "                                              batch_size=16,  # Batch size\n",
    "                                              validation_data=(x_aug_val_tensor, y_aug_val_tensor)  # Validation data\n",
    "                                               ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch for Validation Accuracy: 2 (Val Accuracy: 0.4036726951599121)\n",
      "Best Epoch for Training Accuracy: 969 (Train Accuracy: 0.48711445927619934)\n",
      "Best Epoch for Training Loss: 981 (Train Loss: 1.508829116821289)\n",
      "Best Epoch for Validation Loss: 26 (Val Loss: 2.134901523590088)\n",
      "\n",
      "Overall Best Performance Metrics:\n",
      "Maximum Validation Accuracy: 0.4036726951599121\n",
      "Maximum Training Accuracy: 0.48711445927619934\n",
      "Minimum Training Loss: 1.508829116821289\n",
      "Minimum Validation Loss: 2.134901523590088\n"
     ]
    }
   ],
   "source": [
    "print_metrics(history_many_to_many_aug_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_history(history_many_to_many_aug_complex, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file = \"many_to_many_LSTM_complex_aug_model.h5\"  \n",
    "many_to_many_model_aug_complex.save(model_file)\n",
    "import pickle\n",
    "\n",
    "# Save the training history\n",
    "history_file = \"many_to_many_LSTM_complex_aug_model_history_bs16.pkl\"\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history_many_to_many_aug_complex.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "/tmp/tfhub_modules/22bffebf9723377261c6cd19440f9601d0ec68d6.lock.tmpeed7096edc09413a99f24b4a8ed170c4; Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2100aee8586e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Pretrained Word2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/Wiki-words-250/2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected a string, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   is_hub_module_v1 = tf.io.gfile.exists(\n\u001b[1;32m     95\u001b[0m       native_module.get_module_proto_path(module_path))\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \"\"\"\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     return resolver.atomic_download(handle, download, module_dir,\n\u001b[0;32m---> 82\u001b[0;31m                                     self._lock_file_timeout_sec())\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lock_file_timeout_sec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    382\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         tf_utils.atomic_write_string_to_file(lock_file, lock_contents,\n\u001b[0;32m--> 384\u001b[0;31m                                              overwrite=False)\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Must test condition again, since another process could have created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# the module and deleted the old lock file since last test.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow_hub/tf_utils.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[0;34m(filename, contents, overwrite)\u001b[0m\n\u001b[1;32m     63\u001b[0m                    tf.compat.as_bytes(uuid.uuid4().hex))\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m\"\"\"Writes file_content to the file. Appends to the end of the file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cds-language/lang101/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_prewrite_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                                            \"File isn't open for writing\")\n\u001b[1;32m     87\u001b[0m       self._writable_file = _pywrap_file_io.WritableFile(\n\u001b[0;32m---> 88\u001b[0;31m           compat.path_to_bytes(self.__name), compat.as_bytes(self.__mode))\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /tmp/tfhub_modules/22bffebf9723377261c6cd19440f9601d0ec68d6.lock.tmpeed7096edc09413a99f24b4a8ed170c4; Permission denied"
     ]
    }
   ],
   "source": [
    "def get_word2vec_enc(moves):\n",
    "    \"\"\"\n",
    "    get word2vec value for each move in sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    encoded_moves = []\n",
    "    for move in moves:\n",
    "        tokens = review.split(\" \")\n",
    "        word2vec_embedding = embed(tokens)\n",
    "        encoded_reviews.append(word2vec_embedding)\n",
    "    return encoded_reviews\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    encode text value to numeric value\n",
    "    \"\"\"\n",
    "    # encode words into word2vec\n",
    "    reviews = df['review'].tolist()\n",
    "    \n",
    "    encoded_reviews = get_word2vec_enc(reviews)\n",
    "    padded_encoded_reviews = get_padded_encoded_reviews(encoded_reviews)\n",
    "    # encoded sentiment\n",
    "    sentiments = df['sentiment'].tolist()\n",
    "    encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]\n",
    "    X = np.array(padded_encoded_reviews)\n",
    "    Y = np.array(encoded_sentiment)\n",
    "    return X, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input-output pairs\n",
    "xx, yy = make_x_y(4, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function to split the sequence data into input and target arrays taking into account the separate sequences (separate dance couples)\n",
    "def make_x_y_emb(ts, data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ts : int\n",
    "        Time steps for the sliding window.\n",
    "    data : list of lists\n",
    "        List of move sequences.\n",
    "\n",
    "    This function creates two arrays, x and y. \n",
    "    x is the input data and y is the target data.\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "    \n",
    "    for sequence in data:\n",
    "        sequence_length = len(sequence)\n",
    "        for offset in range(sequence_length - ts):\n",
    "            x.append(sequence[offset:offset + ts])\n",
    "            y.append(sequence[offset + ts])\n",
    "    x = ' '.join([str(element) for element in x])       \n",
    "    y = ' '.join([str(element) for element in y])  \n",
    "    return x, y\n",
    "\n",
    "\n",
    "# convert the input-output pairs to word embeddings\n",
    "def get_word2vec_enc(ts):\n",
    "    \"\"\"\n",
    "    get word2vec value for each move in sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    encoded_moves_xx = []\n",
    "    encoded_moves_yy = []\n",
    " \n",
    "    xx, yy = make_x_y_emb(ts, lists_extracted)\n",
    "    # Convert dance moves to a TensorFlow tensor\n",
    "    xx_tensor = tf.constant(xx, dtype=tf.string)\n",
    "    yy_tensor = tf.constant(yy, dtype=tf.string)\n",
    "    \n",
    "     # Embed each sequence\n",
    "    word2vec_embedding_xx = embed(xx_tensor)\n",
    "    word2vec_embedding_yy = embed(yy_tensor)\n",
    "    \n",
    "    # Convert embeddings to numpy arrays\n",
    "    encoded_moves_xx = np.array(word2vec_embedding_xx)\n",
    "    encoded_moves_yy = np.array(word2vec_embedding_yy)\n",
    "\n",
    "    return encoded_moves_xx, encoded_moves_yy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang101",
   "language": "python",
   "name": "lang101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
